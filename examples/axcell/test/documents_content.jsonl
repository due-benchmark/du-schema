{"name": "1312.6173v4", "contents": [{"tool_name": "djvu", "text": "Multilingual Distributed Representations without Word Alignment Karl Moritz Hermann and Phil Blunsom Department of Computer Science University of Oxford Oxford, OX1 3QD, UK {karl.moritz.hermann,phil.blunsom}@cs.ox.ac.uk Abstract Distributed representations of meaning are a natural way to encode covariance relationships between words and phrases in NLP. By overcoming data sparsity problems, as well as providing information about semantic relatedness which is not available in discrete representations, distributed representations have proven useful in many NLP tasks. Recent work has shown how compositional semantic representations can successfully be applied to a number of monolingual applica- tions such as sentiment analysis. At the same time, there has been some initial success in work on learning shared word-level representations across languages. We combine these two approaches by proposing a method for learning distributed representations in a multilingual setup. Our model learns to assign similar embed- dings to aligned sentences and dissimilar ones to sentence which are not aligned while not requiring word alignments. We show that our representations are seman- tically informative and apply them to a cross-lingual document classification task where we outperform the previous state of the art. Further, by employing parallel corpora of multiple language pairs we find that our model learns representations that capture semantic relationships across languages for which no parallel data was used. 1 Introduction Distributed representations of words are increasingly being used to achieve high levels of generalisa- tion within language modelling tasks. Successful applications of this approach include word-sense disambiguation, word similarity and synonym detection (e.g. [10, 27]). Subsequent work has also attempted to learn distributed semantics of larger structures, allowing us to apply distributed rep- resentation to tasks such as sentiment analysis or paraphrase detection (i.a. [1, 3, 12, 14, 21, 25]). At the same time a second strand of work has focused on transferring linguistic knowledge across languages, and particularly from English into low-resource languages, by means of distributed rep- resentations at the word level [13, 16]. Currently, work on compositional semantic representations focuses on monolingual data while the cross-lingual work focuses on word level representations only. However, it appears logical that these two strands of work should be combined as there exists a plethora of parallel corpora with aligned data at the sentence level or beyond which could be exploited in such work. Further, sentence aligned data provides a plausible concept of semantic similarity, which can be harder to define at the word level. Consider the case of alignment between a German compound noun (e.g. \u201cSchwerlastverkehr\u201d) and its English equivalent (\u201cheavy goods vehicle traffic\u201d). Semantic alignment at the phrase level here appears far more plausible than aligning individual tokens for semantic transfer. 1 a r X i v : 1 3 1 2 . 6 1 7 3 v 4 [ c s . C L ] 2 0 M a r 2 0 1 4 Using this rationale, and building on both work related to learning cross-lingual embeddings as well as to compositional semantic representations, we introduce a model that learns cross-lingual em- beddings at the sentence level. In the following section we will briefly discuss prior work in these two fields before going on to describe the bilingual training signal that we developed for learning multilingual compositional embeddings. Subsequently, we will describe our model in greater detail as well as its training procedure and experimental setup. Finally, we perform a number of evalua- tions and demonstrate that our training signal allows a very simple compositional vector model to outperform the state of the art on a task designed to evaluate its ability to transfer semantic informa- tion across languages. Unlike other work in this area, our model does not require word aligned data. In fact, while we evaluate our model on sentence aligned data in this paper, there is no theoretical requirement for this and technically our algorithm could also be applied to document-level parallel data or even comparable data only. 2 Models of Compositional Distributed Semantics In the case of representing individual words as vectors, the distributional account of semantics pro- vides a plausible explanation of what is encoded in a word vector. This follows the idea that the meaning of a word can be determined by \u201cthe company it keeps\u201d [11], that is by the context it ap- pears in. Such context can easily be encoded in vectors using collocational methods, and is also underlying other methods of learning word embeddings [7, 20]. For a number of important problems, semantic representations of individual words do not suffice, but instead a semantic representation of a larger structure\u2014e.g . a phrase or a sentence\u2014is required. This was highlighted in [10], who proposed a mechanism for modifying a word\u2019s representation based on its individual context. The distributional account of semantics can, due to sparsity, not be applied to such larger linguistic units. A notable exception perhaps is Baroni and Zamparelli [1], who learned distributional representations for adjective noun pairs using a collocational approach on a corpus of unprecedented size. The bigram representations learned from that corpus were subsequently used to learn lexicalised composition functions for the constituent words. Most alternative attempts to extract such higher-level semantic representations have focused on learning composition functions that represent the semantics of a larger structure as a function of the representations of its parts. [21] provides an evaluation of a number of simple composition func- tions applied to bigrams. Applied recursively, such approaches can then easily be reconciled with the co-occurrence based word level representations. There are a number of proposals motivating such recursive or deep composition models. Notably, [3] propose a tensor-based model for semantic composition and, similarly, [4] develop a framework for semantic composition by combining dis- tributional theory with pregroup grammars. The latter framework was empirically evaluated and supported by the results in [12]. More recently, various forms of recursive neural networks have successfully been used for semantic composition and related tasks such as sentiment analysis. Such models include recursive autoencoders [24], matrix-vector recursive neural networks [25], untied recursive neural networks [14] or convolutional networks [15]. 2.1 Multilingual Embeddings Much research has been devoted to the task of inducing distributed semantic representations for single languages. In particular English, with its large number of annotated resources, has enjoyed most attention. Recently, progress has been made at representation learning for languages with fewer available resources. Klementiev et al. [16] described a form of multitask learning on word-aligned parallel data to transfer embeddings from one language to another. Earlier work, Haghighi et al. [13], proposed a method for inducing cross-lingual lexica using monolingual feature representations and a small initial lexicon to bootstrap with. This approach has recently been extended by [18, 19], who developed a method for learning transformation matrices to convert semantic vectors of one language into those of another. Is was demonstrated that this approach can be applied to improve tasks related to machine translation. Their CBOW model is also worth noting for its similarities to the composition function used in this paper. Using a slightly different approach, [29], also learned bilingual embeddings for machine translation. It is important to note that, unlike our proposed system, all of these methods require word aligned parallel data for training. 2 Two recent workshop papers deserve mention in this respect. Both Lauly et al. [17] and Sarath Chan- dar et al. [23] propose methods for learning word embeddings by exploiting bilingual data, not unlike the method proposed in this paper. Instead of the noise-contrastive method developed in this paper, both groups of authors make use of autoencoders to encode monolingual representations and to support the bilingual transfer. So far almost all of this work has been focused on learning multilingual representations at the word level. As distributed representations of larger expressions have been shown to be highly useful for a number of tasks, it seems to be a natural next step to also attempt to induce these using cross-lingual data. This paper provides a first step in that direction. 3 Model Description Language acquisition in humans is widely seen as grounded in sensory-motor experience [22, 2]. Based on this idea, there have been some attempts at using multi-modal data for learning better vector representations of words (e.g . [26]). Such methods, however, are not easily scalable across languages or to large amounts of data for which no secondary or tertiary representation might exist. We abstract the underlying principle one step further and attempt to learn semantics from multi- lingual data. The idea is that, given enough parallel data, a shared representation would be forced to capture the common elements between sentences from different languages. What two parallel sentences have in common, of course, is the semantics of those two sentences. Using this data, we propose a novel method for learning vector representations at the word level and beyond. 3.1 Bilingual Signal Exploiting the semantic similarity of parallel sentences across languages, we can define a simple bilingual (and trivially multilingual) error function as follows: Given a compositional sentence model (CV M) MA , which maps a sentence to a vector, we can train a second CVM MB using a corpus CA,B of parallel data from the language pair A, B . For each pair of parallel sentences (a, b) \u2208 CA,B , we attempt to minimize Edist(a, b) =karoot \u2212 brootk 2 (1) where aroot is the vector representing sentence a and broot the vector representing sentence b. 3.2 The BICVM Model A CVM learns semantic representations of larger syntactic units given the semantic representations of their constituents. We assume individual words to be represented by vectors (x \u2208 Rd). Previous methods employ binary parse trees on the data (e.g . [14, 25]) and use weighted or multi- plicative composition functions. Under such a setup, where each node in the tree is terminal or has two children (p \u2192 c0 , c1 ), a binary composition function could take the following form: p=g(We[c0;c1]+be) (2) where [c0; c1] is the concatenation of the two child vectors, W e \u2208 Rd\u00d72d and be \u2208 Rd the encod- ing matrix and bias, respectively, and g an element-wise activation function such as the hyperbolic tangent. For the purposes of evaluation the bilingual signal proposed above, we simplify this com- position function by setting all weight matrices to the identity and all biases to zero. Thereby the CVM reduces to a simple additive composition function: aroot = |a| X i=0 ai (3) Of course, this is a very simplified CVM, as such a bag-of-words approach no longer accounts for word ordering and other effects which a more complex CVM might capture. However, for the purposes of this evaluation (and with the experimental evaluation in mind), such a simplistic composition function should be sufficient to evaluate the novel objective function proposed here. 3 Figure 1: Description of a bilingual model with parallel input sentences a and b. The objective function of this model is to minimize the distance between the sentence level encoding of the bi- text. Principally any composition function can be used to generate the compositional sentence level representations. The composition function is represented by the CVM boxes in the diagram above. Using this additive CVM we want to optimize the bilingual error signal defined above (Eq. 1). For the moment, assume that MA is a perfectly trained CVM such that aroot represents the semantics of the sentence a. Further, due to the use of parallel data, we know that a and b are semantically equivalent. Hence we transfer the semantic knowledge contained in MA onto MB , by learning \u03b8MB to minimize: Ebi (CA,B ) = X (a,b)\u2208CA,B Edist (a, b) (4) Of course, this objective function assumes a fully trained model which we do not have at this stage. While this can be a useful objective for transferring linguistic knowledge into low-resource lan- guages [16], this precondition is not helpful when there is no model to learn from in first place. We resolve this issue by jointly training both models MA and MB . Applying Ebi to parallel data ensures that both models learn a shared representation at the sentence level. As the parallel input sentences share the same meaning, it is reasonable to assume that mini- mizing Ebi will force the model to learn their semantic representation. Let \u03b8bi = \u03b8MA \u222a \u03b8MB . The joint objective function J (\u03b8bi ) thus becomes: J(\u03b8bi) = Ebi(CA,B) + \u03bb 2 k\u03b8bi k 2 (5) where \u03bbk\u03b8bi k1 is the L2 regularization term. It is apparent that this joint objective J (\u03b8bi ) is degenerate. The models could learn to reduce all embeddings and composition weights to zero and thereby minimize the objective function. We ad- dress this issue by employing a form of contrastive estimation penalizing small distances between non-parallel sentence pairs. For every pair of parallel sentences (a, b) we sample a number of ad- ditional sentences n \u2208 CB , which\u2014with high probability\u2014are not exact translations of a. This is comparable to the second term of the loss function of a large margin nearest neighbour classifier (see Eq. 12 in [28]): Enoise (a, b, n) = [1 + Edist (a, b) \u2212 Edist(a, n)]+ (6) 4 where [x]+ = max(x, 0) denotes the standard hinge loss. Thus, the final objective function to minimize for the BICVM model is: J(\u03b8bi) = X (a,b)\u2208CA,B k X i=1 Enoise (a, b, ni) !+ \u03bb 2 k\u03b8bi k 2 (7) 3.3 Model Learning Given the objective function as defined above, model learning can employ the same techniques as any monolingual CVM. In particular, as the objective function is differentiable, we can use standard gradient descent techniques such as stochastic gradient descent, L-BFGS or the adaptive gradient algorithm AdaGrad [8]. Within each monolingual CVM, we use backpropagation through structure after applying the joint error to each sentence level node. 4 Experiments 4.1 Data and Parameters All model weights were randomly initialised using a Gaussian distribution. There are a number of parameters that can influence model training. We selected the following values for simplicity and comparability with prior work. In future work we will investigate the effect of these parameters in greater detail. L2 regularization (1), step-size (0.1), number of noise elements (50), margin size (50), embedding dimensionality (d=40). The noise elements samples were randomly drawn from the corpus at training time, individually for each training sample and epoch. We use the Europarl corpus (v7)1 for training the bilingual model. The corpus was pre-processed using the set of tools provided by cdec2 [9] for tokenizing and lowercasing the data. Further, all empty sentences as well as their translations were removed from the corpus. We present results from two experiments. The BICVM model was trained on 500k sentence pairs of the English-German parallel section of the Europarl corpus. The BICVM+ model used this dataset in combination with another 500k parallel sentences from the English-French section of the corpus, resulting in 1 million English sentences, each paired up with either a German or a French sentence. Each language\u2019s vocabulary used distinct encodings to avoid potential overlap. The motivation behind B ICVM+ is to investigate whether we can learn better embeddings by intro- ducing additional data in a different language. This is similar to prior work in machine translation where English was used as a pivot for translation between low-resource languages [5]. We use the adaptive gradient method, AdaGrad [8], for updating the weights of our models, and ter- minate training after 50 iterations. Earlier experiments indicated that the BICVM model converges faster than the B ICVM+ model, but we report results on the same number of iterations for better comparability3 . 4.2 Cross-Lingual Document Classification We evaluate our model using the cross-lingual document classification (CLDC) task of Klementiev et al. [16]. This task involves learning language independent embeddings which are then used for document classification across the English-German language pair. For this, CLDC employs a par- ticular kind of supervision, namely using supervised training data in one language and evaluating without supervision in another. Thus, CLDC is a good task for establishing whether our learned representations are semantically useful across multiple languages. We follow the experimental setup described in [16], with the exception that we learn our embeddings using solely the Europarl data and only use the Reuters RCV1/RCV2 corpora during the classifier training and testing stages. Each document in the classification task is represented by the average 1 http://www.statmt.org/europarl/ 2 https://github.com/redpony/cdec 3 These numbers were updated following comments in the ICLR open review process. Results for other dimensionalities and our source code for our model are available at http://www.karlmoritz.com. 5 Model en\u2192de de\u2192en Majority Class 46.8 46.8 Glossed 65.1 68.6 MT 68.1 67.4 I-Matrix 77.6 71.1 BICVM 83.7 71.4 BICVM+ 86.2 76.9 Table 1: Classification accuracy for training on English and German with 1000 labeled examples. Cross-lingual compositional representations (B ICVM and BICVM+), cross-lingual representations using learned embeddings and an interaction matrix (I-Matrix) [16] translated (MT) and glossed (Glossed) words, and the majority class baseline. The MT and Glossed results are also taken from Klementiev et al. [16]. 100 200 500 1000 5000 10000 50 60 70 80 Training Documents (en) C l a s s i fi c a t i o n A c c u r a c y ( % ) 100 200 500 1000 5000 10000 50 60 70 80 Training Documents (de) BICVM BICVM+ I-Matrix MT Glossed Majority Class Figure 2: Classification accuracy for a number of models (see Table 1 for model descriptions). The left chart shows results for these models when trained on English data and evaluated on German data, the right chart vice versa. of the d-dimensional representations of all its sentences. We train the multiclass classifier using the same settings and implementation of the averaged perceptron classifier [6] as used in [16]. We ran the CLDC experiments both by training on English and testing on German documents and vice versa. Using the data splits provided by [16], we used varying training data sizes from 100 to 10,000 documents for training the multiclass classifier. The results of this task across training sizes are shown in Figure 2. Table 1 shows the results for training on 1,000 documents. Both models, BICVM and BICVM+ outperform all prior work on this task. Further, the BICVM+ model outperforms the BICVM model, indicating the usefulness of adding training data even from a separate language pair. 4.3 Visualization While the CLDC experiment focused on establishing the semantic content of the sentence level representations, we also want to briefly investigate the induced word embeddings. In particular the BICVM+ model is interesting for that purpose, as it allows us to evaluate our approach of using English as a pivot language in a multilingual setup. In Figure 3 we show the t-SNE projections for a number of English, French and German words. Of particular interest should be the right chart, which highlights bilingual embeddings between French and German words. Even though the model did not use any parallel French-German data during training, it still managed to learn semantic word-word similarity across these two languages. 6 Figure 3: The left scatter plot shows t-SNE projections for a weekdays in all three languages using the representations learned in the BICVM+ model. Even though the model did not use any parallel French-German data during training, it still learns semantic similarity between these two languages using English as a pivot. To highlight this, the right plot shows another set of words (months of the year) using only the German and French words. 5 Conclusions With this paper we have proposed a novel method for inducing cross-lingual distributed represen- tations for compositional semantics. Using a very simple method for semantic composition, we nevertheless managed to obtain state of the art results on the CLDC task, specifically designed to evaluate semantic transfer across languages. After extending our approach to include multilingual training data in the BICVM+ model, we were able to demonstrate that adding additional languages further improves the model. Furthermore, using some qualitative experiments and visualizations, we showed that our approach also allows us to learn semantically related embeddings across languages without any direct training data. Our approach provides great flexibility in training data and requires little to no annotation. Hav- ing demonstrated the successful training of semantic representations using sentence aligned data, a plausible next step is to attempt training using document-aligned data or even corpora of comparable documents. This may provide even greater possibilities for working with low-resource languages. In the same vein, the success of our pivoting experiments suggest further work. Unlike other pivot approaches, it is easy to extend our model to have multiple pivot languages. Thus some pivots could preserve different aspects such as case, gender etc., and overcome other issues related to having a single pivot language. As we have achieved the results in this paper with a relatively simple CV M, it would also be inter- esting to establish whether our objective function can be used in combination with more complex compositional vector models such as MV-RNN [25] or tensor-based approaches, to see whether these can further improve results on both mono- and multilingual tasks when used in conjunction with our cross-lingual objective function. Related to this, we will also apply our model to a wider variety of tasks including machine translation and multilingual information extraction. Acknowledgements The authors would like to thank Alexandre Klementiev and his co-authors for making their datasets and averaged perceptron implementation available, as well as answering a number of questions related to their work on this task. This work was supported by EPSRC grant EP/K036580/1 and a Xerox Foundation Award. 7 References [1] Marco Baroni and Roberto Zamparelli. Nouns are vectors, adjectives are matrices: Represent- ing adjective-noun constructions in semantic space. In Proceedings of EMNLP, 2010. [2] Paul Bloom. Precis of how children learn the meanings of words. Behavioral and Brain Sciences, 24:1095\u20131103, 2001. [3] Stephen Clark and Stephen Pulman. Combining symbolic and distributional models of mean- ing. In Proceedings of AAAI Spring Symposium on Quantum Interaction. AAAI Press, 2007. [4] Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen Clark. Mathematical foundations for a com- positional distributional model of meaning. Lambek Festschrift. Linguistic Analysis, 36:345\u2013 384, 2010. [5] Trevor Cohn and Mirella Lapata. Machine translation by triangulation: Making effective use of multi-parallel corpora. In Proceedings of ACL, pages 728\u2013735, Prague, Czech Republic, June 2007. Association for Computational Linguistics. [6] Michael Collins. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of ACL-EMNLP. Association for Computational Linguistics, 2002. doi: 10.3115/1118693.1118694. [7] Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of ICML, 2008. [8] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121\u20132159, July 2011. ISSN 1532-4435. [9] Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of ACL, 2010. [10] K. Erk and S. Pad \u0301o . A structured vector space model for word meaning in context. Proceedings of EMNLP, 2008. [11] J. R . Firth. A synopsis of linguistic theory 1930-55 . 1952-59:1\u201332, 1957. [12] Edward Grefenstette and Mehrnoosh Sadrzadeh. Experimental support for a categorical com- positional distributional model of meaning. In Proceedings of EMNLP, 2011. [13] Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. Learning bilingual lexicons from monolingual corpora. In Proceedings of ACL-HLT, 2008. [14] Karl Moritz Hermann and Phil Blunsom. The Role of Syntax in Vector Space Models of Compositional Semantics. In Proceedings of ACL, 2013. [15] Nal Kalchbrenner and Phil Blunsom. Recurrent convolutional neural networks for discourse compositionality. In Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, 2013. [16] Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. Inducing crosslingual distributed representations of words. In Proceedings of COLING, 2012. [17] Stanislas Lauly, Alex Boulanger, and Hugo Larochelle. Learning multilingual word represen- tations using a bag-of-words autoencoder. In Deep Learning Workshop at NIPS, 2013. [18] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. CoRR, 2013. [19] Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. Exploiting similarities among languages for machine translation. CoRR, 2013. [20] Tom \u0301a \u02c7s Mikolov, Martin Karafi\u0301at, Luk \u0301a \u02c7s Burget, Jan \u02c7Cernock \u0301y, and Sanjeev Khudanpur. Re- current neural network based language model. In Proceedings of INTERSPEECH, 2010. [21] Jeff Mitchell and Mirella Lapata. Vector-based models of semantic composition. In In Pro- ceedings of ACL, 2008. [22] D. Roy. Grounded spoken language acquisition: Experiments in word learning. IEEE Trans- actions on Multimedia, 5(2):197\u2013209, June 2003. ISSN 1520-9210. doi: 10.1109/TMM.2003. 811618. 8 [23] A P Sarath Chandar, M Khapra Mitesh, B Ravindran, Vikas Raykar, and Amrita Saha. Multi- lingual deep learning. In Deep Learning Workshop at NIPS, 2013. [24] Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Man- ning. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Pro- ceedings of EMNLP, 2011. [25] Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. Semantic compo- sitionality through recursive matrix-vector spaces. In Proceedings of EMNLP-CoNLL, pages 1201\u20131211, 2012. [26] Nitish Srivastava and Ruslan Salakhutdinov. Multimodal learning with deep boltzmann ma- chines. In Proceedings of NIPS. 2012. [27] P. D . Turney and P. Pantel. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37(1):141\u2013188, 2010. [28] Kilian Q. Weinberger and Lawrence K. Saul. Distance metric learning for large margin nearest neighbor classification. Journal of Machine Learning Research, 10:207\u2013244, June 2009. ISSN 1532-4435. [29] Will Y. Zou, Richard Socher, Daniel Cer, and Christopher D. Manning. Bilingual word em- beddings for phrase-based machine translation. In Proceedings of EMNLP, 2013. 9", "common_format": {"doc_id": "./1312.6173v4.hocr", "tokens": ["Multilingual", "Distributed", "Representations", "without", "Word", "Alignment", "Karl", "Moritz", "Hermann", "and", "Phil", "Blunsom", "Department", "of", "Computer", "Science", "University", "of", "Oxford", "Oxford,", "OX1", "3QD,", "UK", "{karl.moritz.hermann,phil.blunsom}@cs.ox.ac.uk", "Abstract", "Distributed", "representations", "of", "meaning", "are", "a", "natural", "way", "to", "encode", "covariance", "relationships", "between", "words", "and", "phrases", "in", "NLP.", "By", "overcoming", "data", "sparsity", "problems,", "as", "well", "as", "providing", "information", "about", "semantic", "relatedness", "which", "is", "not", "available", "in", "discrete", "representations,", "distributed", "representations", "have", "proven", "useful", "in", "many", "NLP", "tasks.", "Recent", "work", "has", "shown", "how", "compositional", "semantic", "representations", "can", "successfully", "be", "applied", "to", "a", "number", "of", "monolingual", "applica-", "tions", "such", "as", "sentiment", "analysis.", "At", "the", "same", "time,", "there", "has", "been", "some", "initial", "success", "in", "work", "on", "learning", "shared", "word-level", "representations", "across", "languages.", "We", "combine", "these", "two", "approaches", "by", "proposing", "a", "method", "for", "learning", "distributed", "representations", "in", "a", "multilingual", "setup.", "Our", "model", "learns", "to", "assign", "similar", "embed-", "dings", "to", "aligned", "sentences", "and", "dissimilar", "ones", "to", "sentence", "which", "are", "not", "aligned", "while", "not", "requiring", "word", "alignments.", "We", "show", "that", "our", "representations", "are", "seman-", "tically", "informative", "and", "apply", "them", "to", "a", "cross-lingual", "document", "classification", "task", "where", "we", "outperform", "the", "previous", "state", "of", "the", "art.", "Further,", "by", "employing", "parallel", "corpora", "of", "multiple", "language", "pairs", "we", "find", "that", "our", "model", "learns", "representations", "that", "capture", "semantic", "relationships", "across", "languages", "for", "which", "no", "parallel", "data", "was", "used.", "1", "Introduction", "Distributed", "representations", "of", "words", "are", "increasingly", "being", "used", "to", "achieve", "high", "levels", "of", "generalisa-", "tion", "within", "language", "modelling", "tasks.", "Successful", "applications", "of", "this", "approach", "include", "word-sense", "disambiguation,", "word", "similarity", "and", "synonym", "detection", "(e.g.", "[10,", "27]).", "Subsequent", "work", "has", "also", "attempted", "to", "learn", "distributed", "semantics", "of", "larger", "structures,", "allowing", "us", "to", "apply", "distributed", "rep-", "resentation", "to", "tasks", "such", "as", "sentiment", "analysis", "or", "paraphrase", "detection", "(i.a.", "[1,", "3,", "12,", "14,", "21,", "25]).", "At", "the", "same", "time", "a", "second", "strand", "of", "work", "has", "focused", "on", "transferring", "linguistic", "knowledge", "across", "languages,", "and", "particularly", "from", "English", "into", "low-resource", "languages,", "by", "means", "of", "distributed", "rep-", "resentations", "at", "the", "word", "level", "[13,", "16].", "Currently,", "work", "on", "compositional", "semantic", "representations", "focuses", "on", "monolingual", "data", "while", "the", "cross-lingual", "work", "focuses", "on", "word", "level", "representations", "only.", "However,", "it", "appears", "logical", "that", "these", "two", "strands", "of", "work", "should", "be", "combined", "as", "there", "exists", "a", "plethora", "of", "parallel", "corpora", "with", "aligned", "data", "at", "the", "sentence", "level", "or", "beyond", "which", "could", "be", "exploited", "in", "such", "work.", "Further,", "sentence", "aligned", "data", "provides", "a", "plausible", "concept", "of", "semantic", "similarity,", "which", "can", "be", "harder", "to", "define", "at", "the", "word", "level.", "Consider", "the", "case", "of", "alignment", "between", "a", "German", "compound", "noun", "(e.g.", "\u201cSchwerlastverkehr\u201d)", "and", "its", "English", "equivalent", "(\u201cheavy", "goods", "vehicle", "traffic\u201d).", "Semantic", "alignment", "at", "the", "phrase", "level", "here", "appears", "far", "more", "plausible", "than", "aligning", "individual", "tokens", "for", "semantic", "transfer.", "1", "a", "r", "X", "i", "v", ":", "1", "3", "1", "2", ".", "6", "1", "7", "3", "v", "4", "[", "c", "s", ".", "C", "L", "]", "2", "0", "M", "a", "r", "2", "0", "1", "4", "Using", "this", "rationale,", "and", "building", "on", "both", "work", "related", "to", "learning", "cross-lingual", "embeddings", "as", "well", "as", "to", "compositional", "semantic", "representations,", "we", "introduce", "a", "model", "that", "learns", "cross-lingual", "em-", "beddings", "at", "the", "sentence", "level.", "In", "the", "following", "section", "we", "will", "briefly", "discuss", "prior", "work", "in", "these", "two", "fields", "before", "going", "on", "to", "describe", "the", "bilingual", "training", "signal", "that", "we", "developed", "for", "learning", "multilingual", "compositional", "embeddings.", "Subsequently,", "we", "will", "describe", "our", "model", "in", "greater", "detail", "as", "well", "as", "its", "training", "procedure", "and", "experimental", "setup.", "Finally,", "we", "perform", "a", "number", "of", "evalua-", "tions", "and", "demonstrate", "that", "our", "training", "signal", "allows", "a", "very", "simple", "compositional", "vector", "model", "to", "outperform", "the", "state", "of", "the", "art", "on", "a", "task", "designed", "to", "evaluate", "its", "ability", "to", "transfer", "semantic", "informa-", "tion", "across", "languages.", "Unlike", "other", "work", "in", "this", "area,", "our", "model", "does", "not", "require", "word", "aligned", "data.", "In", "fact,", "while", "we", "evaluate", "our", "model", "on", "sentence", "aligned", "data", "in", "this", "paper,", "there", "is", "no", "theoretical", "requirement", "for", "this", "and", "technically", "our", "algorithm", "could", "also", "be", "applied", "to", "document-level", "parallel", "data", "or", "even", "comparable", "data", "only.", "2", "Models", "of", "Compositional", "Distributed", "Semantics", "In", "the", "case", "of", "representing", "individual", "words", "as", "vectors,", "the", "distributional", "account", "of", "semantics", "pro-", "vides", "a", "plausible", "explanation", "of", "what", "is", "encoded", "in", "a", "word", "vector.", "This", "follows", "the", "idea", "that", "the", "meaning", "of", "a", "word", "can", "be", "determined", "by", "\u201cthe", "company", "it", "keeps\u201d", "[11],", "that", "is", "by", "the", "context", "it", "ap-", "pears", "in.", "Such", "context", "can", "easily", "be", "encoded", "in", "vectors", "using", "collocational", "methods,", "and", "is", "also", "underlying", "other", "methods", "of", "learning", "word", "embeddings", "[7,", "20].", "For", "a", "number", "of", "important", "problems,", "semantic", "representations", "of", "individual", "words", "do", "not", "suffice,", "but", "instead", "a", "semantic", "representation", "of", "a", "larger", "structure\u2014e.g", ".", "a", "phrase", "or", "a", "sentence\u2014is", "required.", "This", "was", "highlighted", "in", "[10],", "who", "proposed", "a", "mechanism", "for", "modifying", "a", "word\u2019s", "representation", "based", "on", "its", "individual", "context.", "The", "distributional", "account", "of", "semantics", "can,", "due", "to", "sparsity,", "not", "be", "applied", "to", "such", "larger", "linguistic", "units.", "A", "notable", "exception", "perhaps", "is", "Baroni", "and", "Zamparelli", "[1],", "who", "learned", "distributional", "representations", "for", "adjective", "noun", "pairs", "using", "a", "collocational", "approach", "on", "a", "corpus", "of", "unprecedented", "size.", "The", "bigram", "representations", "learned", "from", "that", "corpus", "were", "subsequently", "used", "to", "learn", "lexicalised", "composition", "functions", "for", "the", "constituent", "words.", "Most", "alternative", "attempts", "to", "extract", "such", "higher-level", "semantic", "representations", "have", "focused", "on", "learning", "composition", "functions", "that", "represent", "the", "semantics", "of", "a", "larger", "structure", "as", "a", "function", "of", "the", "representations", "of", "its", "parts.", "[21]", "provides", "an", "evaluation", "of", "a", "number", "of", "simple", "composition", "func-", "tions", "applied", "to", "bigrams.", "Applied", "recursively,", "such", "approaches", "can", "then", "easily", "be", "reconciled", "with", "the", "co-occurrence", "based", "word", "level", "representations.", "There", "are", "a", "number", "of", "proposals", "motivating", "such", "recursive", "or", "deep", "composition", "models.", "Notably,", "[3]", "propose", "a", "tensor-based", "model", "for", "semantic", "composition", "and,", "similarly,", "[4]", "develop", "a", "framework", "for", "semantic", "composition", "by", "combining", "dis-", "tributional", "theory", "with", "pregroup", "grammars.", "The", "latter", "framework", "was", "empirically", "evaluated", "and", "supported", "by", "the", "results", "in", "[12].", "More", "recently,", "various", "forms", "of", "recursive", "neural", "networks", "have", "successfully", "been", "used", "for", "semantic", "composition", "and", "related", "tasks", "such", "as", "sentiment", "analysis.", "Such", "models", "include", "recursive", "autoencoders", "[24],", "matrix-vector", "recursive", "neural", "networks", "[25],", "untied", "recursive", "neural", "networks", "[14]", "or", "convolutional", "networks", "[15].", "2.1", "Multilingual", "Embeddings", "Much", "research", "has", "been", "devoted", "to", "the", "task", "of", "inducing", "distributed", "semantic", "representations", "for", "single", "languages.", "In", "particular", "English,", "with", "its", "large", "number", "of", "annotated", "resources,", "has", "enjoyed", "most", "attention.", "Recently,", "progress", "has", "been", "made", "at", "representation", "learning", "for", "languages", "with", "fewer", "available", "resources.", "Klementiev", "et", "al.", "[16]", "described", "a", "form", "of", "multitask", "learning", "on", "word-aligned", "parallel", "data", "to", "transfer", "embeddings", "from", "one", "language", "to", "another.", "Earlier", "work,", "Haghighi", "et", "al.", "[13],", "proposed", "a", "method", "for", "inducing", "cross-lingual", "lexica", "using", "monolingual", "feature", "representations", "and", "a", "small", "initial", "lexicon", "to", "bootstrap", "with.", "This", "approach", "has", "recently", "been", "extended", "by", "[18,", "19],", "who", "developed", "a", "method", "for", "learning", "transformation", "matrices", "to", "convert", "semantic", "vectors", "of", "one", "language", "into", "those", "of", "another.", "Is", "was", "demonstrated", "that", "this", "approach", "can", "be", "applied", "to", "improve", "tasks", "related", "to", "machine", "translation.", "Their", "CBOW", "model", "is", "also", "worth", "noting", "for", "its", "similarities", "to", "the", "composition", "function", "used", "in", "this", "paper.", "Using", "a", "slightly", "different", "approach,", "[29],", "also", "learned", "bilingual", "embeddings", "for", "machine", "translation.", "It", "is", "important", "to", "note", "that,", "unlike", "our", "proposed", "system,", "all", "of", "these", "methods", "require", "word", "aligned", "parallel", "data", "for", "training.", "2", "Two", "recent", "workshop", "papers", "deserve", "mention", "in", "this", "respect.", "Both", "Lauly", "et", "al.", "[17]", "and", "Sarath", "Chan-", "dar", "et", "al.", "[23]", "propose", "methods", "for", "learning", "word", "embeddings", "by", "exploiting", "bilingual", "data,", "not", "unlike", "the", "method", "proposed", "in", "this", "paper.", "Instead", "of", "the", "noise-contrastive", "method", "developed", "in", "this", "paper,", "both", "groups", "of", "authors", "make", "use", "of", "autoencoders", "to", "encode", "monolingual", "representations", "and", "to", "support", "the", "bilingual", "transfer.", "So", "far", "almost", "all", "of", "this", "work", "has", "been", "focused", "on", "learning", "multilingual", "representations", "at", "the", "word", "level.", "As", "distributed", "representations", "of", "larger", "expressions", "have", "been", "shown", "to", "be", "highly", "useful", "for", "a", "number", "of", "tasks,", "it", "seems", "to", "be", "a", "natural", "next", "step", "to", "also", "attempt", "to", "induce", "these", "using", "cross-lingual", "data.", "This", "paper", "provides", "a", "first", "step", "in", "that", "direction.", "3", "Model", "Description", "Language", "acquisition", "in", "humans", "is", "widely", "seen", "as", "grounded", "in", "sensory-motor", "experience", "[22,", "2].", "Based", "on", "this", "idea,", "there", "have", "been", "some", "attempts", "at", "using", "multi-modal", "data", "for", "learning", "better", "vector", "representations", "of", "words", "(e.g", ".", "[26]).", "Such", "methods,", "however,", "are", "not", "easily", "scalable", "across", "languages", "or", "to", "large", "amounts", "of", "data", "for", "which", "no", "secondary", "or", "tertiary", "representation", "might", "exist.", "We", "abstract", "the", "underlying", "principle", "one", "step", "further", "and", "attempt", "to", "learn", "semantics", "from", "multi-", "lingual", "data.", "The", "idea", "is", "that,", "given", "enough", "parallel", "data,", "a", "shared", "representation", "would", "be", "forced", "to", "capture", "the", "common", "elements", "between", "sentences", "from", "different", "languages.", "What", "two", "parallel", "sentences", "have", "in", "common,", "of", "course,", "is", "the", "semantics", "of", "those", "two", "sentences.", "Using", "this", "data,", "we", "propose", "a", "novel", "method", "for", "learning", "vector", "representations", "at", "the", "word", "level", "and", "beyond.", "3.1", "Bilingual", "Signal", "Exploiting", "the", "semantic", "similarity", "of", "parallel", "sentences", "across", "languages,", "we", "can", "define", "a", "simple", "bilingual", "(and", "trivially", "multilingual)", "error", "function", "as", "follows:", "Given", "a", "compositional", "sentence", "model", "(CV", "M)", "MA", ",", "which", "maps", "a", "sentence", "to", "a", "vector,", "we", "can", "train", "a", "second", "CVM", "MB", "using", "a", "corpus", "CA,B", "of", "parallel", "data", "from", "the", "language", "pair", "A,", "B", ".", "For", "each", "pair", "of", "parallel", "sentences", "(a,", "b)", "\u2208", "CA,B", ",", "we", "attempt", "to", "minimize", "Edist(a,", "b)", "=karoot", "\u2212", "brootk", "2", "(1)", "where", "aroot", "is", "the", "vector", "representing", "sentence", "a", "and", "broot", "the", "vector", "representing", "sentence", "b.", "3.2", "The", "BICVM", "Model", "A", "CVM", "learns", "semantic", "representations", "of", "larger", "syntactic", "units", "given", "the", "semantic", "representations", "of", "their", "constituents.", "We", "assume", "individual", "words", "to", "be", "represented", "by", "vectors", "(x", "\u2208", "Rd).", "Previous", "methods", "employ", "binary", "parse", "trees", "on", "the", "data", "(e.g", ".", "[14,", "25])", "and", "use", "weighted", "or", "multi-", "plicative", "composition", "functions.", "Under", "such", "a", "setup,", "where", "each", "node", "in", "the", "tree", "is", "terminal", "or", "has", "two", "children", "(p", "\u2192", "c0", ",", "c1", "),", "a", "binary", "composition", "function", "could", "take", "the", "following", "form:", "p=g(We[c0;c1]+be)", "(2)", "where", "[c0;", "c1]", "is", "the", "concatenation", "of", "the", "two", "child", "vectors,", "W", "e", "\u2208", "Rd\u00d72d", "and", "be", "\u2208", "Rd", "the", "encod-", "ing", "matrix", "and", "bias,", "respectively,", "and", "g", "an", "element-wise", "activation", "function", "such", "as", "the", "hyperbolic", "tangent.", "For", "the", "purposes", "of", "evaluation", "the", "bilingual", "signal", "proposed", "above,", "we", "simplify", "this", "com-", "position", "function", "by", "setting", "all", "weight", "matrices", "to", "the", "identity", "and", "all", "biases", "to", "zero.", "Thereby", "the", "CVM", "reduces", "to", "a", "simple", "additive", "composition", "function:", "aroot", "=", "|a|", "X", "i=0", "ai", "(3)", "Of", "course,", "this", "is", "a", "very", "simplified", "CVM,", "as", "such", "a", "bag-of-words", "approach", "no", "longer", "accounts", "for", "word", "ordering", "and", "other", "effects", "which", "a", "more", "complex", "CVM", "might", "capture.", "However,", "for", "the", "purposes", "of", "this", "evaluation", "(and", "with", "the", "experimental", "evaluation", "in", "mind),", "such", "a", "simplistic", "composition", "function", "should", "be", "sufficient", "to", "evaluate", "the", "novel", "objective", "function", "proposed", "here.", "3", "Figure", "1:", "Description", "of", "a", "bilingual", "model", "with", "parallel", "input", "sentences", "a", "and", "b.", "The", "objective", "function", "of", "this", "model", "is", "to", "minimize", "the", "distance", "between", "the", "sentence", "level", "encoding", "of", "the", "bi-", "text.", "Principally", "any", "composition", "function", "can", "be", "used", "to", "generate", "the", "compositional", "sentence", "level", "representations.", "The", "composition", "function", "is", "represented", "by", "the", "CVM", "boxes", "in", "the", "diagram", "above.", "Using", "this", "additive", "CVM", "we", "want", "to", "optimize", "the", "bilingual", "error", "signal", "defined", "above", "(Eq.", "1).", "For", "the", "moment,", "assume", "that", "MA", "is", "a", "perfectly", "trained", "CVM", "such", "that", "aroot", "represents", "the", "semantics", "of", "the", "sentence", "a.", "Further,", "due", "to", "the", "use", "of", "parallel", "data,", "we", "know", "that", "a", "and", "b", "are", "semantically", "equivalent.", "Hence", "we", "transfer", "the", "semantic", "knowledge", "contained", "in", "MA", "onto", "MB", ",", "by", "learning", "\u03b8MB", "to", "minimize:", "Ebi", "(CA,B", ")", "=", "X", "(a,b)\u2208CA,B", "Edist", "(a,", "b)", "(4)", "Of", "course,", "this", "objective", "function", "assumes", "a", "fully", "trained", "model", "which", "we", "do", "not", "have", "at", "this", "stage.", "While", "this", "can", "be", "a", "useful", "objective", "for", "transferring", "linguistic", "knowledge", "into", "low-resource", "lan-", "guages", "[16],", "this", "precondition", "is", "not", "helpful", "when", "there", "is", "no", "model", "to", "learn", "from", "in", "first", "place.", "We", "resolve", "this", "issue", "by", "jointly", "training", "both", "models", "MA", "and", "MB", ".", "Applying", "Ebi", "to", "parallel", "data", "ensures", "that", "both", "models", "learn", "a", "shared", "representation", "at", "the", "sentence", "level.", "As", "the", "parallel", "input", "sentences", "share", "the", "same", "meaning,", "it", "is", "reasonable", "to", "assume", "that", "mini-", "mizing", "Ebi", "will", "force", "the", "model", "to", "learn", "their", "semantic", "representation.", "Let", "\u03b8bi", "=", "\u03b8MA", "\u222a", "\u03b8MB", ".", "The", "joint", "objective", "function", "J", "(\u03b8bi", ")", "thus", "becomes:", "J(\u03b8bi)", "=", "Ebi(CA,B)", "+", "\u03bb", "2", "k\u03b8bi", "k", "2", "(5)", "where", "\u03bbk\u03b8bi", "k1", "is", "the", "L2", "regularization", "term.", "It", "is", "apparent", "that", "this", "joint", "objective", "J", "(\u03b8bi", ")", "is", "degenerate.", "The", "models", "could", "learn", "to", "reduce", "all", "embeddings", "and", "composition", "weights", "to", "zero", "and", "thereby", "minimize", "the", "objective", "function.", "We", "ad-", "dress", "this", "issue", "by", "employing", "a", "form", "of", "contrastive", "estimation", "penalizing", "small", "distances", "between", "non-parallel", "sentence", "pairs.", "For", "every", "pair", "of", "parallel", "sentences", "(a,", "b)", "we", "sample", "a", "number", "of", "ad-", "ditional", "sentences", "n", "\u2208", "CB", ",", "which\u2014with", "high", "probability\u2014are", "not", "exact", "translations", "of", "a.", "This", "is", "comparable", "to", "the", "second", "term", "of", "the", "loss", "function", "of", "a", "large", "margin", "nearest", "neighbour", "classifier", "(see", "Eq.", "12", "in", "[28]):", "Enoise", "(a,", "b,", "n)", "=", "[1", "+", "Edist", "(a,", "b)", "\u2212", "Edist(a,", "n)]+", "(6)", "4", "where", "[x]+", "=", "max(x,", "0)", "denotes", "the", "standard", "hinge", "loss.", "Thus,", "the", "final", "objective", "function", "to", "minimize", "for", "the", "BICVM", "model", "is:", "J(\u03b8bi)", "=", "X", "(a,b)\u2208CA,B", "k", "X", "i=1", "Enoise", "(a,", "b,", "ni)", "!+", "\u03bb", "2", "k\u03b8bi", "k", "2", "(7)", "3.3", "Model", "Learning", "Given", "the", "objective", "function", "as", "defined", "above,", "model", "learning", "can", "employ", "the", "same", "techniques", "as", "any", "monolingual", "CVM.", "In", "particular,", "as", "the", "objective", "function", "is", "differentiable,", "we", "can", "use", "standard", "gradient", "descent", "techniques", "such", "as", "stochastic", "gradient", "descent,", "L-BFGS", "or", "the", "adaptive", "gradient", "algorithm", "AdaGrad", "[8].", "Within", "each", "monolingual", "CVM,", "we", "use", "backpropagation", "through", "structure", "after", "applying", "the", "joint", "error", "to", "each", "sentence", "level", "node.", "4", "Experiments", "4.1", "Data", "and", "Parameters", "All", "model", "weights", "were", "randomly", "initialised", "using", "a", "Gaussian", "distribution.", "There", "are", "a", "number", "of", "parameters", "that", "can", "influence", "model", "training.", "We", "selected", "the", "following", "values", "for", "simplicity", "and", "comparability", "with", "prior", "work.", "In", "future", "work", "we", "will", "investigate", "the", "effect", "of", "these", "parameters", "in", "greater", "detail.", "L2", "regularization", "(1),", "step-size", "(0.1),", "number", "of", "noise", "elements", "(50),", "margin", "size", "(50),", "embedding", "dimensionality", "(d=40).", "The", "noise", "elements", "samples", "were", "randomly", "drawn", "from", "the", "corpus", "at", "training", "time,", "individually", "for", "each", "training", "sample", "and", "epoch.", "We", "use", "the", "Europarl", "corpus", "(v7)1", "for", "training", "the", "bilingual", "model.", "The", "corpus", "was", "pre-processed", "using", "the", "set", "of", "tools", "provided", "by", "cdec2", "[9]", "for", "tokenizing", "and", "lowercasing", "the", "data.", "Further,", "all", "empty", "sentences", "as", "well", "as", "their", "translations", "were", "removed", "from", "the", "corpus.", "We", "present", "results", "from", "two", "experiments.", "The", "BICVM", "model", "was", "trained", "on", "500k", "sentence", "pairs", "of", "the", "English-German", "parallel", "section", "of", "the", "Europarl", "corpus.", "The", "BICVM+", "model", "used", "this", "dataset", "in", "combination", "with", "another", "500k", "parallel", "sentences", "from", "the", "English-French", "section", "of", "the", "corpus,", "resulting", "in", "1", "million", "English", "sentences,", "each", "paired", "up", "with", "either", "a", "German", "or", "a", "French", "sentence.", "Each", "language\u2019s", "vocabulary", "used", "distinct", "encodings", "to", "avoid", "potential", "overlap.", "The", "motivation", "behind", "B", "ICVM+", "is", "to", "investigate", "whether", "we", "can", "learn", "better", "embeddings", "by", "intro-", "ducing", "additional", "data", "in", "a", "different", "language.", "This", "is", "similar", "to", "prior", "work", "in", "machine", "translation", "where", "English", "was", "used", "as", "a", "pivot", "for", "translation", "between", "low-resource", "languages", "[5].", "We", "use", "the", "adaptive", "gradient", "method,", "AdaGrad", "[8],", "for", "updating", "the", "weights", "of", "our", "models,", "and", "ter-", "minate", "training", "after", "50", "iterations.", "Earlier", "experiments", "indicated", "that", "the", "BICVM", "model", "converges", "faster", "than", "the", "B", "ICVM+", "model,", "but", "we", "report", "results", "on", "the", "same", "number", "of", "iterations", "for", "better", "comparability3", ".", "4.2", "Cross-Lingual", "Document", "Classification", "We", "evaluate", "our", "model", "using", "the", "cross-lingual", "document", "classification", "(CLDC)", "task", "of", "Klementiev", "et", "al.", "[16].", "This", "task", "involves", "learning", "language", "independent", "embeddings", "which", "are", "then", "used", "for", "document", "classification", "across", "the", "English-German", "language", "pair.", "For", "this,", "CLDC", "employs", "a", "par-", "ticular", "kind", "of", "supervision,", "namely", "using", "supervised", "training", "data", "in", "one", "language", "and", "evaluating", "without", "supervision", "in", "another.", "Thus,", "CLDC", "is", "a", "good", "task", "for", "establishing", "whether", "our", "learned", "representations", "are", "semantically", "useful", "across", "multiple", "languages.", "We", "follow", "the", "experimental", "setup", "described", "in", "[16],", "with", "the", "exception", "that", "we", "learn", "our", "embeddings", "using", "solely", "the", "Europarl", "data", "and", "only", "use", "the", "Reuters", "RCV1/RCV2", "corpora", "during", "the", "classifier", "training", "and", "testing", "stages.", "Each", "document", "in", "the", "classification", "task", "is", "represented", "by", "the", "average", "1", "http://www.statmt.org/europarl/", "2", "https://github.com/redpony/cdec", "3", "These", "numbers", "were", "updated", "following", "comments", "in", "the", "ICLR", "open", "review", "process.", "Results", "for", "other", "dimensionalities", "and", "our", "source", "code", "for", "our", "model", "are", "available", "at", "http://www.karlmoritz.com.", "5", "Model", "en\u2192de", "de\u2192en", "Majority", "Class", "46.8", "46.8", "Glossed", "65.1", "68.6", "MT", "68.1", "67.4", "I-Matrix", "77.6", "71.1", "BICVM", "83.7", "71.4", "BICVM+", "86.2", "76.9", "Table", "1:", "Classification", "accuracy", "for", "training", "on", "English", "and", "German", "with", "1000", "labeled", "examples.", "Cross-lingual", "compositional", "representations", "(B", "ICVM", "and", "BICVM+),", "cross-lingual", "representations", "using", "learned", "embeddings", "and", "an", "interaction", "matrix", "(I-Matrix)", "[16]", "translated", "(MT)", "and", "glossed", "(Glossed)", "words,", "and", "the", "majority", "class", "baseline.", "The", "MT", "and", "Glossed", "results", "are", "also", "taken", "from", "Klementiev", "et", "al.", "[16].", "100", "200", "500", "1000", "5000", "10000", "50", "60", "70", "80", "Training", "Documents", "(en)", "C", "l", "a", "s", "s", "i", "fi", "c", "a", "t", "i", "o", "n", "A", "c", "c", "u", "r", "a", "c", "y", "(", "%", ")", "100", "200", "500", "1000", "5000", "10000", "50", "60", "70", "80", "Training", "Documents", "(de)", "BICVM", "BICVM+", "I-Matrix", "MT", "Glossed", "Majority", "Class", "Figure", "2:", "Classification", "accuracy", "for", "a", "number", "of", "models", "(see", "Table", "1", "for", "model", "descriptions).", "The", "left", "chart", "shows", "results", "for", "these", "models", "when", "trained", "on", "English", "data", "and", "evaluated", "on", "German", "data,", "the", "right", "chart", "vice", "versa.", "of", "the", "d-dimensional", "representations", "of", "all", "its", "sentences.", "We", "train", "the", "multiclass", "classifier", "using", "the", "same", "settings", "and", "implementation", "of", "the", "averaged", "perceptron", "classifier", "[6]", "as", "used", "in", "[16].", "We", "ran", "the", "CLDC", "experiments", "both", "by", "training", "on", "English", "and", "testing", "on", "German", "documents", "and", "vice", "versa.", "Using", "the", "data", "splits", "provided", "by", "[16],", "we", "used", "varying", "training", "data", "sizes", "from", "100", "to", "10,000", "documents", "for", "training", "the", "multiclass", "classifier.", "The", "results", "of", "this", "task", "across", "training", "sizes", "are", "shown", "in", "Figure", "2.", "Table", "1", "shows", "the", "results", "for", "training", "on", "1,000", "documents.", "Both", "models,", "BICVM", "and", "BICVM+", "outperform", "all", "prior", "work", "on", "this", "task.", "Further,", "the", "BICVM+", "model", "outperforms", "the", "BICVM", "model,", "indicating", "the", "usefulness", "of", "adding", "training", "data", "even", "from", "a", "separate", "language", "pair.", "4.3", "Visualization", "While", "the", "CLDC", "experiment", "focused", "on", "establishing", "the", "semantic", "content", "of", "the", "sentence", "level", "representations,", "we", "also", "want", "to", "briefly", "investigate", "the", "induced", "word", "embeddings.", "In", "particular", "the", "BICVM+", "model", "is", "interesting", "for", "that", "purpose,", "as", "it", "allows", "us", "to", "evaluate", "our", "approach", "of", "using", "English", "as", "a", "pivot", "language", "in", "a", "multilingual", "setup.", "In", "Figure", "3", "we", "show", "the", "t-SNE", "projections", "for", "a", "number", "of", "English,", "French", "and", "German", "words.", "Of", "particular", "interest", "should", "be", "the", "right", "chart,", "which", "highlights", "bilingual", "embeddings", "between", "French", "and", "German", "words.", "Even", "though", "the", "model", "did", "not", "use", "any", "parallel", "French-German", "data", "during", "training,", "it", "still", "managed", "to", "learn", "semantic", "word-word", "similarity", "across", "these", "two", "languages.", "6", "Figure", "3:", "The", "left", "scatter", "plot", "shows", "t-SNE", "projections", "for", "a", "weekdays", "in", "all", "three", "languages", "using", "the", "representations", "learned", "in", "the", "BICVM+", "model.", "Even", "though", "the", "model", "did", "not", "use", "any", "parallel", "French-German", "data", "during", "training,", "it", "still", "learns", "semantic", "similarity", "between", "these", "two", "languages", "using", "English", "as", "a", "pivot.", "To", "highlight", "this,", "the", "right", "plot", "shows", "another", "set", "of", "words", "(months", "of", "the", "year)", "using", "only", "the", "German", "and", "French", "words.", "5", "Conclusions", "With", "this", "paper", "we", "have", "proposed", "a", "novel", "method", "for", "inducing", "cross-lingual", "distributed", "represen-", "tations", "for", "compositional", "semantics.", "Using", "a", "very", "simple", "method", "for", "semantic", "composition,", "we", "nevertheless", "managed", "to", "obtain", "state", "of", "the", "art", "results", "on", "the", "CLDC", "task,", "specifically", "designed", "to", "evaluate", "semantic", "transfer", "across", "languages.", "After", "extending", "our", "approach", "to", "include", "multilingual", "training", "data", "in", "the", "BICVM+", "model,", "we", "were", "able", "to", "demonstrate", "that", "adding", "additional", "languages", "further", "improves", "the", "model.", "Furthermore,", "using", "some", "qualitative", "experiments", "and", "visualizations,", "we", "showed", "that", "our", "approach", "also", "allows", "us", "to", "learn", "semantically", "related", "embeddings", "across", "languages", "without", "any", "direct", "training", "data.", "Our", "approach", "provides", "great", "flexibility", "in", "training", "data", "and", "requires", "little", "to", "no", "annotation.", "Hav-", "ing", "demonstrated", "the", "successful", "training", "of", "semantic", "representations", "using", "sentence", "aligned", "data,", "a", "plausible", "next", "step", "is", "to", "attempt", "training", "using", "document-aligned", "data", "or", "even", "corpora", "of", "comparable", "documents.", "This", "may", "provide", "even", "greater", "possibilities", "for", "working", "with", "low-resource", "languages.", "In", "the", "same", "vein,", "the", "success", "of", "our", "pivoting", "experiments", "suggest", "further", "work.", "Unlike", "other", "pivot", "approaches,", "it", "is", "easy", "to", "extend", "our", "model", "to", "have", "multiple", "pivot", "languages.", "Thus", "some", "pivots", "could", "preserve", "different", "aspects", "such", "as", "case,", "gender", "etc.,", "and", "overcome", "other", "issues", "related", "to", "having", "a", "single", "pivot", "language.", "As", "we", "have", "achieved", "the", "results", "in", "this", "paper", "with", "a", "relatively", "simple", "CV", "M,", "it", "would", "also", "be", "inter-", "esting", "to", "establish", "whether", "our", "objective", "function", "can", "be", "used", "in", "combination", "with", "more", "complex", "compositional", "vector", "models", "such", "as", "MV-RNN", "[25]", "or", "tensor-based", "approaches,", "to", "see", "whether", "these", "can", "further", "improve", "results", "on", "both", "mono-", "and", "multilingual", "tasks", "when", "used", "in", "conjunction", "with", "our", "cross-lingual", "objective", "function.", "Related", "to", "this,", "we", "will", "also", "apply", "our", "model", "to", "a", "wider", "variety", "of", "tasks", "including", "machine", "translation", "and", "multilingual", "information", "extraction.", "Acknowledgements", "The", "authors", "would", "like", "to", "thank", "Alexandre", "Klementiev", "and", "his", "co-authors", "for", "making", "their", "datasets", "and", "averaged", "perceptron", "implementation", "available,", "as", "well", "as", "answering", "a", "number", "of", "questions", "related", "to", "their", "work", "on", "this", "task.", "This", "work", "was", "supported", "by", "EPSRC", "grant", "EP/K036580/1", "and", "a", "Xerox", "Foundation", "Award.", "7", "References", "[1]", "Marco", "Baroni", "and", "Roberto", "Zamparelli.", "Nouns", "are", "vectors,", "adjectives", "are", "matrices:", "Represent-", "ing", "adjective-noun", "constructions", "in", "semantic", "space.", "In", "Proceedings", "of", "EMNLP,", "2010.", "[2]", "Paul", "Bloom.", "Precis", "of", "how", "children", "learn", "the", "meanings", "of", "words.", "Behavioral", "and", "Brain", "Sciences,", "24:1095\u20131103,", "2001.", "[3]", "Stephen", "Clark", "and", "Stephen", "Pulman.", "Combining", "symbolic", "and", "distributional", "models", "of", "mean-", "ing.", "In", "Proceedings", "of", "AAAI", "Spring", "Symposium", "on", "Quantum", "Interaction.", "AAAI", "Press,", "2007.", "[4]", "Bob", "Coecke,", "Mehrnoosh", "Sadrzadeh,", "and", "Stephen", "Clark.", "Mathematical", "foundations", "for", "a", "com-", "positional", "distributional", "model", "of", "meaning.", "Lambek", "Festschrift.", "Linguistic", "Analysis,", "36:345\u2013", "384,", "2010.", "[5]", "Trevor", "Cohn", "and", "Mirella", "Lapata.", "Machine", "translation", "by", "triangulation:", "Making", "effective", "use", "of", "multi-parallel", "corpora.", "In", "Proceedings", "of", "ACL,", "pages", "728\u2013735,", "Prague,", "Czech", "Republic,", "June", "2007.", "Association", "for", "Computational", "Linguistics.", "[6]", "Michael", "Collins.", "Discriminative", "training", "methods", "for", "hidden", "markov", "models:", "Theory", "and", "experiments", "with", "perceptron", "algorithms.", "In", "Proceedings", "of", "ACL-EMNLP.", "Association", "for", "Computational", "Linguistics,", "2002.", "doi:", "10.3115/1118693.1118694.", "[7]", "Ronan", "Collobert", "and", "Jason", "Weston.", "A", "unified", "architecture", "for", "natural", "language", "processing:", "Deep", "neural", "networks", "with", "multitask", "learning.", "In", "Proceedings", "of", "ICML,", "2008.", "[8]", "John", "Duchi,", "Elad", "Hazan,", "and", "Yoram", "Singer.", "Adaptive", "subgradient", "methods", "for", "online", "learning", "and", "stochastic", "optimization.", "Journal", "of", "Machine", "Learning", "Research,", "12:2121\u20132159,", "July", "2011.", "ISSN", "1532-4435.", "[9]", "Chris", "Dyer,", "Adam", "Lopez,", "Juri", "Ganitkevitch,", "Johnathan", "Weese,", "Ferhan", "Ture,", "Phil", "Blunsom,", "Hendra", "Setiawan,", "Vladimir", "Eidelman,", "and", "Philip", "Resnik.", "cdec:", "A", "decoder,", "alignment,", "and", "learning", "framework", "for", "finite-state", "and", "context-free", "translation", "models.", "In", "Proceedings", "of", "ACL,", "2010.", "[10]", "K.", "Erk", "and", "S.", "Pad", "\u0301o", ".", "A", "structured", "vector", "space", "model", "for", "word", "meaning", "in", "context.", "Proceedings", "of", "EMNLP,", "2008.", "[11]", "J.", "R", ".", "Firth.", "A", "synopsis", "of", "linguistic", "theory", "1930-55", ".", "1952-59:1\u201332,", "1957.", "[12]", "Edward", "Grefenstette", "and", "Mehrnoosh", "Sadrzadeh.", "Experimental", "support", "for", "a", "categorical", "com-", "positional", "distributional", "model", "of", "meaning.", "In", "Proceedings", "of", "EMNLP,", "2011.", "[13]", "Aria", "Haghighi,", "Percy", "Liang,", "Taylor", "Berg-Kirkpatrick,", "and", "Dan", "Klein.", "Learning", "bilingual", "lexicons", "from", "monolingual", "corpora.", "In", "Proceedings", "of", "ACL-HLT,", "2008.", "[14]", "Karl", "Moritz", "Hermann", "and", "Phil", "Blunsom.", "The", "Role", "of", "Syntax", "in", "Vector", "Space", "Models", "of", "Compositional", "Semantics.", "In", "Proceedings", "of", "ACL,", "2013.", "[15]", "Nal", "Kalchbrenner", "and", "Phil", "Blunsom.", "Recurrent", "convolutional", "neural", "networks", "for", "discourse", "compositionality.", "In", "Proceedings", "of", "the", "Workshop", "on", "Continuous", "Vector", "Space", "Models", "and", "their", "Compositionality,", "2013.", "[16]", "Alexandre", "Klementiev,", "Ivan", "Titov,", "and", "Binod", "Bhattarai.", "Inducing", "crosslingual", "distributed", "representations", "of", "words.", "In", "Proceedings", "of", "COLING,", "2012.", "[17]", "Stanislas", "Lauly,", "Alex", "Boulanger,", "and", "Hugo", "Larochelle.", "Learning", "multilingual", "word", "represen-", "tations", "using", "a", "bag-of-words", "autoencoder.", "In", "Deep", "Learning", "Workshop", "at", "NIPS,", "2013.", "[18]", "Tomas", "Mikolov,", "Kai", "Chen,", "Greg", "Corrado,", "and", "Jeffrey", "Dean.", "Efficient", "estimation", "of", "word", "representations", "in", "vector", "space.", "CoRR,", "2013.", "[19]", "Tomas", "Mikolov,", "Quoc", "V.", "Le,", "and", "Ilya", "Sutskever.", "Exploiting", "similarities", "among", "languages", "for", "machine", "translation.", "CoRR,", "2013.", "[20]", "Tom", "\u0301a", "\u02c7s", "Mikolov,", "Martin", "Karafi\u0301at,", "Luk", "\u0301a", "\u02c7s", "Burget,", "Jan", "\u02c7Cernock", "\u0301y,", "and", "Sanjeev", "Khudanpur.", "Re-", "current", "neural", "network", "based", "language", "model.", "In", "Proceedings", "of", "INTERSPEECH,", "2010.", "[21]", "Jeff", "Mitchell", "and", "Mirella", "Lapata.", "Vector-based", "models", "of", "semantic", "composition.", "In", "In", "Pro-", "ceedings", "of", "ACL,", "2008.", "[22]", "D.", "Roy.", "Grounded", "spoken", "language", "acquisition:", "Experiments", "in", "word", "learning.", "IEEE", "Trans-", "actions", "on", "Multimedia,", "5(2):197\u2013209,", "June", "2003.", "ISSN", "1520-9210.", "doi:", "10.1109/TMM.2003.", "811618.", "8", "[23]", "A", "P", "Sarath", "Chandar,", "M", "Khapra", "Mitesh,", "B", "Ravindran,", "Vikas", "Raykar,", "and", "Amrita", "Saha.", "Multi-", "lingual", "deep", "learning.", "In", "Deep", "Learning", "Workshop", "at", "NIPS,", "2013.", "[24]", "Richard", "Socher,", "Jeffrey", "Pennington,", "Eric", "H.", "Huang,", "Andrew", "Y.", "Ng,", "and", "Christopher", "D.", "Man-", "ning.", "Semi-supervised", "recursive", "autoencoders", "for", "predicting", "sentiment", "distributions.", "In", "Pro-", "ceedings", "of", "EMNLP,", "2011.", "[25]", "Richard", "Socher,", "Brody", "Huval,", "Christopher", "D.", "Manning,", "and", "Andrew", "Y.", "Ng.", "Semantic", "compo-", "sitionality", "through", "recursive", "matrix-vector", "spaces.", "In", "Proceedings", "of", "EMNLP-CoNLL,", "pages", "1201\u20131211,", "2012.", "[26]", "Nitish", "Srivastava", "and", "Ruslan", "Salakhutdinov.", "Multimodal", "learning", "with", "deep", "boltzmann", "ma-", "chines.", "In", "Proceedings", "of", "NIPS.", "2012.", "[27]", "P.", "D", ".", "Turney", "and", "P.", "Pantel.", "From", "frequency", "to", "meaning:", "Vector", "space", "models", "of", "semantics.", "Journal", "of", "Artificial", "Intelligence", "Research,", "37(1):141\u2013188,", "2010.", "[28]", "Kilian", "Q.", "Weinberger", "and", "Lawrence", "K.", "Saul.", "Distance", "metric", "learning", "for", "large", "margin", "nearest", "neighbor", "classification.", "Journal", "of", "Machine", "Learning", "Research,", "10:207\u2013244,", "June", "2009.", "ISSN", "1532-4435.", "[29]", "Will", "Y.", "Zou,", "Richard", "Socher,", "Daniel", "Cer,", "and", "Christopher", "D.", "Manning.", "Bilingual", "word", "em-", "beddings", "for", "phrase-based", "machine", "translation.", "In", "Proceedings", "of", "EMNLP,", "2013.", "9"], "positions": [[519, 462, 898, 527], [919, 462, 1266, 513], [1287, 462, 1776, 527], [1798, 462, 2031, 513], [1018, 547, 1189, 596], [1210, 545, 1532, 610], [914, 799, 995, 828], [1007, 798, 1127, 828], [1140, 799, 1308, 828], [1321, 799, 1386, 828], [1398, 798, 1468, 827], [1480, 799, 1635, 828], [997, 846, 1193, 882], [1203, 845, 1239, 873], [1248, 845, 1414, 882], [1426, 845, 1552, 874], [1101, 890, 1273, 927], [1285, 890, 1321, 918], [1330, 890, 1448, 919], [1080, 936, 1207, 970], [1220, 936, 1294, 965], [1311, 936, 1398, 971], [1411, 937, 1470, 965], [709, 979, 1840, 1020], [1182, 1148, 1368, 1183], [600, 1272, 784, 1300], [800, 1272, 1050, 1309], [1068, 1272, 1104, 1300], [1118, 1272, 1260, 1309], [1278, 1281, 1326, 1300], [1344, 1281, 1360, 1300], [1377, 1272, 1491, 1300], [1508, 1281, 1575, 1309], [1592, 1276, 1623, 1300], [1640, 1272, 1756, 1300], [1773, 1272, 1950, 1301], [599, 1318, 809, 1355], [827, 1318, 964, 1347], [981, 1318, 1079, 1347], [1099, 1318, 1156, 1346], [1172, 1318, 1295, 1355], [1313, 1318, 1344, 1346], [1361, 1319, 1442, 1346], [1461, 1319, 1507, 1355], [1525, 1318, 1720, 1355], [1737, 1318, 1805, 1346], [1823, 1318, 1949, 1355], [599, 1363, 761, 1400], [780, 1372, 810, 1391], [827, 1363, 897, 1392], [913, 1372, 943, 1391], [959, 1363, 1119, 1400], [1134, 1363, 1329, 1391], [1345, 1363, 1436, 1391], [1451, 1363, 1595, 1391], [1610, 1363, 1792, 1391], [1808, 1363, 1908, 1392], [1923, 1363, 1948, 1391], [600, 1413, 652, 1437], [667, 1409, 813, 1438], [828, 1409, 858, 1437], [873, 1409, 1001, 1437], [1015, 1409, 1274, 1446], [1292, 1409, 1467, 1437], [1481, 1409, 1730, 1446], [1746, 1409, 1822, 1438], [1836, 1418, 1949, 1446], [599, 1455, 700, 1483], [713, 1455, 744, 1483], [758, 1464, 848, 1492], [861, 1456, 939, 1483], [952, 1455, 1042, 1483], [1063, 1456, 1178, 1483], [1190, 1455, 1274, 1484], [1286, 1455, 1339, 1483], [1355, 1455, 1460, 1484], [1473, 1455, 1542, 1484], [1556, 1455, 1790, 1492], [1805, 1455, 1949, 1483], [599, 1500, 848, 1537], [863, 1509, 919, 1528], [934, 1500, 1134, 1537], [1147, 1500, 1186, 1528], [1201, 1500, 1320, 1537], [1334, 1504, 1365, 1528], [1380, 1509, 1396, 1528], [1409, 1500, 1535, 1528], [1548, 1500, 1584, 1528], [1595, 1500, 1804, 1537], [1818, 1500, 1948, 1537], [600, 1546, 678, 1574], [696, 1546, 769, 1574], [786, 1555, 816, 1574], [834, 1546, 994, 1574], [1009, 1546, 1149, 1583], [1176, 1546, 1217, 1574], [1231, 1546, 1281, 1574], [1297, 1555, 1380, 1574], [1395, 1546, 1476, 1580], [1494, 1546, 1576, 1574], [1590, 1546, 1643, 1574], [1659, 1546, 1737, 1574], [1754, 1555, 1839, 1574], [1854, 1546, 1950, 1574], [601, 1601, 721, 1620], [737, 1592, 768, 1620], [782, 1592, 866, 1621], [880, 1601, 920, 1620], [934, 1592, 1068, 1629], [1084, 1592, 1189, 1620], [1204, 1592, 1380, 1621], [1393, 1592, 1642, 1629], [1659, 1601, 1759, 1620], [1775, 1592, 1948, 1629], [599, 1638, 653, 1665], [664, 1637, 806, 1665], [817, 1637, 901, 1665], [912, 1641, 972, 1666], [985, 1637, 1167, 1674], [1179, 1637, 1220, 1674], [1231, 1637, 1396, 1674], [1409, 1646, 1425, 1665], [1436, 1637, 1559, 1665], [1570, 1637, 1618, 1665], [1628, 1637, 1763, 1674], [1774, 1637, 1949, 1665], [599, 1683, 848, 1720], [860, 1683, 891, 1711], [903, 1692, 919, 1711], [930, 1683, 1131, 1720], [1143, 1687, 1236, 1720], [1252, 1683, 1316, 1712], [1326, 1683, 1428, 1711], [1439, 1683, 1535, 1711], [1548, 1687, 1578, 1711], [1590, 1683, 1691, 1720], [1703, 1683, 1817, 1711], [1827, 1683, 1948, 1711], [600, 1729, 687, 1766], [702, 1733, 733, 1757], [747, 1729, 867, 1766], [882, 1733, 1037, 1757], [1053, 1729, 1110, 1757], [1124, 1729, 1287, 1757], [1300, 1738, 1373, 1757], [1388, 1733, 1418, 1757], [1433, 1733, 1574, 1757], [1587, 1729, 1687, 1758], [1702, 1738, 1750, 1757], [1764, 1733, 1816, 1757], [1830, 1729, 1949, 1766], [600, 1774, 691, 1803], [701, 1778, 753, 1802], [761, 1774, 912, 1811], [923, 1774, 1006, 1803], [1017, 1774, 1205, 1811], [1220, 1775, 1273, 1802], [1284, 1774, 1368, 1803], [1378, 1774, 1440, 1802], [1449, 1783, 1503, 1802], [1511, 1774, 1761, 1811], [1773, 1783, 1821, 1802], [1832, 1783, 1948, 1802], [600, 1820, 702, 1857], [714, 1820, 905, 1849], [918, 1820, 975, 1848], [989, 1820, 1078, 1857], [1091, 1820, 1173, 1848], [1185, 1824, 1215, 1848], [1229, 1829, 1245, 1848], [1257, 1820, 1470, 1857], [1482, 1820, 1645, 1848], [1657, 1820, 1872, 1848], [1884, 1820, 1950, 1848], [600, 1866, 700, 1895], [712, 1875, 759, 1895], [771, 1866, 957, 1903], [969, 1866, 1018, 1894], [1029, 1866, 1169, 1903], [1184, 1870, 1258, 1894], [1270, 1866, 1305, 1894], [1315, 1866, 1364, 1894], [1378, 1870, 1427, 1894], [1445, 1866, 1572, 1900], [1585, 1866, 1626, 1903], [1639, 1866, 1814, 1903], [1826, 1866, 1950, 1903], [600, 1920, 725, 1948], [739, 1911, 775, 1939], [786, 1911, 923, 1948], [937, 1911, 1085, 1948], [1098, 1911, 1177, 1948], [1192, 1920, 1239, 1940], [1253, 1911, 1316, 1939], [1330, 1911, 1392, 1939], [1404, 1920, 1459, 1939], [1472, 1911, 1574, 1939], [1588, 1911, 1684, 1939], [1699, 1911, 1948, 1948], [600, 1957, 662, 1985], [677, 1961, 798, 1994], [816, 1957, 960, 1985], [977, 1957, 1187, 1994], [1206, 1966, 1306, 1985], [1324, 1957, 1487, 1994], [1505, 1957, 1553, 1985], [1569, 1957, 1668, 1986], [1685, 1966, 1725, 1985], [1741, 1957, 1865, 1994], [1882, 1957, 1950, 1985], [600, 2012, 661, 2032], [673, 2003, 758, 2031], [452, 2182, 471, 2216], [525, 2182, 794, 2217], [450, 2303, 635, 2331], [644, 2303, 893, 2340], [905, 2303, 941, 2331], [948, 2303, 1046, 2332], [1059, 2312, 1107, 2331], [1117, 2303, 1318, 2340], [1328, 2303, 1419, 2340], [1429, 2303, 1504, 2331], [1514, 2307, 1545, 2331], [1556, 2303, 1679, 2332], [1688, 2303, 1761, 2340], [1771, 2303, 1863, 2332], [1875, 2303, 1911, 2331], [1918, 2303, 2098, 2340], [450, 2348, 513, 2376], [527, 2348, 631, 2377], [644, 2348, 793, 2385], [806, 2348, 972, 2385], [986, 2348, 1076, 2376], [1096, 2348, 1271, 2377], [1286, 2348, 1482, 2385], [1497, 2348, 1532, 2376], [1543, 2348, 1600, 2376], [1615, 2348, 1765, 2385], [1778, 2348, 1899, 2376], [1912, 2348, 2099, 2377], [450, 2394, 713, 2431], [729, 2394, 813, 2423], [828, 2394, 984, 2431], [999, 2394, 1056, 2422], [1071, 2403, 1220, 2431], [1234, 2394, 1384, 2422], [1399, 2394, 1468, 2431], [1493, 2394, 1552, 2428], [1568, 2394, 1644, 2429], [1667, 2394, 1856, 2431], [1869, 2394, 1953, 2423], [1965, 2394, 2018, 2422], [2035, 2394, 2099, 2422], [451, 2440, 612, 2477], [628, 2444, 658, 2468], [674, 2440, 755, 2468], [771, 2440, 946, 2468], [962, 2440, 1122, 2468], [1138, 2440, 1174, 2468], [1187, 2440, 1282, 2477], [1297, 2444, 1465, 2474], [1484, 2440, 1625, 2477], [1640, 2449, 1674, 2468], [1691, 2444, 1722, 2468], [1738, 2440, 1828, 2477], [1843, 2440, 2018, 2468], [2033, 2449, 2098, 2477], [449, 2485, 631, 2513], [645, 2489, 676, 2513], [690, 2485, 770, 2513], [786, 2485, 859, 2513], [874, 2494, 905, 2513], [921, 2485, 1081, 2513], [1095, 2485, 1225, 2522], [1240, 2494, 1274, 2513], [1286, 2485, 1466, 2522], [1479, 2485, 1630, 2513], [1645, 2485, 1705, 2520], [1730, 2485, 1769, 2519], [1786, 2485, 1812, 2519], [1832, 2485, 1877, 2519], [1896, 2485, 1941, 2519], [1957, 2485, 2005, 2519], [2021, 2484, 2097, 2520], [450, 2531, 491, 2559], [504, 2531, 554, 2559], [568, 2540, 651, 2559], [665, 2531, 737, 2559], [752, 2540, 768, 2559], [783, 2531, 895, 2559], [911, 2531, 1009, 2559], [1023, 2531, 1059, 2559], [1070, 2531, 1154, 2560], [1167, 2531, 1220, 2559], [1235, 2531, 1363, 2559], [1377, 2540, 1416, 2559], [1430, 2531, 1622, 2568], [1636, 2531, 1789, 2568], [1802, 2531, 1983, 2568], [1998, 2540, 2097, 2559], [450, 2577, 624, 2614], [639, 2577, 696, 2605], [708, 2577, 899, 2614], [911, 2577, 991, 2605], [1003, 2577, 1128, 2614], [1141, 2577, 1204, 2605], [1217, 2577, 1431, 2606], [1443, 2577, 1616, 2614], [1630, 2577, 1670, 2614], [1683, 2586, 1786, 2605], [1800, 2577, 1836, 2605], [1846, 2577, 2021, 2605], [2033, 2586, 2098, 2614], [449, 2622, 646, 2650], [660, 2626, 689, 2650], [700, 2622, 749, 2650], [761, 2622, 844, 2651], [856, 2622, 933, 2651], [948, 2622, 1008, 2656], [1025, 2622, 1084, 2656], [450, 2693, 614, 2730], [630, 2693, 714, 2722], [727, 2702, 767, 2721], [781, 2693, 1014, 2730], [1029, 2693, 1173, 2721], [1187, 2693, 1436, 2730], [1451, 2693, 1573, 2721], [1588, 2702, 1628, 2721], [1642, 2693, 1850, 2730], [1864, 2693, 1932, 2721], [1945, 2693, 2036, 2722], [2050, 2693, 2099, 2721], [450, 2739, 663, 2776], [674, 2739, 758, 2768], [768, 2739, 889, 2767], [901, 2748, 941, 2767], [951, 2739, 1035, 2768], [1045, 2739, 1123, 2768], [1132, 2739, 1381, 2776], [1393, 2739, 1471, 2776], [1487, 2740, 1642, 2773], [1655, 2739, 1677, 2767], [1687, 2748, 1810, 2776], [1822, 2739, 1934, 2776], [1944, 2739, 2006, 2767], [2015, 2739, 2099, 2767], [450, 2788, 511, 2813], [525, 2784, 639, 2812], [654, 2784, 689, 2812], [700, 2784, 784, 2813], [798, 2784, 906, 2812], [918, 2784, 957, 2812], [970, 2784, 1132, 2812], [1147, 2793, 1177, 2812], [1192, 2784, 1274, 2812], [1287, 2784, 1378, 2812], [1394, 2793, 1410, 2812], [1422, 2784, 1558, 2821], [1571, 2784, 1607, 2812], [1617, 2784, 1741, 2821], [1754, 2793, 1879, 2821], [1893, 2784, 1965, 2813], [1979, 2784, 2099, 2821], [450, 2830, 518, 2858], [529, 2834, 557, 2858], [566, 2830, 615, 2858], [626, 2834, 766, 2858], [776, 2830, 854, 2859], [863, 2839, 897, 2858], [905, 2830, 1026, 2867], [1036, 2830, 1136, 2859], [1146, 2830, 1236, 2858], [1245, 2830, 1284, 2858], [1293, 2830, 1445, 2867], [1455, 2830, 1486, 2858], [1497, 2830, 1570, 2858], [1580, 2830, 1672, 2859], [1688, 2830, 1815, 2864], [1828, 2834, 1969, 2858], [1979, 2830, 2099, 2867], [450, 2876, 518, 2904], [530, 2876, 671, 2913], [687, 2885, 703, 2904], [715, 2876, 864, 2913], [877, 2880, 1006, 2913], [1018, 2876, 1054, 2904], [1066, 2876, 1210, 2904], [1225, 2876, 1387, 2913], [1403, 2876, 1502, 2905], [1516, 2885, 1572, 2904], [1584, 2876, 1623, 2904], [1635, 2876, 1742, 2904], [1754, 2880, 1785, 2904], [1798, 2876, 1898, 2904], [1912, 2880, 1941, 2904], [1953, 2876, 2002, 2904], [2016, 2876, 2099, 2905], [450, 2921, 537, 2950], [552, 2921, 701, 2950], [710, 2921, 760, 2949], [769, 2930, 839, 2949], [849, 2921, 885, 2949], [893, 2921, 1057, 2958], [1065, 2921, 1203, 2950], [1214, 2930, 1230, 2949], [1239, 2921, 1371, 2950], [1381, 2921, 1555, 2958], [1565, 2930, 1646, 2949], [1657, 2921, 1726, 2958], [1743, 2921, 2098, 2956], [451, 2967, 509, 2995], [523, 2967, 559, 2995], [575, 2967, 701, 3004], [715, 2967, 885, 3004], [900, 2967, 1028, 3004], [1042, 2967, 1138, 3004], [1154, 2967, 1272, 2996], [1286, 2967, 1424, 3002], [1449, 2967, 1600, 2996], [1616, 2967, 1780, 3004], [1795, 2971, 1823, 2995], [1837, 2967, 1886, 2995], [1899, 2967, 2007, 3004], [2021, 2967, 2099, 2996], [449, 3013, 521, 3041], [533, 3022, 656, 3050], [669, 3013, 714, 3041], [726, 3022, 809, 3041], [820, 3013, 970, 3050], [981, 3013, 1051, 3041], [1064, 3013, 1198, 3050], [1210, 3013, 1376, 3042], [1387, 3013, 1492, 3041], [1506, 3013, 1553, 3041], [1566, 3013, 1710, 3041], [1723, 3013, 1854, 3041], [1269, 3137, 1280, 3165], [97, 2265, 134, 2308], [97, 2235, 133, 2272], [83, 2188, 133, 2246], [83, 2162, 133, 2184], [98, 2117, 133, 2164], [103, 2102, 134, 2113], [82, 2058, 133, 2089], [82, 2010, 134, 2051], [82, 1975, 133, 2006], [82, 1929, 133, 1968], [125, 1913, 134, 1924], [82, 1864, 134, 1906], [82, 1829, 133, 1860], [83, 1781, 133, 1821], [82, 1740, 134, 1781], [98, 1698, 133, 1745], [82, 1654, 133, 1700], [81, 1594, 142, 1613], [97, 1549, 134, 1588], [97, 1517, 134, 1550], [125, 1504, 134, 1515], [82, 1443, 134, 1497], [83, 1393, 133, 1441], [81, 1370, 142, 1389], [82, 1281, 133, 1320], [82, 1237, 134, 1278], [83, 1141, 133, 1218], [97, 1101, 134, 1144], [97, 1071, 133, 1108], [82, 1017, 133, 1056], [82, 974, 134, 1015], [82, 938, 133, 969], [82, 888, 133, 934], [451, 354, 548, 391], [559, 354, 616, 382], [628, 354, 781, 388], [795, 354, 853, 382], [863, 354, 1000, 391], [1011, 363, 1051, 382], [1061, 354, 1134, 382], [1146, 354, 1230, 383], [1239, 354, 1351, 382], [1363, 358, 1393, 382], [1405, 354, 1539, 391], [1550, 354, 1763, 391], [1775, 354, 1972, 391], [1986, 363, 2016, 382], [2029, 354, 2099, 383], [452, 409, 482, 428], [499, 404, 530, 428], [546, 400, 779, 437], [796, 400, 940, 428], [956, 400, 1215, 437], [1234, 409, 1281, 429], [1296, 400, 1452, 428], [1468, 409, 1484, 428], [1500, 400, 1602, 428], [1618, 400, 1679, 428], [1694, 400, 1790, 428], [1807, 400, 2020, 437], [2036, 409, 2098, 428], [450, 445, 597, 482], [613, 449, 642, 473], [655, 445, 704, 473], [718, 449, 859, 473], [872, 445, 958, 474], [980, 446, 1013, 473], [1026, 445, 1076, 473], [1089, 445, 1248, 482], [1263, 445, 1378, 473], [1391, 454, 1438, 474], [1452, 445, 1515, 474], [1528, 445, 1635, 482], [1649, 445, 1766, 473], [1780, 445, 1861, 482], [1874, 445, 1958, 474], [1971, 445, 2001, 473], [2015, 445, 2099, 473], [451, 495, 511, 520], [525, 491, 612, 519], [627, 491, 733, 519], [747, 491, 840, 528], [855, 500, 895, 519], [909, 495, 940, 519], [955, 491, 1091, 519], [1106, 491, 1155, 519], [1169, 491, 1316, 528], [1330, 491, 1458, 528], [1473, 491, 1570, 528], [1584, 491, 1646, 519], [1660, 500, 1707, 520], [1721, 491, 1888, 528], [1903, 491, 1951, 519], [1964, 491, 2099, 528], [451, 537, 652, 574], [664, 537, 898, 574], [910, 537, 1117, 574], [1135, 537, 1362, 574], [1376, 546, 1423, 566], [1435, 537, 1498, 566], [1510, 537, 1647, 565], [1659, 546, 1714, 565], [1725, 537, 1827, 565], [1840, 537, 1870, 565], [1882, 541, 1997, 574], [2008, 537, 2099, 565], [452, 591, 482, 610], [498, 582, 567, 611], [582, 591, 613, 610], [628, 582, 665, 610], [680, 582, 807, 619], [821, 582, 986, 619], [1001, 582, 1058, 610], [1072, 582, 1287, 619], [1302, 586, 1396, 619], [1418, 582, 1540, 619], [1556, 591, 1603, 611], [1616, 582, 1750, 619], [1764, 591, 1780, 610], [1794, 582, 1920, 610], [1933, 582, 1969, 610], [1980, 582, 2098, 611], [451, 628, 528, 656], [545, 628, 602, 656], [616, 628, 818, 656], [832, 628, 894, 656], [907, 637, 961, 656], [975, 628, 1102, 665], [1117, 628, 1214, 665], [1229, 628, 1332, 657], [1349, 637, 1365, 656], [1379, 637, 1451, 665], [1466, 628, 1574, 665], [1588, 628, 1822, 665], [1836, 632, 1938, 657], [1952, 628, 2054, 656], [2068, 632, 2099, 656], [451, 674, 636, 711], [647, 674, 696, 702], [709, 678, 782, 702], [794, 674, 829, 702], [838, 674, 887, 702], [900, 678, 942, 702], [952, 683, 992, 702], [1005, 683, 1021, 702], [1032, 674, 1098, 702], [1108, 674, 1254, 711], [1266, 678, 1296, 702], [1308, 674, 1443, 703], [1454, 674, 1490, 702], [1504, 674, 1608, 711], [1619, 678, 1650, 702], [1661, 674, 1787, 702], [1799, 674, 1943, 702], [1955, 674, 2098, 702], [451, 719, 513, 747], [526, 728, 625, 747], [638, 719, 811, 756], [827, 719, 938, 748], [950, 719, 1034, 747], [1045, 719, 1129, 748], [1139, 719, 1170, 747], [1181, 719, 1238, 747], [1252, 728, 1327, 753], [1340, 728, 1395, 747], [1405, 719, 1507, 747], [1519, 719, 1592, 747], [1604, 723, 1657, 747], [1666, 719, 1783, 756], [1794, 719, 1878, 748], [1890, 719, 2010, 756], [2021, 719, 2097, 747], [451, 766, 483, 793], [497, 765, 566, 799], [582, 765, 673, 794], [687, 774, 734, 794], [748, 765, 883, 794], [896, 774, 951, 793], [964, 765, 1066, 793], [1080, 774, 1120, 793], [1135, 769, 1276, 793], [1290, 765, 1410, 802], [1424, 765, 1492, 793], [1505, 765, 1536, 793], [1550, 765, 1607, 793], [1621, 774, 1720, 802], [1736, 765, 1818, 793], [1831, 765, 1856, 793], [1871, 774, 1911, 793], [1925, 765, 2099, 793], [450, 811, 651, 848], [662, 811, 710, 839], [722, 811, 779, 839], [795, 811, 852, 839], [865, 811, 1045, 848], [1059, 820, 1113, 839], [1126, 811, 1285, 848], [1298, 811, 1389, 839], [1403, 811, 1467, 839], [1479, 811, 1518, 839], [1532, 811, 1651, 848], [1664, 815, 1695, 839], [1708, 811, 1963, 840], [1975, 811, 2099, 848], [451, 856, 518, 884], [530, 865, 564, 884], [575, 865, 650, 885], [662, 856, 854, 893], [866, 856, 934, 884], [946, 856, 1024, 893], [451, 989, 474, 1023], [525, 989, 678, 1024], [693, 989, 736, 1024], [748, 989, 1055, 1033], [1069, 989, 1310, 1024], [1325, 989, 1537, 1024], [451, 1105, 483, 1132], [496, 1104, 545, 1132], [558, 1113, 628, 1132], [640, 1104, 676, 1132], [684, 1104, 889, 1141], [902, 1104, 1067, 1133], [1080, 1104, 1178, 1133], [1193, 1113, 1223, 1132], [1237, 1108, 1364, 1138], [1378, 1104, 1427, 1132], [1440, 1104, 1659, 1132], [1672, 1108, 1800, 1132], [1811, 1104, 1847, 1132], [1858, 1104, 2017, 1132], [2030, 1113, 2098, 1141], [451, 1150, 535, 1179], [553, 1159, 569, 1178], [583, 1150, 733, 1187], [748, 1150, 939, 1187], [954, 1150, 990, 1178], [1003, 1150, 1083, 1179], [1097, 1150, 1122, 1178], [1139, 1150, 1275, 1178], [1291, 1150, 1321, 1178], [1338, 1159, 1354, 1178], [1369, 1150, 1452, 1179], [1468, 1154, 1575, 1179], [1602, 1150, 1672, 1178], [1689, 1150, 1810, 1179], [1826, 1150, 1876, 1178], [1891, 1150, 1959, 1178], [1974, 1150, 2036, 1178], [2050, 1150, 2099, 1178], [451, 1195, 592, 1232], [605, 1195, 641, 1223], [653, 1204, 669, 1223], [682, 1195, 766, 1224], [779, 1204, 835, 1223], [848, 1195, 887, 1223], [900, 1195, 1085, 1223], [1098, 1195, 1139, 1232], [1153, 1195, 1220, 1223], [1234, 1204, 1383, 1232], [1397, 1195, 1420, 1223], [1431, 1195, 1542, 1232], [1560, 1195, 1633, 1229], [1649, 1195, 1710, 1223], [1723, 1195, 1747, 1223], [1762, 1195, 1802, 1232], [1816, 1195, 1865, 1223], [1879, 1199, 2000, 1223], [2012, 1195, 2035, 1223], [2049, 1204, 2098, 1232], [450, 1250, 535, 1278], [552, 1241, 591, 1269], [620, 1241, 700, 1270], [716, 1245, 837, 1269], [851, 1250, 907, 1269], [923, 1241, 1018, 1278], [1033, 1241, 1072, 1269], [1087, 1241, 1224, 1269], [1240, 1241, 1270, 1269], [1286, 1245, 1402, 1270], [1418, 1241, 1508, 1278], [1523, 1241, 1736, 1269], [1752, 1241, 1900, 1275], [1919, 1241, 1976, 1269], [1992, 1241, 2016, 1269], [2035, 1241, 2099, 1269], [450, 1287, 629, 1324], [641, 1287, 725, 1315], [736, 1287, 874, 1315], [887, 1287, 923, 1315], [932, 1287, 1067, 1324], [1079, 1287, 1162, 1316], [1174, 1287, 1372, 1324], [1388, 1288, 1427, 1321], [1440, 1287, 1503, 1321], [451, 1358, 507, 1385], [517, 1366, 533, 1385], [543, 1357, 669, 1385], [678, 1357, 714, 1385], [721, 1357, 882, 1394], [890, 1357, 1052, 1394], [1065, 1357, 1210, 1385], [1219, 1357, 1469, 1394], [1480, 1357, 1516, 1385], [1523, 1357, 1689, 1386], [1699, 1357, 1797, 1386], [1808, 1357, 1848, 1385], [1858, 1361, 1911, 1385], [1920, 1357, 2036, 1391], [2047, 1357, 2100, 1385], [451, 1403, 566, 1431], [577, 1412, 593, 1431], [604, 1403, 748, 1431], [757, 1403, 992, 1440], [1002, 1403, 1037, 1431], [1045, 1412, 1061, 1431], [1071, 1403, 1166, 1440], [1176, 1407, 1409, 1440], [1413, 1427, 1418, 1431], [1435, 1412, 1451, 1431], [1459, 1403, 1567, 1440], [1577, 1412, 1610, 1431], [1620, 1412, 1636, 1431], [1647, 1403, 1855, 1431], [1865, 1403, 2011, 1440], [2027, 1403, 2097, 1431], [451, 1458, 511, 1478], [523, 1449, 711, 1486], [722, 1449, 753, 1477], [767, 1449, 840, 1483], [853, 1449, 923, 1478], [933, 1449, 1084, 1486], [1096, 1458, 1112, 1477], [1123, 1449, 1311, 1477], [1321, 1449, 1369, 1477], [1379, 1449, 1550, 1486], [1562, 1458, 1578, 1477], [1589, 1449, 1698, 1478], [1710, 1449, 1944, 1486], [1954, 1449, 2048, 1477], [2059, 1458, 2099, 1477], [451, 1494, 487, 1522], [500, 1494, 666, 1523], [677, 1498, 806, 1522], [822, 1494, 885, 1522], [897, 1494, 1116, 1522], [1129, 1498, 1256, 1522], [1267, 1494, 1303, 1522], [1313, 1494, 1472, 1522], [1485, 1503, 1550, 1528], [1564, 1494, 1622, 1522], [1634, 1498, 1664, 1522], [1677, 1494, 1810, 1531], [1823, 1498, 1876, 1522], [1885, 1494, 1924, 1522], [1937, 1494, 2056, 1531], [2068, 1498, 2099, 1522], [452, 1540, 525, 1568], [537, 1540, 633, 1577], [644, 1540, 796, 1577], [809, 1540, 897, 1568], [915, 1540, 943, 1568], [956, 1540, 1077, 1568], [1089, 1540, 1248, 1577], [1259, 1540, 1386, 1577], [1400, 1540, 1425, 1568], [1439, 1540, 1550, 1568], [1564, 1540, 1621, 1568], [1632, 1540, 1814, 1577], [1829, 1540, 1882, 1574], [1896, 1540, 1966, 1569], [1978, 1540, 2099, 1568], [451, 1586, 670, 1614], [681, 1586, 930, 1623], [944, 1586, 991, 1614], [1004, 1586, 1149, 1623], [1161, 1595, 1243, 1614], [1254, 1586, 1332, 1623], [1345, 1586, 1434, 1623], [1448, 1595, 1464, 1614], [1476, 1586, 1689, 1614], [1702, 1586, 1851, 1623], [1864, 1595, 1903, 1614], [1917, 1595, 1933, 1614], [1945, 1595, 2052, 1623], [2066, 1586, 2102, 1614], [450, 1631, 691, 1668], [703, 1631, 774, 1659], [790, 1631, 853, 1659], [863, 1631, 980, 1668], [990, 1631, 1239, 1668], [1252, 1631, 1372, 1659], [1384, 1631, 1463, 1659], [1474, 1631, 1536, 1659], [1546, 1640, 1653, 1668], [1666, 1640, 1745, 1660], [1757, 1631, 1971, 1668], [1982, 1631, 2057, 1659], [2068, 1635, 2099, 1659], [451, 1677, 532, 1705], [544, 1677, 719, 1705], [731, 1677, 935, 1714], [947, 1677, 1098, 1705], [1112, 1677, 1159, 1705], [1170, 1677, 1220, 1705], [1232, 1677, 1413, 1705], [1424, 1677, 1532, 1706], [451, 1749, 535, 1776], [554, 1748, 725, 1777], [744, 1752, 881, 1785], [901, 1752, 931, 1776], [950, 1752, 1061, 1776], [1080, 1748, 1153, 1776], [1171, 1748, 1368, 1785], [1388, 1748, 1532, 1776], [1550, 1748, 1799, 1785], [1818, 1748, 1895, 1777], [1913, 1748, 2040, 1776], [2059, 1757, 2099, 1776], [451, 1793, 585, 1830], [601, 1793, 805, 1830], [821, 1793, 972, 1821], [990, 1793, 1052, 1821], [1066, 1797, 1219, 1830], [1234, 1793, 1283, 1821], [1300, 1793, 1460, 1821], [1478, 1793, 1513, 1821], [1528, 1802, 1544, 1821], [1560, 1793, 1655, 1830], [1672, 1797, 1815, 1821], [1832, 1802, 1862, 1821], [1881, 1802, 1897, 1821], [1913, 1793, 2050, 1821], [2066, 1793, 2102, 1821], [451, 1839, 500, 1867], [510, 1839, 759, 1876], [771, 1839, 807, 1867], [815, 1839, 851, 1867], [863, 1843, 951, 1876], [970, 1839, 1032, 1873], [1045, 1839, 1185, 1876], [1199, 1848, 1235, 1867], [1246, 1839, 1415, 1868], [1426, 1839, 1462, 1867], [1471, 1848, 1487, 1867], [1498, 1839, 1624, 1867], [1634, 1839, 1670, 1867], [1679, 1839, 1788, 1876], [1798, 1839, 2002, 1876], [2013, 1839, 2098, 1867], [451, 1884, 528, 1912], [545, 1884, 664, 1921], [679, 1888, 709, 1912], [723, 1884, 864, 1921], [887, 1884, 1019, 1921], [1033, 1884, 1221, 1921], [1238, 1884, 1312, 1912], [1327, 1884, 1510, 1921], [1526, 1893, 1581, 1912], [1596, 1884, 1665, 1912], [1680, 1884, 1775, 1921], [1788, 1884, 1827, 1912], [1840, 1884, 2012, 1912], [2027, 1884, 2099, 1913], [451, 1930, 500, 1958], [515, 1939, 749, 1958], [764, 1930, 857, 1958], [873, 1930, 956, 1959], [972, 1930, 1050, 1959], [1064, 1930, 1324, 1967], [1351, 1930, 1447, 1958], [1463, 1939, 1512, 1958], [1528, 1939, 1544, 1958], [1560, 1930, 1686, 1958], [1701, 1930, 1736, 1958], [1748, 1930, 1905, 1967], [1923, 1930, 2099, 1967], [452, 1976, 525, 2004], [535, 1976, 685, 2005], [696, 1985, 730, 2004], [740, 1976, 817, 2013], [828, 1976, 1031, 2013], [1043, 1976, 1170, 2004], [1186, 1976, 1324, 2013], [1340, 1976, 1380, 2010], [1394, 1985, 1525, 2013], [1536, 1985, 1552, 2004], [1563, 1976, 1771, 2004], [1782, 1976, 1884, 2004], [1895, 1976, 1943, 2004], [1954, 1976, 2098, 2004], [451, 2021, 654, 2058], [670, 2021, 736, 2055], [754, 2021, 905, 2058], [925, 2021, 966, 2055], [984, 2021, 1112, 2058], [1128, 2030, 1144, 2049], [1158, 2021, 1338, 2050], [1352, 2021, 1400, 2049], [1415, 2021, 1559, 2049], [1574, 2021, 1778, 2058], [1792, 2021, 1833, 2058], [1848, 2021, 2023, 2058], [2038, 2021, 2098, 2049], [451, 2067, 621, 2095], [637, 2067, 742, 2104], [758, 2067, 830, 2096], [845, 2076, 994, 2104], [1010, 2076, 1183, 2104], [1212, 2067, 1275, 2095], [1291, 2067, 1376, 2095], [1391, 2067, 1571, 2096], [1587, 2076, 1648, 2096], [1665, 2067, 1853, 2104], [1869, 2067, 2024, 2096], [2042, 2067, 2099, 2095], [452, 2113, 612, 2150], [627, 2113, 668, 2150], [684, 2113, 733, 2141], [748, 2113, 854, 2141], [871, 2113, 901, 2141], [920, 2113, 993, 2147], [1021, 2114, 1109, 2141], [1124, 2113, 1263, 2150], [1281, 2113, 1399, 2142], [1416, 2113, 1510, 2141], [1527, 2113, 1563, 2141], [1575, 2113, 1725, 2142], [1740, 2113, 1842, 2141], [1858, 2113, 2006, 2142], [2023, 2113, 2099, 2142], [452, 2158, 652, 2195], [663, 2158, 740, 2186], [751, 2158, 827, 2186], [839, 2158, 886, 2186], [898, 2158, 1043, 2186], [1055, 2158, 1259, 2195], [1272, 2158, 1329, 2186], [1340, 2158, 1452, 2186], [1464, 2158, 1544, 2186], [1559, 2158, 1632, 2186], [1645, 2167, 1675, 2186], [1690, 2158, 1850, 2186], [1861, 2158, 2001, 2195], [2018, 2158, 2099, 2187], [451, 2204, 567, 2232], [585, 2204, 705, 2232], [720, 2204, 870, 2233], [887, 2204, 1102, 2232], [1122, 2204, 1195, 2238], [1214, 2204, 1438, 2233], [1452, 2204, 1602, 2233], [1618, 2204, 1720, 2232], [1736, 2204, 1885, 2233], [1905, 2203, 1978, 2238], [1996, 2204, 2099, 2232], [450, 2250, 600, 2279], [611, 2250, 714, 2278], [725, 2250, 874, 2279], [891, 2250, 952, 2284], [967, 2259, 1001, 2278], [1012, 2250, 1236, 2279], [1248, 2250, 1397, 2279], [1413, 2249, 1487, 2284], [451, 2371, 499, 2401], [544, 2371, 764, 2409], [776, 2371, 995, 2409], [451, 2465, 546, 2493], [562, 2465, 699, 2493], [715, 2465, 768, 2493], [786, 2465, 863, 2493], [880, 2465, 1008, 2494], [1025, 2469, 1056, 2493], [1072, 2465, 1122, 2493], [1138, 2465, 1205, 2493], [1221, 2465, 1256, 2493], [1270, 2465, 1414, 2502], [1431, 2465, 1606, 2493], [1624, 2465, 1768, 2493], [1785, 2465, 2034, 2502], [2052, 2465, 2100, 2493], [452, 2510, 548, 2547], [562, 2510, 735, 2547], [758, 2511, 791, 2538], [804, 2510, 964, 2547], [977, 2510, 1111, 2547], [1128, 2510, 1200, 2539], [1214, 2510, 1250, 2538], [1266, 2510, 1347, 2547], [1361, 2510, 1487, 2538], [1500, 2510, 1536, 2538], [1548, 2510, 1707, 2538], [1720, 2519, 1885, 2544], [1901, 2510, 1954, 2538], [1970, 2510, 2099, 2547], [451, 2560, 531, 2584], [540, 2556, 692, 2584], [707, 2556, 859, 2593], [870, 2565, 1009, 2593], [1019, 2556, 1072, 2584], [1083, 2556, 1160, 2584], [1170, 2556, 1259, 2584], [1269, 2560, 1298, 2584], [1306, 2556, 1540, 2593], [1550, 2556, 1684, 2593], [1694, 2556, 1742, 2584], [1751, 2556, 1914, 2593], [1925, 2556, 1997, 2585], [2007, 2556, 2100, 2585], [452, 2602, 597, 2631], [609, 2611, 774, 2630], [794, 2602, 985, 2631], [998, 2606, 1028, 2630], [1041, 2602, 1077, 2630], [1095, 2602, 1156, 2636], [1173, 2602, 1330, 2630], [1345, 2611, 1361, 2630], [1374, 2602, 1453, 2630], [1466, 2602, 1502, 2630], [1512, 2602, 1666, 2630], [1679, 2602, 1813, 2639], [1826, 2611, 1866, 2630], [1880, 2602, 2099, 2639], [450, 2647, 573, 2684], [589, 2647, 657, 2675], [672, 2651, 703, 2675], [719, 2647, 845, 2675], [860, 2647, 1057, 2684], [1074, 2647, 1154, 2675], [1169, 2656, 1228, 2675], [1243, 2647, 1392, 2684], [1407, 2651, 1438, 2675], [1455, 2647, 1583, 2675], [1610, 2647, 1722, 2675], [1737, 2647, 1829, 2681], [1847, 2647, 2000, 2684], [2016, 2651, 2046, 2675], [2061, 2647, 2097, 2675], [454, 2693, 527, 2727], [539, 2693, 690, 2730], [702, 2702, 718, 2721], [729, 2693, 851, 2721], [863, 2693, 910, 2721], [920, 2693, 1064, 2730], [1075, 2693, 1288, 2730], [1298, 2693, 1396, 2721], [1405, 2693, 1494, 2730], [1506, 2693, 1714, 2730], [1725, 2693, 1838, 2721], [1848, 2693, 2097, 2730], [452, 2739, 509, 2767], [522, 2748, 538, 2767], [552, 2739, 639, 2767], [651, 2739, 747, 2767], [759, 2739, 879, 2767], [891, 2743, 922, 2767], [934, 2739, 1087, 2776], [1100, 2739, 1181, 2768], [1198, 2739, 1269, 2767], [1284, 2739, 1433, 2776], [1445, 2739, 1498, 2767], [1511, 2739, 1644, 2776], [1656, 2739, 1733, 2767], [1746, 2739, 1893, 2767], [1905, 2739, 1946, 2776], [1961, 2739, 2021, 2773], [2039, 2739, 2097, 2773], [451, 2784, 520, 2813], [536, 2784, 703, 2821], [720, 2793, 736, 2812], [751, 2784, 874, 2812], [890, 2784, 937, 2812], [952, 2784, 1086, 2821], [1102, 2784, 1345, 2812], [1360, 2784, 1498, 2812], [1515, 2788, 1545, 2812], [1561, 2788, 1683, 2813], [1698, 2784, 1842, 2812], [1859, 2788, 1975, 2813], [1992, 2784, 2028, 2812], [2041, 2793, 2099, 2812], [451, 2830, 599, 2867], [613, 2830, 676, 2858], [691, 2830, 777, 2858], [791, 2830, 827, 2858], [840, 2830, 968, 2858], [991, 2831, 1018, 2858], [1034, 2839, 1095, 2859], [1111, 2830, 1333, 2858], [1348, 2830, 1409, 2858], [1423, 2830, 1480, 2858], [1497, 2830, 1646, 2867], [1661, 2839, 1717, 2858], [1730, 2830, 1769, 2858], [1784, 2830, 1904, 2867], [1918, 2834, 1949, 2858], [1963, 2830, 2099, 2867], [451, 2876, 530, 2904], [544, 2876, 656, 2904], [669, 2880, 700, 2904], [713, 2876, 852, 2904], [865, 2876, 1048, 2904], [1067, 2876, 1156, 2904], [1169, 2876, 1291, 2905], [1303, 2876, 1405, 2904], [1418, 2876, 1443, 2904], [1459, 2876, 1523, 2904], [1536, 2876, 1631, 2905], [1644, 2876, 1748, 2913], [1762, 2876, 1809, 2904], [1821, 2876, 1858, 2904], [1873, 2876, 2054, 2904], [2068, 2880, 2099, 2904], [451, 2921, 500, 2949], [513, 2921, 717, 2958], [730, 2921, 867, 2949], [879, 2921, 955, 2949], [968, 2921, 999, 2949], [1012, 2921, 1069, 2949], [1083, 2930, 1181, 2958], [1202, 2921, 1299, 2958], [1314, 2930, 1330, 2949], [1344, 2921, 1466, 2958], [1479, 2921, 1621, 2949], [1634, 2921, 1792, 2958], [1811, 2921, 1884, 2955], [1901, 2921, 1965, 2949], [1978, 2921, 2099, 2949], [450, 2967, 597, 3004], [614, 2967, 812, 3004], [831, 2967, 879, 2995], [896, 2967, 1035, 2995], [1052, 2967, 1235, 2995], [1268, 2968, 1293, 2995], [1310, 2967, 1334, 2995], [1353, 2967, 1514, 3004], [1531, 2971, 1562, 2995], [1579, 2971, 1650, 2995], [1667, 2967, 1736, 3001], [1756, 2967, 1859, 2995], [1877, 2976, 1931, 2995], [1947, 2967, 2099, 3004], [452, 3017, 573, 3050], [588, 3013, 627, 3041], [638, 3013, 674, 3041], [683, 3013, 767, 3041], [779, 3013, 917, 3041], [929, 3013, 1046, 3050], [1058, 3013, 1141, 3042], [1154, 3013, 1274, 3050], [1285, 3013, 1409, 3050], [1421, 3013, 1489, 3041], [1500, 3013, 1548, 3041], [1559, 3013, 1695, 3050], [1265, 3137, 1284, 3165], [451, 355, 521, 383], [530, 358, 632, 382], [641, 354, 803, 391], [812, 363, 918, 391], [929, 354, 1054, 383], [1064, 354, 1198, 382], [1208, 354, 1239, 382], [1249, 354, 1306, 382], [1316, 358, 1442, 391], [1457, 354, 1536, 382], [1547, 354, 1642, 391], [1652, 358, 1681, 382], [1691, 354, 1727, 382], [1742, 354, 1803, 388], [1817, 354, 1875, 382], [1886, 354, 1989, 383], [1999, 354, 2098, 383], [451, 400, 503, 428], [512, 404, 541, 428], [551, 400, 587, 428], [601, 400, 663, 434], [675, 409, 806, 437], [815, 400, 953, 428], [964, 400, 1012, 428], [1021, 400, 1155, 437], [1165, 400, 1248, 429], [1258, 400, 1455, 437], [1466, 400, 1506, 437], [1516, 400, 1682, 437], [1691, 400, 1838, 437], [1848, 400, 1924, 434], [1936, 404, 1988, 428], [1996, 400, 2099, 428], [451, 445, 500, 473], [512, 445, 635, 473], [647, 445, 798, 482], [811, 445, 841, 473], [854, 445, 911, 473], [924, 454, 1022, 482], [1039, 445, 1158, 473], [1170, 445, 1206, 473], [1216, 445, 1265, 473], [1277, 445, 1558, 474], [1570, 445, 1693, 473], [1706, 445, 1873, 482], [1885, 445, 1916, 473], [1929, 445, 1986, 473], [1999, 454, 2097, 482], [450, 491, 523, 519], [540, 500, 650, 528], [669, 491, 705, 519], [720, 491, 838, 519], [857, 491, 945, 519], [961, 500, 1016, 519], [1033, 491, 1069, 519], [1085, 491, 1300, 519], [1318, 495, 1349, 519], [1367, 491, 1483, 519], [1500, 491, 1708, 528], [1724, 491, 1974, 528], [1994, 491, 2051, 519], [2068, 495, 2099, 519], [452, 541, 574, 574], [585, 537, 635, 565], [646, 537, 793, 574], [805, 537, 936, 565], [452, 607, 493, 636], [505, 607, 550, 635], [562, 607, 671, 635], [683, 607, 722, 635], [734, 607, 770, 635], [779, 607, 836, 635], [850, 607, 934, 636], [944, 607, 998, 635], [1010, 607, 1088, 635], [1100, 607, 1228, 635], [1240, 616, 1280, 635], [1292, 607, 1426, 644], [1438, 607, 1640, 644], [1651, 607, 1900, 644], [1915, 611, 1943, 635], [1954, 607, 2004, 635], [2016, 607, 2099, 636], [451, 653, 537, 682], [553, 653, 596, 681], [609, 653, 784, 681], [795, 653, 1044, 690], [1057, 653, 1093, 681], [1102, 653, 1197, 690], [1208, 653, 1398, 690], [1410, 653, 1487, 682], [1497, 653, 1575, 681], [1588, 653, 1692, 682], [1704, 657, 1735, 681], [1746, 653, 1784, 681], [1795, 653, 1900, 690], [1911, 653, 2012, 681], [2024, 653, 2071, 681], [2083, 662, 2099, 681], [451, 699, 576, 727], [587, 699, 623, 727], [631, 699, 721, 733], [734, 699, 757, 727], [768, 708, 865, 727], [878, 703, 908, 727], [918, 699, 957, 727], [969, 708, 985, 727], [996, 699, 1110, 727], [1121, 703, 1191, 727], [1202, 703, 1266, 736], [1278, 703, 1308, 727], [1320, 699, 1384, 727], [1397, 703, 1520, 736], [1530, 703, 1560, 727], [1572, 699, 1681, 727], [1692, 699, 1776, 727], [1786, 699, 1875, 736], [1886, 699, 2099, 736], [451, 744, 527, 772], [543, 744, 614, 772], [626, 753, 718, 781], [729, 744, 869, 781], [883, 753, 899, 772], [911, 744, 975, 772], [987, 748, 1051, 781], [1063, 744, 1094, 772], [1106, 744, 1168, 772], [1179, 744, 1333, 772], [451, 860, 473, 895], [525, 860, 659, 895], [673, 860, 918, 904], [451, 967, 613, 1003], [629, 966, 808, 1003], [823, 966, 854, 994], [868, 966, 995, 994], [1012, 966, 1036, 994], [1053, 966, 1164, 1003], [1180, 975, 1251, 994], [1267, 975, 1298, 994], [1315, 966, 1470, 1003], [1485, 966, 1515, 994], [1531, 970, 1769, 1003], [1784, 966, 1961, 1003], [1979, 966, 2039, 1000], [2056, 966, 2097, 1000], [451, 1011, 550, 1039], [567, 1020, 607, 1039], [624, 1011, 680, 1039], [699, 1011, 775, 1045], [795, 1011, 876, 1039], [892, 1011, 968, 1040], [984, 1011, 1061, 1039], [1079, 1020, 1164, 1039], [1182, 1015, 1318, 1048], [1338, 1015, 1366, 1039], [1381, 1011, 1470, 1048], [1487, 1011, 1690, 1039], [1707, 1011, 1775, 1039], [1791, 1011, 1839, 1039], [1855, 1011, 1989, 1048], [2005, 1011, 2100, 1039], [451, 1061, 553, 1086], [565, 1057, 814, 1094], [829, 1057, 865, 1085], [876, 1057, 974, 1086], [990, 1057, 1051, 1094], [1055, 1081, 1060, 1085], [1084, 1057, 1171, 1092], [1194, 1057, 1274, 1086], [1288, 1057, 1436, 1091], [1451, 1057, 1598, 1091], [1615, 1066, 1663, 1085], [1677, 1061, 1729, 1085], [1742, 1057, 1837, 1094], [1852, 1057, 1983, 1085], [1998, 1066, 2097, 1085], [451, 1103, 613, 1140], [627, 1112, 661, 1131], [672, 1107, 702, 1131], [715, 1103, 795, 1140], [808, 1107, 945, 1131], [958, 1103, 994, 1131], [1003, 1103, 1071, 1131], [1083, 1103, 1130, 1131], [1141, 1103, 1241, 1132], [1253, 1112, 1293, 1131], [1306, 1103, 1472, 1140], [1484, 1112, 1518, 1131], [1529, 1103, 1647, 1140], [1658, 1103, 1892, 1140], [1905, 1103, 2001, 1140], [2012, 1103, 2097, 1131], [450, 1174, 503, 1201], [520, 1173, 648, 1201], [663, 1173, 712, 1201], [727, 1173, 906, 1210], [921, 1173, 1069, 1210], [1085, 1182, 1143, 1201], [1160, 1177, 1224, 1210], [1240, 1173, 1352, 1201], [1369, 1173, 1426, 1201], [1443, 1177, 1566, 1210], [1581, 1177, 1612, 1201], [1628, 1173, 1709, 1201], [1727, 1173, 1886, 1201], [1904, 1173, 1983, 1201], [1999, 1173, 2098, 1201], [451, 1219, 564, 1256], [578, 1219, 654, 1247], [677, 1219, 740, 1247], [754, 1219, 821, 1247], [835, 1219, 860, 1247], [875, 1219, 945, 1253], [961, 1219, 1050, 1256], [1064, 1219, 1184, 1256], [1198, 1219, 1322, 1256], [1335, 1219, 1412, 1253], [1429, 1228, 1445, 1247], [1460, 1219, 1565, 1247], [1579, 1219, 1813, 1256], [1827, 1219, 1929, 1248], [1942, 1219, 1981, 1247], [1994, 1219, 2099, 1247], [451, 1269, 481, 1293], [497, 1269, 618, 1302], [633, 1265, 682, 1293], [698, 1274, 842, 1293], [857, 1265, 1002, 1293], [1018, 1265, 1156, 1294], [1173, 1269, 1327, 1293], [1345, 1265, 1424, 1293], [1440, 1265, 1581, 1293], [1596, 1265, 1769, 1302], [1795, 1265, 1885, 1293], [1900, 1269, 1960, 1294], [1975, 1265, 2099, 1302], [452, 1314, 606, 1338], [620, 1310, 697, 1339], [710, 1310, 740, 1338], [753, 1319, 906, 1344], [921, 1310, 957, 1338], [967, 1319, 1082, 1344], [1097, 1310, 1122, 1338], [1137, 1310, 1186, 1338], [1200, 1310, 1360, 1338], [1374, 1310, 1410, 1338], [1420, 1310, 1506, 1338], [1519, 1314, 1579, 1339], [1594, 1314, 1759, 1338], [1779, 1310, 1876, 1347], [1889, 1310, 1946, 1338], [1961, 1310, 2037, 1344], [2052, 1319, 2099, 1339], [450, 1365, 580, 1393], [593, 1365, 609, 1384], [621, 1356, 711, 1385], [722, 1356, 845, 1384], [857, 1356, 905, 1384], [916, 1356, 1050, 1393], [1063, 1360, 1165, 1385], [1175, 1356, 1424, 1393], [1439, 1360, 1467, 1384], [1478, 1356, 1527, 1384], [1539, 1356, 1622, 1385], [1634, 1356, 1712, 1385], [1725, 1356, 1782, 1384], [1793, 1356, 1923, 1393], [451, 1461, 499, 1491], [544, 1461, 704, 1499], [716, 1461, 825, 1499], [451, 1548, 624, 1585], [640, 1548, 689, 1576], [705, 1548, 850, 1576], [867, 1548, 1023, 1585], [1039, 1548, 1075, 1576], [1087, 1548, 1211, 1585], [1227, 1552, 1382, 1576], [1400, 1557, 1500, 1576], [1517, 1548, 1690, 1585], [1708, 1557, 1755, 1577], [1770, 1557, 1826, 1576], [1842, 1548, 1942, 1576], [1958, 1557, 1974, 1576], [1991, 1548, 2099, 1585], [450, 1594, 597, 1631], [616, 1594, 687, 1629], [706, 1594, 835, 1631], [853, 1594, 1067, 1631], [1087, 1603, 1167, 1622], [1185, 1594, 1321, 1622], [1341, 1603, 1372, 1622], [1392, 1594, 1522, 1623], [1553, 1594, 1651, 1623], [1671, 1603, 1687, 1622], [1705, 1594, 1939, 1631], [1959, 1598, 2099, 1622], [451, 1639, 553, 1667], [569, 1639, 640, 1674], [645, 1639, 693, 1674], [710, 1638, 783, 1673], [788, 1663, 794, 1673], [812, 1639, 911, 1668], [927, 1648, 1011, 1676], [1029, 1648, 1045, 1667], [1061, 1643, 1201, 1667], [1216, 1643, 1247, 1667], [1263, 1648, 1279, 1667], [1294, 1643, 1403, 1673], [1420, 1648, 1467, 1668], [1482, 1648, 1538, 1667], [1554, 1639, 1628, 1667], [1644, 1648, 1660, 1667], [1676, 1639, 1789, 1667], [1805, 1639, 1902, 1668], [1919, 1638, 1991, 1673], [2010, 1639, 2099, 1676], [452, 1694, 468, 1713], [484, 1694, 591, 1722], [610, 1684, 689, 1725], [710, 1685, 746, 1713], [759, 1685, 883, 1722], [899, 1685, 967, 1713], [983, 1685, 1063, 1713], [1079, 1685, 1128, 1713], [1145, 1685, 1293, 1722], [1309, 1685, 1373, 1722], [1389, 1683, 1427, 1721], [1440, 1685, 1469, 1713], [1474, 1709, 1479, 1713], [1510, 1686, 1566, 1713], [1582, 1685, 1656, 1713], [1672, 1685, 1736, 1722], [1752, 1685, 1788, 1713], [1801, 1685, 1925, 1722], [1942, 1689, 2097, 1713], [454, 1728, 496, 1769], [508, 1728, 536, 1769], [555, 1737, 576, 1761], [592, 1730, 671, 1771], [678, 1755, 684, 1765], [698, 1740, 745, 1760], [758, 1735, 881, 1768], [891, 1735, 922, 1759], [934, 1731, 1089, 1759], [1020, 1814, 1154, 1855], [1166, 1814, 1194, 1855], [1212, 1814, 1356, 1855], [1372, 1834, 1398, 1835], [1413, 1814, 1507, 1855], [1515, 1805, 1528, 1824], [2053, 1817, 2098, 1852], [451, 1893, 550, 1922], [563, 1903, 643, 1927], [658, 1893, 683, 1921], [696, 1893, 746, 1921], [757, 1897, 860, 1922], [870, 1893, 1074, 1930], [1088, 1897, 1228, 1921], [1241, 1903, 1260, 1921], [1273, 1893, 1330, 1921], [1343, 1892, 1419, 1927], [1434, 1893, 1484, 1921], [1495, 1897, 1598, 1922], [1608, 1893, 1812, 1930], [1826, 1897, 1966, 1921], [1979, 1892, 2003, 1921], [451, 1998, 501, 2028], [544, 1999, 612, 2028], [625, 1998, 765, 2028], [778, 1999, 890, 2028], [451, 2085, 479, 2113], [492, 2085, 588, 2114], [602, 2085, 698, 2113], [712, 2085, 856, 2113], [868, 2085, 1117, 2122], [1130, 2085, 1166, 2113], [1175, 2085, 1270, 2122], [1282, 2085, 1426, 2122], [1438, 2085, 1516, 2113], [1530, 2085, 1619, 2122], [1631, 2085, 1680, 2113], [1692, 2085, 1837, 2113], [1848, 2085, 2097, 2122], [451, 2130, 486, 2158], [495, 2130, 571, 2158], [582, 2130, 787, 2158], [803, 2131, 856, 2158], [869, 2139, 989, 2158], [1001, 2130, 1167, 2159], [1178, 2130, 1276, 2159], [1290, 2134, 1320, 2158], [1332, 2130, 1370, 2158], [1381, 2130, 1572, 2167], [1583, 2130, 1624, 2167], [1636, 2134, 1752, 2159], [1766, 2130, 1800, 2165], [1816, 2136, 1837, 2160], [1854, 2123, 1924, 2165], [451, 2201, 592, 2230], [607, 2201, 744, 2229], [759, 2201, 882, 2238], [894, 2201, 999, 2238], [1012, 2210, 1099, 2238], [1113, 2205, 1188, 2229], [1203, 2210, 1243, 2229], [1256, 2201, 1305, 2229], [1319, 2201, 1386, 2229], [1401, 2201, 1461, 2238], [1465, 2225, 1470, 2229], [1494, 2201, 1553, 2235], [1568, 2200, 1635, 2236], [1650, 2201, 1708, 2229], [1720, 2210, 1775, 2229], [1789, 2201, 1939, 2238], [1953, 2210, 1986, 2229], [1999, 2201, 2098, 2229], [450, 2247, 590, 2284], [603, 2247, 806, 2284], [819, 2247, 981, 2275], [1000, 2247, 1102, 2276], [1115, 2247, 1189, 2275], [1203, 2256, 1219, 2275], [1232, 2251, 1326, 2284], [1341, 2247, 1441, 2276], [1453, 2247, 1528, 2275], [1540, 2247, 1620, 2275], [1632, 2247, 1663, 2275], [1676, 2247, 1725, 2275], [1738, 2251, 1798, 2275], [1811, 2247, 1836, 2275], [1850, 2247, 1987, 2275], [1999, 2256, 2033, 2275], [2044, 2247, 2097, 2275], [451, 2296, 511, 2321], [523, 2292, 657, 2320], [670, 2292, 702, 2328], [716, 2299, 753, 2320], [769, 2302, 800, 2327], [808, 2316, 812, 2328], [824, 2302, 854, 2326], [860, 2292, 881, 2327], [896, 2301, 912, 2320], [922, 2292, 1028, 2329], [1040, 2292, 1243, 2329], [1256, 2292, 1392, 2320], [1404, 2292, 1495, 2320], [1507, 2292, 1574, 2320], [1586, 2292, 1635, 2320], [1647, 2292, 1806, 2329], [1818, 2292, 1906, 2320], [1073, 2365, 1471, 2406], [2053, 2368, 2098, 2403], [451, 2452, 550, 2481], [568, 2449, 619, 2490], [632, 2449, 673, 2490], [691, 2452, 715, 2480], [731, 2452, 780, 2480], [794, 2452, 1022, 2480], [1036, 2452, 1072, 2480], [1083, 2452, 1132, 2480], [1146, 2456, 1206, 2481], [1220, 2452, 1301, 2480], [1315, 2456, 1441, 2486], [1458, 2452, 1500, 2481], [1503, 2452, 1515, 2465], [1537, 2458, 1558, 2482], [1577, 2445, 1683, 2480], [1699, 2452, 1756, 2480], [1771, 2451, 1801, 2480], [1823, 2458, 1844, 2482], [1863, 2445, 1909, 2480], [1925, 2452, 1974, 2480], [1988, 2452, 2098, 2480], [451, 2498, 502, 2535], [515, 2498, 622, 2526], [636, 2498, 693, 2526], [706, 2498, 781, 2532], [795, 2498, 999, 2535], [1016, 2498, 1073, 2526], [1086, 2508, 1105, 2535], [1120, 2507, 1157, 2526], [1170, 2498, 1390, 2527], [1404, 2498, 1563, 2527], [1577, 2498, 1713, 2526], [1728, 2498, 1801, 2526], [1815, 2507, 1846, 2526], [1861, 2498, 1910, 2526], [1922, 2498, 2098, 2535], [451, 2547, 580, 2580], [599, 2544, 656, 2571], [668, 2543, 717, 2571], [729, 2552, 875, 2580], [889, 2543, 925, 2571], [935, 2543, 1105, 2572], [1118, 2543, 1167, 2571], [1179, 2543, 1326, 2580], [1340, 2543, 1437, 2580], [1449, 2543, 1600, 2580], [1615, 2543, 1719, 2577], [1734, 2552, 1781, 2572], [1795, 2543, 1930, 2580], [1944, 2543, 2001, 2571], [2015, 2552, 2098, 2571], [450, 2589, 583, 2626], [597, 2589, 734, 2617], [748, 2589, 788, 2626], [804, 2589, 912, 2626], [928, 2589, 967, 2617], [981, 2589, 1094, 2626], [1107, 2589, 1244, 2617], [1261, 2593, 1291, 2617], [1306, 2589, 1355, 2617], [1369, 2589, 1495, 2626], [1510, 2589, 1567, 2617], [1583, 2589, 1622, 2617], [1636, 2589, 1735, 2617], [1751, 2593, 1781, 2617], [1796, 2598, 1875, 2617], [1899, 2589, 2035, 2626], [2050, 2589, 2099, 2617], [452, 2635, 548, 2664], [561, 2635, 685, 2663], [699, 2639, 729, 2663], [742, 2644, 758, 2663], [771, 2635, 880, 2672], [892, 2635, 1022, 2664], [1034, 2635, 1237, 2672], [1250, 2635, 1395, 2663], [1155, 2770, 1235, 2794], [1252, 2773, 1280, 2782], [1309, 2710, 1339, 2739], [1296, 2748, 1352, 2806], [1298, 2818, 1349, 2838], [1363, 2770, 1392, 2794], [2053, 2760, 2098, 2795], [451, 2876, 495, 2905], [510, 2885, 625, 2910], [645, 2876, 702, 2904], [721, 2876, 745, 2904], [765, 2885, 781, 2904], [798, 2885, 869, 2913], [888, 2876, 1051, 2913], [1069, 2876, 1176, 2910], [1196, 2885, 1226, 2904], [1246, 2876, 1319, 2904], [1337, 2885, 1353, 2904], [1369, 2876, 1590, 2913], [1610, 2876, 1759, 2913], [1777, 2885, 1816, 2904], [1834, 2876, 1939, 2913], [1956, 2880, 2097, 2904], [451, 2921, 498, 2949], [515, 2921, 598, 2950], [616, 2921, 754, 2958], [773, 2921, 830, 2949], [848, 2921, 932, 2949], [949, 2921, 1055, 2949], [1074, 2921, 1174, 2950], [1193, 2930, 1209, 2949], [1226, 2930, 1310, 2949], [1327, 2921, 1468, 2958], [1486, 2921, 1583, 2950], [1602, 2921, 1698, 2958], [1715, 2925, 1844, 2958], [1877, 2922, 2031, 2955], [2052, 2921, 2100, 2949], [451, 2967, 500, 2995], [515, 2976, 660, 3004], [678, 2967, 713, 2995], [727, 2967, 784, 2995], [801, 2967, 970, 2996], [987, 2967, 1058, 3002], [1075, 2967, 1147, 2996], [1163, 2967, 1212, 2995], [1228, 2967, 1443, 3004], [1459, 2967, 1628, 2996], [1644, 2967, 1674, 2995], [1691, 2967, 1797, 3002], [1817, 2967, 1890, 2995], [1907, 2976, 1923, 2995], [1940, 2967, 2098, 3004], [451, 3013, 654, 3050], [666, 3013, 803, 3041], [816, 3013, 924, 3041], [935, 3013, 974, 3041], [987, 3013, 1138, 3041], [1149, 3017, 1180, 3041], [1192, 3013, 1327, 3042], [1339, 3013, 1388, 3041], [1400, 3013, 1489, 3042], [1501, 3013, 1650, 3050], [1662, 3013, 1799, 3041], [1810, 3013, 1961, 3050], [1972, 3013, 2052, 3041], [1266, 3137, 1282, 3166], [451, 1216, 557, 1253], [578, 1216, 602, 1244], [628, 1216, 820, 1253], [837, 1216, 873, 1244], [887, 1225, 903, 1244], [919, 1216, 1066, 1253], [1082, 1216, 1185, 1244], [1201, 1216, 1273, 1245], [1289, 1216, 1413, 1253], [1429, 1216, 1514, 1253], [1531, 1220, 1686, 1244], [1705, 1226, 1724, 1244], [1742, 1216, 1799, 1244], [1817, 1215, 1840, 1244], [1870, 1216, 1934, 1244], [1950, 1216, 2099, 1253], [451, 1262, 587, 1290], [602, 1262, 638, 1290], [650, 1262, 707, 1290], [724, 1262, 826, 1290], [841, 1262, 866, 1290], [882, 1266, 913, 1290], [928, 1262, 1083, 1290], [1098, 1262, 1147, 1290], [1162, 1262, 1297, 1290], [1311, 1262, 1448, 1291], [1464, 1262, 1513, 1290], [1529, 1266, 1669, 1290], [1684, 1262, 1762, 1291], [1777, 1262, 1927, 1299], [1942, 1262, 1978, 1290], [1990, 1262, 2040, 1290], [2053, 1262, 2098, 1290], [451, 1312, 519, 1336], [536, 1308, 716, 1345], [729, 1317, 786, 1345], [798, 1308, 1002, 1345], [1014, 1308, 1151, 1336], [1163, 1317, 1219, 1336], [1230, 1308, 1269, 1336], [1280, 1308, 1355, 1336], [1367, 1312, 1398, 1336], [1410, 1312, 1549, 1345], [1561, 1308, 1610, 1336], [1622, 1308, 1856, 1345], [1869, 1312, 2010, 1336], [2021, 1308, 2099, 1337], [450, 1353, 709, 1390], [725, 1353, 788, 1381], [800, 1353, 1003, 1390], [1016, 1353, 1152, 1381], [1164, 1353, 1189, 1381], [1201, 1353, 1392, 1390], [1403, 1353, 1444, 1390], [1456, 1353, 1505, 1381], [1519, 1353, 1605, 1382], [1616, 1353, 1710, 1381], [1723, 1353, 1754, 1381], [1766, 1353, 1815, 1381], [1827, 1353, 1962, 1390], [1975, 1353, 2078, 1382], [451, 1530, 548, 1567], [561, 1530, 617, 1558], [632, 1530, 762, 1559], [775, 1530, 872, 1559], [886, 1539, 933, 1559], [945, 1534, 1025, 1559], [1037, 1534, 1067, 1558], [1080, 1530, 1224, 1567], [1236, 1530, 1285, 1558], [1296, 1530, 1444, 1567], [1456, 1539, 1536, 1558], [1549, 1530, 1645, 1567], [1658, 1530, 1778, 1558], [1792, 1530, 1887, 1559], [1900, 1530, 1966, 1567], [1988, 1530, 2026, 1565], [2043, 1531, 2100, 1558], [451, 1576, 500, 1604], [513, 1580, 656, 1610], [672, 1585, 792, 1604], [805, 1576, 867, 1604], [879, 1575, 952, 1610], [968, 1576, 992, 1604], [1008, 1585, 1024, 1604], [1036, 1576, 1183, 1613], [1196, 1576, 1310, 1604], [1324, 1576, 1421, 1605], [1437, 1576, 1510, 1604], [1523, 1576, 1585, 1604], [1598, 1586, 1678, 1610], [1693, 1580, 1860, 1613], [1874, 1576, 1924, 1604], [1938, 1576, 2097, 1604], [451, 1621, 486, 1649], [498, 1621, 548, 1649], [563, 1625, 704, 1649], [719, 1631, 747, 1649], [772, 1621, 899, 1655], [917, 1621, 975, 1649], [990, 1625, 1020, 1649], [1035, 1621, 1084, 1649], [1098, 1630, 1153, 1649], [1168, 1621, 1203, 1649], [1214, 1621, 1338, 1658], [1353, 1621, 1429, 1655], [1446, 1630, 1493, 1650], [1507, 1621, 1597, 1650], [1612, 1621, 1674, 1649], [1689, 1631, 1708, 1649], [1724, 1621, 1781, 1649], [1797, 1620, 1812, 1649], [1828, 1630, 1876, 1649], [1892, 1621, 2099, 1658], [451, 1667, 628, 1704], [656, 1668, 761, 1695], [777, 1676, 824, 1696], [839, 1667, 965, 1695], [981, 1667, 1030, 1695], [1047, 1667, 1191, 1695], [1206, 1667, 1387, 1704], [1403, 1667, 1563, 1695], [1579, 1667, 1609, 1695], [1625, 1666, 1698, 1701], [1716, 1671, 1788, 1695], [1805, 1666, 1877, 1701], [1884, 1691, 1890, 1701], [1908, 1667, 1948, 1704], [1964, 1667, 2099, 1704], [452, 1712, 528, 1751], [546, 1717, 577, 1741], [589, 1713, 753, 1741], [985, 1818, 1038, 1852], [1046, 1815, 1139, 1858], [1145, 1815, 1155, 1856], [1173, 1831, 1201, 1840], [1269, 1806, 1325, 1864], [1218, 1875, 1374, 1906], [1388, 1818, 1472, 1852], [1480, 1815, 1522, 1856], [1534, 1815, 1562, 1856], [2053, 1818, 2098, 1853], [451, 1986, 495, 2015], [505, 1995, 620, 2020], [634, 1986, 691, 2014], [704, 1986, 853, 2023], [865, 1986, 1002, 2014], [1015, 1995, 1149, 2014], [1164, 1995, 1180, 2014], [1192, 1986, 1268, 2023], [1281, 1986, 1394, 2014], [1406, 1986, 1509, 2014], [1520, 1986, 1620, 2015], [1632, 1995, 1679, 2015], [1691, 1986, 1731, 2014], [1743, 1990, 1796, 2014], [1806, 1986, 1882, 2015], [1895, 1990, 1923, 2014], [1934, 1986, 1991, 2014], [2006, 1990, 2097, 2023], [450, 2032, 551, 2060], [567, 2032, 624, 2060], [643, 2041, 698, 2060], [714, 2032, 753, 2060], [771, 2041, 787, 2060], [803, 2032, 904, 2060], [920, 2032, 1069, 2069], [1086, 2032, 1134, 2060], [1150, 2032, 1342, 2069], [1359, 2032, 1511, 2069], [1528, 2032, 1708, 2069], [1725, 2032, 1788, 2060], [1805, 2032, 2019, 2061], [2036, 2032, 2098, 2060], [451, 2086, 563, 2114], [579, 2077, 653, 2111], [667, 2077, 724, 2105], [737, 2077, 946, 2114], [958, 2077, 983, 2105], [996, 2081, 1049, 2105], [1059, 2077, 1176, 2114], [1189, 2077, 1277, 2106], [1289, 2077, 1371, 2105], [1383, 2077, 1407, 2105], [1421, 2086, 1461, 2105], [1473, 2077, 1576, 2105], [1588, 2081, 1618, 2105], [1631, 2077, 1712, 2105], [1725, 2077, 1804, 2105], [1816, 2077, 1847, 2105], [1859, 2077, 1923, 2105], [1933, 2077, 2029, 2114], [2045, 2078, 2099, 2105], [450, 2123, 568, 2152], [580, 2123, 637, 2151], [650, 2123, 732, 2151], [743, 2123, 784, 2160], [792, 2123, 902, 2160], [915, 2123, 1042, 2160], [1053, 2123, 1126, 2151], [1138, 2123, 1255, 2151], [1269, 2122, 1341, 2157], [1357, 2123, 1414, 2151], [1426, 2122, 1499, 2157], [1507, 2147, 1512, 2151], [450, 2194, 606, 2231], [619, 2194, 672, 2228], [688, 2198, 718, 2222], [730, 2194, 853, 2231], [866, 2194, 933, 2222], [945, 2203, 1067, 2222], [1080, 2194, 1142, 2222], [1152, 2194, 1225, 2222], [1238, 2194, 1355, 2222], [1368, 2194, 1450, 2222], [1463, 2203, 1479, 2222], [1492, 2194, 1598, 2222], [1609, 2194, 1843, 2231], [1857, 2198, 1885, 2222], [1896, 2194, 1946, 2222], [1959, 2198, 2099, 2222], [450, 2239, 537, 2268], [555, 2239, 598, 2267], [612, 2239, 662, 2267], [673, 2239, 797, 2276], [810, 2239, 895, 2276], [907, 2243, 1062, 2267], [1078, 2239, 1163, 2267], [1175, 2239, 1225, 2267], [1238, 2248, 1321, 2267], [1334, 2239, 1484, 2276], [1499, 2239, 1521, 2267], [1533, 2239, 1557, 2267], [1571, 2239, 1748, 2267], [1760, 2243, 1791, 2267], [1805, 2248, 1925, 2267], [1937, 2239, 1999, 2267], [2011, 2239, 2098, 2267], [450, 2285, 564, 2322], [577, 2285, 630, 2319], [645, 2285, 708, 2314], [720, 2285, 804, 2313], [816, 2285, 865, 2313], [877, 2285, 979, 2313], [991, 2289, 1021, 2313], [1033, 2285, 1115, 2313], [1127, 2285, 1202, 2313], [1214, 2285, 1358, 2313], [1370, 2285, 1613, 2322], [1629, 2286, 1684, 2313], [1696, 2284, 1738, 2319], [1755, 2298, 1783, 2307], [1799, 2284, 1876, 2323], [1892, 2288, 1915, 2314], [1929, 2284, 2005, 2323], [2015, 2309, 2020, 2313], [2036, 2285, 2099, 2313], [446, 2331, 526, 2368], [537, 2331, 686, 2368], [698, 2331, 835, 2359], [849, 2331, 872, 2360], [877, 2328, 933, 2369], [939, 2328, 949, 2369], [964, 2331, 1030, 2359], [1043, 2331, 1196, 2359], [1011, 2446, 1112, 2487], [1129, 2462, 1157, 2471], [1173, 2446, 1343, 2489], [1359, 2453, 1387, 2480], [1405, 2420, 1426, 2450], [1407, 2477, 1424, 2505], [1438, 2446, 1497, 2487], [1506, 2446, 1516, 2487], [1524, 2441, 1537, 2460], [2053, 2448, 2098, 2484], [451, 2560, 550, 2589], [563, 2557, 650, 2598], [659, 2557, 689, 2598], [705, 2560, 729, 2588], [743, 2560, 792, 2588], [805, 2560, 846, 2594], [860, 2560, 1090, 2597], [1102, 2564, 1185, 2588], [451, 2631, 475, 2658], [490, 2630, 515, 2658], [533, 2634, 674, 2667], [689, 2630, 751, 2658], [765, 2630, 822, 2658], [835, 2630, 915, 2667], [930, 2630, 1079, 2667], [1096, 2630, 1119, 2659], [1124, 2627, 1181, 2668], [1187, 2627, 1197, 2668], [1216, 2630, 1240, 2658], [1258, 2630, 1444, 2667], [1471, 2630, 1535, 2658], [1550, 2630, 1667, 2658], [1684, 2630, 1775, 2658], [1791, 2630, 1872, 2658], [1888, 2634, 1918, 2658], [1933, 2630, 2043, 2658], [2060, 2630, 2099, 2658], [451, 2676, 648, 2713], [664, 2676, 721, 2704], [734, 2676, 937, 2713], [951, 2676, 1077, 2713], [1091, 2680, 1122, 2704], [1135, 2685, 1204, 2704], [1219, 2676, 1276, 2704], [1289, 2676, 1412, 2713], [1425, 2676, 1580, 2704], [1593, 2676, 1642, 2704], [1655, 2676, 1804, 2713], [1817, 2676, 1962, 2704], [1981, 2677, 2035, 2704], [2049, 2676, 2098, 2704], [451, 2721, 533, 2749], [548, 2721, 605, 2749], [621, 2721, 702, 2749], [715, 2721, 756, 2758], [770, 2721, 946, 2758], [961, 2730, 977, 2749], [991, 2721, 1070, 2749], [1084, 2721, 1120, 2749], [1131, 2721, 1310, 2750], [1324, 2721, 1495, 2749], [1509, 2721, 1681, 2758], [1696, 2721, 1783, 2749], [1798, 2721, 1947, 2749], [1961, 2721, 2099, 2750], [451, 2767, 650, 2804], [665, 2771, 805, 2795], [818, 2767, 907, 2804], [930, 2768, 986, 2795], [999, 2776, 1088, 2804], [1102, 2767, 1166, 2804], [1180, 2767, 1215, 2795], [1226, 2767, 1350, 2804], [1365, 2771, 1520, 2795], [1539, 2764, 1581, 2805], [1593, 2764, 1621, 2805], [1639, 2776, 1686, 2796], [1701, 2767, 1816, 2804], [1831, 2776, 1847, 2795], [1861, 2767, 1987, 2795], [2000, 2767, 2036, 2795], [2048, 2767, 2098, 2795], [451, 2813, 576, 2841], [591, 2817, 746, 2841], [761, 2823, 784, 2841], [803, 2819, 824, 2843], [844, 2812, 889, 2847], [896, 2837, 902, 2847], [918, 2813, 1133, 2842], [1146, 2813, 1219, 2850], [1232, 2813, 1506, 2850], [1520, 2817, 1572, 2841], [1585, 2817, 1672, 2841], [1685, 2813, 1873, 2841], [1888, 2813, 1924, 2841], [1936, 2823, 1964, 2841], [1987, 2813, 2057, 2841], [2073, 2813, 2097, 2841], [451, 2858, 643, 2895], [658, 2862, 689, 2886], [704, 2858, 754, 2886], [770, 2858, 882, 2886], [898, 2862, 973, 2886], [988, 2858, 1024, 2886], [1036, 2858, 1086, 2886], [1101, 2858, 1162, 2886], [1179, 2858, 1316, 2886], [1332, 2858, 1367, 2886], [1381, 2867, 1397, 2886], [1412, 2858, 1493, 2895], [1509, 2858, 1624, 2895], [1639, 2862, 1756, 2886], [1771, 2858, 1938, 2895], [1953, 2858, 2100, 2886], [452, 2904, 516, 2939], [528, 2905, 581, 2941], [601, 2904, 637, 2932], [649, 2904, 680, 2932], [695, 2904, 782, 2939], [855, 2997, 962, 3031], [970, 2994, 1012, 3035], [1024, 2996, 1048, 3033], [1060, 2994, 1096, 3035], [1113, 3010, 1141, 3019], [1160, 2994, 1184, 3035], [1199, 3001, 1227, 3028], [1240, 2997, 1324, 3031], [1332, 2994, 1374, 3035], [1387, 2994, 1414, 3035], [1431, 3014, 1457, 3015], [1471, 2994, 1605, 3035], [1617, 2994, 1691, 3040], [2053, 2997, 2098, 3032], [1265, 3137, 1284, 3165], [451, 354, 550, 383], [571, 351, 636, 392], [663, 367, 691, 376], [716, 351, 845, 392], [857, 351, 888, 392], [908, 354, 1032, 382], [1051, 354, 1100, 382], [1118, 354, 1256, 382], [1272, 354, 1363, 391], [1380, 354, 1452, 382], [1483, 354, 1573, 388], [1593, 354, 1643, 382], [1659, 354, 1732, 382], [1749, 354, 1898, 391], [1914, 354, 2051, 382], [2068, 358, 2099, 382], [451, 400, 606, 428], [618, 400, 665, 428], [676, 400, 726, 428], [739, 400, 873, 429], [886, 400, 988, 428], [1000, 400, 1035, 428], [818, 505, 918, 546], [935, 521, 963, 530], [1031, 496, 1087, 554], [980, 565, 1137, 595], [1204, 464, 1218, 484], [1183, 496, 1239, 554], [1185, 566, 1236, 585], [1250, 508, 1357, 542], [1365, 505, 1407, 546], [1419, 507, 1443, 544], [1455, 505, 1504, 546], [1510, 463, 1581, 588], [1599, 479, 1620, 509], [1601, 536, 1618, 564], [1631, 505, 1691, 546], [1700, 505, 1710, 546], [1718, 500, 1731, 519], [2053, 508, 2098, 543], [451, 662, 500, 692], [544, 663, 655, 692], [667, 662, 829, 700], [451, 748, 549, 777], [563, 748, 612, 776], [626, 748, 775, 785], [789, 748, 926, 776], [941, 757, 971, 776], [987, 748, 1108, 776], [1123, 748, 1227, 782], [1243, 748, 1345, 776], [1359, 748, 1494, 785], [1508, 757, 1564, 776], [1578, 748, 1701, 785], [1715, 748, 1764, 776], [1779, 757, 1862, 776], [1876, 748, 2050, 785], [2067, 757, 2097, 776], [452, 803, 508, 831], [519, 794, 727, 831], [739, 794, 846, 823], [859, 795, 892, 822], [902, 794, 1067, 831], [1081, 803, 1111, 822], [1124, 794, 1173, 822], [1184, 794, 1333, 831], [1344, 794, 1480, 822], [1491, 794, 1516, 822], [1528, 794, 1758, 828], [1771, 803, 1818, 823], [1828, 803, 1884, 822], [1894, 803, 1949, 822], [1961, 794, 2099, 822], [451, 839, 586, 876], [600, 839, 724, 867], [738, 839, 913, 876], [930, 839, 1004, 867], [1020, 848, 1050, 867], [1068, 839, 1228, 867], [1244, 839, 1380, 876], [1394, 839, 1525, 873], [1543, 839, 1682, 868], [1700, 848, 1733, 867], [1748, 839, 1797, 867], [1813, 839, 1949, 876], [1964, 839, 2100, 876], [452, 885, 611, 922], [622, 885, 772, 914], [787, 885, 839, 919], [854, 885, 967, 913], [979, 885, 1053, 913], [1065, 885, 1273, 922], [1286, 885, 1393, 919], [1406, 894, 1453, 914], [1463, 894, 1518, 913], [1529, 885, 1804, 922], [1816, 885, 1944, 922], [1956, 889, 2099, 913], [452, 931, 526, 959], [538, 931, 680, 968], [693, 931, 742, 959], [750, 931, 829, 968], [840, 940, 920, 959], [931, 935, 962, 959], [974, 931, 1048, 959], [1061, 935, 1202, 959], [1214, 931, 1291, 960], [1303, 931, 1391, 959], [451, 1045, 474, 1079], [525, 1045, 794, 1089], [451, 1148, 499, 1178], [544, 1149, 627, 1178], [640, 1149, 704, 1178], [717, 1149, 919, 1178], [451, 1235, 502, 1263], [515, 1235, 618, 1263], [631, 1235, 757, 1272], [772, 1244, 851, 1264], [864, 1235, 1022, 1272], [1036, 1235, 1198, 1263], [1210, 1235, 1299, 1272], [1314, 1244, 1330, 1263], [1343, 1235, 1494, 1264], [1507, 1235, 1705, 1263], [1726, 1235, 1821, 1263], [1835, 1244, 1884, 1263], [1898, 1244, 1914, 1263], [1927, 1235, 2053, 1263], [2066, 1235, 2102, 1263], [450, 1284, 629, 1317], [645, 1280, 707, 1308], [720, 1289, 776, 1308], [791, 1280, 942, 1308], [956, 1280, 1058, 1308], [1073, 1280, 1209, 1317], [1231, 1281, 1285, 1308], [1300, 1280, 1431, 1308], [1446, 1280, 1495, 1308], [1509, 1280, 1668, 1317], [1683, 1280, 1784, 1309], [1800, 1280, 1848, 1308], [1863, 1280, 2026, 1317], [2042, 1280, 2099, 1308], [451, 1326, 679, 1363], [696, 1326, 768, 1355], [783, 1326, 864, 1363], [879, 1326, 971, 1355], [1000, 1327, 1033, 1354], [1049, 1326, 1147, 1354], [1163, 1326, 1247, 1355], [1262, 1335, 1309, 1355], [1325, 1326, 1388, 1355], [1404, 1326, 1580, 1363], [1596, 1326, 1645, 1354], [1661, 1326, 1754, 1354], [1769, 1326, 1805, 1354], [1819, 1326, 1902, 1354], [1917, 1330, 2097, 1363], [451, 1372, 481, 1400], [495, 1376, 609, 1409], [622, 1372, 721, 1400], [742, 1372, 786, 1400], [799, 1372, 1028, 1409], [1042, 1372, 1097, 1407], [1113, 1372, 1256, 1409], [1270, 1372, 1356, 1407], [1372, 1372, 1498, 1400], [1510, 1372, 1546, 1400], [1557, 1372, 1643, 1400], [1656, 1372, 1801, 1400], [1817, 1371, 1892, 1407], [1907, 1372, 2022, 1409], [2037, 1372, 2099, 1400], [452, 1416, 527, 1452], [543, 1417, 726, 1454], [741, 1417, 986, 1454], [1001, 1416, 1130, 1452], [1154, 1417, 1217, 1445], [1231, 1417, 1317, 1445], [1332, 1417, 1476, 1445], [1493, 1417, 1623, 1454], [1639, 1426, 1718, 1446], [1731, 1417, 1889, 1454], [1904, 1417, 2005, 1446], [2020, 1417, 2099, 1445], [451, 1463, 500, 1491], [514, 1472, 622, 1500], [638, 1467, 667, 1491], [680, 1463, 808, 1500], [822, 1463, 903, 1497], [920, 1463, 1118, 1500], [1132, 1463, 1180, 1491], [1193, 1463, 1268, 1491], [1282, 1463, 1409, 1500], [1425, 1463, 1540, 1500], [1555, 1463, 1613, 1491], [1627, 1463, 1733, 1500], [1756, 1464, 1809, 1491], [1823, 1472, 1878, 1491], [1892, 1463, 1941, 1491], [1955, 1463, 2099, 1500], [451, 1517, 558, 1545], [574, 1501, 653, 1543], [672, 1508, 719, 1536], [732, 1508, 860, 1545], [874, 1508, 923, 1536], [936, 1508, 1083, 1545], [1097, 1508, 1208, 1536], [1230, 1508, 1293, 1536], [1307, 1517, 1414, 1545], [1430, 1517, 1491, 1537], [1505, 1508, 1735, 1545], [1748, 1508, 1837, 1545], [1851, 1508, 1901, 1536], [1915, 1512, 1960, 1536], [1973, 1508, 2009, 1536], [2020, 1508, 2097, 1536], [450, 1554, 596, 1591], [607, 1554, 648, 1591], [661, 1547, 750, 1582], [767, 1554, 808, 1588], [823, 1554, 871, 1582], [883, 1554, 1056, 1591], [1069, 1554, 1126, 1582], [1139, 1554, 1337, 1591], [1349, 1554, 1399, 1582], [1411, 1554, 1487, 1582], [1505, 1554, 1632, 1588], [1648, 1554, 1687, 1582], [1699, 1558, 1801, 1591], [1815, 1558, 1970, 1582], [1985, 1563, 2015, 1582], [2029, 1554, 2099, 1583], [452, 1609, 482, 1628], [495, 1600, 571, 1628], [582, 1600, 770, 1628], [784, 1609, 863, 1629], [874, 1600, 1017, 1629], [1029, 1600, 1109, 1628], [1120, 1600, 1169, 1628], [1181, 1609, 1299, 1637], [450, 1671, 503, 1698], [513, 1674, 634, 1707], [642, 1670, 749, 1698], [761, 1670, 841, 1698], [851, 1674, 911, 1699], [922, 1670, 1132, 1707], [1148, 1670, 1211, 1698], [1223, 1670, 1357, 1699], [1369, 1670, 1471, 1698], [1482, 1679, 1543, 1699], [1556, 1670, 1669, 1698], [1680, 1679, 1720, 1698], [1731, 1669, 1813, 1699], [1825, 1674, 1965, 1698], [1975, 1670, 2053, 1707], [2066, 1670, 2102, 1698], [451, 1716, 500, 1744], [512, 1716, 785, 1753], [797, 1716, 921, 1753], [934, 1716, 1049, 1744], [1062, 1716, 1098, 1744], [1108, 1716, 1157, 1744], [1169, 1716, 1313, 1753], [1326, 1725, 1443, 1753], [1462, 1716, 1525, 1744], [1539, 1716, 1698, 1745], [1712, 1716, 1814, 1744], [1826, 1716, 1901, 1744], [1914, 1716, 1971, 1744], [1985, 1716, 2100, 1744], [451, 1762, 481, 1790], [493, 1762, 699, 1790], [711, 1762, 783, 1791], [796, 1762, 919, 1790], [930, 1761, 1012, 1791], [1022, 1762, 1146, 1799], [1159, 1766, 1314, 1790], [1327, 1762, 1407, 1790], [1418, 1762, 1468, 1790], [1479, 1762, 1734, 1799], [1747, 1762, 1861, 1790], [1874, 1762, 1909, 1790], [1918, 1762, 1968, 1790], [1979, 1771, 2097, 1799], [450, 1807, 594, 1844], [607, 1807, 637, 1835], [654, 1807, 665, 1835], [681, 1807, 799, 1835], [812, 1807, 937, 1844], [950, 1811, 1115, 1841], [1130, 1807, 1204, 1835], [1215, 1807, 1318, 1844], [1330, 1816, 1371, 1844], [1383, 1807, 1455, 1836], [1468, 1807, 1561, 1835], [1574, 1816, 1590, 1835], [1602, 1807, 1734, 1836], [1747, 1816, 1780, 1835], [1793, 1816, 1809, 1835], [1821, 1807, 1935, 1835], [1948, 1811, 2097, 1835], [451, 1853, 532, 1881], [544, 1853, 718, 1890], [732, 1853, 913, 1890], [924, 1853, 999, 1881], [1011, 1853, 1133, 1881], [1144, 1853, 1309, 1890], [1323, 1857, 1353, 1881], [1366, 1853, 1454, 1882], [1465, 1853, 1610, 1890], [1622, 1853, 1752, 1890], [451, 1924, 514, 1952], [525, 1924, 701, 1953], [712, 1924, 824, 1952], [837, 1930, 856, 1952], [862, 1924, 996, 1953], [1010, 1924, 1035, 1952], [1048, 1928, 1078, 1952], [1090, 1924, 1266, 1961], [1278, 1924, 1411, 1953], [1422, 1933, 1469, 1953], [1480, 1933, 1536, 1952], [1548, 1924, 1629, 1952], [1640, 1924, 1735, 1952], [1746, 1924, 1943, 1961], [1956, 1924, 1996, 1961], [2008, 1924, 2098, 1952], [451, 1969, 562, 2006], [577, 1969, 740, 1997], [754, 1969, 821, 1997], [835, 1969, 865, 1997], [880, 1978, 896, 1997], [910, 1969, 1051, 1997], [1063, 1969, 1220, 2006], [1241, 1969, 1312, 1997], [1327, 1969, 1352, 1997], [1368, 1969, 1481, 1997], [1494, 1973, 1525, 1997], [1538, 1969, 1618, 2006], [1631, 1969, 1715, 1998], [1728, 1969, 1759, 1997], [1773, 1969, 1912, 1997], [1925, 1969, 2099, 1997], [451, 2015, 550, 2044], [562, 2015, 687, 2052], [700, 2024, 761, 2044], [773, 2015, 848, 2043], [862, 2024, 892, 2043], [906, 2024, 922, 2043], [933, 2015, 1017, 2052], [1028, 2015, 1076, 2043], [1087, 2015, 1260, 2043], [1272, 2015, 1409, 2044], [1421, 2015, 1635, 2044], [1647, 2015, 1810, 2052], [1827, 2014, 1879, 2049], [450, 2086, 503, 2113], [514, 2094, 569, 2113], [580, 2085, 629, 2113], [641, 2085, 778, 2122], [789, 2085, 925, 2122], [935, 2085, 1067, 2119], [1080, 2085, 1231, 2114], [1245, 2085, 1298, 2119], [1311, 2085, 1358, 2113], [1368, 2085, 1513, 2122], [1524, 2085, 1574, 2113], [1585, 2085, 1711, 2122], [1724, 2085, 1760, 2113], [1768, 2094, 1823, 2113], [1834, 2085, 1961, 2119], [1975, 2085, 2032, 2113], [2044, 2089, 2098, 2113], [451, 2131, 562, 2159], [575, 2131, 702, 2168], [716, 2131, 790, 2159], [802, 2130, 842, 2160], [855, 2131, 1016, 2159], [1035, 2131, 1147, 2159], [1159, 2131, 1358, 2168], [1372, 2131, 1523, 2159], [1536, 2131, 1597, 2159], [1609, 2131, 1658, 2159], [1672, 2131, 1806, 2160], [1820, 2131, 1923, 2159], [1935, 2140, 2097, 2168], [451, 2177, 541, 2205], [556, 2177, 625, 2205], [640, 2177, 690, 2205], [705, 2183, 724, 2205], [730, 2177, 865, 2206], [881, 2177, 992, 2211], [1009, 2177, 1061, 2205], [1075, 2186, 1122, 2206], [1136, 2181, 1235, 2214], [1248, 2177, 1354, 2205], [1371, 2186, 1411, 2205], [1426, 2177, 1475, 2205], [1491, 2186, 1574, 2205], [1588, 2177, 1714, 2205], [1729, 2177, 1764, 2205], [1776, 2177, 1928, 2205], [1944, 2177, 1992, 2205], [2005, 2177, 2100, 2205], [451, 2215, 693, 2259], [700, 2246, 705, 2250], [451, 2325, 501, 2355], [545, 2325, 795, 2363], [807, 2326, 989, 2355], [1001, 2325, 1235, 2355], [450, 2413, 503, 2440], [516, 2412, 651, 2441], [663, 2421, 718, 2440], [729, 2412, 832, 2440], [843, 2412, 932, 2449], [945, 2412, 995, 2440], [1007, 2412, 1220, 2449], [1232, 2412, 1396, 2440], [1407, 2412, 1622, 2440], [1636, 2412, 1771, 2447], [1784, 2412, 1850, 2440], [1862, 2412, 1898, 2440], [1908, 2412, 2099, 2441], [451, 2462, 480, 2486], [494, 2458, 530, 2486], [549, 2458, 622, 2492], [645, 2458, 716, 2486], [732, 2458, 798, 2486], [811, 2458, 946, 2487], [962, 2458, 1096, 2495], [1110, 2458, 1259, 2495], [1273, 2458, 1475, 2495], [1488, 2458, 1686, 2495], [1702, 2458, 1801, 2487], [1817, 2467, 1865, 2486], [1879, 2458, 1949, 2486], [1962, 2458, 2038, 2486], [2052, 2458, 2100, 2486], [451, 2503, 614, 2531], [627, 2503, 842, 2531], [857, 2512, 956, 2531], [972, 2503, 1021, 2531], [1035, 2503, 1308, 2540], [1322, 2503, 1470, 2540], [1483, 2503, 1553, 2540], [1575, 2504, 1632, 2531], [1645, 2503, 1712, 2537], [1728, 2503, 1836, 2532], [1851, 2503, 1988, 2540], [2005, 2512, 2021, 2531], [2034, 2512, 2098, 2540], [451, 2549, 556, 2577], [569, 2549, 642, 2577], [657, 2549, 693, 2577], [706, 2549, 903, 2586], [920, 2549, 1041, 2586], [1055, 2549, 1144, 2586], [1160, 2549, 1335, 2586], [1350, 2549, 1477, 2586], [1492, 2549, 1560, 2577], [1575, 2549, 1605, 2577], [1620, 2558, 1679, 2577], [1693, 2549, 1842, 2586], [1857, 2549, 1915, 2577], [1930, 2549, 2099, 2586], [451, 2594, 577, 2623], [592, 2594, 781, 2631], [797, 2594, 828, 2622], [844, 2594, 973, 2622], [1000, 2594, 1090, 2628], [1109, 2594, 1217, 2623], [1233, 2594, 1258, 2622], [1276, 2603, 1292, 2622], [1308, 2594, 1389, 2631], [1405, 2594, 1471, 2622], [1486, 2594, 1534, 2622], [1549, 2594, 1745, 2631], [1761, 2594, 1894, 2623], [1909, 2603, 1963, 2622], [1978, 2594, 2099, 2622], [450, 2640, 699, 2677], [713, 2649, 761, 2668], [774, 2640, 981, 2677], [992, 2640, 1093, 2668], [1106, 2649, 1206, 2668], [1219, 2640, 1356, 2677], [1368, 2640, 1541, 2677], [450, 2712, 503, 2739], [513, 2711, 619, 2740], [629, 2711, 678, 2739], [688, 2711, 903, 2748], [914, 2715, 999, 2748], [1009, 2711, 1167, 2739], [1177, 2711, 1207, 2739], [1221, 2711, 1294, 2745], [1306, 2711, 1378, 2740], [1388, 2711, 1438, 2739], [1448, 2711, 1607, 2748], [1617, 2711, 1679, 2739], [1688, 2720, 1735, 2740], [1745, 2711, 1826, 2739], [1836, 2720, 1891, 2739], [1900, 2711, 2097, 2748], [450, 2756, 539, 2793], [554, 2756, 650, 2793], [664, 2756, 713, 2784], [727, 2756, 871, 2793], [885, 2756, 952, 2784], [967, 2756, 1024, 2784], [1038, 2756, 1110, 2793], [1123, 2765, 1178, 2784], [1192, 2756, 1241, 2784], [1255, 2757, 1379, 2784], [1394, 2756, 1616, 2785], [1630, 2765, 1756, 2793], [1769, 2756, 1876, 2793], [1890, 2756, 1939, 2784], [1953, 2756, 2100, 2784], [451, 2802, 578, 2839], [593, 2802, 651, 2830], [665, 2802, 774, 2839], [790, 2806, 897, 2839], [921, 2802, 1002, 2830], [1016, 2802, 1179, 2830], [1193, 2802, 1223, 2830], [1238, 2802, 1287, 2830], [1301, 2802, 1516, 2830], [1531, 2802, 1597, 2830], [1611, 2802, 1635, 2830], [1650, 2802, 1841, 2839], [1854, 2802, 1895, 2839], [1909, 2802, 1959, 2830], [1974, 2811, 2099, 2839], [505, 2876, 512, 2893], [519, 2883, 1207, 2915], [503, 2921, 514, 2938], [519, 2929, 1209, 2961], [503, 2966, 513, 2983], [518, 2973, 605, 2999], [620, 2973, 746, 2999], [762, 2982, 833, 3000], [846, 2973, 964, 3007], [979, 2973, 1121, 3007], [1136, 2977, 1287, 2999], [1303, 2973, 1330, 2999], [1344, 2973, 1389, 2999], [1403, 2974, 1488, 3000], [1502, 2982, 1572, 3007], [1586, 2973, 1685, 3000], [1699, 2982, 1818, 3007], [1844, 2973, 1952, 2999], [1967, 2973, 2010, 2999], [2024, 2973, 2100, 2999], [451, 3015, 693, 3041], [705, 3015, 757, 3041], [768, 3024, 817, 3041], [828, 3024, 923, 3041], [934, 3015, 1003, 3041], [1014, 3015, 1057, 3041], [1067, 3024, 1116, 3041], [1126, 3015, 1218, 3041], [1229, 3024, 1273, 3041], [1284, 3015, 1415, 3042], [1426, 3019, 1452, 3041], [1463, 3016, 2029, 3048], [1265, 3136, 1282, 3166], [962, 345, 1069, 373], [1258, 345, 1397, 373], [1448, 345, 1587, 373], [962, 392, 1106, 429], [1118, 392, 1205, 421], [1292, 392, 1361, 421], [1482, 392, 1551, 421], [962, 438, 1094, 467], [1292, 437, 1359, 467], [1482, 438, 1552, 467], [962, 484, 1023, 511], [1292, 483, 1359, 512], [1482, 483, 1553, 512], [962, 529, 1101, 557], [1292, 529, 1362, 558], [1482, 529, 1549, 557], [963, 576, 1097, 605], [1293, 576, 1362, 605], [1482, 576, 1553, 604], [963, 622, 1122, 651], [1292, 621, 1363, 651], [1482, 621, 1553, 651], [450, 709, 540, 737], [558, 709, 582, 737], [604, 709, 829, 738], [844, 718, 988, 746], [1003, 709, 1050, 737], [1064, 709, 1191, 746], [1206, 718, 1246, 737], [1260, 709, 1385, 746], [1401, 709, 1458, 737], [1472, 709, 1604, 738], [1619, 709, 1691, 738], [1710, 709, 1787, 738], [1801, 709, 1919, 737], [1934, 709, 2097, 746], [450, 755, 673, 792], [685, 755, 919, 792], [930, 755, 1179, 792], [1194, 755, 1226, 790], [1232, 755, 1342, 784], [1356, 755, 1413, 783], [1427, 755, 1610, 790], [1624, 755, 1837, 792], [1848, 755, 2097, 792], [449, 800, 539, 837], [555, 800, 676, 828], [692, 800, 890, 837], [909, 800, 966, 828], [984, 809, 1020, 828], [1037, 800, 1213, 828], [1229, 800, 1336, 828], [1354, 800, 1518, 835], [1539, 800, 1600, 834], [1620, 800, 1780, 828], [1797, 800, 1883, 835], [1902, 800, 1959, 828], [1976, 800, 2099, 837], [451, 846, 609, 881], [624, 846, 732, 880], [748, 846, 805, 874], [819, 846, 868, 874], [881, 846, 1020, 883], [1034, 846, 1111, 874], [1125, 846, 1269, 874], [1290, 846, 1353, 874], [1366, 847, 1427, 874], [1441, 846, 1498, 874], [1512, 846, 1644, 875], [1656, 846, 1763, 874], [1778, 855, 1827, 874], [1841, 846, 1905, 874], [1919, 846, 2006, 874], [2020, 846, 2099, 874], [450, 892, 641, 921], [654, 896, 683, 920], [695, 892, 731, 920], [748, 892, 821, 926], [600, 1515, 657, 1544], [720, 1515, 779, 1544], [842, 1515, 901, 1544], [956, 1515, 1033, 1544], [1076, 1515, 1155, 1544], [1190, 1515, 1288, 1544], [573, 1404, 611, 1433], [573, 1311, 611, 1340], [573, 1217, 611, 1246], [573, 1124, 611, 1153], [724, 1579, 864, 1616], [876, 1580, 1062, 1607], [1077, 1579, 1140, 1614], [464, 1462, 493, 1487], [464, 1449, 492, 1459], [473, 1431, 492, 1447], [473, 1416, 492, 1428], [473, 1400, 492, 1412], [464, 1387, 492, 1397], [464, 1365, 492, 1386], [473, 1346, 492, 1362], [473, 1327, 492, 1343], [468, 1315, 492, 1326], [464, 1304, 492, 1314], [473, 1284, 492, 1303], [473, 1263, 492, 1282], [464, 1223, 492, 1251], [473, 1205, 492, 1221], [473, 1186, 492, 1202], [473, 1165, 492, 1185], [473, 1150, 492, 1164], [473, 1132, 492, 1148], [473, 1115, 492, 1131], [473, 1094, 501, 1113], [464, 1070, 499, 1081], [464, 1037, 493, 1066], [464, 1022, 499, 1033], [1357, 1515, 1413, 1544], [1477, 1515, 1535, 1544], [1599, 1515, 1657, 1544], [1713, 1515, 1790, 1544], [1833, 1515, 1912, 1544], [1946, 1515, 2044, 1544], [1330, 1404, 1367, 1433], [1330, 1274, 1367, 1303], [1330, 1143, 1367, 1172], [1330, 1013, 1367, 1042], [1481, 1579, 1621, 1616], [1633, 1580, 1819, 1607], [1833, 1579, 1896, 1614], [643, 1673, 777, 1702], [873, 1673, 1032, 1702], [1127, 1673, 1266, 1701], [1359, 1673, 1420, 1700], [1513, 1673, 1645, 1702], [1738, 1673, 1882, 1710], [1894, 1673, 1981, 1702], [451, 1790, 557, 1827], [570, 1790, 597, 1818], [616, 1790, 840, 1819], [853, 1799, 998, 1827], [1010, 1790, 1058, 1818], [1070, 1799, 1086, 1818], [1098, 1790, 1224, 1818], [1236, 1790, 1272, 1818], [1281, 1790, 1398, 1818], [1413, 1790, 1478, 1825], [1490, 1790, 1580, 1818], [1596, 1790, 1607, 1818], [1623, 1790, 1671, 1818], [1683, 1790, 1785, 1818], [1797, 1790, 2018, 1827], [2036, 1790, 2099, 1818], [451, 1836, 505, 1864], [520, 1836, 602, 1864], [618, 1836, 717, 1865], [733, 1836, 839, 1864], [856, 1836, 904, 1864], [919, 1836, 1003, 1864], [1018, 1836, 1135, 1864], [1153, 1836, 1241, 1865], [1257, 1836, 1370, 1864], [1386, 1845, 1426, 1864], [1442, 1836, 1567, 1873], [1583, 1836, 1650, 1864], [1667, 1836, 1724, 1864], [1740, 1836, 1895, 1865], [1911, 1845, 1951, 1864], [1967, 1836, 2099, 1865], [451, 1882, 527, 1916], [540, 1882, 590, 1910], [601, 1882, 679, 1919], [690, 1882, 773, 1910], [784, 1882, 851, 1911], [863, 1891, 957, 1911], [451, 2037, 486, 2065], [496, 2037, 545, 2065], [558, 2036, 794, 2065], [805, 2037, 1054, 2074], [1068, 2037, 1104, 2065], [1114, 2037, 1153, 2065], [1166, 2037, 1202, 2065], [1217, 2041, 1382, 2065], [1398, 2038, 1452, 2065], [1464, 2037, 1538, 2065], [1550, 2037, 1600, 2065], [1612, 2037, 1777, 2065], [1791, 2037, 1938, 2065], [1948, 2037, 2037, 2074], [2050, 2037, 2099, 2065], [452, 2091, 534, 2110], [547, 2082, 670, 2119], [684, 2082, 742, 2110], [754, 2082, 1013, 2119], [1025, 2082, 1060, 2110], [1070, 2082, 1119, 2110], [1132, 2082, 1277, 2119], [1289, 2086, 1465, 2119], [1477, 2082, 1624, 2110], [1638, 2082, 1679, 2116], [1695, 2091, 1726, 2110], [1738, 2082, 1813, 2110], [1826, 2082, 1856, 2110], [1871, 2082, 1944, 2116], [450, 2154, 503, 2181], [516, 2162, 568, 2181], [582, 2153, 631, 2181], [645, 2153, 753, 2182], [767, 2153, 966, 2190], [981, 2153, 1054, 2181], [1067, 2153, 1107, 2190], [1121, 2153, 1248, 2190], [1262, 2162, 1302, 2181], [1316, 2153, 1441, 2190], [1456, 2153, 1513, 2181], [1527, 2153, 1636, 2190], [1649, 2162, 1689, 2181], [1703, 2153, 1835, 2182], [1849, 2153, 2025, 2181], [2042, 2153, 2099, 2181], [451, 2199, 518, 2228], [531, 2208, 625, 2228], [646, 2199, 743, 2236], [756, 2199, 806, 2227], [819, 2199, 887, 2227], [901, 2199, 984, 2236], [998, 2199, 1144, 2236], [1157, 2199, 1197, 2236], [1214, 2199, 1287, 2233], [1302, 2208, 1349, 2228], [1362, 2199, 1437, 2227], [1450, 2199, 1574, 2236], [1588, 2199, 1715, 2236], [1729, 2199, 1796, 2227], [1810, 2199, 1887, 2227], [1902, 2199, 1981, 2227], [1998, 2199, 2055, 2228], [2068, 2203, 2099, 2227], [455, 2244, 563, 2278], [576, 2244, 752, 2272], [766, 2244, 814, 2272], [826, 2244, 953, 2281], [966, 2244, 1015, 2272], [1027, 2244, 1192, 2272], [1206, 2244, 1359, 2272], [1376, 2244, 1440, 2272], [1451, 2244, 1557, 2272], [1571, 2244, 1607, 2272], [1617, 2244, 1673, 2272], [1687, 2244, 1754, 2272], [1766, 2253, 1866, 2272], [1880, 2244, 2007, 2281], [2021, 2244, 2097, 2272], [452, 2299, 500, 2318], [513, 2290, 617, 2319], [629, 2290, 660, 2318], [672, 2290, 779, 2327], [791, 2290, 818, 2318], [835, 2290, 924, 2318], [940, 2290, 951, 2318], [968, 2290, 1067, 2319], [1081, 2290, 1130, 2318], [1141, 2290, 1247, 2318], [1260, 2290, 1308, 2318], [1319, 2290, 1447, 2327], [1459, 2299, 1498, 2318], [1515, 2290, 1602, 2324], [1614, 2290, 1801, 2318], [451, 2361, 529, 2389], [542, 2361, 669, 2395], [685, 2361, 819, 2390], [834, 2361, 891, 2389], [905, 2361, 1064, 2390], [1079, 2361, 1264, 2398], [1278, 2361, 1317, 2389], [1328, 2361, 1409, 2398], [1421, 2361, 1505, 2390], [1517, 2370, 1557, 2389], [1570, 2361, 1626, 2389], [1641, 2361, 1715, 2389], [1733, 2361, 1860, 2395], [1875, 2361, 1924, 2389], [1938, 2361, 2097, 2390], [451, 2406, 553, 2434], [566, 2406, 765, 2443], [780, 2406, 829, 2434], [843, 2406, 977, 2435], [991, 2406, 1102, 2440], [1117, 2406, 1281, 2443], [1294, 2406, 1344, 2434], [1355, 2406, 1526, 2434], [1541, 2406, 1576, 2434], [1588, 2406, 1698, 2443], [1711, 2406, 1838, 2443], [1851, 2406, 1919, 2434], [1932, 2415, 2007, 2435], [2020, 2406, 2099, 2434], [452, 2461, 468, 2480], [480, 2456, 614, 2489], [626, 2452, 774, 2489], [785, 2452, 855, 2489], [451, 2574, 500, 2604], [544, 2574, 773, 2604], [450, 2668, 551, 2696], [568, 2668, 617, 2696], [634, 2668, 742, 2697], [761, 2668, 946, 2705], [962, 2668, 1090, 2696], [1107, 2677, 1147, 2696], [1164, 2668, 1361, 2705], [1378, 2668, 1428, 2696], [1446, 2668, 1590, 2696], [1608, 2672, 1730, 2696], [1746, 2668, 1782, 2696], [1796, 2668, 1846, 2696], [1864, 2672, 2004, 2696], [2021, 2668, 2099, 2697], [450, 2714, 709, 2751], [724, 2723, 771, 2743], [785, 2714, 849, 2742], [862, 2718, 941, 2743], [953, 2718, 984, 2742], [996, 2714, 1104, 2751], [1117, 2714, 1293, 2751], [1305, 2714, 1355, 2742], [1368, 2714, 1497, 2742], [1510, 2714, 1594, 2743], [1607, 2714, 1814, 2751], [1833, 2715, 1866, 2742], [1878, 2714, 2038, 2751], [2050, 2714, 2099, 2742], [452, 2759, 611, 2788], [628, 2759, 730, 2787], [746, 2759, 770, 2787], [788, 2759, 961, 2796], [977, 2759, 1024, 2787], [1039, 2759, 1101, 2787], [1114, 2768, 1254, 2796], [1273, 2768, 1304, 2787], [1321, 2759, 1343, 2787], [1359, 2759, 1462, 2788], [1478, 2768, 1513, 2787], [1530, 2763, 1561, 2787], [1576, 2759, 1711, 2788], [1726, 2768, 1781, 2787], [1797, 2759, 1946, 2796], [1962, 2759, 1998, 2787], [2010, 2759, 2099, 2796], [451, 2805, 576, 2842], [589, 2814, 619, 2833], [634, 2814, 650, 2833], [660, 2805, 744, 2842], [755, 2805, 904, 2842], [916, 2805, 946, 2833], [959, 2814, 975, 2833], [987, 2805, 1189, 2842], [1201, 2809, 1295, 2842], [451, 2877, 483, 2904], [496, 2876, 603, 2913], [616, 2876, 632, 2905], [646, 2885, 693, 2905], [706, 2876, 790, 2905], [802, 2876, 851, 2904], [863, 2876, 966, 2905], [977, 2876, 1159, 2913], [1173, 2876, 1220, 2904], [1233, 2885, 1249, 2904], [1261, 2876, 1387, 2904], [1398, 2876, 1434, 2904], [1443, 2876, 1577, 2913], [1591, 2876, 1705, 2904], [1718, 2876, 1775, 2904], [1788, 2876, 1920, 2905], [1932, 2876, 2040, 2905], [2057, 2876, 2102, 2905], [450, 2921, 609, 2958], [620, 2921, 742, 2949], [754, 2921, 862, 2949], [873, 2921, 912, 2949], [924, 2921, 973, 2949], [984, 2921, 1063, 2958], [1074, 2921, 1164, 2955], [1178, 2921, 1278, 2950], [1289, 2921, 1453, 2958], [1466, 2921, 1613, 2958], [1625, 2921, 1823, 2958], [1835, 2921, 1973, 2950], [1985, 2921, 2099, 2949], [452, 2967, 509, 2995], [524, 2967, 656, 2996], [672, 2967, 780, 2996], [807, 2968, 890, 2996], [906, 2967, 1019, 3004], [1035, 2967, 1084, 2995], [1100, 2967, 1202, 2995], [1217, 2967, 1269, 2995], [1284, 2971, 1337, 2995], [1350, 2976, 1405, 2995], [1422, 2976, 1478, 3004], [1493, 2967, 1617, 3004], [1632, 2967, 1893, 2996], [1909, 2967, 1977, 2995], [1992, 2967, 2099, 3004], [451, 3013, 587, 3050], [600, 3013, 623, 3041], [635, 3013, 695, 3041], [707, 3013, 855, 3050], [867, 3017, 897, 3041], [909, 3013, 991, 3041], [1004, 3013, 1148, 3041], [1161, 3013, 1343, 3042], [1356, 3013, 1512, 3050], [1525, 3022, 1625, 3041], [1638, 3013, 1722, 3041], [1734, 3017, 1794, 3042], [1806, 3013, 1979, 3050], [1265, 3137, 1283, 3166], [451, 986, 557, 1023], [571, 986, 598, 1015], [617, 986, 680, 1014], [693, 986, 747, 1014], [760, 990, 867, 1014], [878, 986, 943, 1023], [955, 986, 1054, 1015], [1068, 986, 1171, 1015], [1182, 986, 1365, 1023], [1379, 986, 1427, 1014], [1440, 995, 1456, 1014], [1468, 986, 1629, 1023], [1643, 986, 1674, 1014], [1687, 986, 1726, 1014], [1739, 986, 1821, 1014], [1833, 986, 1996, 1023], [2010, 986, 2099, 1023], [451, 1031, 500, 1059], [511, 1031, 760, 1068], [774, 1031, 895, 1059], [907, 1031, 938, 1059], [950, 1031, 999, 1059], [1013, 1031, 1172, 1060], [1186, 1031, 1297, 1059], [1314, 1032, 1397, 1060], [1410, 1031, 1523, 1068], [1536, 1031, 1585, 1059], [1598, 1031, 1700, 1059], [1712, 1031, 1763, 1059], [1776, 1035, 1828, 1059], [1839, 1040, 1894, 1059], [1907, 1040, 1963, 1068], [1975, 1031, 2099, 1068], [451, 1077, 712, 1106], [724, 1077, 792, 1105], [804, 1077, 910, 1114], [923, 1077, 1059, 1114], [1073, 1077, 1095, 1105], [1108, 1077, 1167, 1105], [1180, 1077, 1275, 1105], [1290, 1077, 1434, 1105], [1448, 1077, 1605, 1114], [1616, 1077, 1754, 1106], [1766, 1077, 1850, 1105], [1862, 1081, 1922, 1106], [1935, 1077, 2097, 1114], [450, 1123, 539, 1160], [551, 1123, 676, 1160], [690, 1132, 720, 1151], [735, 1132, 751, 1151], [763, 1123, 854, 1160], [872, 1124, 913, 1151], [925, 1123, 1075, 1160], [1086, 1123, 1153, 1157], [1168, 1123, 1217, 1151], [1228, 1123, 1307, 1160], [1318, 1123, 1383, 1160], [1395, 1123, 1494, 1152], [1509, 1123, 1631, 1151], [1644, 1127, 1689, 1151], [1700, 1123, 1736, 1151], [1745, 1123, 1843, 1152], [1858, 1123, 1990, 1158], [2004, 1123, 2040, 1151], [2050, 1123, 2099, 1151], [451, 1168, 533, 1205], [545, 1168, 634, 1205], [646, 1168, 719, 1205], [731, 1168, 780, 1196], [792, 1168, 924, 1197], [937, 1168, 994, 1196], [1006, 1168, 1120, 1196], [1132, 1168, 1240, 1197], [451, 1363, 473, 1397], [526, 1363, 780, 1398], [450, 1510, 530, 1538], [545, 1510, 601, 1538], [616, 1519, 709, 1547], [722, 1519, 769, 1539], [782, 1510, 859, 1539], [872, 1510, 1024, 1547], [1039, 1519, 1055, 1538], [1069, 1510, 1159, 1539], [1173, 1510, 1296, 1538], [1310, 1510, 1358, 1538], [1371, 1510, 1515, 1547], [1529, 1510, 1742, 1547], [1757, 1510, 1932, 1538], [1945, 1519, 2098, 1547], [451, 1556, 558, 1584], [576, 1556, 624, 1584], [640, 1556, 874, 1593], [891, 1556, 1061, 1584], [1092, 1556, 1189, 1593], [1207, 1565, 1223, 1584], [1240, 1565, 1311, 1593], [1329, 1556, 1437, 1593], [1454, 1556, 1577, 1584], [1594, 1556, 1641, 1584], [1658, 1556, 1802, 1584], [1820, 1556, 2032, 1593], [2052, 1565, 2099, 1585], [451, 1601, 651, 1630], [667, 1601, 815, 1638], [830, 1605, 861, 1629], [876, 1601, 978, 1629], [994, 1605, 1067, 1629], [1082, 1601, 1118, 1629], [1129, 1601, 1179, 1629], [1194, 1605, 1237, 1629], [1249, 1601, 1356, 1629], [1372, 1610, 1412, 1629], [1426, 1601, 1476, 1629], [1490, 1601, 1598, 1630], [1614, 1601, 1688, 1635], [1706, 1601, 1893, 1638], [1907, 1601, 2053, 1638], [2068, 1605, 2099, 1629], [451, 1647, 585, 1676], [600, 1647, 744, 1675], [759, 1647, 885, 1675], [899, 1656, 999, 1675], [1015, 1647, 1188, 1684], [1210, 1647, 1297, 1675], [1310, 1647, 1471, 1684], [1486, 1656, 1540, 1675], [1555, 1647, 1704, 1684], [1718, 1651, 1749, 1675], [1763, 1647, 1884, 1675], [1898, 1647, 2099, 1684], [451, 1693, 578, 1730], [590, 1693, 658, 1721], [670, 1693, 701, 1721], [713, 1693, 763, 1721], [776, 1693, 935, 1722], [949, 1693, 1060, 1727], [1074, 1702, 1121, 1722], [1133, 1702, 1212, 1722], [1225, 1693, 1292, 1721], [1304, 1697, 1335, 1721], [1347, 1693, 1549, 1721], [1561, 1693, 1623, 1721], [1635, 1693, 1745, 1730], [1759, 1693, 1922, 1721], [1934, 1693, 2097, 1730], [451, 1738, 563, 1766], [572, 1738, 722, 1775], [734, 1738, 784, 1766], [794, 1738, 904, 1766], [920, 1738, 1135, 1772], [1146, 1738, 1235, 1775], [1247, 1747, 1332, 1766], [1342, 1738, 1514, 1775], [1525, 1738, 1724, 1775], [1737, 1738, 1794, 1766], [1804, 1738, 2040, 1772], [2052, 1747, 2099, 1767], [452, 1784, 575, 1813], [587, 1784, 648, 1812], [659, 1793, 714, 1812], [726, 1784, 875, 1821], [889, 1784, 953, 1812], [966, 1784, 1069, 1813], [1082, 1793, 1116, 1812], [1130, 1788, 1160, 1812], [1172, 1784, 1254, 1812], [1267, 1784, 1474, 1821], [1485, 1784, 1597, 1812], [1609, 1784, 1807, 1821], [1821, 1793, 1921, 1812], [1935, 1784, 2097, 1821], [451, 1830, 577, 1859], [589, 1839, 645, 1867], [657, 1830, 751, 1858], [762, 1830, 890, 1867], [902, 1830, 978, 1858], [451, 1900, 514, 1929], [530, 1900, 679, 1937], [694, 1900, 834, 1937], [851, 1904, 934, 1937], [948, 1900, 1107, 1937], [1123, 1900, 1154, 1928], [1169, 1900, 1297, 1937], [1313, 1900, 1380, 1928], [1397, 1900, 1454, 1928], [1469, 1900, 1600, 1937], [1617, 1900, 1692, 1928], [1707, 1904, 1738, 1928], [1754, 1909, 1793, 1928], [1810, 1900, 1991, 1928], [2018, 1901, 2098, 1929], [451, 1946, 502, 1983], [515, 1946, 737, 1974], [750, 1946, 799, 1974], [813, 1946, 981, 1974], [994, 1946, 1121, 1983], [1134, 1946, 1170, 1974], [1181, 1946, 1325, 1974], [1338, 1946, 1587, 1983], [1601, 1946, 1690, 1983], [1704, 1950, 1845, 1974], [1858, 1946, 1978, 1983], [1991, 1946, 2067, 1980], [2083, 1955, 2099, 1974], [450, 1992, 599, 2029], [609, 1996, 680, 2020], [690, 1996, 754, 2029], [765, 1992, 789, 2020], [801, 1996, 832, 2020], [843, 1996, 966, 2029], [976, 1992, 1103, 2029], [1113, 1992, 1202, 2029], [1212, 1992, 1510, 2029], [1521, 1992, 1589, 2020], [1599, 2001, 1633, 2020], [1642, 2001, 1717, 2021], [1728, 2001, 1853, 2029], [1863, 1992, 1899, 2020], [1907, 1992, 2099, 2029], [451, 2037, 637, 2065], [654, 2037, 724, 2065], [738, 2046, 808, 2074], [819, 2037, 944, 2074], [956, 2046, 1031, 2066], [1043, 2041, 1158, 2074], [1168, 2037, 1364, 2074], [1378, 2037, 1425, 2065], [1436, 2037, 1573, 2074], [1585, 2037, 1657, 2066], [1669, 2037, 1883, 2066], [1895, 2037, 2068, 2074], [451, 2109, 483, 2136], [497, 2108, 546, 2136], [560, 2117, 643, 2136], [656, 2108, 734, 2142], [749, 2108, 799, 2136], [813, 2117, 933, 2136], [948, 2108, 984, 2136], [994, 2117, 1049, 2136], [1060, 2108, 1196, 2145], [1209, 2108, 1408, 2145], [1424, 2112, 1547, 2145], [1559, 2108, 1671, 2136], [1684, 2108, 1776, 2137], [1796, 2108, 1907, 2137], [1920, 2108, 2005, 2136], [2016, 2108, 2100, 2145], [452, 2154, 644, 2191], [657, 2154, 680, 2182], [690, 2154, 715, 2182], [727, 2163, 799, 2191], [811, 2158, 841, 2182], [853, 2154, 961, 2182], [972, 2163, 1027, 2182], [1037, 2154, 1139, 2182], [1151, 2158, 1181, 2182], [1192, 2154, 1268, 2183], [1279, 2154, 1416, 2191], [1426, 2154, 1510, 2191], [1520, 2154, 1693, 2191], [1709, 2154, 1789, 2182], [1803, 2163, 1888, 2182], [1898, 2154, 1995, 2191], [2008, 2154, 2099, 2182], [450, 2208, 589, 2236], [603, 2199, 744, 2227], [759, 2203, 874, 2236], [891, 2199, 965, 2227], [980, 2208, 1010, 2227], [1026, 2208, 1105, 2233], [1121, 2199, 1233, 2236], [1247, 2203, 1313, 2233], [1330, 2199, 1387, 2227], [1402, 2208, 1563, 2228], [1577, 2199, 1661, 2227], [1675, 2199, 1771, 2227], [1786, 2199, 1898, 2227], [1912, 2203, 1943, 2227], [1956, 2199, 2068, 2236], [2083, 2208, 2099, 2227], [452, 2245, 548, 2282], [559, 2245, 643, 2282], [654, 2245, 811, 2282], [451, 2315, 493, 2343], [508, 2324, 555, 2344], [566, 2315, 643, 2344], [656, 2315, 799, 2344], [812, 2315, 861, 2343], [873, 2315, 979, 2343], [993, 2315, 1024, 2343], [1036, 2315, 1093, 2343], [1106, 2324, 1199, 2352], [1211, 2315, 1283, 2344], [1296, 2324, 1312, 2343], [1324, 2315, 1478, 2352], [1492, 2315, 1600, 2352], [1614, 2315, 1671, 2344], [1676, 2316, 1720, 2349], [1735, 2315, 1757, 2343], [1769, 2315, 1871, 2344], [1884, 2315, 1948, 2343], [1960, 2315, 1999, 2343], [2011, 2315, 2098, 2343], [451, 2361, 548, 2398], [563, 2365, 593, 2389], [608, 2361, 751, 2389], [766, 2361, 899, 2390], [913, 2370, 967, 2389], [981, 2361, 1130, 2398], [1144, 2361, 1281, 2389], [1296, 2370, 1352, 2389], [1365, 2361, 1404, 2389], [1417, 2361, 1493, 2389], [1507, 2361, 1538, 2389], [1553, 2361, 1758, 2389], [1773, 2361, 1845, 2390], [1860, 2370, 1944, 2389], [1958, 2361, 2099, 2398], [451, 2407, 684, 2444], [701, 2411, 804, 2436], [820, 2407, 937, 2435], [956, 2407, 1030, 2435], [1048, 2416, 1079, 2435], [1097, 2408, 1259, 2435], [1280, 2406, 1341, 2441], [1362, 2416, 1396, 2435], [1412, 2407, 1619, 2435], [1637, 2407, 1830, 2444], [1850, 2411, 1881, 2435], [1899, 2416, 1950, 2435], [1967, 2407, 2100, 2436], [451, 2452, 534, 2480], [549, 2461, 605, 2480], [620, 2452, 732, 2480], [746, 2452, 882, 2489], [895, 2452, 1001, 2480], [1018, 2461, 1058, 2480], [1072, 2452, 1145, 2480], [1160, 2461, 1265, 2480], [1282, 2452, 1339, 2480], [1354, 2452, 1556, 2489], [1570, 2452, 1650, 2480], [1667, 2452, 1755, 2481], [1769, 2452, 1844, 2480], [1859, 2452, 1890, 2480], [1904, 2452, 2099, 2489], [451, 2498, 523, 2527], [536, 2507, 591, 2526], [604, 2498, 817, 2535], [831, 2498, 980, 2535], [993, 2498, 1139, 2526], [1160, 2498, 1285, 2526], [1299, 2502, 1330, 2526], [1344, 2498, 1411, 2532], [1427, 2507, 1474, 2527], [1487, 2498, 1550, 2527], [1565, 2498, 1629, 2526], [1644, 2498, 1734, 2535], [1747, 2507, 1802, 2526], [1815, 2498, 1917, 2526], [1931, 2502, 1961, 2526], [1976, 2507, 1992, 2526], [2006, 2498, 2100, 2527], [451, 2544, 563, 2581], [575, 2544, 611, 2572], [620, 2544, 700, 2572], [713, 2544, 869, 2581], [881, 2544, 1020, 2572], [1032, 2544, 1205, 2572], [1218, 2544, 1276, 2572], [1288, 2544, 1489, 2581], [1501, 2544, 1695, 2572], [1707, 2544, 1880, 2572], [450, 2729, 860, 2773], [451, 2876, 514, 2904], [526, 2876, 644, 2904], [658, 2876, 759, 2905], [772, 2876, 832, 2904], [844, 2880, 874, 2904], [886, 2876, 978, 2904], [989, 2876, 1160, 2904], [1172, 2876, 1362, 2905], [1376, 2876, 1433, 2904], [1444, 2876, 1490, 2904], [1504, 2876, 1676, 2904], [1689, 2876, 1737, 2904], [1748, 2876, 1871, 2913], [1883, 2876, 1958, 2904], [1969, 2876, 2097, 2904], [452, 2921, 509, 2949], [528, 2921, 673, 2958], [690, 2925, 867, 2958], [885, 2921, 1144, 2958], [1163, 2921, 1317, 2955], [1339, 2930, 1370, 2949], [1389, 2921, 1459, 2950], [1478, 2930, 1508, 2949], [1529, 2921, 1697, 2958], [1716, 2930, 1732, 2949], [1750, 2921, 1876, 2949], [1893, 2921, 1929, 2949], [1944, 2921, 2097, 2958], [450, 2967, 562, 2995], [576, 2971, 606, 2995], [620, 2967, 695, 2995], [708, 2967, 792, 2996], [805, 2976, 845, 2995], [859, 2967, 916, 2995], [931, 2967, 1005, 2995], [1026, 2967, 1097, 2995], [1112, 2967, 1196, 2996], [1209, 2976, 1270, 2996], [1286, 2967, 1447, 3004], [1460, 2967, 1501, 3004], [1515, 2967, 1639, 2996], [1654, 2971, 1738, 3004], [1751, 2966, 1992, 2996], [2011, 2967, 2068, 2995], [2083, 2976, 2099, 2995], [450, 3014, 552, 3041], [565, 3013, 751, 3041], [763, 3013, 879, 3042], [1265, 3138, 1283, 3165], [451, 348, 680, 383], [474, 426, 515, 460], [540, 427, 647, 454], [659, 426, 770, 454], [783, 426, 840, 454], [852, 426, 984, 454], [994, 426, 1185, 463], [1202, 427, 1307, 454], [1321, 435, 1370, 454], [1381, 430, 1507, 460], [1522, 426, 1682, 463], [1696, 435, 1744, 454], [1756, 426, 1903, 454], [1921, 427, 2098, 463], [540, 472, 592, 509], [605, 472, 847, 509], [859, 472, 1077, 500], [1091, 472, 1122, 500], [1135, 472, 1279, 500], [1293, 481, 1391, 509], [1409, 473, 1442, 500], [1453, 472, 1658, 509], [1670, 472, 1708, 509], [1712, 473, 1856, 506], [1870, 472, 1960, 501], [474, 532, 515, 566], [540, 532, 612, 560], [630, 532, 750, 560], [786, 532, 884, 560], [903, 532, 939, 560], [953, 532, 1023, 561], [1041, 532, 1175, 560], [1193, 532, 1274, 560], [1292, 532, 1341, 560], [1358, 532, 1514, 569], [1533, 532, 1569, 560], [1584, 532, 1692, 561], [1727, 532, 1912, 561], [1928, 532, 1991, 561], [2006, 533, 2099, 560], [540, 577, 690, 611], [704, 576, 951, 611], [965, 577, 1055, 606], [474, 637, 515, 671], [541, 637, 672, 674], [685, 637, 777, 666], [789, 637, 846, 665], [860, 637, 991, 674], [1004, 637, 1137, 665], [1157, 637, 1342, 674], [1356, 637, 1505, 674], [1519, 637, 1576, 665], [1589, 637, 1808, 665], [1820, 637, 1937, 665], [1951, 637, 1987, 665], [1997, 646, 2098, 665], [540, 683, 600, 720], [619, 684, 652, 711], [663, 683, 867, 720], [880, 683, 918, 720], [919, 683, 1014, 711], [1023, 683, 1132, 720], [1144, 683, 1331, 720], [1343, 693, 1383, 711], [1396, 683, 1548, 719], [1559, 684, 1751, 711], [1765, 683, 1867, 711], [1879, 684, 1973, 717], [1987, 683, 2077, 712], [474, 743, 515, 777], [540, 743, 607, 771], [619, 743, 750, 777], [764, 743, 951, 771], [964, 743, 1142, 777], [1157, 743, 1214, 771], [1226, 743, 1357, 780], [1369, 743, 1468, 772], [1485, 743, 1712, 771], [1723, 743, 1916, 771], [1929, 743, 1976, 771], [1988, 752, 2004, 771], [2015, 752, 2098, 771], [539, 789, 703, 826], [716, 789, 935, 817], [949, 789, 1051, 817], [1064, 789, 1100, 817], [1111, 789, 1261, 826], [1283, 789, 1415, 817], [1426, 789, 1606, 826], [1622, 790, 1788, 826], [1798, 789, 1949, 826], [1965, 788, 2100, 818], [541, 835, 610, 869], [623, 835, 713, 864], [474, 894, 515, 929], [540, 896, 649, 924], [662, 895, 750, 924], [765, 895, 822, 923], [836, 895, 956, 923], [970, 896, 1090, 932], [1113, 895, 1256, 923], [1270, 895, 1443, 923], [1456, 895, 1497, 932], [1510, 895, 1729, 932], [1750, 895, 1877, 932], [1891, 895, 2032, 924], [2044, 904, 2099, 923], [540, 940, 576, 968], [589, 940, 813, 977], [828, 949, 962, 977], [991, 941, 1024, 968], [1039, 940, 1243, 977], [1259, 940, 1297, 977], [1302, 940, 1387, 974], [1403, 949, 1495, 977], [1512, 939, 1665, 974], [1683, 941, 1805, 977], [1823, 940, 1925, 969], [1940, 940, 2097, 977], [539, 987, 615, 1015], [627, 986, 717, 1015], [731, 986, 925, 1014], [937, 986, 985, 1014], [996, 986, 1241, 1023], [1253, 986, 1445, 1023], [474, 1046, 515, 1080], [540, 1046, 675, 1074], [692, 1046, 819, 1075], [854, 1046, 1098, 1075], [1115, 1046, 1242, 1083], [1260, 1046, 1397, 1074], [1416, 1046, 1464, 1074], [1479, 1046, 1591, 1074], [1609, 1046, 1733, 1075], [1750, 1046, 1877, 1074], [1905, 1046, 2023, 1083], [2042, 1046, 2099, 1074], [540, 1092, 740, 1129], [759, 1092, 831, 1121], [849, 1096, 1025, 1129], [1044, 1092, 1228, 1129], [1266, 1093, 1299, 1120], [1316, 1092, 1521, 1129], [1539, 1092, 1577, 1129], [1585, 1092, 1820, 1121], [1840, 1092, 2034, 1120], [2052, 1092, 2100, 1120], [540, 1137, 786, 1174], [798, 1137, 989, 1174], [1003, 1137, 1093, 1166], [1111, 1137, 1171, 1165], [1193, 1136, 1643, 1166], [474, 1199, 515, 1232], [540, 1199, 647, 1226], [663, 1198, 819, 1227], [834, 1198, 892, 1226], [906, 1199, 998, 1227], [1012, 1199, 1144, 1226], [1173, 1198, 1201, 1226], [1216, 1198, 1331, 1226], [1347, 1198, 1541, 1226], [1556, 1198, 1604, 1226], [1619, 1198, 1732, 1226], [1748, 1198, 1896, 1235], [1910, 1198, 2096, 1235], [540, 1244, 626, 1280], [638, 1243, 741, 1271], [752, 1243, 901, 1272], [915, 1243, 987, 1272], [999, 1243, 1153, 1271], [1164, 1243, 1307, 1280], [1325, 1244, 1358, 1271], [1369, 1243, 1574, 1280], [1586, 1243, 1624, 1280], [1628, 1243, 1735, 1277], [1749, 1243, 1839, 1272], [474, 1303, 515, 1337], [539, 1303, 617, 1332], [628, 1303, 737, 1337], [750, 1303, 824, 1331], [835, 1304, 948, 1337], [962, 1303, 1019, 1331], [1031, 1304, 1140, 1331], [1152, 1303, 1264, 1340], [1280, 1303, 1429, 1340], [1441, 1303, 1633, 1340], [1643, 1303, 1781, 1331], [1793, 1303, 1841, 1331], [1851, 1303, 1954, 1331], [1964, 1303, 2099, 1340], [541, 1349, 599, 1377], [609, 1349, 770, 1377], [780, 1349, 997, 1386], [1009, 1349, 1138, 1378], [1147, 1349, 1184, 1386], [1185, 1349, 1329, 1377], [1339, 1350, 1490, 1386], [1498, 1349, 1659, 1383], [1675, 1348, 1918, 1383], [1929, 1349, 1997, 1386], [2007, 1349, 2097, 1378], [540, 1395, 628, 1424], [645, 1394, 828, 1424], [474, 1455, 515, 1489], [540, 1455, 627, 1484], [645, 1456, 733, 1492], [752, 1455, 852, 1483], [867, 1456, 978, 1492], [996, 1455, 1057, 1484], [1073, 1455, 1293, 1489], [1311, 1455, 1478, 1484], [1493, 1456, 1609, 1489], [1627, 1455, 1741, 1483], [1757, 1456, 1840, 1489], [1859, 1455, 1924, 1483], [1940, 1455, 2097, 1489], [540, 1500, 661, 1528], [678, 1500, 835, 1534], [853, 1500, 1002, 1528], [1017, 1500, 1183, 1534], [1203, 1500, 1260, 1528], [1276, 1500, 1373, 1537], [1389, 1500, 1512, 1528], [1542, 1500, 1625, 1528], [1650, 1500, 1678, 1528], [1694, 1500, 1831, 1534], [1850, 1500, 2022, 1537], [2042, 1500, 2099, 1528], [540, 1546, 675, 1583], [693, 1546, 873, 1575], [890, 1546, 937, 1574], [955, 1546, 1129, 1574], [1147, 1546, 1205, 1574], [1223, 1546, 1421, 1574], [1439, 1546, 1613, 1574], [1631, 1546, 1758, 1574], [1795, 1547, 1828, 1574], [1845, 1546, 2050, 1583], [2068, 1546, 2106, 1583], [537, 1592, 622, 1626], [636, 1592, 726, 1621], [454, 1652, 515, 1686], [540, 1653, 577, 1680], [589, 1652, 648, 1680], [659, 1652, 716, 1680], [727, 1652, 756, 1681], [768, 1652, 828, 1680], [830, 1652, 849, 1680], [853, 1676, 858, 1680], [872, 1652, 900, 1680], [911, 1652, 1075, 1680], [1085, 1656, 1187, 1681], [1197, 1661, 1287, 1689], [1297, 1652, 1399, 1680], [1409, 1652, 1457, 1680], [1466, 1652, 1549, 1681], [1560, 1652, 1701, 1689], [1711, 1652, 1742, 1680], [1752, 1656, 1881, 1680], [1894, 1652, 2098, 1689], [540, 1698, 578, 1735], [582, 1699, 726, 1732], [740, 1698, 830, 1727], [454, 1758, 515, 1792], [539, 1759, 564, 1787], [577, 1759, 603, 1786], [607, 1782, 612, 1786], [626, 1758, 713, 1786], [732, 1758, 760, 1786], [773, 1758, 912, 1795], [926, 1758, 961, 1786], [971, 1758, 1123, 1795], [1135, 1758, 1240, 1795], [1256, 1757, 1386, 1787], [1392, 1782, 1397, 1786], [1420, 1757, 1655, 1792], [1673, 1757, 1759, 1787], [454, 1818, 515, 1852], [540, 1818, 667, 1847], [680, 1818, 881, 1847], [895, 1818, 952, 1846], [965, 1818, 1152, 1846], [1165, 1818, 1344, 1847], [1364, 1818, 1586, 1855], [1600, 1822, 1723, 1855], [1734, 1818, 1782, 1846], [1795, 1827, 1811, 1846], [1823, 1818, 2003, 1855], [2015, 1827, 2098, 1846], [539, 1863, 703, 1900], [715, 1863, 934, 1891], [946, 1863, 1048, 1891], [1060, 1863, 1095, 1891], [1105, 1863, 1255, 1900], [1273, 1864, 1306, 1891], [1317, 1863, 1521, 1900], [1534, 1863, 1572, 1900], [1576, 1864, 1720, 1897], [1733, 1863, 1823, 1892], [454, 1924, 515, 1958], [540, 1924, 613, 1952], [631, 1924, 792, 1961], [814, 1925, 906, 1961], [924, 1924, 1028, 1961], [1049, 1924, 1156, 1961], [1173, 1924, 1466, 1961], [1488, 1924, 1545, 1952], [1563, 1925, 1631, 1952], [1649, 1924, 1748, 1952], [1786, 1924, 1935, 1961], [1952, 1924, 2099, 1961], [540, 1969, 675, 1997], [689, 1969, 768, 1997], [780, 1969, 988, 2006], [1000, 1978, 1134, 2006], [1152, 1970, 1185, 1997], [1196, 1969, 1400, 2006], [1413, 1969, 1451, 2006], [1453, 1969, 1627, 2003], [1640, 1969, 1730, 1998], [454, 2029, 515, 2063], [540, 2029, 613, 2057], [630, 2029, 741, 2057], [759, 2030, 912, 2057], [930, 2029, 988, 2057], [1005, 2029, 1071, 2057], [1088, 2029, 1245, 2057], [1281, 2029, 1344, 2057], [1362, 2029, 1439, 2057], [1456, 2029, 1492, 2057], [1508, 2029, 1620, 2066], [1638, 2029, 1668, 2057], [1686, 2030, 1794, 2057], [1811, 2029, 1908, 2066], [1925, 2029, 2047, 2057], [2066, 2029, 2102, 2057], [540, 2075, 783, 2112], [796, 2075, 973, 2104], [991, 2076, 1024, 2103], [1035, 2075, 1240, 2112], [1252, 2075, 1290, 2112], [1292, 2075, 1377, 2109], [1391, 2075, 1481, 2104], [454, 2134, 515, 2169], [540, 2135, 599, 2163], [613, 2135, 838, 2163], [853, 2135, 910, 2163], [924, 2135, 990, 2163], [1004, 2135, 1161, 2163], [1187, 2136, 1350, 2163], [1363, 2135, 1587, 2164], [1602, 2135, 1704, 2163], [1718, 2135, 1867, 2164], [1883, 2135, 1930, 2163], [1944, 2135, 2099, 2163], [540, 2181, 824, 2218], [853, 2182, 886, 2209], [900, 2181, 1105, 2218], [1121, 2181, 1158, 2218], [1168, 2181, 1215, 2209], [1233, 2181, 1393, 2218], [1409, 2191, 1449, 2209], [1466, 2181, 1654, 2210], [1672, 2182, 1776, 2210], [1789, 2181, 1886, 2218], [1900, 2181, 2022, 2210], [2038, 2181, 2101, 2210], [541, 2226, 619, 2254], [631, 2226, 922, 2263], [936, 2226, 1026, 2255], [454, 2287, 515, 2321], [540, 2287, 711, 2315], [729, 2287, 926, 2321], [948, 2288, 1019, 2316], [1037, 2287, 1129, 2321], [1152, 2287, 1209, 2315], [1227, 2287, 1327, 2315], [1345, 2287, 1504, 2315], [1542, 2287, 1688, 2324], [1707, 2287, 1906, 2324], [1924, 2287, 2099, 2315], [539, 2332, 789, 2369], [802, 2332, 838, 2360], [847, 2332, 955, 2361], [973, 2333, 1006, 2360], [1017, 2332, 1222, 2369], [1234, 2332, 1272, 2369], [1279, 2332, 1436, 2366], [1450, 2332, 1540, 2361], [454, 2392, 515, 2426], [541, 2392, 685, 2421], [699, 2392, 800, 2429], [814, 2392, 893, 2420], [905, 2392, 1083, 2429], [1099, 2392, 1156, 2420], [1169, 2393, 1259, 2429], [1272, 2392, 1456, 2420], [1476, 2392, 1624, 2429], [1637, 2392, 1838, 2429], [1850, 2392, 1934, 2421], [1945, 2401, 2098, 2429], [540, 2438, 648, 2466], [660, 2438, 750, 2475], [763, 2447, 779, 2466], [790, 2438, 1011, 2475], [1025, 2438, 1232, 2466], [1250, 2439, 1283, 2466], [1294, 2439, 1380, 2475], [1392, 2439, 1544, 2475], [1558, 2438, 1717, 2475], [1731, 2443, 1762, 2466], [1771, 2438, 1868, 2472], [1882, 2438, 1972, 2467], [454, 2498, 515, 2532], [540, 2499, 647, 2526], [666, 2498, 812, 2532], [832, 2498, 891, 2526], [908, 2498, 1003, 2532], [1023, 2498, 1104, 2535], [1121, 2498, 1264, 2532], [1285, 2498, 1343, 2526], [1359, 2498, 1472, 2535], [1489, 2499, 1584, 2526], [1619, 2498, 1760, 2526], [1777, 2498, 1948, 2526], [1965, 2498, 2001, 2526], [2016, 2498, 2099, 2527], [539, 2544, 789, 2581], [802, 2544, 833, 2572], [845, 2548, 947, 2573], [959, 2553, 1057, 2581], [1078, 2544, 1182, 2578], [1196, 2544, 1286, 2573], [454, 2604, 515, 2638], [540, 2605, 647, 2632], [661, 2604, 807, 2638], [822, 2604, 910, 2639], [923, 2605, 955, 2632], [969, 2605, 1020, 2638], [1036, 2604, 1093, 2632], [1106, 2604, 1169, 2641], [1183, 2604, 1348, 2633], [1369, 2604, 1542, 2641], [1556, 2604, 1737, 2632], [1752, 2613, 1862, 2641], [1875, 2604, 2038, 2641], [2052, 2604, 2100, 2632], [540, 2650, 680, 2678], [691, 2650, 874, 2678], [894, 2650, 998, 2684], [1012, 2650, 1102, 2679], [454, 2710, 515, 2744], [540, 2711, 614, 2738], [617, 2709, 633, 2738], [634, 2709, 647, 2738], [662, 2710, 809, 2744], [825, 2710, 936, 2738], [950, 2709, 1091, 2744], [1107, 2710, 1174, 2738], [1175, 2709, 1191, 2738], [1193, 2709, 1206, 2738], [1221, 2711, 1341, 2747], [1356, 2711, 1410, 2739], [1425, 2700, 1564, 2739], [1565, 2709, 1593, 2747], [1610, 2710, 1667, 2738], [1683, 2710, 1810, 2747], [1824, 2710, 2016, 2747], [2041, 2711, 2098, 2738], [540, 2759, 657, 2783], [668, 2755, 771, 2783], [782, 2755, 917, 2784], [927, 2755, 1021, 2783], [1033, 2755, 1182, 2792], [1194, 2755, 1304, 2783], [1323, 2756, 1356, 2783], [1367, 2755, 1571, 2792], [1584, 2755, 1621, 2792], [1625, 2755, 1903, 2789], [1917, 2755, 2007, 2784], [454, 2815, 515, 2849], [539, 2815, 603, 2844], [615, 2815, 754, 2843], [769, 2815, 826, 2843], [841, 2815, 962, 2843], [976, 2816, 1096, 2852], [1123, 2815, 1337, 2843], [1351, 2815, 1468, 2843], [1484, 2815, 1520, 2843], [1533, 2815, 1677, 2843], [1692, 2815, 1905, 2852], [1931, 2816, 1964, 2843], [1978, 2816, 2012, 2843], [2025, 2816, 2098, 2843], [540, 2861, 684, 2898], [696, 2861, 734, 2898], [736, 2861, 821, 2895], [834, 2861, 924, 2890], [454, 2921, 515, 2955], [540, 2922, 577, 2949], [592, 2922, 665, 2958], [688, 2921, 852, 2950], [866, 2921, 981, 2958], [994, 2921, 1142, 2958], [1156, 2921, 1345, 2958], [1364, 2921, 1571, 2958], [1586, 2921, 1616, 2949], [1630, 2921, 1713, 2950], [1726, 2921, 1869, 2958], [1890, 2922, 1981, 2949], [1994, 2922, 2098, 2950], [540, 2968, 658, 2996], [670, 2977, 710, 2995], [719, 2967, 919, 3001], [933, 2966, 1166, 3002], [1178, 2968, 1253, 2996], [1264, 2967, 1354, 2996], [1371, 2967, 1459, 2996], [1475, 2966, 1657, 2996], [1674, 2967, 1734, 2995], [1755, 2967, 2097, 2996], [541, 3013, 672, 3042], [1266, 3137, 1282, 3166], [454, 354, 515, 388], [540, 354, 568, 382], [581, 355, 603, 382], [616, 354, 720, 383], [732, 354, 878, 388], [893, 355, 928, 382], [940, 354, 1061, 391], [1074, 354, 1196, 388], [1210, 355, 1234, 382], [1249, 354, 1428, 388], [1442, 354, 1534, 382], [1548, 354, 1673, 391], [1688, 354, 1746, 382], [1758, 354, 1874, 382], [1888, 354, 1974, 383], [1994, 354, 2098, 382], [540, 400, 654, 437], [666, 400, 743, 437], [755, 400, 898, 437], [916, 401, 949, 428], [960, 401, 1046, 437], [1058, 401, 1210, 437], [1224, 400, 1383, 437], [1397, 405, 1428, 428], [1437, 400, 1534, 434], [1548, 400, 1638, 429], [454, 462, 515, 496], [540, 462, 670, 490], [684, 462, 804, 496], [817, 462, 930, 499], [943, 462, 1139, 499], [1154, 462, 1221, 490], [1234, 463, 1271, 490], [1286, 463, 1404, 499], [1418, 462, 1549, 491], [1562, 463, 1594, 490], [1608, 463, 1666, 499], [1682, 462, 1739, 490], [1752, 462, 1947, 499], [1959, 463, 1996, 490], [2011, 463, 2098, 490], [540, 508, 621, 545], [646, 508, 920, 545], [933, 508, 1083, 537], [1097, 508, 1312, 536], [1328, 508, 1375, 536], [1387, 508, 1555, 545], [1569, 508, 1729, 536], [1742, 508, 1956, 536], [1980, 509, 2012, 536], [2025, 509, 2098, 536], [540, 553, 684, 590], [696, 553, 734, 590], [738, 554, 882, 587], [896, 553, 986, 582], [454, 615, 515, 650], [540, 616, 670, 644], [683, 616, 802, 650], [816, 616, 918, 653], [929, 616, 1037, 650], [1050, 616, 1245, 653], [1256, 617, 1293, 644], [1306, 616, 1463, 653], [1478, 616, 1535, 644], [1547, 616, 1677, 645], [1689, 617, 1721, 644], [1734, 617, 1792, 653], [1810, 616, 1961, 645], [1974, 625, 2098, 653], [541, 661, 705, 698], [719, 661, 846, 698], [859, 661, 1010, 690], [1023, 661, 1248, 690], [1262, 670, 1376, 698], [1401, 662, 1434, 689], [1447, 661, 1652, 698], [1666, 661, 1704, 698], [1710, 661, 1990, 695], [2005, 670, 2097, 698], [544, 707, 734, 741], [748, 707, 838, 736], [454, 769, 515, 803], [540, 769, 640, 797], [656, 769, 823, 798], [838, 769, 896, 797], [911, 769, 1024, 797], [1040, 769, 1283, 798], [1310, 769, 1505, 797], [1519, 769, 1654, 806], [1669, 769, 1741, 798], [1756, 769, 1832, 806], [1846, 769, 2021, 797], [2036, 778, 2098, 797], [540, 815, 653, 843], [672, 816, 705, 843], [716, 815, 920, 852], [933, 815, 971, 852], [973, 815, 1070, 844], [1084, 815, 1174, 844], [454, 877, 515, 911], [540, 878, 566, 905], [582, 878, 609, 905], [614, 901, 619, 905], [636, 878, 752, 914], [767, 877, 825, 905], [840, 878, 865, 905], [882, 877, 992, 905], [1019, 878, 1108, 905], [1122, 877, 1286, 914], [1300, 881, 1331, 905], [1346, 877, 1496, 914], [1519, 878, 1626, 905], [1641, 886, 1731, 914], [1746, 877, 1862, 905], [1879, 877, 1914, 905], [1927, 877, 2097, 905], [539, 923, 668, 952], [679, 923, 717, 960], [719, 923, 869, 960], [879, 923, 1073, 960], [1083, 923, 1245, 957], [1260, 923, 1512, 958], [1526, 923, 1616, 952], [454, 985, 515, 1019], [540, 985, 642, 1013], [653, 985, 690, 1020], [702, 985, 894, 1022], [905, 985, 962, 1013], [974, 986, 1135, 1014], [1146, 986, 1183, 1013], [1196, 985, 1276, 1014], [1292, 985, 1436, 1013], [1447, 985, 1550, 1013], [1562, 985, 1696, 1022], [1708, 985, 1755, 1013], [1765, 985, 1846, 1022], [1857, 985, 1972, 1022], [1983, 989, 2100, 1013], [540, 1031, 687, 1068], [697, 1031, 921, 1059], [935, 1031, 1064, 1060], [1073, 1031, 1111, 1068], [1113, 1031, 1257, 1059], [1268, 1032, 1419, 1068], [1428, 1031, 1589, 1065], [1606, 1031, 1807, 1065], [1819, 1032, 1895, 1060], [1905, 1031, 1995, 1060], [2011, 1031, 2099, 1060], [544, 1075, 727, 1105], [454, 1139, 515, 1173], [539, 1139, 611, 1167], [626, 1140, 657, 1167], [672, 1140, 747, 1173], [764, 1139, 894, 1167], [910, 1139, 1029, 1173], [1046, 1139, 1155, 1167], [1170, 1139, 1235, 1173], [1253, 1139, 1310, 1167], [1325, 1139, 1520, 1176], [1534, 1140, 1571, 1167], [1587, 1139, 1744, 1176], [1771, 1139, 1924, 1176], [1938, 1139, 2021, 1168], [2036, 1148, 2098, 1167], [539, 1184, 687, 1221], [701, 1184, 748, 1212], [758, 1184, 974, 1221], [987, 1184, 1126, 1212], [1138, 1184, 1320, 1212], [1338, 1185, 1371, 1212], [1382, 1184, 1587, 1221], [1599, 1184, 1637, 1221], [1641, 1185, 1785, 1218], [1799, 1184, 1889, 1213], [1265, 3137, 1283, 3166]], "scores": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "structures": {"pages": {"version": "1.0", "structure_value": [[0, 470], [470, 1191], [1191, 1786], [1786, 2185], [2185, 2752], [2752, 3167], [3167, 3590], [3590, 4113], [4113, 4289]], "positions": [[0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300]]}, "lines": {"version": "1.0", "structure_value": [[0, 4], [4, 6], [6, 12], [12, 16], [16, 19], [19, 23], [23, 24], [24, 25], [25, 36], [36, 47], [47, 58], [58, 67], [67, 79], [79, 90], [90, 104], [104, 114], [114, 126], [126, 138], [138, 151], [151, 163], [163, 174], [174, 187], [187, 199], [199, 210], [210, 212], [212, 214], [214, 228], [228, 240], [240, 253], [253, 267], [267, 284], [284, 300], [300, 313], [313, 320], [320, 332], [332, 346], [346, 363], [363, 380], [380, 397], [397, 410], [410, 424], [424, 436], [436, 437], [437, 438], [438, 439], [439, 440], [440, 441], [441, 442], [442, 443], [443, 444], [444, 445], [445, 446], [446, 447], [447, 448], [448, 449], [449, 450], [450, 451], [451, 452], [452, 453], [453, 454], [454, 455], [455, 456], [456, 457], [457, 458], [458, 459], [459, 460], [460, 461], [461, 462], [462, 463], [463, 464], [464, 465], [465, 466], [466, 467], [467, 468], [468, 469], [469, 470], [470, 485], [485, 498], [498, 515], [515, 531], [531, 543], [543, 559], [559, 574], [574, 592], [592, 609], [609, 627], [627, 641], [641, 647], [647, 653], [653, 668], [668, 686], [686, 706], [706, 722], [722, 731], [731, 746], [746, 762], [762, 777], [777, 793], [793, 808], [808, 822], [822, 835], [835, 843], [843, 855], [855, 870], [870, 886], [886, 900], [900, 913], [913, 927], [927, 940], [940, 952], [952, 967], [967, 981], [981, 992], [992, 1000], [1000, 1003], [1003, 1017], [1017, 1031], [1031, 1045], [1045, 1059], [1059, 1074], [1074, 1086], [1086, 1103], [1103, 1117], [1117, 1133], [1133, 1149], [1149, 1164], [1164, 1178], [1178, 1190], [1190, 1191], [1191, 1208], [1208, 1224], [1224, 1239], [1239, 1253], [1253, 1257], [1257, 1274], [1274, 1290], [1290, 1309], [1309, 1319], [1319, 1322], [1322, 1336], [1336, 1352], [1352, 1367], [1367, 1383], [1383, 1398], [1398, 1414], [1414, 1427], [1427, 1444], [1444, 1458], [1458, 1461], [1461, 1475], [1475, 1487], [1487, 1507], [1507, 1526], [1526, 1535], [1535, 1540], [1540, 1541], [1541, 1542], [1542, 1557], [1557, 1561], [1561, 1574], [1574, 1589], [1589, 1607], [1607, 1624], [1624, 1641], [1641, 1642], [1642, 1643], [1643, 1655], [1655, 1656], [1656, 1664], [1664, 1679], [1679, 1694], [1694, 1711], [1711, 1719], [1719, 1721], [1721, 1722], [1722, 1723], [1723, 1724], [1724, 1725], [1725, 1726], [1726, 1742], [1742, 1757], [1757, 1772], [1772, 1785], [1785, 1786], [1786, 1802], [1802, 1819], [1819, 1833], [1833, 1847], [1847, 1864], [1864, 1880], [1880, 1900], [1900, 1915], [1915, 1918], [1918, 1922], [1922, 1923], [1923, 1924], [1924, 1927], [1927, 1928], [1928, 1946], [1946, 1960], [1960, 1979], [1979, 1991], [1991, 2007], [2007, 2024], [2024, 2043], [2043, 2051], [2051, 2055], [2055, 2056], [2056, 2057], [2057, 2059], [2059, 2060], [2060, 2061], [2061, 2069], [2069, 2088], [2088, 2102], [2102, 2116], [2116, 2133], [2133, 2149], [2149, 2165], [2165, 2170], [2170, 2183], [2183, 2184], [2184, 2185], [2185, 2201], [2201, 2207], [2207, 2209], [2209, 2210], [2210, 2211], [2211, 2212], [2212, 2213], [2213, 2214], [2214, 2218], [2218, 2219], [2219, 2220], [2220, 2221], [2221, 2223], [2223, 2224], [2224, 2225], [2225, 2228], [2228, 2243], [2243, 2258], [2258, 2271], [2271, 2283], [2283, 2293], [2293, 2295], [2295, 2299], [2299, 2314], [2314, 2328], [2328, 2343], [2343, 2358], [2358, 2370], [2370, 2386], [2386, 2402], [2402, 2418], [2418, 2426], [2426, 2442], [2442, 2456], [2456, 2470], [2470, 2487], [2487, 2497], [2497, 2513], [2513, 2529], [2529, 2542], [2542, 2559], [2559, 2572], [2572, 2590], [2590, 2592], [2592, 2596], [2596, 2609], [2609, 2624], [2624, 2637], [2637, 2651], [2651, 2666], [2666, 2673], [2673, 2689], [2689, 2704], [2704, 2719], [2719, 2720], [2720, 2721], [2721, 2722], [2722, 2723], [2723, 2724], [2724, 2739], [2739, 2751], [2751, 2752], [2752, 2753], [2753, 2755], [2755, 2758], [2758, 2759], [2759, 2760], [2760, 2761], [2761, 2762], [2762, 2763], [2763, 2764], [2764, 2765], [2765, 2766], [2766, 2767], [2767, 2768], [2768, 2769], [2769, 2770], [2770, 2771], [2771, 2772], [2772, 2773], [2773, 2774], [2774, 2788], [2788, 2797], [2797, 2810], [2810, 2826], [2826, 2830], [2830, 2836], [2836, 2837], [2837, 2838], [2838, 2839], [2839, 2840], [2840, 2843], [2843, 2844], [2844, 2845], [2845, 2846], [2846, 2847], [2847, 2848], [2848, 2849], [2849, 2850], [2850, 2851], [2851, 2852], [2852, 2853], [2853, 2854], [2854, 2855], [2855, 2856], [2856, 2857], [2857, 2858], [2858, 2859], [2859, 2860], [2860, 2861], [2861, 2862], [2862, 2863], [2863, 2864], [2864, 2865], [2865, 2866], [2866, 2867], [2867, 2873], [2873, 2874], [2874, 2875], [2875, 2876], [2876, 2877], [2877, 2880], [2880, 2881], [2881, 2882], [2882, 2883], [2883, 2884], [2884, 2885], [2885, 2887], [2887, 2903], [2903, 2919], [2919, 2925], [2925, 2940], [2940, 2954], [2954, 2970], [2970, 2988], [2988, 3003], [3003, 3018], [3018, 3033], [3033, 3047], [3047, 3051], [3051, 3053], [3053, 3067], [3067, 3081], [3081, 3098], [3098, 3107], [3107, 3125], [3125, 3138], [3138, 3153], [3153, 3166], [3166, 3167], [3167, 3184], [3184, 3200], [3200, 3213], [3213, 3232], [3232, 3240], [3240, 3242], [3242, 3256], [3256, 3269], [3269, 3285], [3285, 3297], [3297, 3312], [3312, 3324], [3324, 3338], [3338, 3343], [3343, 3358], [3358, 3371], [3371, 3386], [3386, 3398], [3398, 3414], [3414, 3431], [3431, 3447], [3447, 3450], [3450, 3470], [3470, 3485], [3485, 3498], [3498, 3513], [3513, 3530], [3530, 3540], [3540, 3541], [3541, 3556], [3556, 3569], [3569, 3586], [3586, 3589], [3589, 3590], [3590, 3591], [3591, 3604], [3604, 3615], [3615, 3630], [3630, 3633], [3633, 3646], [3646, 3659], [3659, 3672], [3672, 3682], [3682, 3684], [3684, 3697], [3697, 3709], [3709, 3715], [3715, 3727], [3727, 3737], [3737, 3742], [3742, 3755], [3755, 3766], [3766, 3780], [3780, 3791], [3791, 3793], [3793, 3806], [3806, 3818], [3818, 3829], [3829, 3831], [3831, 3850], [3850, 3853], [3853, 3867], [3867, 3879], [3879, 3889], [3889, 3901], [3901, 3910], [3910, 3926], [3926, 3933], [3933, 3945], [3945, 3957], [3957, 3960], [3960, 3971], [3971, 3979], [3979, 3991], [3991, 4003], [4003, 4017], [4017, 4023], [4023, 4037], [4037, 4041], [4041, 4059], [4059, 4070], [4070, 4084], [4084, 4088], [4088, 4101], [4101, 4111], [4111, 4112], [4112, 4113], [4113, 4129], [4129, 4139], [4139, 4154], [4154, 4164], [4164, 4168], [4168, 4182], [4182, 4192], [4192, 4194], [4194, 4206], [4206, 4212], [4212, 4229], [4229, 4236], [4236, 4251], [4251, 4262], [4262, 4263], [4263, 4278], [4278, 4288], [4288, 4289]], "positions": [[519, 462, 2031, 527], [1018, 545, 1532, 610], [914, 798, 1635, 828], [997, 845, 1552, 882], [1101, 890, 1448, 927], [1080, 936, 1470, 971], [709, 979, 1840, 1020], [1182, 1148, 1368, 1183], [600, 1272, 1950, 1309], [599, 1318, 1949, 1355], [599, 1363, 1948, 1400], [600, 1409, 1949, 1446], [599, 1455, 1949, 1492], [599, 1500, 1948, 1537], [600, 1546, 1950, 1583], [601, 1592, 1948, 1629], [599, 1637, 1949, 1674], [599, 1683, 1948, 1720], [600, 1729, 1949, 1766], [600, 1774, 1948, 1811], [600, 1820, 1950, 1857], [600, 1866, 1950, 1903], [600, 1911, 1948, 1948], [600, 1957, 1950, 1994], [600, 2003, 758, 2032], [452, 2182, 794, 2217], [450, 2303, 2098, 2340], [450, 2348, 2099, 2385], [450, 2394, 2099, 2431], [451, 2440, 2098, 2477], [449, 2484, 2097, 2522], [450, 2531, 2097, 2568], [450, 2577, 2098, 2614], [449, 2622, 1084, 2656], [450, 2693, 2099, 2730], [450, 2739, 2099, 2776], [450, 2784, 2099, 2821], [450, 2830, 2099, 2867], [450, 2876, 2099, 2913], [450, 2921, 2098, 2958], [451, 2967, 2099, 3004], [449, 3013, 1854, 3050], [1269, 3137, 1280, 3165], [97, 2265, 134, 2308], [97, 2235, 133, 2272], [83, 2188, 133, 2246], [83, 2162, 133, 2184], [98, 2117, 133, 2164], [103, 2102, 134, 2113], [82, 2058, 133, 2089], [82, 2010, 134, 2051], [82, 1975, 133, 2006], [82, 1929, 133, 1968], [125, 1913, 134, 1924], [82, 1864, 134, 1906], [82, 1829, 133, 1860], [83, 1781, 133, 1821], [82, 1740, 134, 1781], [98, 1698, 133, 1745], [82, 1654, 133, 1700], [81, 1594, 142, 1613], [97, 1549, 134, 1588], [97, 1517, 134, 1550], [125, 1504, 134, 1515], [82, 1443, 134, 1497], [83, 1393, 133, 1441], [81, 1370, 142, 1389], [82, 1281, 133, 1320], [82, 1237, 134, 1278], [83, 1141, 133, 1218], [97, 1101, 134, 1144], [97, 1071, 133, 1108], [82, 1017, 133, 1056], [82, 974, 134, 1015], [82, 938, 133, 969], [82, 888, 133, 934], [451, 354, 2099, 391], [452, 400, 2098, 437], [450, 445, 2099, 482], [451, 491, 2099, 528], [451, 537, 2099, 574], [452, 582, 2098, 619], [451, 628, 2099, 665], [451, 674, 2098, 711], [451, 719, 2097, 756], [451, 765, 2099, 802], [450, 811, 2099, 848], [451, 856, 1024, 893], [451, 989, 1537, 1033], [451, 1104, 2098, 1141], [451, 1150, 2099, 1187], [451, 1195, 2098, 1232], [450, 1241, 2099, 1278], [450, 1287, 1503, 1324], [451, 1357, 2100, 1394], [451, 1403, 2097, 1440], [451, 1449, 2099, 1486], [451, 1494, 2099, 1531], [452, 1540, 2099, 1577], [451, 1586, 2102, 1623], [450, 1631, 2099, 1668], [451, 1677, 1532, 1714], [451, 1748, 2099, 1785], [451, 1793, 2102, 1830], [451, 1839, 2098, 1876], [451, 1884, 2099, 1921], [451, 1930, 2099, 1967], [452, 1976, 2098, 2013], [451, 2021, 2098, 2058], [451, 2067, 2099, 2104], [452, 2113, 2099, 2150], [452, 2158, 2099, 2195], [451, 2203, 2099, 2238], [450, 2249, 1487, 2284], [451, 2371, 995, 2409], [451, 2465, 2100, 2502], [452, 2510, 2099, 2547], [451, 2556, 2100, 2593], [452, 2602, 2099, 2639], [450, 2647, 2097, 2684], [454, 2693, 2097, 2730], [452, 2739, 2097, 2776], [451, 2784, 2099, 2821], [451, 2830, 2099, 2867], [451, 2876, 2099, 2913], [451, 2921, 2099, 2958], [450, 2967, 2099, 3004], [452, 3013, 1695, 3050], [1265, 3137, 1284, 3165], [451, 354, 2098, 391], [451, 400, 2099, 437], [451, 445, 2097, 482], [450, 491, 2099, 528], [452, 537, 936, 574], [452, 607, 2099, 644], [451, 653, 2099, 690], [451, 699, 2099, 736], [451, 744, 1333, 781], [451, 860, 918, 904], [451, 966, 2097, 1003], [451, 1011, 2100, 1048], [451, 1057, 2097, 1094], [451, 1103, 2097, 1140], [450, 1173, 2098, 1210], [451, 1219, 2099, 1256], [451, 1265, 2099, 1302], [452, 1310, 2099, 1347], [450, 1356, 1923, 1393], [451, 1461, 825, 1499], [451, 1548, 2099, 1585], [450, 1594, 2099, 1631], [451, 1638, 2099, 1676], [452, 1683, 2097, 1725], [454, 1728, 1089, 1771], [1020, 1814, 1507, 1855], [1515, 1805, 1528, 1824], [2053, 1817, 2098, 1852], [451, 1892, 2003, 1930], [451, 1998, 890, 2028], [451, 2085, 2097, 2122], [451, 2123, 1924, 2167], [451, 2200, 2098, 2238], [450, 2247, 2097, 2284], [451, 2292, 1906, 2329], [1073, 2365, 1471, 2406], [2053, 2368, 2098, 2403], [451, 2449, 1500, 2490], [1503, 2452, 1515, 2465], [1537, 2445, 2098, 2482], [451, 2498, 2098, 2535], [451, 2543, 2098, 2580], [450, 2589, 2099, 2626], [452, 2635, 1395, 2672], [1155, 2770, 1280, 2794], [1309, 2710, 1339, 2739], [1296, 2748, 1352, 2806], [1298, 2818, 1349, 2838], [1363, 2770, 1392, 2794], [2053, 2760, 2098, 2795], [451, 2876, 2097, 2913], [451, 2921, 2100, 2958], [451, 2967, 2098, 3004], [451, 3013, 2052, 3050], [1266, 3137, 1282, 3166], [451, 1215, 2099, 1253], [451, 1262, 2098, 1299], [451, 1308, 2099, 1345], [450, 1353, 2078, 1390], [451, 1530, 2100, 1567], [451, 1575, 2097, 1613], [451, 1620, 2099, 1658], [451, 1666, 2099, 1704], [452, 1712, 753, 1751], [985, 1815, 1201, 1858], [1269, 1806, 1325, 1864], [1218, 1875, 1374, 1906], [1388, 1815, 1562, 1856], [2053, 1818, 2098, 1853], [451, 1986, 2097, 2023], [450, 2032, 2098, 2069], [451, 2077, 2099, 2114], [450, 2122, 1512, 2160], [450, 2194, 2099, 2231], [450, 2239, 2098, 2276], [450, 2284, 2099, 2323], [446, 2328, 1196, 2369], [1011, 2446, 1387, 2489], [1405, 2420, 1426, 2450], [1407, 2477, 1424, 2505], [1438, 2446, 1516, 2487], [1524, 2441, 1537, 2460], [2053, 2448, 2098, 2484], [451, 2557, 1185, 2598], [451, 2627, 2099, 2668], [451, 2676, 2098, 2713], [451, 2721, 2099, 2758], [451, 2764, 2098, 2805], [451, 2812, 2097, 2850], [451, 2858, 2100, 2895], [452, 2904, 782, 2941], [855, 2994, 1691, 3040], [2053, 2997, 2098, 3032], [1265, 3137, 1284, 3165], [451, 351, 2099, 392], [451, 400, 1035, 429], [818, 505, 963, 546], [1031, 496, 1087, 554], [980, 565, 1137, 595], [1204, 464, 1218, 484], [1183, 496, 1239, 554], [1185, 566, 1236, 585], [1250, 505, 1504, 546], [1510, 463, 1581, 588], [1599, 479, 1620, 509], [1601, 536, 1618, 564], [1631, 505, 1710, 546], [1718, 500, 1731, 519], [2053, 508, 2098, 543], [451, 662, 829, 700], [451, 748, 2097, 785], [452, 794, 2099, 831], [451, 839, 2100, 876], [452, 885, 2099, 922], [452, 931, 1391, 968], [451, 1045, 794, 1089], [451, 1148, 919, 1178], [451, 1235, 2102, 1272], [450, 1280, 2099, 1317], [451, 1326, 2097, 1363], [451, 1371, 2099, 1409], [452, 1416, 2099, 1454], [451, 1463, 2099, 1500], [451, 1501, 2097, 1545], [450, 1547, 2099, 1591], [452, 1600, 1299, 1637], [450, 1669, 2102, 1707], [451, 1716, 2100, 1753], [451, 1761, 2097, 1799], [450, 1807, 2097, 1844], [451, 1853, 1752, 1890], [451, 1924, 2098, 1961], [451, 1969, 2099, 2006], [451, 2014, 1879, 2052], [450, 2085, 2098, 2122], [451, 2130, 2097, 2168], [451, 2177, 2100, 2214], [451, 2215, 705, 2259], [451, 2325, 1235, 2363], [450, 2412, 2099, 2449], [451, 2458, 2100, 2495], [451, 2503, 2098, 2540], [451, 2549, 2099, 2586], [451, 2594, 2099, 2631], [450, 2640, 1541, 2677], [450, 2711, 2097, 2748], [450, 2756, 2100, 2793], [451, 2802, 2099, 2839], [505, 2876, 512, 2893], [519, 2883, 1207, 2915], [503, 2921, 514, 2938], [519, 2929, 1209, 2961], [503, 2966, 513, 2983], [518, 2973, 2100, 3007], [451, 3015, 2029, 3048], [1265, 3136, 1282, 3166], [962, 345, 1069, 373], [1258, 345, 1587, 373], [962, 392, 1361, 429], [1482, 392, 1551, 421], [962, 438, 1094, 467], [1292, 437, 1359, 467], [1482, 438, 1552, 467], [962, 484, 1023, 511], [1292, 483, 1359, 512], [1482, 483, 1553, 512], [962, 529, 1101, 557], [1292, 529, 1362, 558], [1482, 529, 1549, 557], [963, 576, 1097, 605], [1293, 576, 1362, 605], [1482, 576, 1553, 604], [963, 622, 1122, 651], [1292, 621, 1363, 651], [1482, 621, 1553, 651], [450, 709, 2097, 746], [450, 755, 2097, 792], [449, 800, 2099, 837], [451, 846, 2099, 883], [450, 892, 821, 926], [600, 1515, 1288, 1544], [573, 1404, 611, 1433], [573, 1311, 611, 1340], [573, 1217, 611, 1246], [573, 1124, 611, 1153], [724, 1579, 1140, 1616], [464, 1462, 493, 1487], [464, 1449, 492, 1459], [473, 1431, 492, 1447], [473, 1416, 492, 1428], [473, 1400, 492, 1412], [464, 1387, 492, 1397], [464, 1365, 492, 1386], [473, 1346, 492, 1362], [473, 1327, 492, 1343], [468, 1315, 492, 1326], [464, 1304, 492, 1314], [473, 1284, 492, 1303], [473, 1263, 492, 1282], [464, 1223, 492, 1251], [473, 1205, 492, 1221], [473, 1186, 492, 1202], [473, 1165, 492, 1185], [473, 1150, 492, 1164], [473, 1132, 492, 1148], [473, 1115, 492, 1131], [473, 1094, 501, 1113], [464, 1070, 499, 1081], [464, 1037, 493, 1066], [464, 1022, 499, 1033], [1357, 1515, 2044, 1544], [1330, 1404, 1367, 1433], [1330, 1274, 1367, 1303], [1330, 1143, 1367, 1172], [1330, 1013, 1367, 1042], [1481, 1579, 1896, 1616], [643, 1673, 777, 1702], [873, 1673, 1032, 1702], [1127, 1673, 1266, 1701], [1359, 1673, 1420, 1700], [1513, 1673, 1645, 1702], [1738, 1673, 1981, 1710], [451, 1790, 2099, 1827], [451, 1836, 2099, 1873], [451, 1882, 957, 1919], [451, 2036, 2099, 2074], [452, 2082, 1944, 2119], [450, 2153, 2099, 2190], [451, 2199, 2099, 2236], [455, 2244, 2097, 2281], [452, 2290, 1801, 2327], [451, 2361, 2097, 2398], [451, 2406, 2099, 2443], [452, 2452, 855, 2489], [451, 2574, 773, 2604], [450, 2668, 2099, 2705], [450, 2714, 2099, 2751], [452, 2759, 2099, 2796], [451, 2805, 1295, 2842], [451, 2876, 2102, 2913], [450, 2921, 2099, 2958], [452, 2967, 2099, 3004], [451, 3013, 1979, 3050], [1265, 3137, 1283, 3166], [451, 986, 2099, 1023], [451, 1031, 2099, 1068], [451, 1077, 2097, 1114], [450, 1123, 2099, 1160], [451, 1168, 1240, 1205], [451, 1363, 780, 1398], [450, 1510, 2098, 1547], [451, 1556, 2099, 1593], [451, 1601, 2099, 1638], [451, 1647, 2099, 1684], [451, 1693, 2097, 1730], [451, 1738, 2099, 1775], [452, 1784, 2097, 1821], [451, 1830, 978, 1867], [451, 1900, 2098, 1937], [451, 1946, 2099, 1983], [450, 1992, 2099, 2029], [451, 2037, 2068, 2074], [451, 2108, 2100, 2145], [452, 2154, 2099, 2191], [450, 2199, 2099, 2236], [452, 2245, 811, 2282], [451, 2315, 2098, 2352], [451, 2361, 2099, 2398], [451, 2406, 2100, 2444], [451, 2452, 2099, 2489], [451, 2498, 2100, 2535], [451, 2544, 1880, 2581], [450, 2729, 860, 2773], [451, 2876, 2097, 2913], [452, 2921, 2097, 2958], [450, 2966, 2099, 3004], [450, 3013, 879, 3042], [1265, 3138, 1283, 3165], [451, 348, 680, 383], [474, 426, 2098, 463], [540, 472, 1960, 509], [474, 532, 2099, 569], [540, 576, 1055, 611], [474, 637, 2098, 674], [540, 683, 2077, 720], [474, 743, 2098, 780], [539, 788, 2100, 826], [541, 835, 713, 869], [474, 894, 2099, 932], [540, 939, 2097, 977], [539, 986, 1445, 1023], [474, 1046, 2099, 1083], [540, 1092, 2100, 1129], [540, 1136, 1643, 1174], [474, 1198, 2096, 1235], [540, 1243, 1839, 1280], [474, 1303, 2099, 1340], [541, 1348, 2097, 1386], [540, 1394, 828, 1424], [474, 1455, 2097, 1492], [540, 1500, 2099, 1537], [540, 1546, 2106, 1583], [537, 1592, 726, 1626], [454, 1652, 2098, 1689], [540, 1698, 830, 1735], [454, 1757, 1759, 1795], [454, 1818, 2098, 1855], [539, 1863, 1823, 1900], [454, 1924, 2099, 1961], [540, 1969, 1730, 2006], [454, 2029, 2102, 2066], [540, 2075, 1481, 2112], [454, 2134, 2099, 2169], [540, 2181, 2101, 2218], [541, 2226, 1026, 2263], [454, 2287, 2099, 2324], [539, 2332, 1540, 2369], [454, 2392, 2098, 2429], [540, 2438, 1972, 2475], [454, 2498, 2099, 2535], [539, 2544, 1286, 2581], [454, 2604, 2100, 2641], [540, 2650, 1102, 2684], [454, 2700, 2098, 2747], [540, 2755, 2007, 2792], [454, 2815, 2098, 2852], [540, 2861, 924, 2898], [454, 2921, 2098, 2958], [540, 2966, 2097, 3002], [541, 3013, 672, 3042], [1266, 3137, 1282, 3166], [454, 354, 2098, 391], [540, 400, 1638, 437], [454, 462, 2098, 499], [540, 508, 2098, 545], [540, 553, 986, 590], [454, 615, 2098, 653], [541, 661, 2097, 698], [544, 707, 838, 741], [454, 769, 2098, 806], [540, 815, 1174, 852], [454, 877, 2097, 914], [539, 923, 1616, 960], [454, 985, 2100, 1022], [540, 1031, 2099, 1068], [544, 1075, 727, 1105], [454, 1139, 2098, 1176], [539, 1184, 1889, 1221], [1265, 3137, 1283, 3166]]}}}}, {"tool_name": "tesseract", "text": "Multilingual Distributed Representations without Word Alignment Karl Moritz Hermann and Phil Blunsom Department of Computer Science University of Oxford Oxford, OX1 3QD, UK {karl.moritz.hermann, phil.blunsom}@cs.ox.ac.uk Abstract Distributed representations of meaning are a natural way to encode covariance relationships between words and phrases in NLP. By overcoming data sparsity problems, as well as providing information about semantic relatedness which is not available in discrete representations, distributed representations have proven useful in many NLP tasks. Recent work has shown how compositional semantic representations can successfully be applied to a number of monolingual applica- tions such as sentiment analysis. At the same time, there has been some initial success in work on learning shared word-level representations across languages. We combine these two approaches by proposing a method for learning distributed representations in a multilingual setup. Our model learns to assign similar embed- dings to aligned sentences and dissimilar ones to sentence which are not aligned while not requiring word alignments. We show that our representations are seman- tically informative and apply them to a cross-lingual document classification task where we outperform the previous state of the art. Further, by employing parallel corpora of multiple language pairs we find that our model learns representations that capture semantic relationships across languages for which no parallel data was used. 1 Introduction Distributed representations of words are increasingly being used to achieve high levels of generalisa- tion within language modelling tasks. Successful applications of this approach include word-sense disambiguation, word similarity and synonym detection (e.g. [10, 27]). Subsequent work has also attempted to learn distributed semantics of larger structures, allowing us to apply distributed rep- resentation to tasks such as sentiment analysis or paraphrase detection (i.a. [1, 3, 12, 14, 21, 25]). At the same time a second strand of work has focused on transferring linguistic knowledge across languages, and particularly from English into low-resource languages, by means of distributed rep- resentations at the word level [13, 16]. Currently, work on compositional semantic representations focuses on monolingual data while the cross-lingual work focuses on word level representations only. However, it appears logical that these two strands of work should be combined as there exists a plethora of parallel corpora with aligned data at the sentence level or beyond which could be exploited in such work. Further, sentence aligned data provides a plausible concept of semantic similarity, which can be harder to define at the word level. Consider the case of alignment between a German compound noun (e.g. \u201cSchwerlastverkehr\u2019\u2019) and its English equivalent (\u201cheavy goods vehicle traffic\u2019). Semantic alignment at the phrase level here appears far more plausible than aligning individual tokens for semantic transfer. Using this rationale, and building on both work related to learning cross-lingual embeddings as well as to compositional semantic representations, we introduce a model that learns cross-lingual em- beddings at the sentence level. In the following section we will briefly discuss prior work in these two fields before going on to describe the bilingual training signal that we developed for learning multilingual compositional embeddings. Subsequently, we will describe our model in greater detail as well as its training procedure and experimental setup. Finally, we perform a number of evalua- tions and demonstrate that our training signal allows a very simple compositional vector model to outperform the state of the art on a task designed to evaluate its ability to transfer semantic informa- tion across languages. Unlike other work in this area, our model does not require word aligned data. In fact, while we evaluate our model on sentence aligned data in this paper, there is no theoretical requirement for this and technically our algorithm could also be applied to document-level parallel data or even comparable data only. 2 Models of Compositional Distributed Semantics In the case of representing individual words as vectors, the distributional account of semantics pro- vides a plausible explanation of what is encoded in a word vector. This follows the idea that the meaning of a word can be determined by \u201cthe company it keeps\u201d [11], that is by the context it ap- pears in. Such context can easily be encoded in vectors using collocational methods, and is also underlying other methods of learning word embeddings [7, 20]. For a number of important problems, semantic representations of individual words do not suffice, but instead a semantic representation of a larger structure\u2014e.g. a phrase or a sentence\u2014is required. This was highlighted in [10], who proposed a mechanism for modifying a word\u2019s representation based on its individual context. The distributional account of semantics can, due to sparsity, not be applied to such larger linguistic units. A notable exception perhaps is Baroni and Zamparelli [1], who learned distributional representations for adjective noun pairs using a collocational approach on a corpus of unprecedented size. The bigram representations learned from that corpus were subsequently used to learn lexicalised composition functions for the constituent words. Most alternative attempts to extract such higher-level semantic representations have focused on learning composition functions that represent the semantics of a larger structure as a function of the representations of its parts. [21] provides an evaluation of a number of simple composition func- tions applied to bigrams. Applied recursively, such approaches can then easily be reconciled with the co-occurrence based word level representations. There are a number of proposals motivating such recursive or deep composition models. Notably, [3] propose a tensor-based model for semantic composition and, similarly, [4] develop a framework for semantic composition by combining dis- tributional theory with pregroup grammars. The latter framework was empirically evaluated and supported by the results in [12]. More recently, various forms of recursive neural networks have successfully been used for semantic composition and related tasks such as sentiment analysis. Such models include recursive autoencoders [24], matrix-vector recursive neural networks [25], untied recursive neural networks [14] or convolutional networks [15]. 2.1 Multilingual Embeddings Much research has been devoted to the task of inducing distributed semantic representations for single languages. In particular English, with its large number of annotated resources, has enjoyed most attention. Recently, progress has been made at representation learning for languages with fewer available resources. Klementiev et al. [16] described a form of multitask learning on word-aligned parallel data to transfer embeddings from one language to another. Earlier work, Haghighi et al. [13], proposed a method for inducing cross-lingual lexica using monolingual feature representations and a small initial lexicon to bootstrap with. This approach has recently been extended by [18, 19], who developed a method for learning transformation matrices to convert semantic vectors of one language into those of another. Is was demonstrated that this approach can be applied to improve tasks related to machine translation. Their CBOW model is also worth noting for its similarities to the composition function used in this paper. Using a slightly different approach, [29], also learned bilingual embeddings for machine translation. It is important to note that, unlike our proposed system, all of these methods require word aligned parallel data for training. Two recent workshop papers deserve mention in this respect. Both Lauly et al. [17] and Sarath Chan- dar et al. [23] propose methods for learning word embeddings by exploiting bilingual data, not unlike the method proposed in this paper. Instead of the noise-contrastive method developed in this paper, both groups of authors make use of autoencoders to encode monolingual representations and to support the bilingual transfer. So far almost all of this work has been focused on learning multilingual representations at the word level. As distributed representations of larger expressions have been shown to be highly useful for a number of tasks, it seems to be a natural next step to also attempt to induce these using cross-lingual data. This paper provides a first step in that direction. 3 Model Description Language acquisition in humans is widely seen as grounded in sensory-motor experience [22, 2]. Based on this idea, there have been some attempts at using multi-modal data for learning better vector representations of words (e.g. [26]). Such methods, however, are not easily scalable across languages or to large amounts of data for which no secondary or tertiary representation might exist. We abstract the underlying principle one step further and attempt to learn semantics from multi- lingual data. The idea is that, given enough parallel data, a shared representation would be forced to capture the common elements between sentences from different languages. What two parallel sentences have in common, of course, is the semantics of those two sentences. Using this data, we propose a novel method for learning vector representations at the word level and beyond. 3.1 Bilingual Signal Exploiting the semantic similarity of parallel sentences across languages, we can define a simple bilingual (and trivially multilingual) error function as follows: Given a compositional sentence model (CVM) M4, which maps a sentence to a vector, we can train a second CVM Mp using a corpus C4\\,5 of parallel data from the language pair A, B. For each pair of parallel sentences (a,b) \u20ac C4.p, we attempt to minimize Eaist (a, b) = ||Groot \u2014 broot ll (1) where @,-oo\u00a2 1s the vector representing sentence a and 6,4: the vector representing sentence b. 3.2. The BICVM Model A CVM learns semantic representations of larger syntactic units given the semantic representations of their constituents. We assume individual words to be represented by vectors (x \u20ac R\u00ae). Previous methods employ binary parse trees on the data (e.g. [14, 25]) and use weighted or multi- plicative composition functions. Under such a setup, where each node in the tree is terminal or has two children (p \u2014 co, \u20ac1), a binary composition function could take the following form: p= g(W*[co; c1] + b\u00b0) (2) where [co; \u00a21] is the concatenation of the two child vectors, W\u00b0 \u20ac IR?*?\u00a2 and 6\u00b0 \u20ac R\u00ae the encod- ing matrix and bias, respectively, and g an element-wise activation function such as the hyperbolic tangent. For the purposes of evaluation the bilingual signal proposed above, we simplify this com- position function by setting all weight matrices to the identity and all biases to zero. Thereby the CVM reduces to a simple additive composition function: |a| Groot = S- ay (3) 1=0 Of course, this is a very simplified CVM, as such a bag-of-words approach no longer accounts for word ordering and other effects which a more complex CVM might capture. However, for the purposes of this evaluation (and with the experimental evaluation in mind), such a simplistic composition function should be sufficient to evaluate the novel objective function proposed here. (0000) (oo ee) (00 00) (00 oo) at a2 a3 a4 Figure 1: Description of a bilingual model with parallel input sentences a and 6. The objective function of this model is to minimize the distance between the sentence level encoding of the bi- text. Principally any composition function can be used to generate the compositional sentence level representations. The composition function is represented by the CVM boxes in the diagram above. Using this additive CVM we want to optimize the bilingual error signal defined above (Eq. 1). For the moment, assume that M 4 is a perfectly trained CVM such that a@,oo\u00a2 represents the semantics of the sentence a. Further, due to the use of parallel data, we know that a and b are semantically equivalent. Hence we transfer the semantic knowledge contained in M4 onto Mag, by learning 944, to minimize: Byi(Ca.p)= S> Buise(a,b) (4) (a,b)EC 4 B Of course, this objective function assumes a fully trained model which we do not have at this stage. While this can be a useful objective for transferring linguistic knowledge into low-resource lan- guages [16], this precondition is not helpful when there is no model to learn from in first place. We resolve this issue by jointly training both models M 4 and Mp. Applying \u00a3; to parallel data ensures that both models learn a shared representation at the sentence level. As the parallel input sentences share the same meaning, it is reasonable to assume that mini- mizing F,,; will force the model to learn their semantic representation. Let 04; = 004, UO@m,. The joint objective function J(6;;) thus becomes: A J(0y:) = Evi(Ca,B) + 5 li@eill\u201d (3) where A||03;||1 is the Lz regularization term. It is apparent that this joint objective J(@,;) is degenerate. The models could learn to reduce all embeddings and composition weights to zero and thereby minimize the objective function. We ad- dress this issue by employing a form of contrastive estimation penalizing small distances between non-parallel sentence pairs. For every pair of parallel sentences (a,b) we sample a number of ad- ditional sentences n \u20ac Cg, which\u2014with high probability\u2014are not exact translations of a. This is comparable to the second term of the loss function of a large margin nearest neighbour classifier (see Eq. 12 in [28]): noise (a, b, n) = [1 + aust (a, b) \u2014_ Eaist(, ny, (6) where [x], = maz(x,0) denotes the standard hinge loss. Thus, the final objective function to minimize for the BICVM model is: k X J (Obi) = S- (>: Enoise (a, b, v0) + 5 lel\u201d (7) (a,b)EC4,B \\i=1 3.3 Model Learning Given the objective function as defined above, model learning can employ the same techniques as any monolingual CVM. In particular, as the objective function is differentiable, we can use standard gradient descent techniques such as stochastic gradient descent, L-BFGS or the adaptive gradient algorithm AdaGrad [8]. Within each monolingual CVM, we use backpropagation through structure after applying the joint error to each sentence level node. 4 Experiments 4.1 Data and Parameters All model weights were randomly initialised using a Gaussian distribution. There are a number of parameters that can influence model training. We selected the following values for simplicity and comparability with prior work. In future work we will investigate the effect of these parameters in greater detail. L2 regularization (1), step-size (0.1), number of noise elements (50), margin size (50), embedding dimensionality (d=40). The noise elements samples were randomly drawn from the corpus at training time, individually for each training sample and epoch. We use the Europarl corpus (v7)! for training the bilingual model. The corpus was pre-processed using the set of tools provided by cdec? [9] for tokenizing and lowercasing the data. Further, all empty sentences as well as their translations were removed from the corpus. We present results from two experiments. The BICVM model was trained on 500k sentence pairs of the English-German parallel section of the Europarl corpus. The BICVM-+ model used this dataset in combination with another 500k parallel sentences from the English-French section of the corpus, resulting in 1 million English sentences, each paired up with either a German or a French sentence. Each language\u2019s vocabulary used distinct encodings to avoid potential overlap. The motivation behind BICVM-+ is to investigate whether we can learn better embeddings by intro- ducing additional data in a different language. This is similar to prior work in machine translation where English was used as a pivot for translation between low-resource languages [5]. We use the adaptive gradient method, AdaGrad [8], for updating the weights of our models, and ter- minate training after 50 iterations. Earlier experiments indicated that the BICVM model converges faster than the BICVM+ model, but we report results on the same number of iterations for better comparability?. 4.2 Cross-Lingual Document Classification We evaluate our model using the cross-lingual document classification (CLDC) task of Klementiev et al. [16]. This task involves learning language independent embeddings which are then used for document classification across the English-German language pair. For this, CLDC employs a par- ticular kind of supervision, namely using supervised training data in one language and evaluating without supervision in another. Thus, CLDC is a good task for establishing whether our learned representations are semantically useful across multiple languages. We follow the experimental setup described in [16], with the exception that we learn our embeddings using solely the Europarl data and only use the Reuters RCV1/RCV2 corpora during the classifier training and testing stages. Each document in the classification task is represented by the average \u2018nttp://www.statmt .org/europarl/ *https://github.com/redpony/cdec >These numbers were updated following comments in the ICLR open review process. Results for other dimensionalities and our source code for our model are available at http://www. karlmoritz.com. Model en\u2014de de\u2014-en Majority Class 46.8 46.8 Glossed 65.1 68.6 MT 68.1 67.4 I-Matrix 77.6 71.1 BICVM 83.7 71.4 BICVM+ 86.2 76.9 Table 1: Classification accuracy for training on English and German with 1000 labeled examples. Cross-lingual compositional representations (BIC VM and BICVM-4), cross-lingual representations using learned embeddings and an interaction matrix (I-Matrix) [16] translated (MT) and glossed (Glossed) words, and the majority class baseline. The MT and Glossed results are also taken from Klementiev et al. [16]. Classification Accuracy (%) 100 =200 \u00a96500) \u00ab\u00a91000 5000 10000 100 200 \u00a7\u00a9500 = 61000 5000 10000 Training Documents (en) Training Documents (de) \u2014@ BICVM \u2014\u00ae BIC VM+ \u2014e\u2014 I-Matrix \u20144\u00ab\u2014 MT \u2014*\u2014 Glossed - - - Majority Class Figure 2: Classification accuracy for a number of models (see Table 1 for model descriptions). The left chart shows results for these models when trained on English data and evaluated on German data, the right chart vice versa. of the d-dimensional representations of all its sentences. We train the multiclass classifier using the same settings and implementation of the averaged perceptron classifier [6] as used in [16]. We ran the CLDC experiments both by training on English and testing on German documents and vice versa. Using the data splits provided by [16], we used varying training data sizes from 100 to 10,000 documents for training the multiclass classifier. The results of this task across training sizes are shown in Figure 2. Table 1 shows the results for training on 1,000 documents. Both models, BICVM and BICVM+ outperform all prior work on this task. Further, the BICVM+ model outperforms the BICVM model, indicating the usefulness of adding training data even from a separate language pair. 4.3 Visualization While the CLDC experiment focused on establishing the semantic content of the sentence level representations, we also want to briefly investigate the induced word embeddings. In particular the BICVM+ model is interesting for that purpose, as it allows us to evaluate our approach of using English as a pivot language in a multilingual setup. In Figure 3 we show the t-SNE projections for a number of English, French and German words. Of particular interest should be the right chart, which highlights bilingual embeddings between French and German words. Even though the model did not use any parallel French-German data during training, it still managed to learn semantic word-word similarity across these two languages. t / Maeexs, ee aera. abr Cirnaaaiaa, . aUugHatyt ; adhaay lyon Janyat Ac HRSA i Vite t= 5 8 - ne nBRORS. wear. GORA ae \u201cHERR: septembre ia sans yi september * = Star Figure 3: The left scatter plot shows t-SNE projections for a weekdays in all three languages using the representations learned in the BIC VM+ model. Even though the model did not use any parallel French-German data during training, it still learns semantic similarity between these two languages using English as a pivot. To highlight this, the right plot shows another set of words (months of the year) using only the German and French words. 5 Conclusions With this paper we have proposed a novel method for inducing cross-lingual distributed represen- tations for compositional semantics. Using a very simple method for semantic composition, we nevertheless managed to obtain state of the art results on the CLDC task, specifically designed to evaluate semantic transfer across languages. After extending our approach to include multilingual training data in the BIC VM+ model, we were able to demonstrate that adding additional languages further improves the model. Furthermore, using some qualitative experiments and visualizations, we showed that our approach also allows us to learn semantically related embeddings across languages without any direct training data. Our approach provides great flexibility in training data and requires little to no annotation. Hav- ing demonstrated the successful training of semantic representations using sentence aligned data, a plausible next step is to attempt training using document-aligned data or even corpora of comparable documents. This may provide even greater possibilities for working with low-resource languages. In the same vein, the success of our pivoting experiments suggest further work. Unlike other pivot approaches, it is easy to extend our model to have multiple pivot languages. Thus some pivots could preserve different aspects such as case, gender etc., and overcome other issues related to having a single pivot language. As we have achieved the results in this paper with a relatively simple CVM, it would also be inter- esting to establish whether our objective function can be used in combination with more complex compositional vector models such as MV-RNN [25] or tensor-based approaches, to see whether these can further improve results on both mono- and multilingual tasks when used in conjunction with our cross-lingual objective function. Related to this, we will also apply our model to a wider variety of tasks including machine translation and multilingual information extraction. Acknowledgements The authors would like to thank Alexandre Klementiev and his co-authors for making their datasets and averaged perceptron implementation available, as well as answering a number of questions related to their work on this task. This work was supported by EPSRC grant EP/K036580/1 and a Xerox Foundation Award. References [1] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] Marco Baroni and Roberto Zamparelli. Nouns are vectors, adjectives are matrices: Represent- ing adjective-noun constructions in semantic space. In Proceedings of EMNLP, 2010. Paul Bloom. Precis of how children learn the meanings of words. Behavioral and Brain Sciences, 24:1095\u20141103, 2001. Stephen Clark and Stephen Pulman. Combining symbolic and distributional models of mean- ing. In Proceedings of AAAI Spring Symposium on Quantum Interaction. AAAI Press, 2007. Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen Clark. Mathematical foundations for a com- positional distributional model of meaning. Lambek Festschrift. Linguistic Analysis, 36:345\u2014 384, 2010. Trevor Cohn and Mirella Lapata. Machine translation by triangulation: Making effective use of multi-parallel corpora. In Proceedings of ACL, pages 728-735, Prague, Czech Republic, June 2007. Association for Computational Linguistics. Michael Collins. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of ACL-EMNLP. Association for Computational Linguistics, 2002. doi: 10.3115/1118693.1118694. Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of ICML, 2008. John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121\u20142159, July 2011. ISSN 1532-4435. Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of ACE, 2010. K. Erk and S. Pad\u00e9. A structured vector space model for word meaning in context. Proceedings of EMNEP, 2008. J.R. Firth. A synopsis of linguistic theory 1930-55. 1952-59:1\u201432, 1957. Edward Grefenstette and Mehrnoosh Sadrzadeh. Experimental support for a categorical com- positional distributional model of meaning. In Proceedings of EMNLP, 2011. Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. Learning bilingual lexicons from monolingual corpora. In Proceedings of ACL-HLT, 2008. Karl Moritz Hermann and Phil Blunsom. The Role of Syntax in Vector Space Models of Compositional Semantics. In Proceedings of ACL, 2013. Nal Kalchbrenner and Phil Blunsom. Recurrent convolutional neural networks for discourse compositionality. In Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, 2013. Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. Inducing crosslingual distributed representations of words. In Proceedings of COLING, 2012. Stanislas Lauly, Alex Boulanger, and Hugo Larochelle. Learning multilingual word represen- tations using a bag-of-words autoencoder. In Deep Learning Workshop at NIPS, 2013. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. CoRR, 2013. Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. Exploiting similarities among languages for machine translation. CoRR, 2013. Toma\u00e9 Mikoloy, Martin Karafidt, Luka8 Burget, Jan Cernocky, and Sanjeev Khudanpur. Re- current neural network based language model. In Proceedings of INTERSPEECH, 2010. Jeff Mitchell and Mirella Lapata. Vector-based models of semantic composition. In In Pro- ceedings of ACL, 2008. D. Roy. Grounded spoken language acquisition: Experiments in word learning. [EEE Trans- actions on Multimedia, 5(2):197\u2014209, June 2003. ISSN 1520-9210. doi: 10.1109/TMM.2003. 811618. [23] [24] [25] [26] [27] [28] [29] A P Sarath Chandar, M Khapra Mitesh, B Ravindran, Vikas Raykar, and Amrita Saha. Multi- lingual deep learning. In Deep Learning Workshop at NIPS, 2013. Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Man- ning. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Pro- ceedings of EMNLP, 2011. Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. Semantic compo- sitionality through recursive matrix-vector spaces. In Proceedings of EMNLP-CoNLL, pages 1201-1211, 2012. Nitish Srivastava and Ruslan Salakhutdinov. Multimodal learning with deep boltzmann ma- chines. In Proceedings of NIPS. 2012. P. D. Tumey and P. Pantel. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37(1):141-188, 2010. Kilian Q. Weinberger and Lawrence K. Saul. Distance metric learning for large margin nearest neighbor classification. Journal of Machine Learning Research, 10:207\u2014244, June 2009. ISSN 1532-4435. Will Y. Zou, Richard Socher, Daniel Cer, and Christopher D. Manning. Bilingual word em- beddings for phrase-based machine translation. In Proceedings of EMNLP, 2013.", "common_format": {"doc_id": "./1312.6173v4.hocr", "tokens": ["Multilingual", "Distributed", "Representations", "without", "Word", "Alignment", "Karl", "Moritz", "Hermann", "and", "Phil", "Blunsom", "Department", "of", "Computer", "Science", "University", "of", "Oxford", "Oxford,", "OX1", "3QD,", "UK", "{karl.moritz.hermann,", "phil.blunsom}@cs.ox.ac.uk", "Abstract", "Distributed", "representations", "of", "meaning", "are", "a", "natural", "way", "to", "encode", "covariance", "relationships", "between", "words", "and", "phrases", "in", "NLP.", "By", "overcoming", "data", "sparsity", "problems,", "as", "well", "as", "providing", "information", "about", "semantic", "relatedness", "which", "is", "not", "available", "in", "discrete", "representations,", "distributed", "representations", "have", "proven", "useful", "in", "many", "NLP", "tasks.", "Recent", "work", "has", "shown", "how", "compositional", "semantic", "representations", "can", "successfully", "be", "applied", "to", "a", "number", "of", "monolingual", "applica-", "tions", "such", "as", "sentiment", "analysis.", "At", "the", "same", "time,", "there", "has", "been", "some", "initial", "success", "in", "work", "on", "learning", "shared", "word-level", "representations", "across", "languages.", "We", "combine", "these", "two", "approaches", "by", "proposing", "a", "method", "for", "learning", "distributed", "representations", "in", "a", "multilingual", "setup.", "Our", "model", "learns", "to", "assign", "similar", "embed-", "dings", "to", "aligned", "sentences", "and", "dissimilar", "ones", "to", "sentence", "which", "are", "not", "aligned", "while", "not", "requiring", "word", "alignments.", "We", "show", "that", "our", "representations", "are", "seman-", "tically", "informative", "and", "apply", "them", "to", "a", "cross-lingual", "document", "classification", "task", "where", "we", "outperform", "the", "previous", "state", "of", "the", "art.", "Further,", "by", "employing", "parallel", "corpora", "of", "multiple", "language", "pairs", "we", "find", "that", "our", "model", "learns", "representations", "that", "capture", "semantic", "relationships", "across", "languages", "for", "which", "no", "parallel", "data", "was", "used.", "1", "Introduction", "Distributed", "representations", "of", "words", "are", "increasingly", "being", "used", "to", "achieve", "high", "levels", "of", "generalisa-", "tion", "within", "language", "modelling", "tasks.", "Successful", "applications", "of", "this", "approach", "include", "word-sense", "disambiguation,", "word", "similarity", "and", "synonym", "detection", "(e.g.", "[10,", "27]).", "Subsequent", "work", "has", "also", "attempted", "to", "learn", "distributed", "semantics", "of", "larger", "structures,", "allowing", "us", "to", "apply", "distributed", "rep-", "resentation", "to", "tasks", "such", "as", "sentiment", "analysis", "or", "paraphrase", "detection", "(i.a.", "[1,", "3,", "12,", "14,", "21,", "25]).", "At", "the", "same", "time", "a", "second", "strand", "of", "work", "has", "focused", "on", "transferring", "linguistic", "knowledge", "across", "languages,", "and", "particularly", "from", "English", "into", "low-resource", "languages,", "by", "means", "of", "distributed", "rep-", "resentations", "at", "the", "word", "level", "[13,", "16].", "Currently,", "work", "on", "compositional", "semantic", "representations", "focuses", "on", "monolingual", "data", "while", "the", "cross-lingual", "work", "focuses", "on", "word", "level", "representations", "only.", "However,", "it", "appears", "logical", "that", "these", "two", "strands", "of", "work", "should", "be", "combined", "as", "there", "exists", "a", "plethora", "of", "parallel", "corpora", "with", "aligned", "data", "at", "the", "sentence", "level", "or", "beyond", "which", "could", "be", "exploited", "in", "such", "work.", "Further,", "sentence", "aligned", "data", "provides", "a", "plausible", "concept", "of", "semantic", "similarity,", "which", "can", "be", "harder", "to", "define", "at", "the", "word", "level.", "Consider", "the", "case", "of", "alignment", "between", "a", "German", "compound", "noun", "(e.g.", "\u201cSchwerlastverkehr\u2019\u2019)", "and", "its", "English", "equivalent", "(\u201cheavy", "goods", "vehicle", "traffic\u2019).", "Semantic", "alignment", "at", "the", "phrase", "level", "here", "appears", "far", "more", "plausible", "than", "aligning", "individual", "tokens", "for", "semantic", "transfer.", "Using", "this", "rationale,", "and", "building", "on", "both", "work", "related", "to", "learning", "cross-lingual", "embeddings", "as", "well", "as", "to", "compositional", "semantic", "representations,", "we", "introduce", "a", "model", "that", "learns", "cross-lingual", "em-", "beddings", "at", "the", "sentence", "level.", "In", "the", "following", "section", "we", "will", "briefly", "discuss", "prior", "work", "in", "these", "two", "fields", "before", "going", "on", "to", "describe", "the", "bilingual", "training", "signal", "that", "we", "developed", "for", "learning", "multilingual", "compositional", "embeddings.", "Subsequently,", "we", "will", "describe", "our", "model", "in", "greater", "detail", "as", "well", "as", "its", "training", "procedure", "and", "experimental", "setup.", "Finally,", "we", "perform", "a", "number", "of", "evalua-", "tions", "and", "demonstrate", "that", "our", "training", "signal", "allows", "a", "very", "simple", "compositional", "vector", "model", "to", "outperform", "the", "state", "of", "the", "art", "on", "a", "task", "designed", "to", "evaluate", "its", "ability", "to", "transfer", "semantic", "informa-", "tion", "across", "languages.", "Unlike", "other", "work", "in", "this", "area,", "our", "model", "does", "not", "require", "word", "aligned", "data.", "In", "fact,", "while", "we", "evaluate", "our", "model", "on", "sentence", "aligned", "data", "in", "this", "paper,", "there", "is", "no", "theoretical", "requirement", "for", "this", "and", "technically", "our", "algorithm", "could", "also", "be", "applied", "to", "document-level", "parallel", "data", "or", "even", "comparable", "data", "only.", "2", "Models", "of", "Compositional", "Distributed", "Semantics", "In", "the", "case", "of", "representing", "individual", "words", "as", "vectors,", "the", "distributional", "account", "of", "semantics", "pro-", "vides", "a", "plausible", "explanation", "of", "what", "is", "encoded", "in", "a", "word", "vector.", "This", "follows", "the", "idea", "that", "the", "meaning", "of", "a", "word", "can", "be", "determined", "by", "\u201cthe", "company", "it", "keeps\u201d", "[11],", "that", "is", "by", "the", "context", "it", "ap-", "pears", "in.", "Such", "context", "can", "easily", "be", "encoded", "in", "vectors", "using", "collocational", "methods,", "and", "is", "also", "underlying", "other", "methods", "of", "learning", "word", "embeddings", "[7,", "20].", "For", "a", "number", "of", "important", "problems,", "semantic", "representations", "of", "individual", "words", "do", "not", "suffice,", "but", "instead", "a", "semantic", "representation", "of", "a", "larger", "structure\u2014e.g.", "a", "phrase", "or", "a", "sentence\u2014is", "required.", "This", "was", "highlighted", "in", "[10],", "who", "proposed", "a", "mechanism", "for", "modifying", "a", "word\u2019s", "representation", "based", "on", "its", "individual", "context.", "The", "distributional", "account", "of", "semantics", "can,", "due", "to", "sparsity,", "not", "be", "applied", "to", "such", "larger", "linguistic", "units.", "A", "notable", "exception", "perhaps", "is", "Baroni", "and", "Zamparelli", "[1],", "who", "learned", "distributional", "representations", "for", "adjective", "noun", "pairs", "using", "a", "collocational", "approach", "on", "a", "corpus", "of", "unprecedented", "size.", "The", "bigram", "representations", "learned", "from", "that", "corpus", "were", "subsequently", "used", "to", "learn", "lexicalised", "composition", "functions", "for", "the", "constituent", "words.", "Most", "alternative", "attempts", "to", "extract", "such", "higher-level", "semantic", "representations", "have", "focused", "on", "learning", "composition", "functions", "that", "represent", "the", "semantics", "of", "a", "larger", "structure", "as", "a", "function", "of", "the", "representations", "of", "its", "parts.", "[21]", "provides", "an", "evaluation", "of", "a", "number", "of", "simple", "composition", "func-", "tions", "applied", "to", "bigrams.", "Applied", "recursively,", "such", "approaches", "can", "then", "easily", "be", "reconciled", "with", "the", "co-occurrence", "based", "word", "level", "representations.", "There", "are", "a", "number", "of", "proposals", "motivating", "such", "recursive", "or", "deep", "composition", "models.", "Notably,", "[3]", "propose", "a", "tensor-based", "model", "for", "semantic", "composition", "and,", "similarly,", "[4]", "develop", "a", "framework", "for", "semantic", "composition", "by", "combining", "dis-", "tributional", "theory", "with", "pregroup", "grammars.", "The", "latter", "framework", "was", "empirically", "evaluated", "and", "supported", "by", "the", "results", "in", "[12].", "More", "recently,", "various", "forms", "of", "recursive", "neural", "networks", "have", "successfully", "been", "used", "for", "semantic", "composition", "and", "related", "tasks", "such", "as", "sentiment", "analysis.", "Such", "models", "include", "recursive", "autoencoders", "[24],", "matrix-vector", "recursive", "neural", "networks", "[25],", "untied", "recursive", "neural", "networks", "[14]", "or", "convolutional", "networks", "[15].", "2.1", "Multilingual", "Embeddings", "Much", "research", "has", "been", "devoted", "to", "the", "task", "of", "inducing", "distributed", "semantic", "representations", "for", "single", "languages.", "In", "particular", "English,", "with", "its", "large", "number", "of", "annotated", "resources,", "has", "enjoyed", "most", "attention.", "Recently,", "progress", "has", "been", "made", "at", "representation", "learning", "for", "languages", "with", "fewer", "available", "resources.", "Klementiev", "et", "al.", "[16]", "described", "a", "form", "of", "multitask", "learning", "on", "word-aligned", "parallel", "data", "to", "transfer", "embeddings", "from", "one", "language", "to", "another.", "Earlier", "work,", "Haghighi", "et", "al.", "[13],", "proposed", "a", "method", "for", "inducing", "cross-lingual", "lexica", "using", "monolingual", "feature", "representations", "and", "a", "small", "initial", "lexicon", "to", "bootstrap", "with.", "This", "approach", "has", "recently", "been", "extended", "by", "[18,", "19],", "who", "developed", "a", "method", "for", "learning", "transformation", "matrices", "to", "convert", "semantic", "vectors", "of", "one", "language", "into", "those", "of", "another.", "Is", "was", "demonstrated", "that", "this", "approach", "can", "be", "applied", "to", "improve", "tasks", "related", "to", "machine", "translation.", "Their", "CBOW", "model", "is", "also", "worth", "noting", "for", "its", "similarities", "to", "the", "composition", "function", "used", "in", "this", "paper.", "Using", "a", "slightly", "different", "approach,", "[29],", "also", "learned", "bilingual", "embeddings", "for", "machine", "translation.", "It", "is", "important", "to", "note", "that,", "unlike", "our", "proposed", "system,", "all", "of", "these", "methods", "require", "word", "aligned", "parallel", "data", "for", "training.", "Two", "recent", "workshop", "papers", "deserve", "mention", "in", "this", "respect.", "Both", "Lauly", "et", "al.", "[17]", "and", "Sarath", "Chan-", "dar", "et", "al.", "[23]", "propose", "methods", "for", "learning", "word", "embeddings", "by", "exploiting", "bilingual", "data,", "not", "unlike", "the", "method", "proposed", "in", "this", "paper.", "Instead", "of", "the", "noise-contrastive", "method", "developed", "in", "this", "paper,", "both", "groups", "of", "authors", "make", "use", "of", "autoencoders", "to", "encode", "monolingual", "representations", "and", "to", "support", "the", "bilingual", "transfer.", "So", "far", "almost", "all", "of", "this", "work", "has", "been", "focused", "on", "learning", "multilingual", "representations", "at", "the", "word", "level.", "As", "distributed", "representations", "of", "larger", "expressions", "have", "been", "shown", "to", "be", "highly", "useful", "for", "a", "number", "of", "tasks,", "it", "seems", "to", "be", "a", "natural", "next", "step", "to", "also", "attempt", "to", "induce", "these", "using", "cross-lingual", "data.", "This", "paper", "provides", "a", "first", "step", "in", "that", "direction.", "3", "Model", "Description", "Language", "acquisition", "in", "humans", "is", "widely", "seen", "as", "grounded", "in", "sensory-motor", "experience", "[22,", "2].", "Based", "on", "this", "idea,", "there", "have", "been", "some", "attempts", "at", "using", "multi-modal", "data", "for", "learning", "better", "vector", "representations", "of", "words", "(e.g.", "[26]).", "Such", "methods,", "however,", "are", "not", "easily", "scalable", "across", "languages", "or", "to", "large", "amounts", "of", "data", "for", "which", "no", "secondary", "or", "tertiary", "representation", "might", "exist.", "We", "abstract", "the", "underlying", "principle", "one", "step", "further", "and", "attempt", "to", "learn", "semantics", "from", "multi-", "lingual", "data.", "The", "idea", "is", "that,", "given", "enough", "parallel", "data,", "a", "shared", "representation", "would", "be", "forced", "to", "capture", "the", "common", "elements", "between", "sentences", "from", "different", "languages.", "What", "two", "parallel", "sentences", "have", "in", "common,", "of", "course,", "is", "the", "semantics", "of", "those", "two", "sentences.", "Using", "this", "data,", "we", "propose", "a", "novel", "method", "for", "learning", "vector", "representations", "at", "the", "word", "level", "and", "beyond.", "3.1", "Bilingual", "Signal", "Exploiting", "the", "semantic", "similarity", "of", "parallel", "sentences", "across", "languages,", "we", "can", "define", "a", "simple", "bilingual", "(and", "trivially", "multilingual)", "error", "function", "as", "follows:", "Given", "a", "compositional", "sentence", "model", "(CVM)", "M4,", "which", "maps", "a", "sentence", "to", "a", "vector,", "we", "can", "train", "a", "second", "CVM", "Mp", "using", "a", "corpus", "C4\\,5", "of", "parallel", "data", "from", "the", "language", "pair", "A,", "B.", "For", "each", "pair", "of", "parallel", "sentences", "(a,b)", "\u20ac", "C4.p,", "we", "attempt", "to", "minimize", "Eaist", "(a,", "b)", "=", "||Groot", "\u2014", "broot", "ll", "(1)", "where", "@,-oo\u00a2", "1s", "the", "vector", "representing", "sentence", "a", "and", "6,4:", "the", "vector", "representing", "sentence", "b.", "3.2.", "The", "BICVM", "Model", "A", "CVM", "learns", "semantic", "representations", "of", "larger", "syntactic", "units", "given", "the", "semantic", "representations", "of", "their", "constituents.", "We", "assume", "individual", "words", "to", "be", "represented", "by", "vectors", "(x", "\u20ac", "R\u00ae).", "Previous", "methods", "employ", "binary", "parse", "trees", "on", "the", "data", "(e.g.", "[14,", "25])", "and", "use", "weighted", "or", "multi-", "plicative", "composition", "functions.", "Under", "such", "a", "setup,", "where", "each", "node", "in", "the", "tree", "is", "terminal", "or", "has", "two", "children", "(p", "\u2014", "co,", "\u20ac1),", "a", "binary", "composition", "function", "could", "take", "the", "following", "form:", "p=", "g(W*[co;", "c1]", "+", "b\u00b0)", "(2)", "where", "[co;", "\u00a21]", "is", "the", "concatenation", "of", "the", "two", "child", "vectors,", "W\u00b0", "\u20ac", "IR?*?\u00a2", "and", "6\u00b0", "\u20ac", "R\u00ae", "the", "encod-", "ing", "matrix", "and", "bias,", "respectively,", "and", "g", "an", "element-wise", "activation", "function", "such", "as", "the", "hyperbolic", "tangent.", "For", "the", "purposes", "of", "evaluation", "the", "bilingual", "signal", "proposed", "above,", "we", "simplify", "this", "com-", "position", "function", "by", "setting", "all", "weight", "matrices", "to", "the", "identity", "and", "all", "biases", "to", "zero.", "Thereby", "the", "CVM", "reduces", "to", "a", "simple", "additive", "composition", "function:", "|a|", "Groot", "=", "S-", "ay", "(3)", "1=0", "Of", "course,", "this", "is", "a", "very", "simplified", "CVM,", "as", "such", "a", "bag-of-words", "approach", "no", "longer", "accounts", "for", "word", "ordering", "and", "other", "effects", "which", "a", "more", "complex", "CVM", "might", "capture.", "However,", "for", "the", "purposes", "of", "this", "evaluation", "(and", "with", "the", "experimental", "evaluation", "in", "mind),", "such", "a", "simplistic", "composition", "function", "should", "be", "sufficient", "to", "evaluate", "the", "novel", "objective", "function", "proposed", "here.", "(0000)", "(oo", "ee)", "(00", "00)", "(00", "oo)", "at", "a2", "a3", "a4", "Figure", "1:", "Description", "of", "a", "bilingual", "model", "with", "parallel", "input", "sentences", "a", "and", "6.", "The", "objective", "function", "of", "this", "model", "is", "to", "minimize", "the", "distance", "between", "the", "sentence", "level", "encoding", "of", "the", "bi-", "text.", "Principally", "any", "composition", "function", "can", "be", "used", "to", "generate", "the", "compositional", "sentence", "level", "representations.", "The", "composition", "function", "is", "represented", "by", "the", "CVM", "boxes", "in", "the", "diagram", "above.", "Using", "this", "additive", "CVM", "we", "want", "to", "optimize", "the", "bilingual", "error", "signal", "defined", "above", "(Eq.", "1).", "For", "the", "moment,", "assume", "that", "M", "4", "is", "a", "perfectly", "trained", "CVM", "such", "that", "a@,oo\u00a2", "represents", "the", "semantics", "of", "the", "sentence", "a.", "Further,", "due", "to", "the", "use", "of", "parallel", "data,", "we", "know", "that", "a", "and", "b", "are", "semantically", "equivalent.", "Hence", "we", "transfer", "the", "semantic", "knowledge", "contained", "in", "M4", "onto", "Mag,", "by", "learning", "944,", "to", "minimize:", "Byi(Ca.p)=", "S>", "Buise(a,b)", "(4)", "(a,b)EC", "4", "B", "Of", "course,", "this", "objective", "function", "assumes", "a", "fully", "trained", "model", "which", "we", "do", "not", "have", "at", "this", "stage.", "While", "this", "can", "be", "a", "useful", "objective", "for", "transferring", "linguistic", "knowledge", "into", "low-resource", "lan-", "guages", "[16],", "this", "precondition", "is", "not", "helpful", "when", "there", "is", "no", "model", "to", "learn", "from", "in", "first", "place.", "We", "resolve", "this", "issue", "by", "jointly", "training", "both", "models", "M", "4", "and", "Mp.", "Applying", "\u00a3;", "to", "parallel", "data", "ensures", "that", "both", "models", "learn", "a", "shared", "representation", "at", "the", "sentence", "level.", "As", "the", "parallel", "input", "sentences", "share", "the", "same", "meaning,", "it", "is", "reasonable", "to", "assume", "that", "mini-", "mizing", "F,,;", "will", "force", "the", "model", "to", "learn", "their", "semantic", "representation.", "Let", "04;", "=", "004,", "UO@m,.", "The", "joint", "objective", "function", "J(6;;)", "thus", "becomes:", "A", "J(0y:)", "=", "Evi(Ca,B)", "+", "5", "li@eill\u201d", "(3)", "where", "A||03;||1", "is", "the", "Lz", "regularization", "term.", "It", "is", "apparent", "that", "this", "joint", "objective", "J(@,;)", "is", "degenerate.", "The", "models", "could", "learn", "to", "reduce", "all", "embeddings", "and", "composition", "weights", "to", "zero", "and", "thereby", "minimize", "the", "objective", "function.", "We", "ad-", "dress", "this", "issue", "by", "employing", "a", "form", "of", "contrastive", "estimation", "penalizing", "small", "distances", "between", "non-parallel", "sentence", "pairs.", "For", "every", "pair", "of", "parallel", "sentences", "(a,b)", "we", "sample", "a", "number", "of", "ad-", "ditional", "sentences", "n", "\u20ac", "Cg,", "which\u2014with", "high", "probability\u2014are", "not", "exact", "translations", "of", "a.", "This", "is", "comparable", "to", "the", "second", "term", "of", "the", "loss", "function", "of", "a", "large", "margin", "nearest", "neighbour", "classifier", "(see", "Eq.", "12", "in", "[28]):", "noise", "(a,", "b,", "n)", "=", "[1", "+", "aust", "(a,", "b)", "\u2014_", "Eaist(,", "ny,", "(6)", "where", "[x],", "=", "maz(x,0)", "denotes", "the", "standard", "hinge", "loss.", "Thus,", "the", "final", "objective", "function", "to", "minimize", "for", "the", "BICVM", "model", "is:", "k", "X", "J", "(Obi)", "=", "S-", "(>:", "Enoise", "(a,", "b,", "v0)", "+", "5", "lel\u201d", "(7)", "(a,b)EC4,B", "\\i=1", "3.3", "Model", "Learning", "Given", "the", "objective", "function", "as", "defined", "above,", "model", "learning", "can", "employ", "the", "same", "techniques", "as", "any", "monolingual", "CVM.", "In", "particular,", "as", "the", "objective", "function", "is", "differentiable,", "we", "can", "use", "standard", "gradient", "descent", "techniques", "such", "as", "stochastic", "gradient", "descent,", "L-BFGS", "or", "the", "adaptive", "gradient", "algorithm", "AdaGrad", "[8].", "Within", "each", "monolingual", "CVM,", "we", "use", "backpropagation", "through", "structure", "after", "applying", "the", "joint", "error", "to", "each", "sentence", "level", "node.", "4", "Experiments", "4.1", "Data", "and", "Parameters", "All", "model", "weights", "were", "randomly", "initialised", "using", "a", "Gaussian", "distribution.", "There", "are", "a", "number", "of", "parameters", "that", "can", "influence", "model", "training.", "We", "selected", "the", "following", "values", "for", "simplicity", "and", "comparability", "with", "prior", "work.", "In", "future", "work", "we", "will", "investigate", "the", "effect", "of", "these", "parameters", "in", "greater", "detail.", "L2", "regularization", "(1),", "step-size", "(0.1),", "number", "of", "noise", "elements", "(50),", "margin", "size", "(50),", "embedding", "dimensionality", "(d=40).", "The", "noise", "elements", "samples", "were", "randomly", "drawn", "from", "the", "corpus", "at", "training", "time,", "individually", "for", "each", "training", "sample", "and", "epoch.", "We", "use", "the", "Europarl", "corpus", "(v7)!", "for", "training", "the", "bilingual", "model.", "The", "corpus", "was", "pre-processed", "using", "the", "set", "of", "tools", "provided", "by", "cdec?", "[9]", "for", "tokenizing", "and", "lowercasing", "the", "data.", "Further,", "all", "empty", "sentences", "as", "well", "as", "their", "translations", "were", "removed", "from", "the", "corpus.", "We", "present", "results", "from", "two", "experiments.", "The", "BICVM", "model", "was", "trained", "on", "500k", "sentence", "pairs", "of", "the", "English-German", "parallel", "section", "of", "the", "Europarl", "corpus.", "The", "BICVM-+", "model", "used", "this", "dataset", "in", "combination", "with", "another", "500k", "parallel", "sentences", "from", "the", "English-French", "section", "of", "the", "corpus,", "resulting", "in", "1", "million", "English", "sentences,", "each", "paired", "up", "with", "either", "a", "German", "or", "a", "French", "sentence.", "Each", "language\u2019s", "vocabulary", "used", "distinct", "encodings", "to", "avoid", "potential", "overlap.", "The", "motivation", "behind", "BICVM-+", "is", "to", "investigate", "whether", "we", "can", "learn", "better", "embeddings", "by", "intro-", "ducing", "additional", "data", "in", "a", "different", "language.", "This", "is", "similar", "to", "prior", "work", "in", "machine", "translation", "where", "English", "was", "used", "as", "a", "pivot", "for", "translation", "between", "low-resource", "languages", "[5].", "We", "use", "the", "adaptive", "gradient", "method,", "AdaGrad", "[8],", "for", "updating", "the", "weights", "of", "our", "models,", "and", "ter-", "minate", "training", "after", "50", "iterations.", "Earlier", "experiments", "indicated", "that", "the", "BICVM", "model", "converges", "faster", "than", "the", "BICVM+", "model,", "but", "we", "report", "results", "on", "the", "same", "number", "of", "iterations", "for", "better", "comparability?.", "4.2", "Cross-Lingual", "Document", "Classification", "We", "evaluate", "our", "model", "using", "the", "cross-lingual", "document", "classification", "(CLDC)", "task", "of", "Klementiev", "et", "al.", "[16].", "This", "task", "involves", "learning", "language", "independent", "embeddings", "which", "are", "then", "used", "for", "document", "classification", "across", "the", "English-German", "language", "pair.", "For", "this,", "CLDC", "employs", "a", "par-", "ticular", "kind", "of", "supervision,", "namely", "using", "supervised", "training", "data", "in", "one", "language", "and", "evaluating", "without", "supervision", "in", "another.", "Thus,", "CLDC", "is", "a", "good", "task", "for", "establishing", "whether", "our", "learned", "representations", "are", "semantically", "useful", "across", "multiple", "languages.", "We", "follow", "the", "experimental", "setup", "described", "in", "[16],", "with", "the", "exception", "that", "we", "learn", "our", "embeddings", "using", "solely", "the", "Europarl", "data", "and", "only", "use", "the", "Reuters", "RCV1/RCV2", "corpora", "during", "the", "classifier", "training", "and", "testing", "stages.", "Each", "document", "in", "the", "classification", "task", "is", "represented", "by", "the", "average", "\u2018nttp://www.statmt", ".org/europarl/", "*https://github.com/redpony/cdec", ">These", "numbers", "were", "updated", "following", "comments", "in", "the", "ICLR", "open", "review", "process.", "Results", "for", "other", "dimensionalities", "and", "our", "source", "code", "for", "our", "model", "are", "available", "at", "http://www.", "karlmoritz.com.", "Model", "en\u2014de", "de\u2014-en", "Majority", "Class", "46.8", "46.8", "Glossed", "65.1", "68.6", "MT", "68.1", "67.4", "I-Matrix", "77.6", "71.1", "BICVM", "83.7", "71.4", "BICVM+", "86.2", "76.9", "Table", "1:", "Classification", "accuracy", "for", "training", "on", "English", "and", "German", "with", "1000", "labeled", "examples.", "Cross-lingual", "compositional", "representations", "(BIC", "VM", "and", "BICVM-4),", "cross-lingual", "representations", "using", "learned", "embeddings", "and", "an", "interaction", "matrix", "(I-Matrix)", "[16]", "translated", "(MT)", "and", "glossed", "(Glossed)", "words,", "and", "the", "majority", "class", "baseline.", "The", "MT", "and", "Glossed", "results", "are", "also", "taken", "from", "Klementiev", "et", "al.", "[16].", "Classification", "Accuracy", "(%)", "100", "=200", "\u00a96500)", "\u00ab\u00a91000", "5000", "10000", "100", "200", "\u00a7\u00a9500", "=", "61000", "5000", "10000", "Training", "Documents", "(en)", "Training", "Documents", "(de)", "\u2014@", "BICVM", "\u2014\u00ae", "BIC", "VM+", "\u2014e\u2014", "I-Matrix", "\u20144\u00ab\u2014", "MT", "\u2014*\u2014", "Glossed", "-", "-", "-", "Majority", "Class", "Figure", "2:", "Classification", "accuracy", "for", "a", "number", "of", "models", "(see", "Table", "1", "for", "model", "descriptions).", "The", "left", "chart", "shows", "results", "for", "these", "models", "when", "trained", "on", "English", "data", "and", "evaluated", "on", "German", "data,", "the", "right", "chart", "vice", "versa.", "of", "the", "d-dimensional", "representations", "of", "all", "its", "sentences.", "We", "train", "the", "multiclass", "classifier", "using", "the", "same", "settings", "and", "implementation", "of", "the", "averaged", "perceptron", "classifier", "[6]", "as", "used", "in", "[16].", "We", "ran", "the", "CLDC", "experiments", "both", "by", "training", "on", "English", "and", "testing", "on", "German", "documents", "and", "vice", "versa.", "Using", "the", "data", "splits", "provided", "by", "[16],", "we", "used", "varying", "training", "data", "sizes", "from", "100", "to", "10,000", "documents", "for", "training", "the", "multiclass", "classifier.", "The", "results", "of", "this", "task", "across", "training", "sizes", "are", "shown", "in", "Figure", "2.", "Table", "1", "shows", "the", "results", "for", "training", "on", "1,000", "documents.", "Both", "models,", "BICVM", "and", "BICVM+", "outperform", "all", "prior", "work", "on", "this", "task.", "Further,", "the", "BICVM+", "model", "outperforms", "the", "BICVM", "model,", "indicating", "the", "usefulness", "of", "adding", "training", "data", "even", "from", "a", "separate", "language", "pair.", "4.3", "Visualization", "While", "the", "CLDC", "experiment", "focused", "on", "establishing", "the", "semantic", "content", "of", "the", "sentence", "level", "representations,", "we", "also", "want", "to", "briefly", "investigate", "the", "induced", "word", "embeddings.", "In", "particular", "the", "BICVM+", "model", "is", "interesting", "for", "that", "purpose,", "as", "it", "allows", "us", "to", "evaluate", "our", "approach", "of", "using", "English", "as", "a", "pivot", "language", "in", "a", "multilingual", "setup.", "In", "Figure", "3", "we", "show", "the", "t-SNE", "projections", "for", "a", "number", "of", "English,", "French", "and", "German", "words.", "Of", "particular", "interest", "should", "be", "the", "right", "chart,", "which", "highlights", "bilingual", "embeddings", "between", "French", "and", "German", "words.", "Even", "though", "the", "model", "did", "not", "use", "any", "parallel", "French-German", "data", "during", "training,", "it", "still", "managed", "to", "learn", "semantic", "word-word", "similarity", "across", "these", "two", "languages.", "t", "/", "Maeexs,", "ee", "aera.", "abr", "Cirnaaaiaa,", ".", "aUugHatyt", ";", "adhaay", "lyon", "Janyat", "Ac", "HRSA", "i", "Vite", "t=", "5", "8", "-", "ne", "nBRORS.", "wear.", "GORA", "ae", "\u201cHERR:", "septembre", "ia", "sans", "yi", "september", "*", "=", "Star", "Figure", "3:", "The", "left", "scatter", "plot", "shows", "t-SNE", "projections", "for", "a", "weekdays", "in", "all", "three", "languages", "using", "the", "representations", "learned", "in", "the", "BIC", "VM+", "model.", "Even", "though", "the", "model", "did", "not", "use", "any", "parallel", "French-German", "data", "during", "training,", "it", "still", "learns", "semantic", "similarity", "between", "these", "two", "languages", "using", "English", "as", "a", "pivot.", "To", "highlight", "this,", "the", "right", "plot", "shows", "another", "set", "of", "words", "(months", "of", "the", "year)", "using", "only", "the", "German", "and", "French", "words.", "5", "Conclusions", "With", "this", "paper", "we", "have", "proposed", "a", "novel", "method", "for", "inducing", "cross-lingual", "distributed", "represen-", "tations", "for", "compositional", "semantics.", "Using", "a", "very", "simple", "method", "for", "semantic", "composition,", "we", "nevertheless", "managed", "to", "obtain", "state", "of", "the", "art", "results", "on", "the", "CLDC", "task,", "specifically", "designed", "to", "evaluate", "semantic", "transfer", "across", "languages.", "After", "extending", "our", "approach", "to", "include", "multilingual", "training", "data", "in", "the", "BIC", "VM+", "model,", "we", "were", "able", "to", "demonstrate", "that", "adding", "additional", "languages", "further", "improves", "the", "model.", "Furthermore,", "using", "some", "qualitative", "experiments", "and", "visualizations,", "we", "showed", "that", "our", "approach", "also", "allows", "us", "to", "learn", "semantically", "related", "embeddings", "across", "languages", "without", "any", "direct", "training", "data.", "Our", "approach", "provides", "great", "flexibility", "in", "training", "data", "and", "requires", "little", "to", "no", "annotation.", "Hav-", "ing", "demonstrated", "the", "successful", "training", "of", "semantic", "representations", "using", "sentence", "aligned", "data,", "a", "plausible", "next", "step", "is", "to", "attempt", "training", "using", "document-aligned", "data", "or", "even", "corpora", "of", "comparable", "documents.", "This", "may", "provide", "even", "greater", "possibilities", "for", "working", "with", "low-resource", "languages.", "In", "the", "same", "vein,", "the", "success", "of", "our", "pivoting", "experiments", "suggest", "further", "work.", "Unlike", "other", "pivot", "approaches,", "it", "is", "easy", "to", "extend", "our", "model", "to", "have", "multiple", "pivot", "languages.", "Thus", "some", "pivots", "could", "preserve", "different", "aspects", "such", "as", "case,", "gender", "etc.,", "and", "overcome", "other", "issues", "related", "to", "having", "a", "single", "pivot", "language.", "As", "we", "have", "achieved", "the", "results", "in", "this", "paper", "with", "a", "relatively", "simple", "CVM,", "it", "would", "also", "be", "inter-", "esting", "to", "establish", "whether", "our", "objective", "function", "can", "be", "used", "in", "combination", "with", "more", "complex", "compositional", "vector", "models", "such", "as", "MV-RNN", "[25]", "or", "tensor-based", "approaches,", "to", "see", "whether", "these", "can", "further", "improve", "results", "on", "both", "mono-", "and", "multilingual", "tasks", "when", "used", "in", "conjunction", "with", "our", "cross-lingual", "objective", "function.", "Related", "to", "this,", "we", "will", "also", "apply", "our", "model", "to", "a", "wider", "variety", "of", "tasks", "including", "machine", "translation", "and", "multilingual", "information", "extraction.", "Acknowledgements", "The", "authors", "would", "like", "to", "thank", "Alexandre", "Klementiev", "and", "his", "co-authors", "for", "making", "their", "datasets", "and", "averaged", "perceptron", "implementation", "available,", "as", "well", "as", "answering", "a", "number", "of", "questions", "related", "to", "their", "work", "on", "this", "task.", "This", "work", "was", "supported", "by", "EPSRC", "grant", "EP/K036580/1", "and", "a", "Xerox", "Foundation", "Award.", "References", "[1]", "[10]", "[11]", "[12]", "[13]", "[14]", "[15]", "[16]", "[17]", "[18]", "[19]", "[20]", "[21]", "[22]", "Marco", "Baroni", "and", "Roberto", "Zamparelli.", "Nouns", "are", "vectors,", "adjectives", "are", "matrices:", "Represent-", "ing", "adjective-noun", "constructions", "in", "semantic", "space.", "In", "Proceedings", "of", "EMNLP,", "2010.", "Paul", "Bloom.", "Precis", "of", "how", "children", "learn", "the", "meanings", "of", "words.", "Behavioral", "and", "Brain", "Sciences,", "24:1095\u20141103,", "2001.", "Stephen", "Clark", "and", "Stephen", "Pulman.", "Combining", "symbolic", "and", "distributional", "models", "of", "mean-", "ing.", "In", "Proceedings", "of", "AAAI", "Spring", "Symposium", "on", "Quantum", "Interaction.", "AAAI", "Press,", "2007.", "Bob", "Coecke,", "Mehrnoosh", "Sadrzadeh,", "and", "Stephen", "Clark.", "Mathematical", "foundations", "for", "a", "com-", "positional", "distributional", "model", "of", "meaning.", "Lambek", "Festschrift.", "Linguistic", "Analysis,", "36:345\u2014", "384,", "2010.", "Trevor", "Cohn", "and", "Mirella", "Lapata.", "Machine", "translation", "by", "triangulation:", "Making", "effective", "use", "of", "multi-parallel", "corpora.", "In", "Proceedings", "of", "ACL,", "pages", "728-735,", "Prague,", "Czech", "Republic,", "June", "2007.", "Association", "for", "Computational", "Linguistics.", "Michael", "Collins.", "Discriminative", "training", "methods", "for", "hidden", "markov", "models:", "Theory", "and", "experiments", "with", "perceptron", "algorithms.", "In", "Proceedings", "of", "ACL-EMNLP.", "Association", "for", "Computational", "Linguistics,", "2002.", "doi:", "10.3115/1118693.1118694.", "Ronan", "Collobert", "and", "Jason", "Weston.", "A", "unified", "architecture", "for", "natural", "language", "processing:", "Deep", "neural", "networks", "with", "multitask", "learning.", "In", "Proceedings", "of", "ICML,", "2008.", "John", "Duchi,", "Elad", "Hazan,", "and", "Yoram", "Singer.", "Adaptive", "subgradient", "methods", "for", "online", "learning", "and", "stochastic", "optimization.", "Journal", "of", "Machine", "Learning", "Research,", "12:2121\u20142159,", "July", "2011.", "ISSN", "1532-4435.", "Chris", "Dyer,", "Adam", "Lopez,", "Juri", "Ganitkevitch,", "Johnathan", "Weese,", "Ferhan", "Ture,", "Phil", "Blunsom,", "Hendra", "Setiawan,", "Vladimir", "Eidelman,", "and", "Philip", "Resnik.", "cdec:", "A", "decoder,", "alignment,", "and", "learning", "framework", "for", "finite-state", "and", "context-free", "translation", "models.", "In", "Proceedings", "of", "ACE,", "2010.", "K.", "Erk", "and", "S.", "Pad\u00e9.", "A", "structured", "vector", "space", "model", "for", "word", "meaning", "in", "context.", "Proceedings", "of", "EMNEP,", "2008.", "J.R.", "Firth.", "A", "synopsis", "of", "linguistic", "theory", "1930-55.", "1952-59:1\u201432,", "1957.", "Edward", "Grefenstette", "and", "Mehrnoosh", "Sadrzadeh.", "Experimental", "support", "for", "a", "categorical", "com-", "positional", "distributional", "model", "of", "meaning.", "In", "Proceedings", "of", "EMNLP,", "2011.", "Aria", "Haghighi,", "Percy", "Liang,", "Taylor", "Berg-Kirkpatrick,", "and", "Dan", "Klein.", "Learning", "bilingual", "lexicons", "from", "monolingual", "corpora.", "In", "Proceedings", "of", "ACL-HLT,", "2008.", "Karl", "Moritz", "Hermann", "and", "Phil", "Blunsom.", "The", "Role", "of", "Syntax", "in", "Vector", "Space", "Models", "of", "Compositional", "Semantics.", "In", "Proceedings", "of", "ACL,", "2013.", "Nal", "Kalchbrenner", "and", "Phil", "Blunsom.", "Recurrent", "convolutional", "neural", "networks", "for", "discourse", "compositionality.", "In", "Proceedings", "of", "the", "Workshop", "on", "Continuous", "Vector", "Space", "Models", "and", "their", "Compositionality,", "2013.", "Alexandre", "Klementiev,", "Ivan", "Titov,", "and", "Binod", "Bhattarai.", "Inducing", "crosslingual", "distributed", "representations", "of", "words.", "In", "Proceedings", "of", "COLING,", "2012.", "Stanislas", "Lauly,", "Alex", "Boulanger,", "and", "Hugo", "Larochelle.", "Learning", "multilingual", "word", "represen-", "tations", "using", "a", "bag-of-words", "autoencoder.", "In", "Deep", "Learning", "Workshop", "at", "NIPS,", "2013.", "Tomas", "Mikolov,", "Kai", "Chen,", "Greg", "Corrado,", "and", "Jeffrey", "Dean.", "Efficient", "estimation", "of", "word", "representations", "in", "vector", "space.", "CoRR,", "2013.", "Tomas", "Mikolov,", "Quoc", "V.", "Le,", "and", "Ilya", "Sutskever.", "Exploiting", "similarities", "among", "languages", "for", "machine", "translation.", "CoRR,", "2013.", "Toma\u00e9", "Mikoloy,", "Martin", "Karafidt,", "Luka8", "Burget,", "Jan", "Cernocky,", "and", "Sanjeev", "Khudanpur.", "Re-", "current", "neural", "network", "based", "language", "model.", "In", "Proceedings", "of", "INTERSPEECH,", "2010.", "Jeff", "Mitchell", "and", "Mirella", "Lapata.", "Vector-based", "models", "of", "semantic", "composition.", "In", "In", "Pro-", "ceedings", "of", "ACL,", "2008.", "D.", "Roy.", "Grounded", "spoken", "language", "acquisition:", "Experiments", "in", "word", "learning.", "[EEE", "Trans-", "actions", "on", "Multimedia,", "5(2):197\u2014209,", "June", "2003.", "ISSN", "1520-9210.", "doi:", "10.1109/TMM.2003.", "811618.", "[23]", "[24]", "[25]", "[26]", "[27]", "[28]", "[29]", "A", "P", "Sarath", "Chandar,", "M", "Khapra", "Mitesh,", "B", "Ravindran,", "Vikas", "Raykar,", "and", "Amrita", "Saha.", "Multi-", "lingual", "deep", "learning.", "In", "Deep", "Learning", "Workshop", "at", "NIPS,", "2013.", "Richard", "Socher,", "Jeffrey", "Pennington,", "Eric", "H.", "Huang,", "Andrew", "Y.", "Ng,", "and", "Christopher", "D.", "Man-", "ning.", "Semi-supervised", "recursive", "autoencoders", "for", "predicting", "sentiment", "distributions.", "In", "Pro-", "ceedings", "of", "EMNLP,", "2011.", "Richard", "Socher,", "Brody", "Huval,", "Christopher", "D.", "Manning,", "and", "Andrew", "Y.", "Ng.", "Semantic", "compo-", "sitionality", "through", "recursive", "matrix-vector", "spaces.", "In", "Proceedings", "of", "EMNLP-CoNLL,", "pages", "1201-1211,", "2012.", "Nitish", "Srivastava", "and", "Ruslan", "Salakhutdinov.", "Multimodal", "learning", "with", "deep", "boltzmann", "ma-", "chines.", "In", "Proceedings", "of", "NIPS.", "2012.", "P.", "D.", "Tumey", "and", "P.", "Pantel.", "From", "frequency", "to", "meaning:", "Vector", "space", "models", "of", "semantics.", "Journal", "of", "Artificial", "Intelligence", "Research,", "37(1):141-188,", "2010.", "Kilian", "Q.", "Weinberger", "and", "Lawrence", "K.", "Saul.", "Distance", "metric", "learning", "for", "large", "margin", "nearest", "neighbor", "classification.", "Journal", "of", "Machine", "Learning", "Research,", "10:207\u2014244,", "June", "2009.", "ISSN", "1532-4435.", "Will", "Y.", "Zou,", "Richard", "Socher,", "Daniel", "Cer,", "and", "Christopher", "D.", "Manning.", "Bilingual", "word", "em-", "beddings", "for", "phrase-based", "machine", "translation.", "In", "Proceedings", "of", "EMNLP,", "2013."], "positions": [[519, 463, 898, 527], [919, 463, 1266, 513], [1287, 463, 1776, 527], [1798, 463, 2031, 513], [1018, 547, 1189, 596], [1210, 545, 1532, 610], [914, 799, 995, 828], [1007, 798, 1127, 828], [1140, 799, 1285, 828], [1287, 799, 1386, 828], [1398, 798, 1468, 827], [1480, 799, 1635, 828], [997, 846, 1192, 882], [1203, 845, 1239, 873], [1248, 845, 1414, 882], [1426, 845, 1552, 874], [1101, 890, 1273, 927], [1285, 890, 1321, 918], [1330, 890, 1448, 919], [1080, 936, 1207, 970], [1220, 936, 1294, 965], [1311, 936, 1398, 971], [1411, 937, 1470, 965], [709, 979, 1214, 1020], [1226, 979, 1840, 1020], [1182, 1148, 1367, 1183], [600, 1272, 784, 1300], [800, 1272, 1050, 1309], [1068, 1272, 1104, 1300], [1118, 1272, 1260, 1309], [1278, 1281, 1326, 1300], [1344, 1281, 1360, 1300], [1377, 1272, 1491, 1300], [1508, 1281, 1575, 1309], [1592, 1276, 1623, 1300], [1640, 1272, 1756, 1300], [1773, 1272, 1950, 1301], [599, 1318, 809, 1355], [827, 1318, 964, 1346], [981, 1318, 1079, 1346], [1099, 1318, 1156, 1346], [1172, 1318, 1295, 1355], [1313, 1318, 1344, 1346], [1361, 1319, 1441, 1346], [1461, 1319, 1507, 1355], [1525, 1318, 1720, 1355], [1737, 1318, 1805, 1346], [1823, 1318, 1949, 1355], [599, 1363, 761, 1400], [780, 1372, 810, 1391], [827, 1363, 897, 1391], [913, 1372, 943, 1391], [959, 1363, 1119, 1400], [1134, 1363, 1329, 1391], [1345, 1363, 1435, 1391], [1451, 1363, 1595, 1391], [1610, 1363, 1792, 1391], [1808, 1363, 1908, 1391], [1923, 1363, 1948, 1391], [600, 1413, 651, 1437], [667, 1409, 813, 1438], [828, 1409, 858, 1437], [873, 1409, 1001, 1437], [1015, 1409, 1274, 1446], [1292, 1409, 1467, 1437], [1481, 1409, 1730, 1446], [1746, 1409, 1822, 1438], [1836, 1418, 1949, 1446], [599, 1455, 700, 1483], [713, 1455, 744, 1483], [758, 1464, 848, 1492], [861, 1456, 939, 1483], [952, 1455, 1041, 1483], [1063, 1456, 1177, 1483], [1190, 1455, 1274, 1483], [1286, 1455, 1339, 1483], [1355, 1455, 1460, 1483], [1473, 1455, 1542, 1483], [1556, 1455, 1790, 1492], [1805, 1455, 1949, 1483], [599, 1500, 848, 1537], [863, 1509, 919, 1528], [934, 1500, 1134, 1537], [1147, 1500, 1186, 1528], [1201, 1500, 1320, 1537], [1334, 1504, 1365, 1528], [1380, 1509, 1396, 1528], [1409, 1500, 1535, 1528], [1548, 1500, 1584, 1528], [1595, 1500, 1804, 1537], [1818, 1500, 1948, 1537], [600, 1546, 678, 1574], [696, 1546, 769, 1574], [786, 1555, 816, 1574], [834, 1546, 993, 1574], [1009, 1546, 1148, 1583], [1176, 1546, 1216, 1574], [1231, 1546, 1281, 1574], [1297, 1555, 1380, 1574], [1395, 1546, 1476, 1580], [1494, 1546, 1576, 1574], [1590, 1546, 1643, 1574], [1659, 1546, 1737, 1574], [1754, 1555, 1821, 1574], [1822, 1546, 1950, 1574], [601, 1601, 721, 1620], [737, 1592, 768, 1620], [782, 1592, 866, 1620], [880, 1601, 920, 1620], [934, 1592, 1068, 1629], [1084, 1592, 1189, 1620], [1204, 1592, 1380, 1621], [1393, 1592, 1642, 1629], [1659, 1601, 1759, 1620], [1775, 1592, 1947, 1629], [600, 1638, 653, 1665], [664, 1637, 806, 1665], [817, 1637, 901, 1665], [912, 1641, 972, 1665], [985, 1637, 1167, 1674], [1179, 1637, 1220, 1674], [1231, 1637, 1396, 1674], [1409, 1646, 1425, 1665], [1436, 1637, 1559, 1665], [1570, 1637, 1618, 1665], [1628, 1637, 1763, 1674], [1774, 1637, 1949, 1665], [599, 1683, 848, 1720], [860, 1683, 891, 1711], [903, 1692, 919, 1711], [930, 1683, 1131, 1720], [1143, 1687, 1235, 1720], [1252, 1683, 1316, 1712], [1326, 1683, 1417, 1711], [1418, 1683, 1535, 1711], [1548, 1687, 1578, 1711], [1590, 1683, 1691, 1720], [1703, 1683, 1817, 1711], [1827, 1683, 1948, 1711], [600, 1729, 687, 1766], [702, 1733, 733, 1757], [747, 1729, 867, 1766], [882, 1733, 1037, 1757], [1053, 1729, 1110, 1757], [1124, 1729, 1287, 1757], [1300, 1738, 1373, 1757], [1388, 1733, 1418, 1757], [1433, 1733, 1574, 1757], [1587, 1729, 1687, 1757], [1702, 1738, 1750, 1757], [1764, 1733, 1815, 1757], [1830, 1729, 1949, 1766], [600, 1774, 691, 1802], [701, 1778, 752, 1802], [761, 1774, 912, 1811], [923, 1774, 1006, 1802], [1017, 1774, 1204, 1811], [1221, 1775, 1273, 1802], [1284, 1774, 1368, 1802], [1378, 1774, 1439, 1802], [1449, 1783, 1503, 1802], [1511, 1774, 1761, 1811], [1773, 1783, 1821, 1802], [1832, 1783, 1948, 1802], [600, 1820, 702, 1857], [714, 1820, 905, 1849], [918, 1820, 975, 1848], [989, 1820, 1078, 1857], [1091, 1820, 1173, 1848], [1185, 1824, 1215, 1848], [1229, 1829, 1245, 1848], [1257, 1820, 1470, 1857], [1482, 1820, 1633, 1848], [1634, 1820, 1872, 1848], [1884, 1820, 1950, 1848], [600, 1866, 700, 1894], [712, 1875, 759, 1894], [771, 1866, 957, 1903], [969, 1866, 1018, 1894], [1029, 1866, 1154, 1903], [1157, 1870, 1258, 1894], [1270, 1866, 1305, 1894], [1315, 1866, 1364, 1894], [1378, 1870, 1426, 1894], [1445, 1866, 1572, 1900], [1585, 1866, 1626, 1903], [1639, 1866, 1814, 1903], [1826, 1866, 1950, 1903], [600, 1920, 725, 1948], [739, 1911, 775, 1939], [786, 1911, 923, 1948], [937, 1911, 1085, 1948], [1098, 1911, 1177, 1948], [1192, 1920, 1239, 1939], [1253, 1911, 1316, 1939], [1330, 1911, 1391, 1939], [1404, 1920, 1459, 1939], [1472, 1911, 1574, 1939], [1588, 1911, 1684, 1939], [1699, 1911, 1948, 1948], [600, 1957, 661, 1985], [677, 1961, 798, 1994], [816, 1957, 960, 1985], [977, 1957, 1187, 1994], [1206, 1966, 1306, 1985], [1324, 1957, 1487, 1994], [1505, 1957, 1553, 1985], [1569, 1957, 1668, 1985], [1685, 1966, 1725, 1985], [1741, 1957, 1865, 1994], [1882, 1957, 1950, 1985], [600, 2012, 646, 2031], [649, 2003, 757, 2031], [452, 2182, 471, 2216], [525, 2182, 794, 2217], [450, 2303, 635, 2331], [644, 2303, 893, 2340], [905, 2303, 941, 2331], [948, 2303, 1031, 2331], [1034, 2312, 1107, 2331], [1117, 2303, 1318, 2340], [1328, 2303, 1419, 2340], [1429, 2303, 1504, 2331], [1514, 2307, 1545, 2331], [1556, 2303, 1679, 2332], [1688, 2303, 1761, 2340], [1771, 2303, 1863, 2332], [1875, 2303, 1911, 2331], [1918, 2303, 2098, 2340], [450, 2348, 513, 2376], [527, 2348, 631, 2376], [644, 2348, 793, 2385], [806, 2348, 972, 2385], [986, 2348, 1075, 2376], [1096, 2348, 1271, 2377], [1286, 2348, 1482, 2385], [1497, 2348, 1532, 2376], [1543, 2348, 1600, 2376], [1615, 2348, 1765, 2385], [1778, 2348, 1899, 2376], [1912, 2348, 2099, 2376], [450, 2394, 713, 2431], [729, 2394, 813, 2422], [828, 2394, 984, 2431], [999, 2394, 1056, 2422], [1071, 2403, 1220, 2431], [1234, 2394, 1384, 2422], [1399, 2394, 1467, 2431], [1493, 2394, 1552, 2428], [1568, 2394, 1643, 2429], [1667, 2394, 1855, 2431], [1869, 2394, 1953, 2422], [1965, 2394, 2018, 2422], [2035, 2394, 2099, 2422], [451, 2440, 612, 2477], [628, 2444, 658, 2468], [674, 2440, 755, 2468], [771, 2440, 946, 2468], [962, 2440, 1122, 2468], [1138, 2440, 1174, 2468], [1187, 2440, 1282, 2477], [1297, 2444, 1465, 2474], [1484, 2440, 1625, 2477], [1640, 2449, 1674, 2468], [1691, 2444, 1722, 2468], [1738, 2440, 1828, 2477], [1843, 2440, 2018, 2468], [2033, 2449, 2098, 2477], [449, 2485, 631, 2513], [645, 2489, 676, 2513], [690, 2485, 770, 2513], [786, 2485, 859, 2513], [874, 2494, 905, 2513], [921, 2485, 1080, 2513], [1095, 2485, 1225, 2522], [1240, 2494, 1274, 2513], [1286, 2485, 1466, 2522], [1479, 2485, 1630, 2513], [1645, 2485, 1704, 2520], [1730, 2485, 1769, 2519], [1786, 2485, 1812, 2519], [1832, 2485, 1877, 2519], [1896, 2485, 1941, 2519], [1957, 2485, 2005, 2519], [2021, 2485, 2096, 2520], [450, 2531, 490, 2559], [504, 2531, 554, 2559], [568, 2540, 651, 2559], [665, 2531, 737, 2559], [752, 2540, 768, 2559], [783, 2531, 895, 2559], [911, 2531, 1009, 2559], [1023, 2531, 1059, 2559], [1070, 2531, 1154, 2559], [1167, 2531, 1220, 2559], [1235, 2531, 1363, 2559], [1377, 2540, 1416, 2559], [1430, 2531, 1622, 2568], [1636, 2531, 1789, 2568], [1802, 2531, 1983, 2568], [1998, 2540, 2097, 2559], [450, 2577, 624, 2614], [639, 2577, 696, 2605], [708, 2577, 899, 2614], [911, 2577, 991, 2605], [1003, 2577, 1128, 2614], [1141, 2577, 1204, 2605], [1217, 2577, 1431, 2605], [1443, 2577, 1616, 2614], [1630, 2577, 1670, 2614], [1683, 2586, 1771, 2605], [1774, 2586, 1819, 2605], [1821, 2577, 2021, 2605], [2033, 2586, 2098, 2614], [449, 2622, 646, 2650], [660, 2626, 688, 2650], [700, 2622, 749, 2650], [761, 2622, 844, 2650], [856, 2622, 933, 2651], [948, 2622, 1008, 2656], [1025, 2622, 1083, 2656], [450, 2693, 614, 2730], [630, 2693, 714, 2721], [727, 2702, 767, 2721], [781, 2693, 1014, 2730], [1029, 2693, 1173, 2721], [1187, 2693, 1436, 2730], [1451, 2693, 1573, 2721], [1588, 2702, 1628, 2721], [1642, 2693, 1850, 2730], [1864, 2693, 1932, 2721], [1945, 2693, 2036, 2721], [2050, 2693, 2099, 2721], [450, 2739, 663, 2776], [674, 2739, 758, 2767], [768, 2739, 889, 2767], [901, 2748, 941, 2767], [951, 2739, 1035, 2767], [1045, 2739, 1123, 2768], [1132, 2739, 1381, 2776], [1393, 2739, 1470, 2776], [1487, 2740, 1642, 2773], [1655, 2739, 1676, 2767], [1687, 2748, 1810, 2776], [1822, 2739, 1934, 2776], [1944, 2739, 2005, 2767], [2015, 2739, 2099, 2767], [450, 2788, 511, 2812], [525, 2784, 639, 2812], [654, 2784, 689, 2812], [700, 2784, 784, 2812], [798, 2784, 906, 2812], [918, 2784, 957, 2812], [970, 2784, 1132, 2812], [1147, 2793, 1177, 2812], [1192, 2784, 1274, 2812], [1287, 2784, 1378, 2812], [1394, 2793, 1410, 2812], [1422, 2784, 1558, 2821], [1571, 2784, 1607, 2812], [1617, 2784, 1741, 2821], [1754, 2793, 1879, 2821], [1893, 2784, 1965, 2812], [1979, 2784, 2099, 2821], [450, 2830, 518, 2858], [529, 2834, 556, 2858], [566, 2830, 615, 2858], [626, 2834, 766, 2858], [776, 2830, 854, 2859], [863, 2839, 897, 2858], [905, 2830, 1026, 2867], [1036, 2830, 1136, 2858], [1146, 2830, 1236, 2858], [1245, 2830, 1284, 2858], [1293, 2830, 1445, 2867], [1455, 2830, 1486, 2858], [1497, 2830, 1570, 2858], [1580, 2830, 1671, 2858], [1688, 2830, 1815, 2864], [1828, 2834, 1969, 2858], [1979, 2830, 2099, 2867], [450, 2876, 518, 2904], [530, 2876, 671, 2913], [687, 2885, 703, 2904], [715, 2876, 864, 2913], [877, 2880, 1005, 2913], [1018, 2876, 1054, 2904], [1066, 2876, 1210, 2904], [1225, 2876, 1387, 2913], [1403, 2876, 1502, 2904], [1516, 2885, 1572, 2904], [1584, 2876, 1623, 2904], [1635, 2876, 1727, 2904], [1728, 2880, 1785, 2904], [1798, 2876, 1898, 2904], [1912, 2880, 1940, 2904], [1953, 2876, 2002, 2904], [2016, 2876, 2099, 2904], [450, 2921, 536, 2950], [552, 2921, 701, 2950], [710, 2921, 760, 2949], [769, 2930, 839, 2949], [849, 2921, 885, 2949], [893, 2921, 1056, 2958], [1065, 2921, 1203, 2949], [1214, 2930, 1230, 2949], [1239, 2921, 1371, 2950], [1381, 2921, 1555, 2958], [1565, 2930, 1625, 2949], [1627, 2921, 1725, 2958], [1743, 2921, 2098, 2956], [451, 2967, 509, 2995], [523, 2967, 559, 2995], [575, 2967, 701, 3004], [715, 2967, 884, 3004], [900, 2967, 1028, 3004], [1042, 2967, 1138, 3004], [1154, 2967, 1272, 2996], [1286, 2967, 1423, 3002], [1449, 2967, 1600, 2996], [1616, 2967, 1779, 3004], [1795, 2971, 1822, 2995], [1837, 2967, 1886, 2995], [1899, 2967, 2007, 3004], [2021, 2967, 2099, 2996], [449, 3013, 521, 3041], [533, 3022, 656, 3050], [669, 3013, 714, 3041], [726, 3022, 809, 3041], [820, 3013, 970, 3050], [981, 3013, 1051, 3041], [1064, 3013, 1198, 3050], [1210, 3013, 1376, 3042], [1387, 3013, 1492, 3041], [1506, 3013, 1553, 3041], [1566, 3013, 1710, 3041], [1723, 3013, 1853, 3041], [451, 354, 548, 391], [559, 354, 616, 382], [628, 354, 781, 388], [795, 354, 853, 382], [863, 354, 1000, 391], [1011, 363, 1051, 382], [1061, 354, 1134, 382], [1146, 363, 1209, 382], [1209, 354, 1351, 382], [1363, 358, 1393, 382], [1405, 354, 1539, 391], [1550, 354, 1763, 391], [1775, 354, 1957, 391], [1960, 363, 2016, 382], [2029, 354, 2099, 382], [452, 409, 482, 428], [499, 404, 530, 428], [546, 400, 779, 437], [796, 400, 940, 428], [956, 400, 1215, 437], [1234, 409, 1281, 428], [1296, 400, 1452, 428], [1468, 409, 1484, 428], [1500, 400, 1590, 428], [1592, 400, 1678, 428], [1694, 400, 1790, 428], [1807, 400, 2020, 437], [2036, 409, 2098, 428], [450, 445, 597, 482], [613, 449, 641, 473], [655, 445, 704, 473], [718, 449, 859, 473], [872, 445, 957, 474], [980, 446, 1013, 473], [1026, 445, 1076, 473], [1089, 445, 1248, 482], [1263, 445, 1378, 473], [1391, 454, 1438, 473], [1452, 445, 1515, 473], [1528, 445, 1635, 482], [1649, 445, 1766, 473], [1780, 445, 1861, 482], [1874, 445, 1958, 473], [1971, 445, 2001, 473], [2015, 445, 2099, 473], [451, 495, 511, 519], [525, 491, 612, 519], [627, 491, 733, 519], [747, 491, 840, 528], [855, 500, 895, 519], [909, 495, 940, 519], [955, 491, 1091, 519], [1106, 491, 1155, 519], [1169, 491, 1316, 528], [1330, 491, 1458, 528], [1473, 491, 1570, 528], [1584, 491, 1645, 519], [1660, 500, 1707, 519], [1721, 491, 1888, 528], [1903, 491, 1951, 519], [1964, 491, 2099, 528], [451, 537, 652, 574], [664, 537, 898, 574], [910, 537, 1116, 574], [1135, 537, 1362, 574], [1376, 546, 1423, 565], [1435, 537, 1498, 565], [1510, 537, 1647, 565], [1659, 546, 1714, 565], [1725, 537, 1827, 565], [1840, 537, 1870, 565], [1882, 541, 1997, 574], [2008, 537, 2099, 565], [452, 591, 482, 610], [498, 582, 567, 610], [582, 591, 613, 610], [628, 582, 665, 610], [680, 582, 807, 619], [821, 582, 986, 619], [1001, 582, 1058, 610], [1072, 582, 1287, 619], [1302, 586, 1395, 619], [1418, 582, 1540, 619], [1556, 591, 1603, 610], [1616, 582, 1750, 619], [1764, 591, 1780, 610], [1794, 582, 1920, 610], [1933, 582, 1969, 610], [1980, 582, 2098, 611], [451, 628, 528, 656], [545, 628, 602, 656], [616, 628, 818, 656], [832, 628, 893, 656], [907, 637, 961, 656], [975, 628, 1102, 665], [1117, 628, 1214, 665], [1229, 628, 1332, 656], [1349, 637, 1365, 656], [1379, 637, 1451, 665], [1466, 628, 1574, 665], [1588, 628, 1822, 665], [1836, 632, 1938, 657], [1952, 628, 2054, 656], [2068, 632, 2099, 656], [451, 674, 636, 711], [647, 674, 696, 702], [709, 678, 782, 702], [794, 674, 829, 702], [838, 674, 887, 702], [900, 678, 941, 702], [952, 683, 992, 702], [1005, 683, 1021, 702], [1032, 674, 1098, 702], [1108, 674, 1254, 711], [1266, 678, 1296, 702], [1308, 674, 1443, 703], [1454, 674, 1490, 702], [1504, 674, 1608, 711], [1619, 678, 1650, 702], [1661, 674, 1787, 702], [1799, 674, 1943, 702], [1955, 674, 2098, 702], [451, 719, 513, 747], [526, 728, 625, 747], [638, 719, 810, 756], [827, 719, 938, 748], [950, 719, 1034, 747], [1045, 719, 1129, 747], [1139, 719, 1170, 747], [1181, 719, 1238, 747], [1252, 728, 1327, 753], [1340, 728, 1395, 747], [1405, 719, 1507, 747], [1519, 719, 1592, 747], [1604, 723, 1656, 747], [1666, 719, 1783, 756], [1794, 719, 1878, 747], [1890, 719, 2010, 756], [2021, 719, 2096, 747], [451, 766, 483, 793], [497, 765, 566, 799], [582, 765, 673, 793], [687, 774, 734, 793], [748, 765, 883, 794], [896, 774, 951, 793], [964, 765, 1066, 793], [1080, 774, 1120, 793], [1135, 769, 1276, 793], [1290, 765, 1410, 802], [1424, 765, 1492, 793], [1505, 765, 1536, 793], [1550, 765, 1607, 793], [1621, 774, 1720, 802], [1736, 765, 1818, 793], [1831, 765, 1856, 793], [1871, 774, 1911, 793], [1925, 765, 2099, 793], [450, 811, 638, 848], [640, 811, 710, 839], [722, 811, 779, 839], [795, 811, 852, 839], [865, 811, 1045, 848], [1059, 820, 1113, 839], [1126, 811, 1285, 848], [1298, 811, 1389, 839], [1403, 811, 1467, 839], [1479, 811, 1518, 839], [1532, 811, 1651, 848], [1664, 815, 1695, 839], [1708, 811, 1963, 840], [1975, 811, 2099, 848], [451, 856, 518, 884], [530, 865, 564, 884], [575, 865, 650, 885], [662, 856, 854, 893], [866, 856, 934, 884], [946, 856, 1023, 893], [451, 989, 474, 1023], [525, 989, 678, 1024], [693, 989, 736, 1024], [748, 989, 1055, 1033], [1069, 989, 1310, 1024], [1325, 989, 1537, 1024], [451, 1105, 483, 1132], [496, 1104, 545, 1132], [558, 1113, 628, 1132], [640, 1104, 676, 1132], [684, 1104, 889, 1141], [902, 1104, 1067, 1133], [1080, 1104, 1178, 1132], [1193, 1113, 1223, 1132], [1237, 1108, 1364, 1138], [1378, 1104, 1427, 1132], [1440, 1104, 1659, 1132], [1672, 1108, 1799, 1132], [1811, 1104, 1847, 1132], [1858, 1104, 2017, 1132], [2030, 1113, 2098, 1141], [451, 1150, 535, 1179], [553, 1159, 569, 1178], [583, 1150, 733, 1187], [748, 1150, 939, 1187], [954, 1150, 990, 1178], [1003, 1150, 1082, 1178], [1097, 1150, 1122, 1178], [1139, 1150, 1275, 1178], [1291, 1150, 1321, 1178], [1338, 1159, 1354, 1178], [1369, 1150, 1452, 1178], [1468, 1154, 1574, 1179], [1602, 1150, 1672, 1178], [1689, 1150, 1810, 1178], [1826, 1150, 1876, 1178], [1891, 1150, 1959, 1178], [1974, 1150, 2035, 1178], [2050, 1150, 2099, 1178], [451, 1195, 592, 1232], [605, 1195, 641, 1223], [653, 1204, 669, 1223], [682, 1195, 766, 1223], [779, 1204, 835, 1223], [848, 1195, 887, 1223], [900, 1195, 1085, 1223], [1098, 1195, 1139, 1232], [1153, 1195, 1220, 1223], [1234, 1204, 1363, 1232], [1364, 1195, 1419, 1232], [1431, 1195, 1542, 1232], [1560, 1195, 1633, 1229], [1649, 1195, 1709, 1223], [1723, 1195, 1747, 1223], [1762, 1195, 1802, 1232], [1816, 1195, 1865, 1223], [1879, 1199, 1999, 1223], [2012, 1195, 2034, 1223], [2049, 1204, 2098, 1232], [450, 1250, 535, 1278], [552, 1241, 590, 1269], [620, 1241, 700, 1270], [716, 1245, 836, 1269], [851, 1250, 907, 1269], [923, 1241, 1018, 1278], [1033, 1241, 1072, 1269], [1087, 1241, 1224, 1269], [1240, 1241, 1270, 1269], [1286, 1245, 1402, 1270], [1418, 1241, 1508, 1278], [1523, 1241, 1736, 1269], [1752, 1241, 1900, 1275], [1919, 1241, 1976, 1269], [1992, 1241, 2016, 1269], [2035, 1241, 2099, 1269], [450, 1287, 629, 1324], [641, 1287, 725, 1315], [736, 1287, 874, 1315], [887, 1287, 923, 1315], [932, 1287, 1067, 1324], [1079, 1287, 1162, 1315], [1174, 1287, 1357, 1324], [1360, 1288, 1427, 1321], [1440, 1287, 1502, 1321], [451, 1358, 507, 1385], [517, 1366, 533, 1385], [543, 1357, 654, 1385], [655, 1357, 714, 1385], [721, 1357, 881, 1394], [890, 1357, 1052, 1394], [1065, 1357, 1210, 1385], [1219, 1357, 1469, 1394], [1480, 1357, 1516, 1385], [1523, 1357, 1689, 1386], [1699, 1357, 1782, 1385], [1785, 1357, 1827, 1385], [1829, 1366, 1898, 1385], [1900, 1357, 2036, 1391], [2047, 1357, 2099, 1385], [451, 1403, 566, 1431], [577, 1412, 593, 1431], [604, 1403, 748, 1431], [757, 1403, 992, 1440], [1002, 1403, 1037, 1431], [1045, 1412, 1061, 1431], [1071, 1403, 1166, 1440], [1176, 1407, 1417, 1440], [1435, 1412, 1451, 1431], [1459, 1403, 1567, 1440], [1577, 1412, 1610, 1431], [1620, 1412, 1636, 1431], [1647, 1403, 1855, 1431], [1865, 1403, 2010, 1440], [2027, 1403, 2097, 1431], [451, 1458, 511, 1477], [523, 1449, 711, 1486], [722, 1449, 753, 1477], [767, 1449, 840, 1483], [853, 1449, 923, 1477], [933, 1449, 1084, 1486], [1096, 1458, 1112, 1477], [1123, 1449, 1311, 1477], [1321, 1449, 1369, 1477], [1379, 1449, 1550, 1486], [1562, 1458, 1578, 1477], [1589, 1449, 1698, 1477], [1710, 1449, 1944, 1486], [1954, 1449, 2048, 1477], [2059, 1458, 2099, 1477], [451, 1494, 487, 1522], [500, 1494, 666, 1523], [677, 1498, 805, 1522], [822, 1494, 885, 1522], [897, 1494, 1116, 1522], [1129, 1498, 1255, 1522], [1267, 1494, 1303, 1522], [1313, 1494, 1472, 1522], [1485, 1503, 1550, 1528], [1564, 1494, 1622, 1522], [1634, 1498, 1664, 1522], [1677, 1494, 1810, 1531], [1823, 1498, 1875, 1522], [1885, 1494, 1924, 1522], [1937, 1494, 2056, 1531], [2068, 1498, 2099, 1522], [452, 1540, 525, 1568], [537, 1540, 633, 1577], [644, 1540, 796, 1577], [809, 1540, 896, 1568], [915, 1540, 943, 1568], [956, 1540, 1077, 1568], [1089, 1540, 1248, 1577], [1259, 1540, 1386, 1577], [1400, 1540, 1425, 1568], [1439, 1540, 1550, 1568], [1564, 1540, 1621, 1568], [1632, 1540, 1814, 1577], [1829, 1540, 1882, 1574], [1896, 1540, 1966, 1568], [1978, 1540, 2099, 1568], [451, 1586, 670, 1614], [681, 1586, 930, 1623], [944, 1586, 991, 1614], [1004, 1586, 1149, 1623], [1161, 1595, 1243, 1614], [1254, 1586, 1332, 1623], [1345, 1586, 1434, 1623], [1448, 1595, 1464, 1614], [1476, 1586, 1689, 1614], [1702, 1586, 1851, 1623], [1864, 1595, 1903, 1614], [1917, 1595, 1933, 1614], [1945, 1595, 2052, 1623], [2066, 1586, 2102, 1614], [450, 1631, 691, 1668], [703, 1631, 773, 1659], [790, 1631, 853, 1659], [863, 1631, 980, 1668], [990, 1631, 1239, 1668], [1252, 1631, 1372, 1659], [1384, 1631, 1463, 1659], [1474, 1631, 1535, 1659], [1546, 1640, 1653, 1668], [1666, 1640, 1745, 1659], [1757, 1631, 1971, 1668], [1982, 1631, 2057, 1659], [2068, 1635, 2099, 1659], [451, 1677, 532, 1705], [544, 1677, 719, 1705], [731, 1677, 935, 1714], [947, 1677, 1098, 1705], [1112, 1677, 1159, 1705], [1170, 1677, 1220, 1705], [1232, 1677, 1412, 1705], [1424, 1677, 1531, 1705], [451, 1749, 534, 1776], [554, 1748, 725, 1777], [744, 1752, 881, 1785], [901, 1752, 931, 1776], [950, 1752, 1060, 1776], [1080, 1748, 1153, 1776], [1171, 1748, 1368, 1785], [1388, 1748, 1532, 1776], [1550, 1748, 1799, 1785], [1818, 1748, 1895, 1777], [1913, 1748, 2040, 1776], [2059, 1757, 2099, 1776], [451, 1793, 585, 1830], [601, 1793, 805, 1830], [821, 1793, 972, 1821], [990, 1793, 1051, 1821], [1066, 1797, 1218, 1830], [1234, 1793, 1283, 1821], [1300, 1793, 1460, 1821], [1478, 1793, 1513, 1821], [1528, 1802, 1544, 1821], [1560, 1793, 1655, 1830], [1672, 1797, 1815, 1821], [1832, 1802, 1862, 1821], [1881, 1802, 1897, 1821], [1913, 1793, 2050, 1821], [2066, 1793, 2102, 1821], [451, 1839, 500, 1867], [510, 1839, 744, 1876], [747, 1839, 807, 1867], [815, 1839, 851, 1867], [863, 1843, 950, 1876], [970, 1839, 1032, 1873], [1045, 1839, 1185, 1876], [1199, 1848, 1235, 1867], [1246, 1839, 1415, 1868], [1426, 1839, 1462, 1867], [1471, 1848, 1487, 1867], [1498, 1839, 1624, 1867], [1634, 1839, 1670, 1867], [1679, 1839, 1788, 1876], [1798, 1839, 2002, 1876], [2013, 1839, 2098, 1867], [451, 1884, 528, 1912], [545, 1884, 664, 1921], [679, 1888, 709, 1912], [723, 1884, 863, 1921], [887, 1884, 1019, 1921], [1033, 1884, 1221, 1921], [1238, 1884, 1312, 1912], [1327, 1884, 1510, 1921], [1526, 1893, 1581, 1912], [1596, 1884, 1665, 1912], [1680, 1884, 1775, 1921], [1788, 1884, 1827, 1912], [1840, 1884, 2012, 1912], [2027, 1884, 2099, 1912], [451, 1930, 500, 1958], [515, 1939, 749, 1958], [764, 1930, 857, 1958], [873, 1930, 956, 1958], [972, 1930, 1050, 1959], [1064, 1930, 1323, 1967], [1351, 1930, 1447, 1958], [1463, 1939, 1512, 1958], [1528, 1939, 1544, 1958], [1560, 1930, 1686, 1958], [1701, 1930, 1736, 1958], [1748, 1930, 1905, 1967], [1923, 1930, 2099, 1967], [452, 1976, 525, 2004], [535, 1976, 685, 2005], [696, 1985, 730, 2004], [740, 1976, 817, 2013], [828, 1976, 1031, 2013], [1043, 1976, 1169, 2004], [1186, 1976, 1324, 2013], [1340, 1976, 1380, 2010], [1394, 1985, 1525, 2013], [1536, 1985, 1552, 2004], [1563, 1976, 1771, 2004], [1782, 1976, 1873, 2004], [1874, 1976, 1943, 2004], [1954, 1976, 2098, 2004], [451, 2021, 654, 2058], [670, 2021, 736, 2055], [754, 2021, 905, 2058], [925, 2021, 966, 2055], [984, 2021, 1112, 2058], [1128, 2030, 1144, 2049], [1158, 2021, 1338, 2049], [1352, 2021, 1400, 2049], [1415, 2021, 1559, 2049], [1574, 2021, 1778, 2058], [1792, 2021, 1833, 2058], [1848, 2021, 2023, 2058], [2038, 2021, 2098, 2049], [451, 2067, 621, 2095], [637, 2067, 742, 2104], [758, 2067, 830, 2095], [845, 2076, 994, 2104], [1010, 2076, 1182, 2104], [1212, 2067, 1275, 2095], [1291, 2067, 1376, 2095], [1391, 2067, 1571, 2095], [1587, 2076, 1648, 2095], [1665, 2067, 1853, 2104], [1869, 2067, 2024, 2096], [2042, 2067, 2099, 2095], [452, 2113, 612, 2150], [627, 2113, 668, 2150], [684, 2113, 733, 2141], [748, 2113, 854, 2141], [871, 2113, 901, 2141], [920, 2113, 992, 2147], [1021, 2114, 1109, 2141], [1124, 2113, 1263, 2150], [1281, 2113, 1399, 2142], [1416, 2113, 1510, 2141], [1527, 2113, 1563, 2141], [1575, 2113, 1725, 2142], [1740, 2113, 1842, 2141], [1858, 2113, 2006, 2141], [2023, 2113, 2099, 2142], [452, 2158, 652, 2195], [663, 2158, 740, 2186], [751, 2158, 827, 2186], [839, 2158, 886, 2186], [898, 2158, 1043, 2186], [1055, 2158, 1259, 2195], [1272, 2158, 1329, 2186], [1340, 2158, 1452, 2186], [1464, 2158, 1544, 2186], [1559, 2158, 1632, 2186], [1645, 2167, 1675, 2186], [1690, 2158, 1849, 2186], [1861, 2158, 2000, 2195], [2018, 2158, 2099, 2187], [451, 2204, 567, 2232], [585, 2204, 705, 2232], [720, 2204, 870, 2233], [887, 2204, 1102, 2232], [1122, 2204, 1195, 2238], [1214, 2204, 1438, 2233], [1452, 2204, 1602, 2233], [1618, 2204, 1720, 2232], [1736, 2204, 1885, 2232], [1905, 2204, 1978, 2238], [1996, 2204, 2099, 2232], [450, 2250, 600, 2279], [611, 2250, 714, 2278], [725, 2250, 860, 2278], [862, 2250, 952, 2284], [967, 2259, 1001, 2278], [1012, 2250, 1236, 2279], [1248, 2250, 1397, 2278], [1413, 2250, 1486, 2284], [451, 2371, 499, 2400], [544, 2371, 764, 2409], [776, 2371, 995, 2409], [451, 2466, 524, 2493], [526, 2465, 699, 2493], [715, 2465, 768, 2493], [786, 2465, 863, 2493], [880, 2465, 1008, 2494], [1025, 2469, 1056, 2493], [1072, 2465, 1122, 2493], [1138, 2465, 1205, 2493], [1221, 2465, 1256, 2493], [1270, 2465, 1414, 2502], [1431, 2465, 1606, 2493], [1624, 2465, 1768, 2493], [1785, 2465, 2034, 2502], [2052, 2465, 2100, 2493], [452, 2510, 548, 2547], [562, 2510, 734, 2547], [758, 2511, 791, 2538], [804, 2510, 964, 2547], [977, 2510, 1111, 2547], [1128, 2510, 1200, 2538], [1214, 2510, 1250, 2538], [1266, 2510, 1347, 2547], [1361, 2510, 1487, 2538], [1500, 2510, 1536, 2538], [1548, 2510, 1707, 2538], [1720, 2519, 1885, 2544], [1901, 2510, 1954, 2538], [1970, 2510, 2099, 2547], [451, 2565, 517, 2584], [520, 2556, 691, 2584], [707, 2556, 859, 2593], [870, 2565, 1009, 2593], [1019, 2556, 1072, 2584], [1083, 2556, 1160, 2584], [1170, 2556, 1240, 2584], [1242, 2560, 1297, 2584], [1306, 2556, 1540, 2593], [1550, 2556, 1684, 2593], [1694, 2556, 1742, 2584], [1751, 2556, 1914, 2593], [1925, 2556, 1997, 2584], [2007, 2556, 2100, 2584], [452, 2602, 597, 2631], [609, 2611, 773, 2630], [794, 2602, 985, 2631], [998, 2606, 1027, 2630], [1041, 2602, 1076, 2630], [1095, 2602, 1156, 2636], [1173, 2602, 1330, 2630], [1345, 2611, 1361, 2630], [1374, 2602, 1453, 2630], [1466, 2602, 1502, 2630], [1512, 2602, 1666, 2630], [1679, 2602, 1813, 2639], [1826, 2611, 1866, 2630], [1880, 2602, 2099, 2639], [450, 2647, 573, 2684], [589, 2647, 657, 2675], [672, 2651, 703, 2675], [719, 2647, 845, 2675], [860, 2647, 1057, 2684], [1074, 2647, 1154, 2675], [1169, 2656, 1228, 2675], [1243, 2647, 1392, 2684], [1407, 2651, 1438, 2675], [1455, 2647, 1582, 2675], [1610, 2647, 1722, 2675], [1737, 2647, 1829, 2681], [1847, 2647, 1989, 2684], [1990, 2647, 2033, 2675], [2035, 2647, 2096, 2675], [454, 2693, 527, 2727], [539, 2693, 690, 2730], [702, 2702, 718, 2721], [729, 2693, 851, 2721], [863, 2693, 910, 2721], [920, 2693, 1064, 2730], [1075, 2693, 1288, 2730], [1298, 2693, 1396, 2721], [1405, 2693, 1494, 2730], [1506, 2693, 1702, 2730], [1704, 2693, 1838, 2721], [1848, 2693, 2097, 2730], [452, 2739, 509, 2767], [522, 2748, 538, 2767], [552, 2739, 639, 2767], [651, 2739, 747, 2767], [759, 2739, 879, 2767], [891, 2743, 922, 2767], [934, 2739, 1087, 2776], [1100, 2739, 1180, 2767], [1198, 2739, 1269, 2767], [1284, 2739, 1433, 2776], [1445, 2739, 1498, 2767], [1511, 2739, 1644, 2776], [1656, 2739, 1733, 2767], [1746, 2739, 1893, 2767], [1905, 2739, 1946, 2776], [1961, 2739, 2021, 2773], [2039, 2739, 2097, 2773], [451, 2784, 520, 2812], [536, 2784, 703, 2821], [720, 2793, 736, 2812], [751, 2784, 874, 2812], [890, 2784, 937, 2812], [952, 2784, 1086, 2821], [1102, 2784, 1345, 2812], [1360, 2784, 1498, 2812], [1515, 2788, 1545, 2812], [1561, 2788, 1682, 2813], [1698, 2784, 1842, 2812], [1859, 2788, 1975, 2813], [1992, 2784, 2028, 2812], [2041, 2793, 2099, 2812], [451, 2830, 599, 2867], [613, 2830, 676, 2858], [691, 2830, 777, 2858], [791, 2830, 827, 2858], [840, 2830, 967, 2858], [991, 2831, 1018, 2858], [1034, 2839, 1095, 2858], [1111, 2830, 1333, 2858], [1348, 2830, 1408, 2858], [1423, 2830, 1480, 2858], [1497, 2830, 1646, 2867], [1661, 2839, 1717, 2858], [1730, 2830, 1769, 2858], [1784, 2830, 1904, 2867], [1918, 2834, 1949, 2858], [1963, 2830, 2099, 2867], [451, 2876, 530, 2904], [544, 2876, 656, 2904], [669, 2880, 700, 2904], [713, 2876, 834, 2904], [835, 2876, 1047, 2904], [1067, 2876, 1156, 2904], [1169, 2876, 1290, 2905], [1303, 2876, 1394, 2904], [1395, 2876, 1443, 2904], [1459, 2876, 1523, 2904], [1536, 2876, 1631, 2904], [1644, 2876, 1748, 2913], [1762, 2876, 1809, 2904], [1821, 2876, 1858, 2904], [1873, 2876, 2054, 2904], [2068, 2880, 2099, 2904], [451, 2921, 500, 2949], [513, 2921, 717, 2958], [730, 2921, 867, 2949], [879, 2921, 955, 2949], [968, 2921, 999, 2949], [1012, 2921, 1069, 2949], [1083, 2930, 1180, 2958], [1202, 2921, 1299, 2958], [0, 0, 2550, 3300], [1314, 2921, 1466, 2958], [1479, 2921, 1620, 2949], [1634, 2921, 1792, 2958], [1811, 2921, 1884, 2955], [1901, 2921, 1965, 2949], [1978, 2921, 2099, 2949], [450, 2967, 597, 3004], [614, 2967, 812, 3004], [831, 2967, 879, 2995], [896, 2967, 1035, 2995], [1052, 2967, 1234, 2995], [1268, 2968, 1292, 2995], [1310, 2967, 1334, 2995], [1353, 2967, 1513, 3004], [1531, 2971, 1562, 2995], [1579, 2971, 1650, 2995], [1667, 2967, 1736, 3001], [1756, 2967, 1859, 2995], [1877, 2976, 1931, 2995], [1947, 2967, 2099, 3004], [452, 3017, 573, 3050], [588, 3013, 627, 3041], [638, 3013, 674, 3041], [683, 3013, 767, 3041], [779, 3013, 917, 3041], [929, 3013, 1046, 3050], [1058, 3013, 1141, 3041], [1154, 3013, 1274, 3050], [1285, 3013, 1409, 3050], [1421, 3013, 1489, 3041], [1500, 3013, 1548, 3041], [1559, 3013, 1694, 3050], [451, 355, 501, 382], [502, 358, 631, 382], [641, 354, 803, 391], [812, 363, 918, 391], [929, 354, 1054, 383], [1064, 354, 1177, 382], [1179, 354, 1239, 382], [1249, 354, 1306, 382], [1316, 358, 1441, 391], [1457, 354, 1536, 382], [1547, 354, 1621, 382], [1623, 358, 1680, 391], [1691, 354, 1726, 382], [1742, 354, 1803, 388], [1817, 354, 1875, 382], [1886, 354, 1989, 383], [1999, 354, 2098, 383], [451, 400, 488, 428], [489, 404, 540, 428], [551, 400, 586, 428], [601, 400, 663, 434], [675, 409, 806, 437], [815, 400, 938, 428], [941, 400, 1012, 428], [1021, 400, 1155, 437], [1165, 400, 1248, 428], [1258, 400, 1440, 437], [1443, 400, 1506, 437], [1516, 400, 1682, 437], [1691, 400, 1838, 437], [1848, 400, 1924, 434], [1936, 404, 1987, 428], [1996, 400, 2099, 428], [451, 445, 500, 473], [512, 445, 635, 473], [647, 454, 778, 482], [779, 445, 841, 473], [854, 445, 911, 473], [924, 454, 1021, 482], [1039, 445, 1158, 473], [1170, 445, 1206, 473], [1216, 445, 1265, 473], [1277, 445, 1558, 474], [1570, 445, 1693, 473], [1706, 445, 1852, 482], [1854, 445, 1916, 473], [1929, 445, 1986, 473], [1999, 454, 2097, 482], [450, 491, 523, 519], [540, 500, 650, 528], [669, 491, 705, 519], [720, 491, 838, 519], [857, 491, 945, 519], [961, 500, 1016, 519], [1033, 491, 1069, 519], [1085, 491, 1300, 519], [1318, 495, 1349, 519], [1367, 491, 1483, 519], [1500, 491, 1708, 528], [1724, 491, 1974, 528], [1994, 491, 2051, 519], [2068, 495, 2099, 519], [452, 541, 573, 574], [585, 537, 635, 565], [646, 537, 793, 574], [805, 537, 935, 565], [452, 607, 493, 636], [505, 607, 550, 635], [562, 607, 670, 635], [683, 607, 722, 635], [734, 607, 770, 635], [779, 607, 836, 635], [850, 607, 934, 635], [944, 607, 998, 635], [1010, 607, 1088, 635], [1100, 607, 1228, 635], [1240, 616, 1280, 635], [1292, 607, 1426, 644], [1438, 607, 1640, 644], [1651, 607, 1900, 644], [1915, 611, 1942, 635], [1954, 607, 2004, 635], [2016, 607, 2099, 635], [451, 653, 536, 682], [553, 653, 596, 681], [609, 653, 784, 681], [795, 653, 1044, 690], [1057, 653, 1093, 681], [1102, 653, 1197, 690], [1208, 653, 1398, 690], [1410, 653, 1487, 682], [1497, 653, 1575, 681], [1588, 653, 1671, 681], [1673, 657, 1735, 681], [1746, 653, 1784, 681], [1795, 653, 1900, 690], [1911, 653, 2012, 681], [2024, 653, 2071, 681], [2083, 662, 2099, 681], [451, 699, 562, 727], [562, 708, 606, 727], [608, 699, 721, 733], [734, 699, 756, 727], [768, 708, 865, 727], [878, 703, 908, 727], [918, 699, 957, 727], [969, 708, 985, 727], [996, 699, 1110, 727], [1121, 703, 1190, 727], [1202, 703, 1266, 736], [1278, 703, 1308, 727], [1320, 699, 1384, 727], [1397, 703, 1519, 736], [1530, 703, 1560, 727], [1572, 699, 1681, 727], [1692, 699, 1776, 727], [1786, 699, 1875, 736], [1886, 699, 2099, 736], [451, 744, 526, 772], [543, 744, 614, 772], [626, 753, 718, 781], [729, 744, 854, 781], [857, 753, 899, 772], [911, 744, 974, 772], [987, 748, 1051, 781], [1063, 744, 1094, 772], [1106, 744, 1167, 772], [1179, 744, 1332, 772], [451, 860, 473, 895], [525, 860, 659, 895], [673, 860, 918, 904], [451, 967, 613, 1003], [629, 966, 808, 1003], [823, 966, 854, 994], [868, 966, 995, 994], [1012, 966, 1036, 994], [1053, 966, 1164, 1003], [1180, 975, 1251, 994], [1267, 975, 1298, 994], [1315, 966, 1470, 1003], [1485, 966, 1515, 994], [1531, 970, 1769, 1003], [1784, 966, 1961, 1003], [1979, 966, 2039, 1000], [2056, 966, 2096, 1000], [451, 1011, 550, 1039], [567, 1020, 607, 1039], [624, 1011, 680, 1039], [699, 1011, 775, 1045], [795, 1011, 876, 1039], [892, 1011, 968, 1040], [984, 1011, 1061, 1039], [1079, 1020, 1164, 1039], [1182, 1015, 1318, 1048], [1338, 1015, 1365, 1039], [1381, 1011, 1470, 1048], [1487, 1011, 1690, 1039], [1707, 1011, 1775, 1039], [1791, 1011, 1839, 1039], [1855, 1011, 1989, 1048], [2005, 1011, 2100, 1039], [451, 1061, 553, 1086], [565, 1057, 814, 1094], [829, 1057, 865, 1085], [876, 1057, 974, 1085], [990, 1057, 1059, 1094], [1084, 1057, 1170, 1092], [1194, 1057, 1274, 1086], [1288, 1057, 1436, 1091], [1451, 1057, 1598, 1091], [1615, 1066, 1663, 1085], [1677, 1061, 1728, 1085], [1742, 1057, 1837, 1094], [1852, 1057, 1983, 1085], [1998, 1066, 2097, 1085], [451, 1103, 599, 1140], [601, 1112, 661, 1131], [672, 1107, 702, 1131], [715, 1103, 795, 1140], [808, 1107, 945, 1131], [958, 1103, 994, 1131], [1003, 1103, 1071, 1131], [1083, 1103, 1130, 1131], [1141, 1103, 1241, 1131], [1253, 1112, 1293, 1131], [1306, 1103, 1452, 1131], [1453, 1112, 1503, 1140], [1504, 1103, 1647, 1140], [1658, 1103, 1892, 1140], [1905, 1103, 1988, 1140], [1990, 1103, 2096, 1131], [451, 1174, 503, 1201], [520, 1173, 647, 1201], [663, 1173, 712, 1201], [727, 1173, 906, 1210], [921, 1173, 1069, 1210], [1085, 1182, 1143, 1201], [1160, 1177, 1224, 1210], [1240, 1173, 1352, 1201], [1369, 1173, 1426, 1201], [1443, 1177, 1565, 1210], [1581, 1177, 1612, 1201], [1628, 1173, 1709, 1201], [1727, 1173, 1886, 1201], [1904, 1173, 1983, 1201], [1999, 1173, 2098, 1201], [451, 1219, 564, 1256], [578, 1219, 653, 1247], [677, 1219, 740, 1247], [754, 1219, 821, 1247], [835, 1219, 860, 1247], [875, 1219, 945, 1253], [961, 1219, 1050, 1256], [1064, 1219, 1184, 1256], [1198, 1219, 1322, 1256], [1335, 1219, 1412, 1253], [1429, 1228, 1445, 1247], [1460, 1219, 1565, 1247], [1579, 1219, 1813, 1256], [1827, 1219, 1929, 1247], [1942, 1219, 1981, 1247], [1994, 1219, 2099, 1247], [451, 1269, 481, 1293], [497, 1269, 618, 1302], [633, 1265, 682, 1293], [698, 1274, 842, 1293], [857, 1265, 1002, 1293], [1018, 1265, 1156, 1293], [1173, 1269, 1327, 1293], [1345, 1265, 1424, 1293], [1440, 1265, 1580, 1293], [1596, 1265, 1768, 1302], [1796, 1265, 1884, 1293], [1900, 1269, 1940, 1293], [1941, 1265, 2099, 1302], [452, 1314, 606, 1338], [620, 1310, 697, 1339], [710, 1310, 740, 1338], [753, 1319, 897, 1338], [900, 1310, 957, 1344], [967, 1319, 1082, 1344], [1097, 1310, 1122, 1338], [1137, 1310, 1186, 1338], [1200, 1310, 1360, 1338], [1374, 1310, 1410, 1338], [1420, 1310, 1506, 1338], [1519, 1314, 1579, 1338], [1594, 1314, 1758, 1338], [1779, 1310, 1876, 1347], [1889, 1310, 1946, 1338], [1961, 1310, 2037, 1344], [2052, 1319, 2099, 1338], [450, 1365, 580, 1393], [593, 1365, 609, 1384], [621, 1356, 711, 1385], [722, 1356, 845, 1384], [857, 1356, 905, 1384], [916, 1356, 1050, 1393], [1063, 1360, 1165, 1385], [1175, 1356, 1424, 1393], [1439, 1360, 1466, 1384], [1478, 1356, 1527, 1384], [1539, 1356, 1622, 1384], [1634, 1356, 1712, 1385], [1725, 1356, 1782, 1384], [1793, 1356, 1922, 1393], [451, 1461, 499, 1491], [544, 1461, 704, 1499], [716, 1461, 825, 1499], [451, 1548, 624, 1585], [640, 1548, 689, 1576], [705, 1548, 850, 1576], [867, 1548, 1023, 1585], [1039, 1548, 1075, 1576], [1087, 1548, 1211, 1585], [1227, 1552, 1382, 1576], [1400, 1557, 1500, 1576], [1517, 1548, 1690, 1585], [1708, 1557, 1755, 1576], [1770, 1557, 1826, 1576], [1842, 1548, 1942, 1576], [1958, 1557, 1974, 1576], [1991, 1548, 2099, 1585], [450, 1594, 597, 1631], [616, 1594, 687, 1629], [706, 1594, 835, 1631], [853, 1594, 1067, 1631], [1087, 1603, 1167, 1622], [1185, 1594, 1321, 1622], [1341, 1603, 1372, 1622], [1392, 1594, 1522, 1622], [1553, 1594, 1651, 1623], [1671, 1603, 1687, 1622], [1705, 1594, 1939, 1631], [1959, 1598, 2099, 1622], [451, 1639, 553, 1667], [569, 1639, 693, 1674], [710, 1638, 794, 1673], [812, 1639, 911, 1667], [927, 1648, 1011, 1676], [1029, 1648, 1045, 1667], [1061, 1643, 1201, 1667], [1216, 1643, 1247, 1667], [1263, 1648, 1279, 1667], [1294, 1643, 1403, 1673], [1420, 1648, 1467, 1667], [1482, 1648, 1538, 1667], [1554, 1639, 1628, 1667], [1644, 1648, 1660, 1667], [1676, 1639, 1789, 1667], [1805, 1639, 1902, 1668], [1919, 1638, 1991, 1673], [2010, 1639, 2099, 1676], [452, 1694, 468, 1713], [484, 1694, 591, 1722], [610, 1684, 689, 1724], [710, 1685, 746, 1713], [759, 1685, 883, 1722], [899, 1685, 967, 1713], [983, 1685, 1063, 1713], [1079, 1685, 1128, 1713], [1145, 1685, 1293, 1722], [1309, 1685, 1373, 1722], [1389, 1683, 1427, 1721], [1440, 1685, 1478, 1713], [1510, 1686, 1566, 1713], [1582, 1685, 1656, 1713], [1672, 1685, 1736, 1722], [1752, 1685, 1788, 1713], [1801, 1685, 1925, 1722], [1942, 1689, 2097, 1713], [454, 1728, 536, 1769], [555, 1737, 576, 1761], [592, 1730, 684, 1770], [698, 1740, 745, 1759], [758, 1735, 880, 1768], [891, 1735, 922, 1759], [934, 1731, 1089, 1759], [1020, 1817, 1104, 1851], [1112, 1814, 1154, 1855], [1166, 1814, 1194, 1855], [1212, 1830, 1240, 1839], [1258, 1814, 1356, 1855], [1372, 1834, 1398, 1835], [1413, 1816, 1488, 1851], [1497, 1805, 1528, 1855], [2053, 1817, 2098, 1852], [451, 1893, 550, 1921], [563, 1903, 643, 1927], [658, 1893, 683, 1921], [696, 1893, 746, 1921], [757, 1897, 860, 1922], [870, 1893, 1074, 1930], [1088, 1897, 1228, 1921], [1241, 1903, 1260, 1921], [1273, 1893, 1330, 1921], [1343, 1892, 1419, 1927], [1434, 1893, 1484, 1921], [1495, 1897, 1598, 1922], [1608, 1893, 1812, 1930], [1826, 1897, 1947, 1921], [1949, 1892, 2002, 1921], [451, 1998, 501, 2028], [544, 1999, 612, 2028], [625, 1998, 765, 2028], [778, 1999, 890, 2028], [451, 2085, 479, 2113], [492, 2085, 548, 2114], [553, 2085, 698, 2113], [712, 2085, 856, 2113], [868, 2085, 1117, 2122], [1130, 2085, 1166, 2113], [1175, 2085, 1270, 2122], [1282, 2085, 1426, 2122], [1438, 2085, 1516, 2113], [1530, 2085, 1619, 2122], [1631, 2085, 1680, 2113], [1692, 2085, 1837, 2113], [1848, 2085, 2097, 2122], [451, 2130, 486, 2158], [495, 2130, 571, 2158], [582, 2130, 786, 2158], [804, 2131, 856, 2158], [869, 2139, 989, 2158], [1001, 2130, 1167, 2159], [1178, 2130, 1262, 2158], [1264, 2134, 1320, 2158], [1332, 2130, 1370, 2158], [1381, 2130, 1572, 2167], [1583, 2130, 1624, 2167], [1636, 2134, 1752, 2159], [1766, 2130, 1800, 2165], [1816, 2136, 1837, 2160], [1854, 2123, 1923, 2165], [451, 2201, 592, 2230], [607, 2201, 744, 2229], [759, 2201, 882, 2238], [894, 2201, 999, 2238], [1012, 2210, 1099, 2238], [1113, 2205, 1188, 2229], [1203, 2210, 1243, 2229], [1256, 2201, 1305, 2229], [1319, 2201, 1386, 2229], [1401, 2201, 1469, 2238], [1494, 2201, 1553, 2235], [1568, 2201, 1635, 2236], [1650, 2201, 1708, 2229], [1720, 2210, 1775, 2229], [1789, 2201, 1939, 2238], [1953, 2210, 1986, 2229], [1999, 2201, 2098, 2229], [450, 2247, 590, 2284], [603, 2247, 806, 2284], [819, 2247, 980, 2275], [1000, 2247, 1102, 2276], [1115, 2247, 1189, 2275], [1203, 2256, 1219, 2275], [1232, 2251, 1326, 2284], [1341, 2247, 1441, 2275], [1453, 2247, 1528, 2275], [1540, 2247, 1601, 2275], [1603, 2247, 1663, 2275], [1676, 2247, 1706, 2275], [1708, 2251, 1798, 2275], [1811, 2247, 1836, 2275], [1850, 2247, 1987, 2275], [1999, 2256, 2033, 2275], [2044, 2247, 2097, 2275], [451, 2296, 511, 2320], [523, 2292, 657, 2320], [670, 2292, 702, 2328], [716, 2299, 753, 2320], [769, 2302, 812, 2328], [824, 2292, 881, 2327], [896, 2301, 912, 2320], [922, 2292, 1028, 2329], [1040, 2292, 1243, 2329], [1256, 2292, 1392, 2320], [1404, 2292, 1495, 2320], [1507, 2292, 1574, 2320], [1586, 2292, 1635, 2320], [1647, 2292, 1806, 2329], [1818, 2292, 1906, 2320], [1073, 2378, 1137, 2404], [1151, 2365, 1314, 2406], [1326, 2365, 1368, 2406], [1383, 2372, 1411, 2399], [1425, 2365, 1471, 2406], [2053, 2368, 2098, 2403], [451, 2452, 550, 2480], [568, 2449, 619, 2490], [632, 2449, 673, 2490], [691, 2452, 715, 2480], [731, 2452, 780, 2480], [794, 2452, 1022, 2480], [1036, 2452, 1072, 2480], [1083, 2452, 1132, 2480], [1146, 2456, 1206, 2480], [1220, 2452, 1301, 2480], [1315, 2456, 1441, 2486], [1458, 2452, 1515, 2481], [1537, 2458, 1558, 2482], [1577, 2445, 1683, 2480], [1699, 2452, 1756, 2480], [1771, 2451, 1801, 2480], [1823, 2458, 1844, 2482], [1863, 2445, 1909, 2480], [1925, 2452, 1974, 2480], [1988, 2452, 2098, 2480], [451, 2498, 502, 2535], [515, 2498, 622, 2526], [636, 2498, 693, 2526], [706, 2498, 781, 2532], [795, 2498, 999, 2535], [1016, 2498, 1073, 2526], [1086, 2508, 1105, 2535], [1120, 2507, 1157, 2526], [1170, 2498, 1390, 2526], [1404, 2498, 1563, 2527], [1577, 2498, 1713, 2526], [1728, 2498, 1801, 2526], [1815, 2507, 1846, 2526], [1861, 2498, 1910, 2526], [1922, 2498, 2098, 2535], [451, 2547, 579, 2580], [599, 2544, 656, 2571], [668, 2543, 717, 2571], [729, 2552, 875, 2580], [889, 2543, 925, 2571], [935, 2543, 1105, 2572], [1118, 2543, 1167, 2571], [1179, 2543, 1326, 2580], [1340, 2543, 1437, 2580], [1449, 2543, 1600, 2580], [1615, 2543, 1719, 2577], [1734, 2552, 1781, 2571], [1795, 2543, 1930, 2580], [1944, 2543, 2001, 2571], [2015, 2552, 2098, 2571], [450, 2589, 583, 2626], [597, 2589, 734, 2617], [748, 2589, 788, 2626], [804, 2589, 912, 2626], [928, 2589, 967, 2617], [981, 2589, 1093, 2626], [1107, 2589, 1244, 2617], [1261, 2593, 1291, 2617], [1306, 2589, 1355, 2617], [1369, 2589, 1495, 2626], [1510, 2589, 1567, 2617], [1583, 2589, 1622, 2617], [1636, 2589, 1735, 2617], [1751, 2593, 1781, 2617], [1796, 2598, 1874, 2617], [1899, 2589, 2035, 2626], [2050, 2589, 2099, 2617], [452, 2635, 548, 2664], [561, 2635, 671, 2663], [673, 2639, 729, 2663], [742, 2644, 758, 2663], [771, 2635, 880, 2672], [892, 2635, 1022, 2664], [1034, 2635, 1237, 2672], [1250, 2635, 1395, 2663], [1309, 2710, 1339, 2739], [1155, 2770, 1235, 2794], [1252, 2773, 1280, 2782], [1296, 2748, 1352, 2806], [1363, 2770, 1392, 2794], [2053, 2760, 2098, 2795], [1298, 2818, 1349, 2838], [451, 2876, 495, 2905], [510, 2885, 625, 2910], [645, 2876, 702, 2904], [721, 2876, 745, 2904], [765, 2885, 781, 2904], [798, 2885, 869, 2913], [888, 2876, 1051, 2913], [1069, 2876, 1166, 2905], [1170, 2885, 1226, 2910], [1246, 2876, 1319, 2904], [1337, 2885, 1353, 2904], [1369, 2876, 1590, 2913], [1610, 2876, 1759, 2913], [1777, 2885, 1816, 2904], [1834, 2876, 1939, 2913], [1956, 2880, 2097, 2904], [451, 2921, 498, 2949], [515, 2921, 598, 2949], [616, 2921, 754, 2958], [773, 2921, 830, 2949], [848, 2921, 932, 2949], [949, 2921, 1055, 2949], [1074, 2921, 1174, 2949], [1193, 2930, 1209, 2949], [1226, 2930, 1310, 2949], [1327, 2921, 1468, 2958], [1486, 2921, 1583, 2950], [1602, 2921, 1697, 2958], [1715, 2925, 1843, 2958], [1877, 2922, 2031, 2955], [2052, 2921, 2100, 2949], [451, 2967, 500, 2995], [515, 2976, 660, 3004], [678, 2967, 713, 2995], [727, 2967, 784, 2995], [801, 2967, 970, 2996], [987, 2967, 1058, 3002], [1075, 2967, 1147, 2995], [1163, 2967, 1212, 2995], [1228, 2967, 1443, 3004], [1459, 2967, 1628, 2996], [1644, 2967, 1674, 2995], [1691, 2967, 1797, 3002], [1817, 2967, 1890, 2995], [1907, 2976, 1923, 2995], [1940, 2967, 2098, 3004], [451, 3013, 654, 3050], [666, 3013, 803, 3041], [816, 3013, 924, 3041], [935, 3013, 974, 3041], [987, 3013, 1137, 3041], [1149, 3017, 1180, 3041], [1192, 3013, 1327, 3042], [1339, 3013, 1388, 3041], [1400, 3013, 1489, 3042], [1501, 3013, 1650, 3050], [1662, 3013, 1799, 3041], [1810, 3022, 1941, 3050], [1942, 3013, 2051, 3041], [812, 1059, 1013, 1101], [1053, 1059, 1140, 1101], [1167, 1059, 1254, 1101], [1294, 1059, 1381, 1101], [1408, 1059, 1495, 1101], [1535, 1059, 1622, 1101], [1649, 1059, 1736, 1101], [897, 1125, 924, 1148], [1138, 1125, 1169, 1148], [1379, 1125, 1409, 1148], [1619, 1125, 1651, 1148], [451, 1216, 557, 1253], [578, 1216, 602, 1244], [628, 1216, 820, 1253], [837, 1216, 873, 1244], [887, 1225, 903, 1244], [919, 1216, 1066, 1253], [1082, 1216, 1185, 1244], [1201, 1216, 1273, 1244], [1289, 1216, 1413, 1253], [1429, 1216, 1513, 1253], [1531, 1220, 1686, 1244], [1705, 1226, 1724, 1244], [1742, 1216, 1799, 1244], [1817, 1215, 1839, 1244], [1870, 1216, 1934, 1244], [1950, 1216, 2099, 1253], [451, 1262, 587, 1290], [602, 1262, 638, 1290], [650, 1262, 707, 1290], [724, 1262, 826, 1290], [841, 1262, 866, 1290], [882, 1266, 913, 1290], [928, 1262, 1083, 1290], [1098, 1262, 1147, 1290], [1162, 1262, 1297, 1290], [1311, 1262, 1448, 1290], [1464, 1262, 1513, 1290], [1529, 1266, 1669, 1290], [1684, 1262, 1762, 1291], [1777, 1262, 1927, 1299], [1942, 1262, 1978, 1290], [1990, 1262, 2040, 1290], [2053, 1262, 2098, 1290], [451, 1312, 518, 1336], [536, 1308, 716, 1345], [729, 1317, 786, 1345], [798, 1308, 1002, 1345], [1014, 1308, 1151, 1336], [1163, 1317, 1219, 1336], [1230, 1308, 1269, 1336], [1280, 1308, 1355, 1336], [1367, 1312, 1398, 1336], [1410, 1312, 1549, 1345], [1561, 1308, 1610, 1336], [1622, 1308, 1856, 1345], [1869, 1312, 2010, 1336], [2021, 1308, 2099, 1337], [450, 1353, 708, 1390], [725, 1353, 788, 1381], [800, 1353, 1003, 1390], [1016, 1353, 1152, 1381], [1164, 1353, 1189, 1381], [1201, 1353, 1392, 1390], [1403, 1353, 1444, 1390], [1456, 1353, 1505, 1381], [1519, 1353, 1605, 1382], [1616, 1353, 1695, 1381], [1698, 1353, 1754, 1381], [1766, 1353, 1815, 1381], [1827, 1353, 1962, 1390], [1975, 1353, 2077, 1382], [451, 1530, 548, 1567], [561, 1530, 617, 1558], [632, 1530, 762, 1559], [775, 1530, 872, 1559], [886, 1539, 933, 1558], [945, 1539, 1012, 1558], [1014, 1534, 1067, 1558], [1080, 1530, 1224, 1567], [1236, 1530, 1285, 1558], [1296, 1530, 1432, 1567], [1434, 1530, 1536, 1558], [1549, 1530, 1645, 1567], [1658, 1530, 1778, 1558], [1792, 1530, 1887, 1559], [1900, 1530, 1965, 1567], [1988, 1530, 2025, 1565], [2043, 1531, 2100, 1558], [451, 1576, 500, 1604], [513, 1580, 656, 1610], [672, 1585, 774, 1604], [775, 1576, 866, 1604], [879, 1575, 924, 1606], [930, 1589, 952, 1610], [968, 1576, 992, 1604], [1008, 1585, 1024, 1604], [1036, 1576, 1183, 1613], [1196, 1576, 1310, 1604], [1324, 1576, 1421, 1605], [1437, 1585, 1488, 1604], [1490, 1576, 1584, 1604], [1598, 1586, 1678, 1610], [1693, 1580, 1860, 1613], [1874, 1576, 1924, 1604], [1938, 1576, 2097, 1604], [451, 1621, 486, 1649], [498, 1621, 548, 1649], [563, 1625, 704, 1649], [719, 1631, 746, 1649], [772, 1621, 899, 1655], [917, 1621, 975, 1649], [990, 1625, 1020, 1649], [1035, 1621, 1084, 1649], [1098, 1630, 1153, 1649], [1168, 1621, 1203, 1649], [1214, 1621, 1338, 1658], [1353, 1621, 1429, 1655], [1446, 1630, 1493, 1649], [1507, 1621, 1597, 1649], [1612, 1621, 1673, 1649], [1689, 1631, 1708, 1649], [1724, 1621, 1781, 1649], [1797, 1620, 1812, 1649], [1828, 1630, 1876, 1649], [1892, 1621, 2099, 1658], [451, 1667, 627, 1704], [656, 1668, 761, 1695], [777, 1676, 805, 1695], [807, 1667, 965, 1695], [981, 1667, 1030, 1695], [1047, 1667, 1191, 1695], [1206, 1667, 1387, 1704], [1403, 1667, 1563, 1695], [1579, 1667, 1609, 1695], [1625, 1666, 1698, 1701], [1716, 1671, 1788, 1695], [1805, 1666, 1877, 1701], [1884, 1667, 1948, 1704], [1964, 1667, 2099, 1704], [452, 1712, 528, 1751], [546, 1717, 577, 1741], [589, 1713, 753, 1741], [985, 1815, 1201, 1857], [1269, 1806, 1325, 1864], [1403, 1815, 1562, 1856], [2053, 1818, 2098, 1853], [1218, 1875, 1322, 1904], [1325, 1887, 1343, 1902], [1349, 1888, 1374, 1906], [451, 1986, 495, 2015], [505, 1995, 620, 2020], [634, 1986, 691, 2014], [704, 1986, 853, 2023], [865, 1986, 1002, 2014], [1015, 1995, 1135, 2014], [1137, 1995, 1180, 2014], [1192, 1986, 1268, 2023], [1281, 1986, 1394, 2014], [1406, 1986, 1509, 2014], [1520, 1986, 1620, 2014], [1632, 1995, 1660, 2014], [1662, 1986, 1731, 2014], [1743, 1995, 1783, 2014], [1785, 1986, 1864, 2015], [1865, 1990, 1922, 2014], [1934, 1986, 1991, 2014], [2006, 1990, 2096, 2023], [451, 2032, 551, 2060], [567, 2032, 624, 2060], [643, 2041, 698, 2060], [714, 2032, 753, 2060], [771, 2041, 787, 2060], [803, 2032, 904, 2060], [920, 2032, 1069, 2069], [1086, 2032, 1134, 2060], [1150, 2032, 1342, 2069], [1359, 2032, 1511, 2069], [1528, 2032, 1708, 2069], [1725, 2032, 1788, 2060], [1805, 2032, 2019, 2060], [2036, 2032, 2098, 2060], [451, 2086, 563, 2114], [579, 2077, 653, 2111], [667, 2077, 724, 2105], [737, 2077, 946, 2114], [958, 2077, 983, 2105], [996, 2081, 1048, 2105], [1059, 2077, 1176, 2114], [1189, 2077, 1277, 2105], [1289, 2077, 1371, 2105], [1383, 2077, 1407, 2105], [1421, 2086, 1461, 2105], [1473, 2077, 1564, 2105], [1566, 2077, 1618, 2105], [1631, 2077, 1712, 2105], [1725, 2077, 1804, 2105], [1816, 2077, 1847, 2105], [1859, 2077, 1922, 2105], [1933, 2077, 2028, 2114], [2046, 2078, 2099, 2105], [450, 2123, 568, 2152], [580, 2123, 637, 2151], [650, 2123, 732, 2151], [743, 2123, 784, 2160], [792, 2123, 902, 2160], [915, 2123, 1042, 2160], [1053, 2123, 1126, 2151], [1138, 2123, 1255, 2151], [1269, 2122, 1314, 2153], [1319, 2136, 1341, 2157], [1357, 2123, 1414, 2151], [1426, 2122, 1511, 2157], [450, 2194, 606, 2231], [619, 2194, 672, 2228], [688, 2198, 718, 2222], [730, 2194, 853, 2231], [866, 2194, 933, 2222], [945, 2203, 1067, 2222], [1080, 2194, 1141, 2222], [1152, 2194, 1225, 2222], [1238, 2194, 1355, 2222], [1368, 2194, 1450, 2222], [1463, 2203, 1479, 2222], [1492, 2194, 1598, 2222], [1609, 2194, 1843, 2231], [1857, 2198, 1884, 2222], [1896, 2194, 1946, 2222], [1959, 2198, 2099, 2222], [450, 2239, 536, 2268], [555, 2239, 598, 2267], [612, 2239, 662, 2267], [673, 2239, 797, 2276], [810, 2239, 894, 2276], [907, 2243, 1062, 2267], [1078, 2239, 1163, 2267], [1175, 2239, 1225, 2267], [1238, 2248, 1321, 2267], [1334, 2239, 1475, 2276], [1478, 2239, 1520, 2273], [1533, 2239, 1557, 2267], [1571, 2239, 1748, 2267], [1760, 2243, 1791, 2267], [1805, 2248, 1906, 2267], [1908, 2239, 1998, 2267], [2011, 2239, 2098, 2267], [450, 2285, 564, 2322], [577, 2285, 630, 2319], [645, 2285, 708, 2313], [720, 2285, 804, 2313], [816, 2285, 865, 2313], [877, 2285, 968, 2313], [969, 2285, 1021, 2313], [1033, 2285, 1115, 2313], [1127, 2285, 1202, 2313], [1214, 2285, 1358, 2313], [1370, 2285, 1612, 2322], [1629, 2286, 1683, 2313], [1696, 2284, 1738, 2319], [1755, 2298, 1783, 2307], [1799, 2284, 1876, 2323], [1892, 2284, 2019, 2323], [2036, 2285, 2099, 2313], [446, 2331, 525, 2368], [537, 2331, 686, 2368], [698, 2331, 835, 2359], [849, 2328, 949, 2369], [964, 2331, 1030, 2359], [1043, 2331, 1196, 2359], [1405, 2420, 1425, 2450], [1011, 2446, 1112, 2487], [1129, 2462, 1157, 2471], [1173, 2446, 1343, 2488], [1359, 2453, 1387, 2480], [1403, 2466, 1428, 2505], [1438, 2441, 1537, 2487], [2053, 2449, 2098, 2484], [451, 2560, 550, 2588], [563, 2557, 689, 2598], [705, 2560, 729, 2588], [743, 2560, 792, 2588], [805, 2560, 846, 2594], [860, 2560, 1090, 2597], [1102, 2564, 1184, 2588], [451, 2631, 474, 2658], [490, 2630, 515, 2658], [533, 2634, 673, 2667], [689, 2630, 750, 2658], [765, 2630, 822, 2658], [835, 2630, 914, 2667], [930, 2630, 1079, 2667], [1096, 2627, 1197, 2668], [1216, 2630, 1240, 2658], [1258, 2630, 1443, 2667], [1471, 2630, 1535, 2658], [1550, 2630, 1667, 2658], [1684, 2630, 1775, 2658], [1791, 2630, 1872, 2658], [1888, 2634, 1918, 2658], [1933, 2630, 2043, 2658], [2060, 2630, 2099, 2658], [451, 2676, 648, 2713], [664, 2676, 721, 2704], [734, 2676, 937, 2713], [951, 2676, 1077, 2713], [1091, 2680, 1122, 2704], [1135, 2685, 1204, 2704], [1219, 2676, 1276, 2704], [1289, 2676, 1412, 2713], [1425, 2676, 1580, 2704], [1593, 2676, 1642, 2704], [1655, 2676, 1804, 2713], [1817, 2676, 1961, 2704], [1982, 2677, 2035, 2704], [2049, 2676, 2098, 2704], [451, 2721, 533, 2749], [548, 2721, 605, 2749], [621, 2721, 702, 2749], [715, 2721, 756, 2758], [770, 2721, 946, 2758], [961, 2730, 977, 2749], [991, 2721, 1070, 2749], [1084, 2721, 1120, 2749], [1131, 2721, 1310, 2750], [1324, 2721, 1495, 2749], [1509, 2721, 1681, 2758], [1696, 2721, 1783, 2749], [1798, 2721, 1947, 2749], [1961, 2721, 2099, 2749], [451, 2767, 650, 2804], [665, 2771, 805, 2795], [818, 2767, 906, 2804], [930, 2768, 986, 2795], [999, 2776, 1088, 2804], [1102, 2767, 1166, 2804], [1180, 2767, 1215, 2795], [1226, 2767, 1350, 2804], [1365, 2771, 1520, 2795], [1539, 2764, 1621, 2805], [1639, 2776, 1686, 2795], [1701, 2767, 1816, 2804], [1831, 2776, 1847, 2795], [1861, 2767, 1972, 2795], [1973, 2767, 2036, 2795], [2048, 2767, 2098, 2795], [451, 2813, 576, 2841], [591, 2817, 746, 2841], [761, 2823, 784, 2841], [803, 2819, 824, 2843], [844, 2812, 902, 2847], [918, 2813, 1133, 2841], [1146, 2813, 1219, 2850], [1232, 2813, 1506, 2850], [1520, 2817, 1571, 2841], [1585, 2817, 1671, 2841], [1685, 2813, 1873, 2841], [1888, 2813, 1924, 2841], [1936, 2823, 1963, 2841], [1987, 2813, 2057, 2841], [2073, 2813, 2097, 2841], [451, 2858, 643, 2895], [658, 2862, 689, 2886], [704, 2858, 754, 2886], [770, 2858, 882, 2886], [898, 2862, 973, 2886], [988, 2858, 1024, 2886], [1036, 2858, 1086, 2886], [1101, 2858, 1162, 2886], [1179, 2858, 1316, 2886], [1332, 2858, 1367, 2886], [1381, 2867, 1397, 2886], [1412, 2858, 1493, 2895], [1509, 2858, 1624, 2895], [1639, 2862, 1755, 2886], [1771, 2858, 1938, 2895], [1953, 2858, 2100, 2886], [452, 2904, 516, 2939], [528, 2905, 580, 2941], [601, 2904, 637, 2932], [649, 2904, 680, 2932], [695, 2904, 782, 2939], [855, 2997, 962, 3031], [970, 2994, 1012, 3035], [1024, 2996, 1048, 3033], [1060, 2994, 1096, 3035], [1113, 3010, 1141, 3019], [1160, 2994, 1184, 3035], [1199, 3001, 1227, 3028], [1240, 2997, 1324, 3031], [1332, 2994, 1374, 3035], [1387, 2994, 1414, 3035], [1431, 3014, 1457, 3015], [1471, 2994, 1605, 3035], [1617, 2994, 1691, 3040], [2053, 2997, 2098, 3032], [451, 354, 550, 382], [571, 351, 636, 392], [663, 367, 691, 376], [716, 351, 888, 392], [908, 354, 1032, 382], [1051, 354, 1100, 382], [1118, 354, 1256, 382], [1272, 354, 1363, 391], [1380, 354, 1451, 382], [1483, 354, 1573, 388], [1593, 354, 1643, 382], [1659, 354, 1732, 382], [1749, 354, 1898, 391], [1914, 354, 2051, 382], [2068, 358, 2099, 382], [451, 400, 606, 428], [618, 400, 665, 428], [676, 400, 726, 428], [739, 400, 873, 429], [886, 400, 977, 428], [978, 400, 1035, 428], [1204, 464, 1218, 484], [1599, 479, 1619, 509], [818, 508, 841, 537], [846, 505, 918, 546], [935, 521, 963, 530], [1031, 496, 1087, 554], [1158, 463, 1239, 588], [1250, 508, 1357, 542], [1365, 505, 1407, 546], [1419, 507, 1443, 544], [1455, 463, 1532, 588], [1553, 512, 1581, 539], [1597, 525, 1622, 564], [1631, 500, 1731, 546], [2053, 508, 2098, 543], [980, 565, 1137, 595], [1185, 566, 1236, 585], [451, 663, 500, 692], [544, 663, 655, 692], [667, 662, 829, 700], [451, 748, 549, 777], [563, 748, 612, 776], [626, 748, 775, 785], [789, 748, 926, 776], [941, 757, 971, 776], [987, 748, 1108, 776], [1123, 748, 1227, 782], [1243, 748, 1345, 776], [1359, 748, 1494, 785], [1508, 757, 1564, 776], [1578, 748, 1701, 785], [1715, 748, 1764, 776], [1779, 757, 1862, 776], [1876, 748, 2050, 785], [2067, 757, 2097, 776], [452, 803, 508, 831], [519, 794, 727, 831], [739, 794, 836, 823], [841, 795, 892, 822], [902, 794, 1067, 831], [1081, 803, 1111, 822], [1124, 794, 1173, 822], [1184, 794, 1333, 831], [1344, 794, 1480, 822], [1491, 794, 1516, 822], [1528, 794, 1758, 828], [1771, 803, 1818, 822], [1828, 803, 1884, 822], [1894, 803, 1949, 822], [1961, 794, 2099, 822], [451, 839, 585, 876], [600, 839, 723, 867], [738, 839, 913, 876], [930, 839, 1004, 867], [1020, 848, 1050, 867], [1068, 839, 1228, 867], [1244, 839, 1379, 876], [1394, 839, 1525, 873], [1543, 839, 1661, 868], [1664, 839, 1733, 868], [1748, 839, 1797, 867], [1813, 839, 1949, 876], [1964, 839, 2099, 876], [452, 885, 611, 922], [622, 885, 752, 914], [753, 885, 838, 919], [855, 885, 967, 913], [979, 885, 1053, 913], [1065, 885, 1273, 922], [1286, 885, 1383, 914], [1387, 894, 1453, 919], [1463, 894, 1518, 913], [1529, 885, 1804, 922], [1816, 885, 1944, 922], [1956, 889, 2099, 913], [452, 931, 526, 959], [538, 931, 680, 968], [693, 931, 742, 959], [750, 931, 828, 968], [840, 940, 920, 959], [931, 935, 962, 959], [974, 931, 1048, 959], [1061, 935, 1182, 959], [1185, 931, 1291, 960], [1303, 931, 1390, 959], [451, 1045, 474, 1079], [525, 1045, 794, 1089], [451, 1148, 499, 1177], [544, 1149, 627, 1178], [640, 1149, 704, 1178], [717, 1149, 919, 1178], [451, 1235, 502, 1263], [515, 1235, 618, 1263], [631, 1235, 757, 1272], [772, 1244, 851, 1263], [864, 1235, 1022, 1272], [1036, 1235, 1198, 1263], [1210, 1235, 1299, 1272], [1314, 1244, 1330, 1263], [1343, 1235, 1494, 1264], [1507, 1235, 1704, 1263], [1726, 1235, 1821, 1263], [1835, 1244, 1884, 1263], [1898, 1244, 1914, 1263], [1927, 1235, 2039, 1263], [2039, 1235, 2102, 1263], [450, 1284, 629, 1317], [645, 1280, 706, 1308], [720, 1289, 776, 1308], [791, 1280, 942, 1308], [956, 1280, 1047, 1308], [1048, 1280, 1208, 1317], [1232, 1281, 1285, 1308], [1300, 1280, 1431, 1308], [1446, 1280, 1495, 1308], [1509, 1280, 1668, 1317], [1683, 1280, 1784, 1309], [1800, 1280, 1848, 1308], [1863, 1280, 2026, 1317], [2042, 1280, 2099, 1308], [451, 1326, 679, 1363], [696, 1326, 768, 1354], [783, 1326, 864, 1363], [879, 1326, 970, 1354], [1000, 1327, 1033, 1354], [1049, 1326, 1147, 1354], [1163, 1326, 1247, 1354], [1262, 1335, 1309, 1354], [1325, 1326, 1388, 1354], [1404, 1326, 1580, 1363], [1596, 1326, 1645, 1354], [1661, 1326, 1753, 1354], [1769, 1326, 1805, 1354], [1819, 1326, 1902, 1354], [1917, 1330, 2097, 1363], [451, 1372, 481, 1400], [495, 1376, 609, 1409], [622, 1372, 720, 1400], [742, 1372, 786, 1400], [799, 1372, 1028, 1409], [1042, 1372, 1097, 1407], [1113, 1372, 1256, 1409], [1270, 1372, 1356, 1407], [1372, 1372, 1498, 1400], [1510, 1372, 1546, 1400], [1557, 1372, 1643, 1400], [1656, 1372, 1801, 1400], [1817, 1372, 1892, 1407], [1907, 1372, 2022, 1409], [2037, 1372, 2099, 1400], [452, 1417, 527, 1452], [543, 1417, 726, 1454], [741, 1417, 986, 1454], [1001, 1416, 1129, 1452], [1154, 1417, 1217, 1445], [1231, 1417, 1317, 1445], [1332, 1417, 1476, 1445], [1493, 1417, 1623, 1454], [1639, 1426, 1718, 1445], [1731, 1417, 1889, 1454], [1904, 1417, 2005, 1445], [2020, 1417, 2099, 1445], [451, 1463, 500, 1491], [514, 1472, 607, 1500], [610, 1467, 666, 1491], [680, 1463, 808, 1500], [822, 1463, 903, 1497], [920, 1463, 1118, 1500], [1132, 1463, 1180, 1491], [1193, 1463, 1268, 1491], [1282, 1463, 1409, 1500], [1425, 1463, 1540, 1500], [1555, 1463, 1613, 1491], [1627, 1463, 1732, 1500], [1757, 1464, 1794, 1491], [1792, 1472, 1878, 1491], [1892, 1463, 1941, 1491], [1955, 1463, 2099, 1500], [451, 1517, 558, 1545], [574, 1501, 653, 1543], [672, 1508, 719, 1536], [732, 1508, 860, 1545], [874, 1508, 923, 1536], [936, 1508, 1083, 1545], [1097, 1508, 1207, 1536], [1230, 1508, 1293, 1536], [1307, 1517, 1414, 1545], [1430, 1517, 1476, 1536], [1479, 1508, 1735, 1545], [1748, 1508, 1837, 1545], [1851, 1508, 1901, 1536], [1915, 1512, 1959, 1536], [1973, 1508, 2009, 1536], [2020, 1508, 2097, 1536], [450, 1554, 596, 1591], [607, 1554, 648, 1591], [661, 1547, 750, 1582], [767, 1554, 808, 1588], [823, 1554, 871, 1582], [883, 1554, 1056, 1591], [1069, 1554, 1126, 1582], [1139, 1554, 1316, 1582], [1318, 1554, 1399, 1591], [1411, 1554, 1486, 1582], [1505, 1554, 1632, 1588], [1648, 1554, 1687, 1582], [1699, 1558, 1801, 1591], [1815, 1558, 1970, 1582], [1985, 1563, 2015, 1582], [2029, 1554, 2099, 1582], [452, 1609, 482, 1628], [495, 1600, 571, 1628], [582, 1600, 770, 1628], [784, 1609, 863, 1628], [874, 1600, 1017, 1629], [1029, 1600, 1109, 1628], [1120, 1600, 1169, 1628], [1181, 1609, 1298, 1637], [451, 1671, 488, 1698], [486, 1679, 621, 1707], [623, 1670, 749, 1698], [761, 1670, 841, 1698], [851, 1674, 911, 1698], [922, 1670, 1131, 1707], [1148, 1670, 1211, 1698], [1223, 1670, 1357, 1699], [1369, 1670, 1471, 1698], [1482, 1679, 1529, 1698], [1531, 1670, 1669, 1698], [1680, 1679, 1720, 1698], [1731, 1670, 1813, 1699], [1825, 1674, 1946, 1698], [1948, 1670, 2053, 1707], [2066, 1670, 2102, 1698], [451, 1716, 500, 1744], [512, 1716, 785, 1753], [797, 1716, 921, 1753], [934, 1716, 1049, 1744], [1062, 1716, 1098, 1744], [1108, 1716, 1157, 1744], [1169, 1716, 1313, 1753], [1326, 1725, 1442, 1753], [1462, 1716, 1525, 1744], [1539, 1716, 1673, 1745], [1677, 1716, 1803, 1744], [1804, 1716, 1901, 1744], [1914, 1716, 1971, 1744], [1985, 1716, 2099, 1744], [451, 1762, 481, 1790], [493, 1762, 699, 1790], [711, 1762, 783, 1790], [796, 1762, 919, 1790], [930, 1762, 1012, 1791], [1022, 1762, 1146, 1799], [1159, 1766, 1314, 1790], [1327, 1762, 1407, 1790], [1418, 1762, 1468, 1790], [1479, 1762, 1734, 1799], [1747, 1762, 1861, 1790], [1874, 1762, 1909, 1790], [1918, 1762, 1968, 1790], [1979, 1771, 2097, 1799], [450, 1807, 594, 1844], [607, 1807, 637, 1835], [654, 1807, 665, 1835], [681, 1807, 799, 1835], [812, 1807, 937, 1844], [950, 1811, 1115, 1841], [1130, 1807, 1204, 1835], [1215, 1807, 1318, 1844], [1330, 1816, 1371, 1844], [1383, 1807, 1455, 1835], [1468, 1807, 1561, 1835], [1574, 1816, 1590, 1835], [1602, 1807, 1714, 1836], [1715, 1816, 1780, 1835], [1793, 1816, 1809, 1835], [1821, 1807, 1935, 1835], [1948, 1811, 2096, 1835], [451, 1853, 532, 1881], [544, 1853, 718, 1890], [732, 1853, 913, 1890], [924, 1853, 999, 1881], [1011, 1853, 1132, 1881], [1144, 1853, 1309, 1890], [1323, 1857, 1353, 1881], [1366, 1853, 1454, 1882], [1465, 1853, 1610, 1890], [1622, 1853, 1751, 1890], [451, 1924, 514, 1952], [525, 1924, 701, 1953], [712, 1924, 824, 1952], [837, 1924, 971, 1953], [975, 1924, 1020, 1952], [1023, 1928, 1078, 1952], [1090, 1924, 1266, 1961], [1278, 1924, 1411, 1952], [1422, 1933, 1469, 1952], [1480, 1933, 1536, 1952], [1548, 1924, 1629, 1952], [1640, 1924, 1735, 1952], [1746, 1924, 1943, 1961], [1956, 1924, 1996, 1961], [2008, 1924, 2098, 1952], [451, 1969, 562, 2006], [577, 1969, 740, 1997], [754, 1969, 821, 1997], [835, 1969, 865, 1997], [880, 1978, 896, 1997], [910, 1969, 1050, 1997], [1063, 1969, 1219, 2006], [1241, 1969, 1312, 1997], [1327, 1969, 1352, 1997], [1368, 1969, 1481, 1997], [1494, 1973, 1525, 1997], [1538, 1969, 1618, 2006], [1631, 1969, 1715, 1997], [1728, 1969, 1759, 1997], [1773, 1969, 1893, 1997], [1895, 1969, 2099, 1997], [451, 2015, 550, 2043], [562, 2015, 687, 2052], [700, 2024, 746, 2043], [749, 2015, 848, 2043], [862, 2024, 892, 2043], [906, 2024, 922, 2043], [933, 2015, 1004, 2052], [1006, 2015, 1076, 2043], [1087, 2015, 1260, 2043], [1272, 2015, 1409, 2043], [1421, 2015, 1635, 2043], [1647, 2015, 1796, 2052], [1798, 2015, 1878, 2049], [451, 2086, 488, 2113], [486, 2094, 569, 2113], [580, 2085, 629, 2113], [641, 2085, 778, 2122], [789, 2085, 924, 2122], [935, 2085, 1067, 2119], [1080, 2085, 1210, 2114], [1212, 2085, 1298, 2119], [1311, 2085, 1358, 2113], [1368, 2085, 1513, 2122], [1524, 2085, 1574, 2113], [1585, 2085, 1711, 2122], [1724, 2085, 1760, 2113], [1768, 2094, 1823, 2113], [1834, 2085, 1961, 2119], [1975, 2094, 2011, 2113], [2013, 2085, 2098, 2113], [451, 2131, 562, 2159], [575, 2131, 702, 2168], [716, 2131, 790, 2159], [802, 2131, 842, 2160], [855, 2131, 1015, 2159], [1035, 2131, 1147, 2159], [1159, 2131, 1358, 2168], [1372, 2131, 1523, 2159], [1536, 2131, 1596, 2159], [1609, 2131, 1658, 2159], [1672, 2131, 1806, 2160], [1820, 2131, 1923, 2159], [1935, 2140, 2097, 2168], [451, 2177, 541, 2205], [556, 2177, 625, 2205], [640, 2177, 690, 2205], [705, 2177, 865, 2206], [881, 2177, 992, 2211], [1009, 2177, 1060, 2205], [1075, 2186, 1122, 2205], [1136, 2181, 1234, 2214], [1248, 2177, 1354, 2205], [1371, 2186, 1411, 2205], [1426, 2177, 1475, 2205], [1491, 2186, 1574, 2205], [1588, 2177, 1700, 2205], [1700, 2186, 1748, 2205], [1749, 2177, 1928, 2205], [1944, 2177, 1992, 2205], [2005, 2177, 2100, 2205], [451, 2215, 704, 2259], [451, 2325, 501, 2354], [545, 2325, 795, 2363], [807, 2326, 973, 2355], [976, 2325, 1235, 2355], [451, 2413, 503, 2440], [516, 2412, 651, 2441], [663, 2421, 718, 2440], [729, 2412, 832, 2440], [843, 2412, 932, 2449], [945, 2412, 995, 2440], [1007, 2412, 1220, 2449], [1232, 2412, 1383, 2440], [1385, 2412, 1622, 2440], [1636, 2412, 1771, 2447], [1784, 2412, 1850, 2440], [1862, 2412, 1898, 2440], [1908, 2412, 2099, 2441], [451, 2462, 479, 2486], [494, 2458, 529, 2486], [549, 2458, 621, 2492], [645, 2458, 716, 2486], [732, 2458, 798, 2486], [811, 2458, 946, 2487], [962, 2458, 1096, 2495], [1110, 2458, 1259, 2495], [1273, 2458, 1474, 2495], [1488, 2458, 1686, 2495], [1702, 2458, 1801, 2486], [1817, 2467, 1865, 2486], [1879, 2458, 1949, 2486], [1962, 2458, 2038, 2486], [2052, 2458, 2100, 2486], [451, 2503, 601, 2531], [603, 2503, 842, 2531], [857, 2512, 956, 2531], [972, 2503, 1021, 2531], [1035, 2503, 1308, 2540], [1322, 2503, 1470, 2540], [1483, 2503, 1552, 2540], [1575, 2504, 1632, 2531], [1645, 2503, 1712, 2537], [1728, 2503, 1836, 2532], [1851, 2503, 1973, 2540], [1976, 2512, 2021, 2531], [2034, 2512, 2098, 2540], [451, 2549, 556, 2577], [569, 2549, 642, 2577], [657, 2549, 693, 2577], [706, 2549, 903, 2586], [920, 2549, 1041, 2586], [1055, 2549, 1144, 2586], [1160, 2549, 1335, 2586], [1350, 2549, 1477, 2586], [1492, 2549, 1560, 2577], [1575, 2549, 1605, 2577], [1620, 2558, 1679, 2577], [1693, 2549, 1842, 2586], [1857, 2549, 1915, 2577], [1930, 2549, 2099, 2586], [451, 2594, 576, 2622], [592, 2594, 781, 2631], [797, 2594, 828, 2622], [844, 2594, 972, 2622], [1000, 2594, 1090, 2628], [1109, 2594, 1217, 2623], [1233, 2594, 1258, 2622], [1276, 2603, 1292, 2622], [1308, 2594, 1389, 2631], [1405, 2594, 1471, 2622], [1486, 2594, 1534, 2622], [1549, 2594, 1745, 2631], [1761, 2594, 1894, 2622], [1909, 2603, 1963, 2622], [1978, 2594, 2099, 2622], [450, 2640, 699, 2677], [713, 2649, 761, 2668], [774, 2640, 981, 2677], [992, 2640, 1093, 2668], [1106, 2649, 1206, 2668], [1219, 2640, 1356, 2677], [1368, 2640, 1540, 2677], [451, 2712, 488, 2739], [486, 2711, 619, 2739], [629, 2711, 678, 2739], [688, 2711, 903, 2748], [914, 2715, 999, 2748], [1009, 2711, 1167, 2739], [1177, 2711, 1207, 2739], [1221, 2711, 1294, 2745], [1306, 2711, 1378, 2739], [1388, 2711, 1438, 2739], [1448, 2711, 1607, 2748], [1617, 2711, 1678, 2739], [1688, 2720, 1735, 2739], [1745, 2711, 1826, 2739], [1836, 2720, 1891, 2739], [1900, 2711, 2097, 2748], [450, 2756, 539, 2793], [554, 2756, 650, 2793], [664, 2756, 713, 2784], [727, 2756, 871, 2793], [885, 2756, 952, 2784], [967, 2756, 1024, 2784], [1038, 2756, 1110, 2793], [1123, 2765, 1178, 2784], [1192, 2756, 1241, 2784], [1255, 2757, 1379, 2784], [1394, 2756, 1616, 2785], [1630, 2765, 1756, 2793], [1769, 2756, 1876, 2793], [1890, 2756, 1939, 2784], [1953, 2756, 2100, 2784], [451, 2802, 578, 2839], [593, 2802, 651, 2830], [665, 2802, 774, 2839], [790, 2806, 896, 2839], [921, 2802, 1002, 2830], [1016, 2802, 1167, 2830], [1168, 2802, 1223, 2830], [1238, 2802, 1287, 2830], [1301, 2802, 1516, 2830], [1531, 2802, 1597, 2830], [1611, 2802, 1635, 2830], [1650, 2802, 1841, 2839], [1854, 2802, 1895, 2839], [1909, 2802, 1959, 2830], [1974, 2811, 2099, 2839], [506, 2877, 893, 2915], [906, 2883, 1207, 2915], [503, 2921, 1209, 2961], [503, 2966, 605, 2999], [620, 2973, 746, 2999], [762, 2982, 833, 2999], [846, 2974, 964, 3007], [979, 2973, 1121, 3007], [1136, 2977, 1287, 2999], [1303, 2974, 1330, 2999], [1345, 2974, 1389, 2999], [1403, 2974, 1488, 3000], [1502, 2982, 1572, 3007], [1586, 2974, 1685, 2999], [1699, 2982, 1818, 3007], [1844, 2974, 1952, 2999], [1967, 2973, 2010, 2999], [2024, 2974, 2100, 2999], [451, 3016, 693, 3041], [705, 3016, 757, 3041], [768, 3024, 817, 3041], [828, 3024, 923, 3041], [934, 3016, 1003, 3041], [1014, 3015, 1057, 3041], [1067, 3024, 1116, 3041], [1126, 3016, 1218, 3041], [1229, 3024, 1273, 3041], [1284, 3015, 1415, 3041], [1426, 3019, 1452, 3041], [1463, 3016, 1700, 3048], [1710, 3018, 2029, 3042], [962, 345, 1069, 373], [1258, 345, 1397, 373], [1448, 345, 1587, 373], [962, 392, 1106, 429], [1118, 392, 1205, 421], [1292, 392, 1361, 421], [1482, 392, 1551, 421], [962, 438, 1094, 467], [1292, 438, 1359, 467], [1482, 438, 1552, 467], [962, 484, 1023, 511], [1292, 483, 1359, 512], [1482, 483, 1553, 512], [962, 529, 1101, 557], [1292, 529, 1362, 558], [1482, 529, 1549, 557], [963, 576, 1097, 605], [1293, 576, 1362, 605], [1482, 576, 1553, 604], [963, 622, 1122, 651], [1292, 621, 1363, 651], [1482, 621, 1553, 651], [450, 709, 540, 737], [558, 709, 582, 737], [604, 709, 829, 738], [844, 718, 988, 746], [1003, 709, 1050, 737], [1064, 709, 1191, 746], [1206, 718, 1246, 737], [1260, 709, 1385, 746], [1401, 709, 1458, 737], [1472, 709, 1604, 738], [1619, 709, 1691, 737], [1710, 709, 1787, 738], [1801, 709, 1919, 737], [1934, 709, 2096, 746], [450, 755, 673, 792], [685, 755, 919, 792], [930, 755, 1179, 792], [1194, 755, 1270, 790], [1275, 756, 1342, 783], [1356, 755, 1413, 783], [1427, 755, 1600, 790], [1604, 755, 1837, 792], [1848, 755, 2097, 792], [449, 800, 539, 837], [555, 800, 676, 828], [692, 800, 890, 837], [909, 800, 966, 828], [984, 809, 1020, 828], [1037, 800, 1213, 828], [1229, 800, 1336, 828], [1354, 800, 1518, 835], [1539, 800, 1600, 834], [1620, 800, 1780, 828], [1797, 800, 1883, 835], [1902, 800, 1959, 828], [1976, 800, 2099, 837], [451, 846, 609, 881], [624, 846, 732, 880], [748, 846, 805, 874], [819, 846, 868, 874], [881, 846, 1020, 883], [1034, 846, 1111, 874], [1125, 846, 1268, 874], [1290, 846, 1353, 874], [1366, 847, 1427, 874], [1441, 846, 1498, 874], [1512, 846, 1644, 875], [1656, 846, 1763, 874], [1778, 855, 1827, 874], [1841, 846, 1905, 874], [1919, 846, 2006, 874], [2020, 846, 2099, 874], [450, 892, 622, 920], [622, 901, 671, 921], [672, 892, 730, 920], [748, 892, 820, 926], [464, 1263, 493, 1487], [464, 1094, 501, 1251], [464, 1022, 499, 1081], [600, 1515, 657, 1544], [720, 1515, 779, 1544], [842, 1515, 901, 1544], [956, 1515, 1033, 1544], [1076, 1515, 1155, 1544], [1190, 1515, 1288, 1544], [1357, 1515, 1413, 1544], [1477, 1515, 1535, 1544], [1599, 1515, 1657, 1544], [0, 0, 2550, 3300], [1713, 1515, 1790, 1544], [1833, 1515, 1912, 1544], [1946, 1515, 2044, 1544], [724, 1579, 864, 1616], [876, 1580, 1062, 1607], [1077, 1579, 1140, 1614], [1481, 1579, 1621, 1616], [1633, 1580, 1819, 1607], [1833, 1579, 1896, 1614], [560, 1679, 631, 1701], [643, 1673, 777, 1702], [789, 1679, 861, 1701], [873, 1673, 935, 1702], [940, 1674, 1032, 1701], [1045, 1678, 1116, 1702], [1127, 1673, 1266, 1701], [1277, 1677, 1348, 1697], [1359, 1673, 1420, 1700], [1431, 1682, 1502, 1698], [1513, 1673, 1645, 1702], [1656, 1688, 1669, 1692], [1681, 1688, 1694, 1692], [1706, 1688, 1719, 1692], [1738, 1673, 1882, 1710], [1894, 1673, 1981, 1702], [451, 1790, 557, 1827], [570, 1790, 597, 1818], [616, 1790, 840, 1819], [853, 1799, 998, 1827], [1010, 1790, 1058, 1818], [1070, 1799, 1086, 1818], [1098, 1790, 1224, 1818], [1236, 1790, 1272, 1818], [1281, 1790, 1398, 1818], [1413, 1790, 1478, 1825], [1490, 1790, 1580, 1818], [1596, 1790, 1607, 1818], [1623, 1790, 1671, 1818], [1683, 1790, 1785, 1818], [1797, 1790, 2017, 1827], [2036, 1790, 2099, 1818], [451, 1836, 504, 1864], [520, 1836, 601, 1864], [618, 1836, 717, 1864], [733, 1836, 839, 1864], [856, 1836, 904, 1864], [919, 1836, 1003, 1864], [1018, 1836, 1135, 1864], [1153, 1836, 1241, 1864], [1257, 1836, 1370, 1864], [1386, 1845, 1426, 1864], [1442, 1836, 1567, 1873], [1583, 1836, 1650, 1864], [1667, 1836, 1724, 1864], [1740, 1836, 1895, 1865], [1911, 1845, 1951, 1864], [1967, 1836, 2099, 1865], [451, 1882, 527, 1916], [540, 1882, 590, 1910], [601, 1882, 678, 1919], [690, 1882, 772, 1910], [784, 1882, 851, 1911], [863, 1891, 956, 1911], [451, 2037, 486, 2065], [496, 2037, 545, 2065], [558, 2036, 794, 2065], [805, 2037, 1040, 2074], [1042, 2046, 1087, 2065], [1089, 2037, 1153, 2065], [1166, 2037, 1202, 2065], [1217, 2041, 1381, 2065], [1399, 2038, 1452, 2065], [1464, 2037, 1538, 2065], [1550, 2037, 1600, 2065], [1612, 2037, 1777, 2065], [1791, 2037, 1938, 2065], [1948, 2037, 2037, 2074], [2050, 2037, 2099, 2065], [452, 2091, 534, 2110], [547, 2082, 670, 2119], [684, 2082, 742, 2110], [754, 2082, 1013, 2119], [1025, 2082, 1060, 2110], [1070, 2082, 1119, 2110], [1132, 2082, 1277, 2119], [1289, 2086, 1465, 2119], [1477, 2082, 1624, 2110], [1638, 2082, 1679, 2116], [1695, 2091, 1726, 2110], [1738, 2082, 1813, 2110], [1826, 2082, 1856, 2110], [1871, 2082, 1943, 2116], [451, 2154, 503, 2181], [516, 2162, 568, 2181], [582, 2153, 631, 2181], [645, 2153, 753, 2182], [767, 2153, 966, 2190], [981, 2153, 1054, 2181], [1067, 2153, 1107, 2190], [1121, 2153, 1248, 2190], [1262, 2162, 1302, 2181], [1316, 2153, 1441, 2190], [1456, 2153, 1513, 2181], [1527, 2153, 1636, 2190], [1649, 2162, 1689, 2181], [1703, 2153, 1835, 2182], [1849, 2153, 2025, 2181], [2042, 2153, 2099, 2181], [451, 2199, 518, 2228], [531, 2208, 624, 2228], [646, 2199, 743, 2236], [756, 2199, 806, 2227], [819, 2199, 887, 2227], [901, 2199, 984, 2236], [998, 2199, 1144, 2236], [1157, 2199, 1197, 2236], [1214, 2199, 1287, 2233], [1302, 2208, 1349, 2227], [1362, 2199, 1437, 2227], [1450, 2199, 1574, 2236], [1588, 2199, 1715, 2236], [1729, 2199, 1796, 2227], [1810, 2199, 1887, 2227], [1902, 2199, 1981, 2227], [1998, 2199, 2055, 2228], [2068, 2203, 2099, 2227], [455, 2244, 563, 2278], [576, 2244, 738, 2272], [740, 2244, 814, 2272], [826, 2244, 953, 2281], [966, 2244, 1015, 2272], [1027, 2244, 1192, 2272], [1206, 2244, 1358, 2272], [1376, 2244, 1440, 2272], [1451, 2244, 1557, 2272], [1571, 2244, 1607, 2272], [1617, 2244, 1673, 2272], [1687, 2244, 1754, 2272], [1766, 2253, 1866, 2272], [1880, 2244, 2007, 2281], [2021, 2244, 2097, 2272], [452, 2299, 500, 2318], [513, 2290, 596, 2318], [598, 2290, 660, 2318], [672, 2290, 779, 2327], [791, 2290, 817, 2318], [835, 2290, 924, 2318], [940, 2290, 951, 2318], [968, 2290, 1052, 2318], [1055, 2290, 1130, 2318], [1141, 2290, 1247, 2318], [1260, 2290, 1308, 2318], [1319, 2290, 1447, 2327], [1459, 2299, 1498, 2318], [1515, 2290, 1602, 2324], [1614, 2290, 1800, 2318], [451, 2361, 529, 2389], [542, 2361, 669, 2395], [685, 2361, 819, 2390], [834, 2361, 891, 2389], [905, 2361, 1064, 2390], [1079, 2361, 1264, 2398], [1278, 2361, 1317, 2389], [1328, 2361, 1409, 2398], [1421, 2361, 1505, 2389], [1517, 2370, 1557, 2389], [1570, 2361, 1626, 2389], [1641, 2361, 1714, 2389], [1733, 2361, 1860, 2395], [1875, 2361, 1924, 2389], [1938, 2361, 2097, 2390], [451, 2406, 553, 2434], [566, 2406, 765, 2443], [780, 2406, 829, 2434], [843, 2406, 977, 2435], [991, 2406, 1102, 2440], [1117, 2406, 1281, 2443], [1294, 2406, 1344, 2434], [1355, 2406, 1526, 2434], [1541, 2406, 1576, 2434], [1588, 2406, 1698, 2443], [1711, 2406, 1838, 2443], [1851, 2406, 1919, 2434], [1932, 2415, 2007, 2435], [2020, 2406, 2099, 2434], [452, 2461, 468, 2480], [480, 2456, 614, 2489], [626, 2452, 774, 2489], [785, 2452, 854, 2489], [451, 2574, 500, 2604], [544, 2574, 773, 2604], [451, 2668, 551, 2696], [568, 2668, 617, 2696], [634, 2668, 742, 2697], [761, 2668, 945, 2705], [962, 2668, 1090, 2696], [1107, 2677, 1147, 2696], [1164, 2668, 1361, 2705], [1378, 2668, 1428, 2696], [1446, 2668, 1590, 2696], [1608, 2672, 1729, 2696], [1746, 2668, 1782, 2696], [1796, 2668, 1846, 2696], [1864, 2672, 2004, 2696], [2021, 2668, 2099, 2697], [450, 2714, 709, 2751], [724, 2723, 771, 2742], [785, 2714, 849, 2742], [862, 2723, 929, 2742], [930, 2718, 984, 2742], [996, 2714, 1104, 2751], [1117, 2714, 1293, 2751], [1305, 2714, 1355, 2742], [1368, 2714, 1497, 2742], [1510, 2714, 1594, 2742], [1607, 2714, 1813, 2751], [1833, 2715, 1866, 2742], [1878, 2714, 2038, 2751], [2050, 2714, 2099, 2742], [452, 2759, 611, 2788], [628, 2759, 719, 2787], [720, 2759, 770, 2787], [788, 2759, 961, 2796], [977, 2759, 1024, 2787], [1039, 2759, 1100, 2787], [1114, 2768, 1254, 2796], [1273, 2768, 1304, 2787], [1321, 2759, 1342, 2787], [1359, 2759, 1462, 2787], [1478, 2768, 1513, 2787], [1530, 2763, 1561, 2787], [1576, 2759, 1711, 2788], [1726, 2768, 1781, 2787], [1797, 2759, 1946, 2796], [1962, 2759, 1998, 2787], [2010, 2759, 2099, 2796], [451, 2805, 576, 2842], [589, 2814, 619, 2833], [634, 2814, 650, 2833], [660, 2805, 743, 2842], [755, 2805, 904, 2842], [916, 2805, 946, 2833], [959, 2814, 975, 2833], [987, 2805, 1189, 2842], [1201, 2809, 1294, 2842], [451, 2877, 483, 2904], [496, 2876, 603, 2913], [616, 2876, 632, 2905], [646, 2885, 693, 2904], [706, 2876, 761, 2904], [762, 2876, 851, 2904], [863, 2876, 940, 2905], [942, 2876, 1159, 2913], [1173, 2876, 1220, 2904], [1233, 2885, 1249, 2904], [1261, 2876, 1387, 2904], [1398, 2876, 1434, 2904], [1443, 2876, 1577, 2913], [1591, 2876, 1705, 2904], [1718, 2876, 1775, 2904], [1788, 2876, 1920, 2905], [1932, 2876, 2039, 2904], [2057, 2876, 2102, 2905], [450, 2921, 609, 2958], [620, 2921, 741, 2949], [754, 2921, 862, 2949], [873, 2921, 912, 2949], [924, 2921, 973, 2949], [984, 2921, 1062, 2958], [1074, 2921, 1164, 2955], [1178, 2921, 1278, 2949], [1289, 2921, 1453, 2958], [1466, 2921, 1613, 2958], [1625, 2921, 1823, 2958], [1835, 2921, 1973, 2949], [1985, 2921, 2099, 2949], [452, 2967, 509, 2995], [524, 2967, 656, 2996], [672, 2967, 779, 2995], [807, 2968, 890, 2996], [906, 2967, 1019, 3004], [1035, 2967, 1084, 2995], [1100, 2967, 1190, 2995], [1192, 2967, 1269, 2995], [1284, 2971, 1336, 2995], [1350, 2976, 1405, 2995], [1422, 2976, 1478, 3004], [1493, 2967, 1617, 3004], [1632, 2967, 1893, 2996], [1909, 2967, 1977, 2995], [1992, 2967, 2099, 3004], [451, 3013, 587, 3050], [600, 3013, 622, 3041], [635, 3013, 695, 3041], [707, 3013, 855, 3050], [867, 3017, 897, 3041], [909, 3013, 991, 3041], [1004, 3013, 1148, 3041], [1161, 3013, 1343, 3041], [1356, 3013, 1512, 3050], [1525, 3022, 1625, 3041], [1638, 3013, 1722, 3041], [1734, 3017, 1794, 3041], [1806, 3013, 1978, 3050], [541, 464, 548, 469], [636, 466, 639, 467], [1837, 436, 1950, 460], [511, 466, 662, 509], [1449, 479, 1676, 545], [1396, 519, 1446, 552], [645, 564, 810, 603], [1454, 551, 1462, 559], [1497, 560, 1619, 595], [1636, 598, 1640, 601], [811, 604, 989, 636], [1614, 602, 1689, 633], [1893, 613, 1985, 645], [840, 630, 888, 651], [894, 613, 1007, 664], [1890, 630, 1898, 651], [1935, 621, 1995, 659], [1074, 685, 1097, 691], [1105, 685, 1115, 693], [1135, 685, 1140, 686], [1675, 687, 1689, 698], [1858, 667, 1888, 682], [699, 684, 832, 733], [1044, 680, 1190, 735], [1596, 684, 1787, 751], [1852, 668, 1908, 706], [621, 759, 750, 798], [1655, 750, 1804, 797], [727, 799, 746, 807], [908, 822, 968, 854], [978, 816, 1029, 854], [1608, 801, 1759, 824], [1805, 797, 1813, 805], [991, 835, 1047, 863], [1740, 824, 1876, 888], [451, 986, 557, 1023], [571, 986, 598, 1015], [617, 986, 680, 1014], [693, 986, 746, 1014], [760, 990, 867, 1014], [878, 986, 942, 1023], [955, 986, 1054, 1014], [1068, 986, 1171, 1015], [1182, 986, 1365, 1023], [1379, 986, 1427, 1014], [1440, 995, 1456, 1014], [1468, 986, 1614, 1023], [1617, 986, 1674, 1014], [1687, 986, 1726, 1014], [1739, 986, 1821, 1014], [1833, 986, 1996, 1023], [2010, 986, 2099, 1023], [451, 1031, 500, 1059], [511, 1031, 760, 1068], [774, 1031, 895, 1059], [907, 1031, 938, 1059], [950, 1031, 999, 1059], [1013, 1031, 1075, 1060], [1080, 1032, 1172, 1059], [1186, 1031, 1296, 1059], [1314, 1032, 1397, 1060], [1410, 1031, 1523, 1068], [1536, 1031, 1585, 1059], [1598, 1031, 1700, 1059], [1712, 1031, 1763, 1059], [1776, 1035, 1827, 1059], [1839, 1040, 1894, 1059], [1907, 1040, 1963, 1068], [1975, 1031, 2099, 1068], [451, 1077, 712, 1106], [724, 1077, 792, 1105], [804, 1077, 910, 1114], [923, 1077, 1050, 1114], [1053, 1077, 1094, 1111], [1108, 1077, 1167, 1105], [1180, 1077, 1275, 1105], [1290, 1077, 1434, 1105], [1448, 1077, 1605, 1114], [1616, 1077, 1754, 1105], [1766, 1077, 1850, 1105], [1862, 1081, 1922, 1105], [1935, 1077, 2097, 1114], [450, 1123, 539, 1160], [551, 1123, 676, 1160], [690, 1132, 720, 1151], [735, 1132, 751, 1151], [763, 1123, 853, 1160], [872, 1124, 913, 1151], [925, 1123, 1074, 1160], [1086, 1123, 1153, 1157], [1168, 1123, 1217, 1151], [1228, 1123, 1306, 1160], [1318, 1123, 1382, 1160], [1395, 1123, 1494, 1151], [1509, 1123, 1631, 1151], [1644, 1127, 1688, 1151], [1700, 1123, 1736, 1151], [1745, 1123, 1843, 1151], [1858, 1123, 1990, 1158], [2004, 1123, 2040, 1151], [2050, 1123, 2099, 1151], [451, 1168, 533, 1205], [545, 1168, 634, 1205], [646, 1168, 719, 1205], [731, 1168, 780, 1196], [792, 1168, 924, 1197], [937, 1168, 994, 1196], [1006, 1168, 1120, 1196], [1132, 1168, 1239, 1196], [451, 1363, 473, 1397], [526, 1363, 780, 1398], [451, 1510, 530, 1538], [545, 1510, 601, 1538], [616, 1519, 709, 1547], [722, 1519, 769, 1538], [782, 1510, 859, 1539], [872, 1510, 1024, 1547], [1039, 1519, 1055, 1538], [1069, 1510, 1159, 1539], [1173, 1510, 1296, 1538], [1310, 1510, 1358, 1538], [1371, 1510, 1515, 1547], [1529, 1510, 1742, 1547], [1757, 1510, 1932, 1538], [1945, 1519, 2098, 1547], [451, 1556, 558, 1584], [576, 1556, 624, 1584], [640, 1556, 874, 1593], [891, 1556, 1060, 1584], [1092, 1556, 1189, 1593], [1207, 1565, 1223, 1584], [1240, 1565, 1311, 1593], [1329, 1556, 1437, 1593], [1454, 1556, 1577, 1584], [1594, 1556, 1641, 1584], [1658, 1556, 1802, 1584], [1820, 1556, 2032, 1593], [2052, 1565, 2099, 1584], [451, 1601, 651, 1630], [667, 1601, 815, 1638], [830, 1605, 861, 1629], [876, 1601, 978, 1629], [994, 1605, 1067, 1629], [1082, 1601, 1118, 1629], [1129, 1601, 1179, 1629], [1194, 1605, 1236, 1629], [1249, 1601, 1356, 1629], [1372, 1610, 1412, 1629], [1426, 1601, 1476, 1629], [1490, 1601, 1570, 1630], [1573, 1601, 1688, 1635], [1706, 1601, 1893, 1638], [1907, 1601, 2053, 1638], [2068, 1605, 2099, 1629], [451, 1647, 585, 1676], [600, 1647, 744, 1675], [759, 1647, 885, 1675], [899, 1656, 999, 1675], [1015, 1647, 1187, 1684], [1210, 1647, 1297, 1675], [1310, 1647, 1471, 1684], [1486, 1656, 1540, 1675], [1555, 1647, 1704, 1684], [1718, 1651, 1749, 1675], [1763, 1647, 1884, 1675], [1898, 1647, 2099, 1684], [451, 1693, 578, 1730], [590, 1693, 658, 1721], [670, 1693, 701, 1721], [713, 1693, 763, 1721], [776, 1693, 838, 1722], [843, 1694, 935, 1721], [949, 1693, 1060, 1727], [1074, 1702, 1121, 1721], [1133, 1702, 1212, 1721], [1225, 1693, 1292, 1721], [1304, 1697, 1335, 1721], [1347, 1693, 1549, 1721], [1561, 1693, 1622, 1721], [1635, 1693, 1745, 1730], [1759, 1693, 1922, 1721], [1934, 1693, 2097, 1730], [451, 1738, 563, 1766], [572, 1738, 722, 1775], [734, 1738, 784, 1766], [794, 1738, 903, 1766], [920, 1738, 1135, 1772], [1146, 1738, 1235, 1775], [1247, 1747, 1332, 1766], [1342, 1738, 1514, 1775], [1525, 1738, 1724, 1775], [1737, 1738, 1794, 1766], [1804, 1738, 2040, 1772], [2052, 1747, 2099, 1766], [452, 1784, 575, 1812], [587, 1784, 647, 1812], [659, 1793, 714, 1812], [726, 1784, 875, 1821], [889, 1784, 953, 1812], [966, 1784, 1069, 1812], [1082, 1793, 1116, 1812], [1130, 1788, 1160, 1812], [1172, 1784, 1254, 1812], [1267, 1784, 1474, 1821], [1485, 1784, 1597, 1812], [1609, 1784, 1807, 1821], [1821, 1793, 1921, 1812], [1935, 1784, 2097, 1821], [451, 1830, 576, 1858], [589, 1839, 645, 1867], [657, 1830, 750, 1858], [762, 1830, 890, 1867], [902, 1830, 977, 1858], [451, 1900, 514, 1929], [530, 1900, 679, 1937], [694, 1900, 834, 1937], [851, 1904, 933, 1937], [948, 1900, 1107, 1937], [1123, 1900, 1154, 1928], [1169, 1900, 1297, 1937], [1313, 1900, 1380, 1928], [1397, 1900, 1454, 1928], [1469, 1900, 1586, 1937], [1588, 1900, 1692, 1928], [1707, 1904, 1738, 1928], [1754, 1909, 1793, 1928], [1810, 1900, 1990, 1928], [2018, 1901, 2098, 1929], [451, 1946, 502, 1983], [515, 1946, 737, 1974], [750, 1946, 799, 1974], [813, 1946, 981, 1974], [994, 1946, 1121, 1983], [1134, 1946, 1170, 1974], [1181, 1946, 1325, 1974], [1338, 1946, 1587, 1983], [1601, 1946, 1690, 1983], [1704, 1950, 1845, 1974], [1858, 1946, 1978, 1983], [1991, 1946, 2067, 1980], [2083, 1955, 2099, 1974], [450, 1992, 599, 2029], [609, 1996, 679, 2020], [690, 1996, 754, 2029], [765, 1992, 789, 2020], [801, 1996, 832, 2020], [843, 1996, 965, 2029], [976, 1992, 1103, 2029], [1113, 1992, 1202, 2029], [1212, 1992, 1510, 2029], [1521, 1992, 1589, 2020], [1599, 2001, 1633, 2020], [1642, 2001, 1717, 2021], [1728, 2001, 1853, 2029], [1863, 1992, 1899, 2020], [1907, 1992, 2099, 2029], [451, 2037, 636, 2065], [654, 2037, 724, 2065], [738, 2046, 808, 2074], [819, 2037, 944, 2074], [956, 2046, 1031, 2066], [1043, 2041, 1158, 2074], [1168, 2037, 1364, 2074], [1378, 2037, 1425, 2065], [1436, 2037, 1573, 2074], [1585, 2037, 1657, 2065], [1669, 2037, 1883, 2065], [1895, 2037, 2067, 2074], [451, 2109, 483, 2136], [497, 2108, 546, 2136], [560, 2117, 643, 2136], [656, 2108, 734, 2142], [749, 2108, 799, 2136], [813, 2117, 933, 2136], [948, 2108, 984, 2136], [994, 2117, 1049, 2136], [1060, 2108, 1196, 2145], [1209, 2108, 1408, 2145], [1424, 2112, 1546, 2145], [1559, 2108, 1671, 2136], [1684, 2108, 1775, 2136], [1796, 2108, 1907, 2137], [1920, 2108, 2005, 2136], [2016, 2108, 2099, 2145], [452, 2154, 634, 2191], [638, 2154, 679, 2188], [690, 2154, 715, 2182], [727, 2163, 799, 2191], [811, 2158, 841, 2182], [853, 2154, 961, 2182], [972, 2163, 1027, 2182], [1037, 2154, 1128, 2182], [1129, 2154, 1181, 2182], [1192, 2154, 1268, 2183], [1279, 2154, 1416, 2191], [1426, 2154, 1509, 2191], [1520, 2154, 1692, 2191], [1709, 2154, 1789, 2182], [1803, 2163, 1870, 2182], [1871, 2154, 1995, 2191], [2008, 2154, 2099, 2182], [450, 2208, 589, 2236], [603, 2199, 743, 2227], [759, 2203, 874, 2236], [891, 2199, 965, 2227], [980, 2208, 1010, 2227], [1026, 2208, 1105, 2233], [1121, 2199, 1233, 2236], [1247, 2203, 1313, 2233], [1330, 2199, 1387, 2227], [1402, 2208, 1545, 2228], [1546, 2199, 1661, 2227], [1675, 2199, 1771, 2227], [1786, 2199, 1898, 2227], [1912, 2203, 1943, 2227], [1956, 2199, 2068, 2236], [2083, 2208, 2099, 2227], [452, 2245, 548, 2282], [559, 2245, 642, 2282], [654, 2245, 810, 2282], [451, 2315, 493, 2343], [508, 2324, 536, 2343], [538, 2315, 624, 2344], [626, 2315, 799, 2344], [812, 2315, 861, 2343], [873, 2315, 979, 2343], [993, 2315, 1024, 2343], [1036, 2315, 1093, 2343], [1106, 2324, 1199, 2352], [1211, 2315, 1283, 2343], [1296, 2324, 1312, 2343], [1324, 2315, 1478, 2352], [1492, 2315, 1600, 2352], [1614, 2315, 1711, 2344], [1714, 2315, 1756, 2349], [1769, 2315, 1871, 2343], [1884, 2315, 1948, 2343], [1960, 2315, 1999, 2343], [2011, 2315, 2098, 2343], [451, 2361, 548, 2398], [563, 2365, 593, 2389], [608, 2361, 751, 2389], [766, 2361, 899, 2389], [913, 2370, 967, 2389], [981, 2361, 1130, 2398], [1144, 2361, 1281, 2389], [1296, 2370, 1352, 2389], [1365, 2361, 1404, 2389], [1417, 2361, 1493, 2389], [1507, 2361, 1538, 2389], [1553, 2361, 1758, 2389], [1773, 2361, 1845, 2389], [1860, 2370, 1944, 2389], [1958, 2361, 2099, 2398], [451, 2407, 684, 2444], [701, 2411, 804, 2436], [820, 2407, 937, 2435], [956, 2407, 1030, 2435], [1048, 2416, 1079, 2435], [1097, 2408, 1259, 2435], [1280, 2407, 1341, 2441], [1362, 2416, 1396, 2435], [1412, 2407, 1619, 2435], [1637, 2407, 1830, 2444], [1850, 2411, 1881, 2435], [1899, 2416, 1950, 2435], [1967, 2407, 2100, 2435], [451, 2452, 534, 2480], [549, 2461, 605, 2480], [620, 2452, 732, 2480], [746, 2452, 882, 2489], [895, 2452, 1001, 2480], [1018, 2461, 1058, 2480], [1072, 2452, 1145, 2480], [1160, 2461, 1265, 2480], [1282, 2452, 1339, 2480], [1354, 2452, 1556, 2489], [1570, 2452, 1650, 2480], [1667, 2452, 1755, 2480], [1769, 2452, 1844, 2480], [1859, 2452, 1890, 2480], [1904, 2452, 2099, 2489], [451, 2498, 523, 2526], [536, 2507, 591, 2526], [604, 2498, 817, 2535], [831, 2498, 980, 2535], [993, 2498, 1138, 2526], [1160, 2498, 1285, 2526], [1299, 2502, 1330, 2526], [1344, 2498, 1411, 2532], [1427, 2507, 1474, 2526], [1487, 2498, 1550, 2526], [1565, 2498, 1629, 2526], [1644, 2498, 1734, 2535], [1747, 2507, 1802, 2526], [1815, 2498, 1917, 2526], [1931, 2502, 1961, 2526], [1976, 2507, 1992, 2526], [2006, 2498, 2100, 2526], [451, 2544, 563, 2581], [575, 2544, 611, 2572], [620, 2544, 700, 2572], [713, 2544, 869, 2581], [881, 2544, 1020, 2572], [1032, 2544, 1205, 2572], [1218, 2544, 1276, 2572], [1288, 2544, 1489, 2581], [1501, 2544, 1695, 2572], [1707, 2544, 1879, 2572], [450, 2729, 860, 2773], [451, 2876, 514, 2904], [526, 2876, 644, 2904], [658, 2876, 759, 2904], [772, 2876, 832, 2904], [844, 2880, 874, 2904], [886, 2876, 978, 2904], [989, 2876, 1160, 2904], [1172, 2876, 1362, 2905], [1376, 2876, 1433, 2904], [1444, 2876, 1490, 2904], [1504, 2876, 1676, 2904], [1689, 2876, 1737, 2904], [1748, 2876, 1871, 2913], [1883, 2876, 1958, 2904], [1969, 2876, 2097, 2904], [452, 2921, 509, 2949], [528, 2921, 673, 2958], [690, 2925, 867, 2958], [885, 2921, 1144, 2958], [1163, 2921, 1317, 2955], [1339, 2930, 1370, 2949], [1389, 2921, 1459, 2949], [1478, 2930, 1508, 2949], [1529, 2921, 1697, 2958], [1716, 2930, 1732, 2949], [1750, 2921, 1876, 2949], [1893, 2921, 1929, 2949], [1944, 2921, 2097, 2958], [450, 2967, 562, 2995], [576, 2971, 606, 2995], [620, 2967, 695, 2995], [708, 2967, 792, 2995], [805, 2976, 845, 2995], [859, 2967, 916, 2995], [931, 2967, 1004, 2995], [1026, 2967, 1097, 2995], [1112, 2967, 1196, 2995], [1209, 2976, 1270, 2995], [1286, 2967, 1447, 3004], [1460, 2967, 1501, 3004], [1515, 2967, 1639, 2996], [1654, 2971, 1737, 3004], [1751, 2967, 1992, 2996], [2011, 2967, 2068, 2995], [2083, 2976, 2099, 2995], [450, 3014, 552, 3041], [565, 3013, 751, 3041], [763, 3013, 878, 3041], [451, 348, 680, 383], [474, 426, 515, 460], [454, 1652, 515, 1686], [454, 1758, 515, 1792], [454, 1818, 515, 1852], [454, 1924, 515, 1958], [454, 2029, 515, 2063], [454, 2135, 515, 2169], [454, 2287, 515, 2321], [454, 2392, 515, 2426], [454, 2498, 515, 2532], [454, 2604, 515, 2638], [454, 2710, 515, 2744], [454, 2815, 515, 2849], [454, 2921, 515, 2955], [540, 427, 647, 454], [659, 426, 770, 454], [783, 426, 840, 454], [852, 426, 984, 454], [994, 426, 1184, 463], [1202, 427, 1307, 454], [1321, 435, 1370, 454], [1381, 430, 1507, 460], [1522, 426, 1682, 463], [1696, 435, 1744, 454], [1756, 426, 1903, 454], [1921, 427, 2098, 463], [540, 472, 592, 509], [605, 472, 847, 509], [859, 472, 1077, 500], [1091, 472, 1122, 500], [1135, 472, 1279, 500], [1293, 481, 1390, 509], [1409, 473, 1442, 500], [1453, 472, 1658, 509], [1670, 472, 1708, 509], [1712, 473, 1856, 506], [1870, 472, 1959, 501], [540, 532, 612, 560], [630, 532, 749, 560], [786, 532, 884, 560], [903, 532, 939, 560], [953, 532, 1023, 560], [1041, 532, 1175, 560], [1193, 532, 1274, 560], [1292, 532, 1341, 560], [1358, 532, 1514, 569], [1533, 532, 1569, 560], [1584, 532, 1691, 560], [1727, 532, 1911, 561], [1928, 532, 1991, 561], [2006, 533, 2098, 560], [540, 577, 690, 611], [704, 577, 951, 611], [965, 577, 1054, 606], [541, 637, 672, 674], [685, 637, 777, 666], [789, 637, 846, 665], [860, 637, 991, 674], [1004, 637, 1136, 665], [1157, 637, 1342, 674], [1356, 637, 1505, 674], [1519, 637, 1576, 665], [1589, 637, 1808, 665], [1820, 637, 1937, 665], [1951, 637, 1987, 665], [1997, 646, 2098, 665], [540, 683, 599, 720], [619, 684, 652, 711], [663, 683, 867, 720], [880, 683, 918, 720], [919, 683, 1014, 711], [1023, 683, 1132, 720], [1144, 683, 1331, 720], [1343, 693, 1382, 711], [1397, 683, 1548, 719], [1559, 684, 1750, 711], [1765, 683, 1853, 711], [1855, 684, 1973, 717], [1987, 683, 2076, 712], [540, 743, 607, 771], [619, 743, 750, 777], [764, 743, 951, 771], [964, 743, 1142, 777], [1157, 743, 1214, 771], [1226, 743, 1357, 780], [1369, 743, 1467, 772], [1485, 743, 1712, 771], [1723, 743, 1916, 771], [1929, 743, 1976, 771], [1988, 752, 2004, 771], [2015, 752, 2098, 771], [539, 789, 703, 826], [716, 789, 935, 817], [949, 789, 1051, 817], [1064, 789, 1100, 817], [1111, 789, 1260, 826], [1283, 789, 1415, 817], [1426, 789, 1606, 826], [1622, 790, 1788, 826], [1798, 789, 1949, 825], [1965, 789, 2100, 818], [541, 835, 610, 869], [623, 835, 712, 864], [540, 896, 649, 924], [662, 895, 750, 924], [765, 895, 822, 923], [836, 895, 956, 923], [970, 896, 1089, 932], [1113, 895, 1238, 923], [1239, 895, 1443, 923], [1456, 895, 1497, 932], [1510, 895, 1729, 932], [1750, 895, 1877, 932], [1891, 895, 2032, 924], [2044, 904, 2099, 923], [540, 940, 576, 968], [589, 940, 813, 977], [828, 949, 961, 977], [991, 941, 1024, 968], [1039, 940, 1243, 977], [1259, 940, 1297, 977], [1302, 940, 1387, 974], [1403, 949, 1495, 977], [1512, 940, 1665, 974], [1683, 941, 1805, 977], [1823, 940, 1925, 969], [1940, 940, 2097, 977], [539, 987, 615, 1015], [627, 986, 716, 1015], [731, 986, 925, 1014], [937, 986, 985, 1014], [996, 986, 1241, 1023], [1253, 986, 1444, 1023], [540, 1046, 675, 1074], [692, 1046, 818, 1075], [854, 1046, 1098, 1075], [1115, 1046, 1242, 1083], [1260, 1046, 1397, 1074], [1416, 1046, 1464, 1074], [1479, 1046, 1591, 1074], [1609, 1046, 1733, 1075], [1750, 1046, 1877, 1074], [1905, 1046, 2023, 1083], [2042, 1046, 2099, 1074], [540, 1092, 740, 1129], [759, 1092, 831, 1120], [849, 1096, 1025, 1129], [1044, 1092, 1227, 1129], [1266, 1093, 1299, 1120], [1316, 1092, 1521, 1129], [1539, 1092, 1577, 1129], [1585, 1092, 1819, 1121], [1840, 1092, 2034, 1120], [2052, 1092, 2100, 1120], [540, 1137, 786, 1174], [798, 1137, 989, 1174], [1003, 1137, 1092, 1166], [1111, 1137, 1171, 1165], [1193, 1137, 1642, 1166], [540, 1199, 647, 1226], [663, 1198, 818, 1227], [834, 1198, 892, 1226], [906, 1199, 998, 1227], [1013, 1199, 1143, 1226], [1173, 1198, 1201, 1226], [1216, 1198, 1331, 1226], [1347, 1198, 1541, 1226], [1556, 1198, 1604, 1226], [1619, 1198, 1732, 1226], [1748, 1198, 1896, 1235], [1910, 1198, 2096, 1235], [540, 1244, 606, 1271], [606, 1243, 741, 1280], [752, 1243, 901, 1271], [915, 1243, 987, 1271], [999, 1243, 1153, 1271], [1164, 1243, 1306, 1280], [1325, 1244, 1358, 1271], [1369, 1243, 1574, 1280], [1586, 1243, 1624, 1280], [1628, 1243, 1735, 1277], [1749, 1243, 1838, 1272], [539, 1303, 617, 1332], [628, 1303, 737, 1337], [750, 1303, 824, 1331], [835, 1304, 948, 1337], [962, 1303, 1019, 1331], [1031, 1304, 1140, 1331], [1152, 1303, 1263, 1340], [1280, 1303, 1429, 1340], [1441, 1303, 1632, 1340], [1643, 1303, 1766, 1331], [1769, 1303, 1841, 1331], [1851, 1303, 1954, 1331], [1964, 1303, 2099, 1340], [541, 1349, 599, 1377], [609, 1349, 770, 1377], [780, 1349, 996, 1386], [1009, 1349, 1137, 1378], [1147, 1349, 1184, 1386], [1185, 1349, 1329, 1377], [1339, 1350, 1490, 1386], [1498, 1349, 1659, 1383], [1675, 1349, 1918, 1383], [1929, 1349, 1997, 1386], [2007, 1349, 2096, 1378], [540, 1395, 628, 1424], [645, 1395, 827, 1424], [540, 1455, 627, 1484], [645, 1456, 733, 1492], [752, 1455, 852, 1483], [867, 1456, 978, 1492], [996, 1455, 1057, 1484], [1073, 1455, 1293, 1489], [1311, 1455, 1478, 1484], [1494, 1456, 1609, 1489], [1627, 1455, 1741, 1483], [1757, 1456, 1840, 1489], [1859, 1455, 1924, 1483], [1940, 1455, 2097, 1489], [540, 1500, 661, 1528], [678, 1500, 835, 1534], [853, 1500, 1002, 1528], [1017, 1500, 1183, 1534], [1203, 1500, 1260, 1528], [1276, 1500, 1373, 1537], [1389, 1500, 1511, 1528], [1542, 1500, 1625, 1528], [1650, 1500, 1678, 1528], [1694, 1500, 1831, 1534], [1850, 1500, 2022, 1537], [2042, 1500, 2099, 1528], [540, 1546, 675, 1583], [693, 1546, 873, 1574], [890, 1546, 937, 1574], [955, 1546, 1129, 1574], [1147, 1546, 1205, 1574], [1223, 1546, 1421, 1574], [1439, 1546, 1613, 1574], [1631, 1546, 1757, 1574], [1795, 1547, 1828, 1574], [1845, 1546, 2050, 1583], [2068, 1546, 2106, 1583], [537, 1592, 622, 1626], [636, 1592, 725, 1621], [540, 1653, 576, 1680], [589, 1652, 648, 1680], [659, 1652, 716, 1680], [727, 1652, 755, 1681], [768, 1652, 857, 1680], [872, 1652, 900, 1680], [911, 1652, 1075, 1680], [1085, 1656, 1187, 1681], [1197, 1661, 1287, 1689], [1297, 1652, 1399, 1680], [1409, 1652, 1457, 1680], [1466, 1652, 1549, 1680], [1560, 1652, 1701, 1689], [1711, 1652, 1742, 1680], [1752, 1656, 1880, 1680], [1894, 1652, 2098, 1689], [540, 1698, 578, 1735], [582, 1699, 718, 1727], [720, 1698, 829, 1732], [539, 1759, 611, 1787], [626, 1758, 712, 1786], [732, 1758, 760, 1786], [773, 1758, 912, 1795], [926, 1758, 961, 1786], [971, 1758, 1123, 1795], [1135, 1758, 1240, 1795], [1256, 1758, 1396, 1787], [1420, 1758, 1655, 1792], [1673, 1758, 1758, 1787], [540, 1818, 667, 1846], [680, 1818, 881, 1847], [895, 1818, 952, 1846], [965, 1818, 1152, 1846], [1165, 1818, 1343, 1847], [1364, 1818, 1586, 1855], [1600, 1822, 1722, 1855], [1734, 1818, 1782, 1846], [1795, 1827, 1811, 1846], [1823, 1818, 2003, 1855], [2015, 1827, 2098, 1846], [539, 1863, 703, 1900], [715, 1863, 934, 1891], [946, 1863, 1048, 1891], [1060, 1863, 1095, 1891], [1105, 1863, 1254, 1900], [1273, 1864, 1306, 1891], [1317, 1863, 1521, 1900], [1534, 1863, 1572, 1900], [1576, 1864, 1720, 1897], [1733, 1863, 1822, 1892], [540, 1924, 613, 1952], [631, 1924, 792, 1961], [814, 1925, 906, 1961], [924, 1924, 1028, 1961], [1049, 1924, 1156, 1961], [1173, 1924, 1466, 1961], [1488, 1924, 1545, 1952], [1563, 1925, 1631, 1952], [1649, 1924, 1747, 1952], [1786, 1924, 1935, 1961], [1952, 1924, 2099, 1961], [540, 1969, 675, 1997], [689, 1969, 768, 1997], [780, 1969, 988, 2006], [1000, 1978, 1133, 2006], [1152, 1970, 1185, 1997], [1196, 1969, 1400, 2006], [1413, 1969, 1451, 2006], [1453, 1969, 1622, 1998], [1621, 1969, 1729, 2003], [540, 2029, 613, 2057], [630, 2029, 741, 2057], [759, 2030, 912, 2057], [930, 2029, 988, 2057], [1005, 2029, 1071, 2057], [1088, 2029, 1244, 2057], [1281, 2029, 1344, 2057], [1362, 2029, 1439, 2057], [1456, 2029, 1492, 2057], [1508, 2029, 1620, 2066], [1638, 2029, 1668, 2057], [1686, 2030, 1794, 2057], [1811, 2029, 1908, 2066], [1925, 2029, 2047, 2057], [2066, 2029, 2102, 2057], [540, 2075, 783, 2112], [796, 2075, 972, 2104], [991, 2076, 1024, 2103], [1035, 2075, 1240, 2112], [1252, 2075, 1290, 2112], [1292, 2075, 1377, 2109], [1391, 2075, 1480, 2104], [540, 2135, 599, 2163], [613, 2135, 838, 2163], [853, 2135, 910, 2163], [924, 2135, 990, 2163], [1004, 2135, 1160, 2163], [1187, 2136, 1349, 2163], [1363, 2135, 1587, 2164], [1602, 2135, 1704, 2163], [1718, 2135, 1867, 2163], [1883, 2135, 1930, 2163], [1944, 2135, 2099, 2163], [540, 2181, 823, 2218], [853, 2182, 886, 2209], [900, 2181, 1105, 2218], [1121, 2181, 1158, 2218], [1168, 2181, 1215, 2209], [1233, 2181, 1393, 2218], [1409, 2191, 1448, 2209], [1466, 2181, 1654, 2210], [1672, 2182, 1776, 2210], [1789, 2181, 1886, 2218], [1900, 2181, 2022, 2210], [2038, 2181, 2101, 2210], [541, 2226, 619, 2254], [631, 2226, 922, 2263], [936, 2226, 1025, 2255], [540, 2287, 711, 2315], [729, 2287, 926, 2321], [948, 2288, 1019, 2316], [1037, 2287, 1129, 2321], [1152, 2287, 1209, 2315], [1227, 2287, 1327, 2315], [1345, 2287, 1503, 2315], [1542, 2287, 1688, 2324], [1707, 2287, 1906, 2324], [1924, 2287, 2099, 2315], [539, 2332, 789, 2369], [802, 2332, 838, 2360], [847, 2332, 954, 2360], [973, 2333, 1006, 2360], [1017, 2332, 1222, 2369], [1234, 2332, 1272, 2369], [1279, 2332, 1436, 2366], [1450, 2332, 1539, 2361], [541, 2392, 685, 2421], [699, 2392, 800, 2429], [814, 2392, 893, 2420], [905, 2392, 1083, 2429], [1099, 2392, 1156, 2420], [1169, 2393, 1259, 2429], [1272, 2392, 1455, 2420], [1476, 2392, 1624, 2429], [1637, 2392, 1838, 2429], [1850, 2392, 1934, 2420], [1945, 2401, 2098, 2429], [540, 2438, 648, 2466], [660, 2438, 750, 2475], [763, 2447, 779, 2466], [790, 2438, 1011, 2475], [1025, 2438, 1231, 2466], [1250, 2439, 1283, 2466], [1294, 2439, 1380, 2475], [1392, 2439, 1544, 2475], [1558, 2438, 1717, 2475], [1731, 2444, 1762, 2466], [1771, 2438, 1868, 2472], [1882, 2438, 1971, 2467], [540, 2499, 647, 2526], [666, 2498, 812, 2532], [832, 2498, 891, 2526], [908, 2498, 1003, 2532], [1023, 2498, 1104, 2535], [1121, 2498, 1264, 2532], [1285, 2498, 1343, 2526], [1359, 2498, 1472, 2535], [1489, 2499, 1583, 2526], [1619, 2498, 1759, 2526], [1777, 2498, 1948, 2526], [1965, 2498, 2001, 2526], [2016, 2498, 2099, 2526], [539, 2544, 789, 2581], [802, 2544, 833, 2572], [845, 2548, 947, 2573], [959, 2553, 1056, 2581], [1078, 2544, 1182, 2578], [1196, 2544, 1285, 2573], [540, 2605, 647, 2632], [661, 2604, 807, 2638], [822, 2604, 910, 2639], [923, 2605, 954, 2632], [969, 2605, 1020, 2638], [1036, 2604, 1093, 2632], [1106, 2604, 1169, 2641], [1183, 2604, 1347, 2633], [1369, 2604, 1542, 2641], [1556, 2604, 1737, 2632], [1752, 2613, 1862, 2641], [1875, 2604, 2038, 2641], [2052, 2604, 2100, 2632], [540, 2650, 661, 2678], [663, 2650, 873, 2678], [894, 2650, 998, 2684], [1012, 2650, 1101, 2679], [540, 2709, 647, 2738], [662, 2710, 809, 2744], [825, 2710, 936, 2738], [950, 2709, 1091, 2744], [1107, 2709, 1206, 2738], [1221, 2711, 1341, 2747], [1356, 2711, 1410, 2739], [1425, 2700, 1593, 2747], [1610, 2710, 1667, 2738], [1683, 2710, 1810, 2747], [1824, 2710, 2015, 2747], [2041, 2711, 2098, 2738], [540, 2759, 656, 2783], [668, 2755, 771, 2783], [782, 2755, 917, 2783], [927, 2755, 1021, 2783], [1033, 2755, 1182, 2792], [1194, 2755, 1303, 2783], [1323, 2756, 1356, 2783], [1367, 2755, 1571, 2792], [1584, 2755, 1621, 2792], [1625, 2755, 1897, 2784], [1897, 2755, 2006, 2789], [539, 2815, 603, 2844], [615, 2815, 754, 2843], [769, 2815, 826, 2843], [841, 2815, 962, 2843], [976, 2816, 1095, 2852], [1123, 2815, 1337, 2843], [1351, 2815, 1468, 2843], [1484, 2815, 1520, 2843], [1533, 2815, 1677, 2843], [1692, 2815, 1904, 2852], [1931, 2816, 1964, 2843], [1978, 2816, 2011, 2843], [2025, 2816, 2098, 2843], [540, 2861, 684, 2898], [696, 2861, 734, 2898], [736, 2861, 821, 2895], [834, 2861, 923, 2890], [540, 2922, 576, 2949], [592, 2922, 664, 2958], [688, 2921, 852, 2950], [866, 2921, 981, 2958], [994, 2921, 1142, 2958], [1156, 2921, 1345, 2958], [1364, 2921, 1571, 2958], [1586, 2921, 1616, 2949], [1630, 2921, 1713, 2949], [1726, 2921, 1868, 2958], [1890, 2922, 1981, 2949], [1995, 2922, 2098, 2950], [540, 2968, 658, 2996], [670, 2977, 709, 2995], [719, 2967, 919, 3001], [933, 2967, 1166, 3002], [1178, 2968, 1253, 2996], [1264, 2967, 1353, 2996], [1371, 2967, 1459, 2996], [1475, 2967, 1656, 2996], [1674, 2967, 1734, 2995], [1755, 2967, 2096, 2996], [541, 3013, 671, 3042], [454, 354, 515, 388], [454, 462, 515, 496], [454, 616, 515, 650], [454, 769, 515, 803], [454, 877, 515, 911], [454, 985, 515, 1019], [454, 1139, 515, 1173], [540, 354, 568, 382], [581, 355, 603, 382], [616, 354, 720, 383], [732, 354, 878, 388], [893, 355, 928, 382], [940, 354, 1061, 391], [1074, 354, 1196, 388], [1210, 355, 1234, 382], [1249, 354, 1428, 388], [1442, 354, 1534, 382], [1548, 354, 1673, 391], [1688, 354, 1746, 382], [1758, 354, 1874, 382], [1888, 354, 1973, 383], [1994, 354, 2098, 382], [540, 400, 654, 437], [666, 400, 743, 437], [755, 400, 897, 437], [916, 401, 949, 428], [960, 401, 1046, 437], [1058, 401, 1210, 437], [1224, 400, 1383, 437], [1397, 406, 1428, 428], [1437, 400, 1534, 434], [1548, 400, 1637, 429], [540, 462, 670, 490], [684, 462, 804, 496], [817, 462, 930, 499], [943, 462, 1139, 499], [1154, 462, 1221, 490], [1234, 463, 1270, 490], [1286, 463, 1404, 499], [1418, 462, 1549, 490], [1562, 463, 1593, 490], [1608, 463, 1666, 499], [1682, 462, 1739, 490], [1752, 462, 1947, 499], [1959, 463, 1995, 490], [2011, 463, 2098, 490], [540, 508, 620, 545], [646, 508, 920, 545], [933, 508, 1083, 537], [1097, 508, 1312, 536], [1328, 508, 1375, 536], [1387, 508, 1555, 545], [1569, 508, 1728, 536], [1742, 508, 1955, 536], [1980, 509, 2012, 536], [2025, 509, 2098, 536], [540, 553, 684, 590], [696, 553, 734, 590], [738, 554, 882, 587], [896, 553, 985, 582], [540, 616, 670, 644], [683, 616, 802, 650], [816, 616, 918, 653], [929, 616, 1037, 650], [1050, 616, 1245, 653], [1256, 617, 1292, 644], [1306, 616, 1463, 653], [1478, 616, 1535, 644], [1547, 616, 1677, 644], [1689, 617, 1720, 644], [1734, 617, 1791, 653], [1810, 616, 1961, 645], [1974, 625, 2098, 653], [541, 661, 705, 698], [719, 661, 846, 698], [859, 661, 1010, 690], [1023, 661, 1248, 690], [1262, 670, 1375, 698], [1401, 662, 1434, 689], [1447, 661, 1652, 698], [1666, 661, 1704, 698], [1710, 661, 1982, 690], [1984, 670, 2097, 698], [544, 707, 734, 741], [748, 707, 837, 736], [540, 769, 640, 797], [656, 769, 823, 798], [838, 769, 896, 797], [911, 769, 1024, 797], [1040, 769, 1282, 798], [1310, 769, 1505, 797], [1519, 769, 1654, 806], [1669, 769, 1741, 797], [1756, 769, 1832, 806], [1846, 769, 2021, 797], [2036, 778, 2098, 797], [540, 815, 652, 843], [672, 816, 705, 843], [716, 815, 920, 852], [933, 815, 971, 852], [973, 815, 1069, 844], [1084, 815, 1173, 844], [540, 878, 565, 905], [582, 878, 618, 905], [636, 878, 752, 914], [767, 877, 825, 905], [840, 878, 864, 905], [882, 877, 991, 905], [1019, 878, 1108, 905], [1122, 877, 1286, 914], [1300, 881, 1331, 905], [1346, 877, 1496, 914], [1519, 878, 1626, 905], [1641, 886, 1731, 914], [1746, 877, 1862, 905], [1879, 877, 1914, 905], [1927, 877, 2096, 905], [539, 923, 667, 952], [679, 923, 717, 960], [719, 923, 868, 960], [879, 923, 1073, 960], [1083, 923, 1245, 957], [1260, 923, 1512, 958], [1526, 923, 1615, 952], [540, 985, 642, 1013], [653, 985, 689, 1020], [703, 985, 894, 1022], [905, 985, 962, 1013], [974, 986, 1135, 1013], [1146, 986, 1182, 1013], [1196, 985, 1275, 1014], [1292, 985, 1436, 1013], [1447, 985, 1550, 1013], [1562, 985, 1696, 1022], [1708, 985, 1755, 1013], [1765, 985, 1846, 1022], [1857, 985, 1972, 1022], [1983, 989, 2099, 1013], [540, 1031, 672, 1068], [673, 1031, 920, 1059], [935, 1031, 1063, 1060], [1073, 1031, 1111, 1068], [1113, 1031, 1257, 1059], [1268, 1032, 1419, 1068], [1428, 1031, 1589, 1065], [1606, 1031, 1807, 1065], [1819, 1032, 1895, 1060], [1905, 1031, 1994, 1060], [2011, 1031, 2099, 1060], [544, 1076, 726, 1105], [540, 1139, 611, 1167], [626, 1140, 656, 1167], [672, 1140, 747, 1173], [764, 1139, 894, 1167], [910, 1139, 1029, 1173], [1046, 1139, 1155, 1167], [1170, 1139, 1235, 1173], [1253, 1139, 1310, 1167], [1325, 1139, 1520, 1176], [1534, 1140, 1570, 1167], [1587, 1139, 1743, 1176], [1771, 1139, 1924, 1176], [1938, 1139, 2021, 1167], [2036, 1148, 2098, 1167], [539, 1184, 687, 1221], [701, 1184, 748, 1212], [758, 1184, 974, 1221], [987, 1184, 1107, 1212], [1109, 1184, 1319, 1212], [1338, 1185, 1371, 1212], [1382, 1184, 1587, 1221], [1599, 1184, 1637, 1221], [1641, 1185, 1785, 1218], [1799, 1184, 1888, 1213]], "scores": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "structures": {"pages": {"version": "1.0", "structure_value": [[0, 437], [437, 1156], [1156, 1746], [1746, 2141], [2141, 2701], [2701, 3096], [3096, 3554], [3554, 4058], [4058, 4232]], "positions": [[0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300]]}, "lines": {"version": "1.0", "structure_value": [[0, 4], [4, 6], [6, 12], [12, 16], [16, 19], [19, 23], [23, 25], [25, 26], [26, 37], [37, 48], [48, 59], [59, 68], [68, 80], [80, 91], [91, 105], [105, 115], [115, 127], [127, 139], [139, 152], [152, 164], [164, 175], [175, 188], [188, 200], [200, 211], [211, 213], [213, 215], [215, 229], [229, 241], [241, 254], [254, 268], [268, 285], [285, 301], [301, 314], [314, 321], [321, 333], [333, 347], [347, 364], [364, 381], [381, 398], [398, 411], [411, 425], [425, 437], [437, 452], [452, 465], [465, 482], [482, 498], [498, 510], [510, 526], [526, 541], [541, 559], [559, 576], [576, 594], [594, 608], [608, 614], [614, 620], [620, 635], [635, 653], [653, 673], [673, 689], [689, 698], [698, 713], [713, 728], [728, 743], [743, 759], [759, 774], [774, 788], [788, 801], [801, 809], [809, 821], [821, 836], [836, 852], [852, 866], [866, 879], [879, 893], [893, 906], [906, 918], [918, 933], [933, 947], [947, 958], [958, 966], [966, 969], [969, 983], [983, 997], [997, 1011], [1011, 1025], [1025, 1040], [1040, 1052], [1052, 1069], [1069, 1083], [1083, 1099], [1099, 1115], [1115, 1130], [1130, 1144], [1144, 1156], [1156, 1173], [1173, 1189], [1189, 1204], [1204, 1218], [1218, 1222], [1222, 1239], [1239, 1255], [1255, 1274], [1274, 1284], [1284, 1287], [1287, 1301], [1301, 1317], [1317, 1331], [1331, 1347], [1347, 1362], [1362, 1378], [1378, 1391], [1391, 1408], [1408, 1422], [1422, 1425], [1425, 1439], [1439, 1451], [1451, 1469], [1469, 1487], [1487, 1494], [1494, 1503], [1503, 1518], [1518, 1522], [1522, 1535], [1535, 1550], [1550, 1567], [1567, 1584], [1584, 1599], [1599, 1605], [1605, 1625], [1625, 1640], [1640, 1655], [1655, 1672], [1672, 1680], [1680, 1681], [1681, 1686], [1686, 1687], [1687, 1703], [1703, 1718], [1718, 1733], [1733, 1746], [1746, 1753], [1753, 1757], [1757, 1773], [1773, 1790], [1790, 1804], [1804, 1818], [1818, 1835], [1835, 1852], [1852, 1872], [1872, 1886], [1886, 1889], [1889, 1893], [1893, 1896], [1896, 1914], [1914, 1928], [1928, 1947], [1947, 1959], [1959, 1975], [1975, 1992], [1992, 2009], [2009, 2015], [2015, 2016], [2016, 2023], [2023, 2030], [2030, 2047], [2047, 2061], [2061, 2075], [2075, 2091], [2091, 2106], [2106, 2122], [2122, 2127], [2127, 2141], [2141, 2156], [2156, 2162], [2162, 2163], [2163, 2164], [2164, 2177], [2177, 2179], [2179, 2182], [2182, 2197], [2197, 2212], [2212, 2225], [2225, 2237], [2237, 2247], [2247, 2249], [2249, 2253], [2253, 2268], [2268, 2282], [2282, 2297], [2297, 2312], [2312, 2324], [2324, 2340], [2340, 2356], [2356, 2372], [2372, 2380], [2380, 2396], [2396, 2410], [2410, 2424], [2424, 2441], [2441, 2451], [2451, 2466], [2466, 2482], [2482, 2495], [2495, 2512], [2512, 2525], [2525, 2542], [2542, 2543], [2543, 2547], [2547, 2560], [2560, 2575], [2575, 2588], [2588, 2602], [2602, 2617], [2617, 2624], [2624, 2640], [2640, 2655], [2655, 2670], [2670, 2672], [2672, 2673], [2673, 2688], [2688, 2701], [2701, 2704], [2704, 2708], [2708, 2711], [2711, 2714], [2714, 2717], [2717, 2720], [2720, 2723], [2723, 2737], [2737, 2746], [2746, 2759], [2759, 2775], [2775, 2779], [2779, 2782], [2782, 2795], [2795, 2801], [2801, 2817], [2817, 2833], [2833, 2849], [2849, 2855], [2855, 2870], [2870, 2884], [2884, 2900], [2900, 2918], [2918, 2933], [2933, 2948], [2948, 2963], [2963, 2977], [2977, 2981], [2981, 2983], [2983, 2997], [2997, 3011], [3011, 3028], [3028, 3037], [3037, 3055], [3055, 3068], [3068, 3083], [3083, 3096], [3096, 3099], [3099, 3101], [3101, 3102], [3102, 3106], [3106, 3109], [3109, 3113], [3113, 3118], [3118, 3122], [3122, 3124], [3124, 3129], [3129, 3131], [3131, 3148], [3148, 3165], [3165, 3178], [3178, 3197], [3197, 3205], [3205, 3207], [3207, 3221], [3221, 3234], [3234, 3250], [3250, 3262], [3262, 3278], [3278, 3290], [3290, 3304], [3304, 3309], [3309, 3324], [3324, 3337], [3337, 3352], [3352, 3364], [3364, 3380], [3380, 3397], [3397, 3413], [3413, 3416], [3416, 3435], [3435, 3450], [3450, 3463], [3463, 3478], [3478, 3495], [3495, 3505], [3505, 3506], [3506, 3521], [3521, 3534], [3534, 3551], [3551, 3554], [3554, 3555], [3555, 3556], [3556, 3557], [3557, 3558], [3558, 3559], [3559, 3560], [3560, 3561], [3561, 3562], [3562, 3563], [3563, 3564], [3564, 3565], [3565, 3566], [3566, 3567], [3567, 3568], [3568, 3569], [3569, 3581], [3581, 3592], [3592, 3606], [3606, 3609], [3609, 3621], [3621, 3634], [3634, 3646], [3646, 3656], [3656, 3658], [3658, 3670], [3670, 3682], [3682, 3688], [3688, 3699], [3699, 3709], [3709, 3714], [3714, 3726], [3726, 3737], [3737, 3750], [3750, 3761], [3761, 3763], [3763, 3775], [3775, 3787], [3787, 3798], [3798, 3800], [3800, 3816], [3816, 3819], [3819, 3829], [3829, 3840], [3840, 3850], [3850, 3861], [3861, 3870], [3870, 3885], [3885, 3892], [3892, 3903], [3903, 3915], [3915, 3918], [3918, 3928], [3928, 3936], [3936, 3947], [3947, 3959], [3959, 3972], [3972, 3978], [3978, 3991], [3991, 3995], [3995, 4007], [4007, 4018], [4018, 4031], [4031, 4035], [4035, 4047], [4047, 4057], [4057, 4058], [4058, 4059], [4059, 4060], [4060, 4061], [4061, 4062], [4062, 4063], [4063, 4064], [4064, 4065], [4065, 4080], [4080, 4090], [4090, 4104], [4104, 4114], [4114, 4118], [4118, 4131], [4131, 4141], [4141, 4143], [4143, 4154], [4154, 4160], [4160, 4175], [4175, 4182], [4182, 4196], [4196, 4207], [4207, 4208], [4208, 4222], [4222, 4232]], "positions": [[519, 463, 2031, 527], [1018, 545, 1532, 610], [914, 798, 1635, 828], [997, 845, 1552, 882], [1101, 890, 1448, 927], [1080, 936, 1470, 971], [709, 979, 1840, 1020], [1182, 1148, 1367, 1183], [600, 1272, 1950, 1309], [599, 1318, 1949, 1355], [599, 1363, 1948, 1400], [600, 1409, 1949, 1446], [599, 1455, 1949, 1492], [599, 1500, 1948, 1537], [600, 1546, 1950, 1583], [601, 1592, 1947, 1629], [600, 1637, 1949, 1674], [599, 1683, 1948, 1720], [600, 1729, 1949, 1766], [600, 1774, 1948, 1811], [600, 1820, 1950, 1857], [600, 1866, 1950, 1903], [600, 1911, 1948, 1948], [600, 1957, 1950, 1994], [600, 2003, 757, 2031], [452, 2182, 794, 2217], [450, 2303, 2098, 2340], [450, 2348, 2099, 2385], [450, 2394, 2099, 2431], [451, 2440, 2098, 2477], [449, 2485, 2096, 2522], [450, 2531, 2097, 2568], [450, 2577, 2098, 2614], [449, 2622, 1083, 2656], [450, 2693, 2099, 2730], [450, 2739, 2099, 2776], [450, 2784, 2099, 2821], [450, 2830, 2099, 2867], [450, 2876, 2099, 2913], [450, 2921, 2098, 2958], [451, 2967, 2099, 3004], [449, 3013, 1853, 3050], [451, 354, 2099, 391], [452, 400, 2098, 437], [450, 445, 2099, 482], [451, 491, 2099, 528], [451, 537, 2099, 574], [452, 582, 2098, 619], [451, 628, 2099, 665], [451, 674, 2098, 711], [451, 719, 2096, 756], [451, 765, 2099, 802], [450, 811, 2099, 848], [451, 856, 1023, 893], [451, 989, 1537, 1033], [451, 1104, 2098, 1141], [451, 1150, 2099, 1187], [451, 1195, 2098, 1232], [450, 1241, 2099, 1278], [450, 1287, 1502, 1324], [451, 1357, 2099, 1394], [451, 1403, 2097, 1440], [451, 1449, 2099, 1486], [451, 1494, 2099, 1531], [452, 1540, 2099, 1577], [451, 1586, 2102, 1623], [450, 1631, 2099, 1668], [451, 1677, 1531, 1714], [451, 1748, 2099, 1785], [451, 1793, 2102, 1830], [451, 1839, 2098, 1876], [451, 1884, 2099, 1921], [451, 1930, 2099, 1967], [452, 1976, 2098, 2013], [451, 2021, 2098, 2058], [451, 2067, 2099, 2104], [452, 2113, 2099, 2150], [452, 2158, 2099, 2195], [451, 2204, 2099, 2238], [450, 2250, 1486, 2284], [451, 2371, 995, 2409], [451, 2465, 2100, 2502], [452, 2510, 2099, 2547], [451, 2556, 2100, 2593], [452, 2602, 2099, 2639], [450, 2647, 2096, 2684], [454, 2693, 2097, 2730], [452, 2739, 2097, 2776], [451, 2784, 2099, 2821], [451, 2830, 2099, 2867], [451, 2876, 2099, 2913], [0, 0, 2550, 3300], [450, 2967, 2099, 3004], [452, 3013, 1694, 3050], [451, 354, 2098, 391], [451, 400, 2099, 437], [451, 445, 2097, 482], [450, 491, 2099, 528], [452, 537, 935, 574], [452, 607, 2099, 644], [451, 653, 2099, 690], [451, 699, 2099, 736], [451, 744, 1332, 781], [451, 860, 918, 904], [451, 966, 2096, 1003], [451, 1011, 2100, 1048], [451, 1057, 2097, 1094], [451, 1103, 2096, 1140], [451, 1173, 2098, 1210], [451, 1219, 2099, 1256], [451, 1265, 2099, 1302], [452, 1310, 2099, 1347], [450, 1356, 1922, 1393], [451, 1461, 825, 1499], [451, 1548, 2099, 1585], [450, 1594, 2099, 1631], [451, 1638, 2099, 1676], [452, 1683, 2097, 1724], [454, 1728, 1089, 1770], [1020, 1805, 2098, 1855], [451, 1892, 2002, 1930], [451, 1998, 890, 2028], [451, 2085, 2097, 2122], [451, 2123, 1923, 2167], [451, 2201, 2098, 2238], [450, 2247, 2097, 2284], [451, 2292, 1906, 2329], [1073, 2365, 2098, 2406], [451, 2445, 2098, 2490], [451, 2498, 2098, 2535], [451, 2543, 2098, 2580], [450, 2589, 2099, 2626], [452, 2635, 1395, 2672], [1309, 2710, 1339, 2739], [1155, 2748, 2098, 2806], [1298, 2818, 1349, 2838], [451, 2876, 2097, 2913], [451, 2921, 2100, 2958], [451, 2967, 2098, 3004], [451, 3013, 2051, 3050], [812, 1059, 1736, 1101], [897, 1125, 1651, 1148], [451, 1215, 2099, 1253], [451, 1262, 2098, 1299], [451, 1308, 2099, 1345], [450, 1353, 2077, 1390], [451, 1530, 2100, 1567], [451, 1575, 2097, 1613], [451, 1620, 2099, 1658], [451, 1666, 2099, 1704], [452, 1712, 753, 1751], [985, 1806, 2098, 1864], [1218, 1875, 1374, 1906], [451, 1986, 2096, 2023], [451, 2032, 2098, 2069], [451, 2077, 2099, 2114], [450, 2122, 1511, 2160], [450, 2194, 2099, 2231], [450, 2239, 2098, 2276], [450, 2284, 2099, 2323], [446, 2328, 1196, 2369], [1405, 2420, 1425, 2450], [1011, 2441, 2098, 2505], [451, 2557, 1184, 2598], [451, 2627, 2099, 2668], [451, 2676, 2098, 2713], [451, 2721, 2099, 2758], [451, 2764, 2098, 2805], [451, 2812, 2097, 2850], [451, 2858, 2100, 2895], [452, 2904, 782, 2941], [855, 2994, 2098, 3040], [451, 351, 2099, 392], [451, 400, 1035, 429], [1204, 464, 1218, 484], [1599, 479, 1619, 509], [818, 463, 2098, 588], [980, 565, 1236, 595], [451, 662, 829, 700], [451, 748, 2097, 785], [452, 794, 2099, 831], [451, 839, 2099, 876], [452, 885, 2099, 922], [452, 931, 1390, 968], [451, 1045, 794, 1089], [451, 1148, 919, 1178], [451, 1235, 2102, 1272], [450, 1280, 2099, 1317], [451, 1326, 2097, 1363], [451, 1372, 2099, 1409], [452, 1416, 2099, 1454], [451, 1463, 2099, 1500], [451, 1501, 2097, 1545], [450, 1547, 2099, 1591], [452, 1600, 1298, 1637], [451, 1670, 2102, 1707], [451, 1716, 2099, 1753], [451, 1762, 2097, 1799], [450, 1807, 2096, 1844], [451, 1853, 1751, 1890], [451, 1924, 2098, 1961], [451, 1969, 2099, 2006], [451, 2015, 1878, 2052], [451, 2085, 2098, 2122], [451, 2131, 2097, 2168], [451, 2177, 2100, 2214], [451, 2215, 704, 2259], [451, 2325, 1235, 2363], [451, 2412, 2099, 2449], [451, 2458, 2100, 2495], [451, 2503, 2098, 2540], [451, 2549, 2099, 2586], [451, 2594, 2099, 2631], [450, 2640, 1540, 2677], [451, 2711, 2097, 2748], [450, 2756, 2100, 2793], [451, 2802, 2099, 2839], [506, 2877, 1207, 2915], [503, 2921, 1209, 2961], [503, 2966, 2100, 3007], [451, 3015, 2029, 3048], [962, 345, 1587, 373], [962, 392, 1551, 429], [962, 438, 1552, 467], [962, 483, 1553, 512], [962, 529, 1549, 558], [963, 576, 1553, 605], [963, 621, 1553, 651], [450, 709, 2096, 746], [450, 755, 2097, 792], [449, 800, 2099, 837], [451, 846, 2099, 883], [450, 892, 820, 926], [464, 1022, 501, 1487], [0, 0, 2550, 3300], [724, 1579, 1896, 1616], [560, 1673, 1981, 1710], [451, 1790, 2099, 1827], [451, 1836, 2099, 1873], [451, 1882, 956, 1919], [451, 2036, 2099, 2074], [452, 2082, 1943, 2119], [451, 2153, 2099, 2190], [451, 2199, 2099, 2236], [455, 2244, 2097, 2281], [452, 2290, 1800, 2327], [451, 2361, 2097, 2398], [451, 2406, 2099, 2443], [452, 2452, 854, 2489], [451, 2574, 773, 2604], [451, 2668, 2099, 2705], [450, 2714, 2099, 2751], [452, 2759, 2099, 2796], [451, 2805, 1294, 2842], [451, 2876, 2102, 2913], [450, 2921, 2099, 2958], [452, 2967, 2099, 3004], [451, 3013, 1978, 3050], [541, 436, 1950, 469], [511, 466, 1676, 545], [1396, 519, 1446, 552], [645, 551, 1640, 603], [782, 602, 1985, 645], [840, 613, 1995, 664], [1074, 667, 1888, 698], [699, 668, 1908, 751], [621, 750, 1804, 798], [727, 797, 1813, 854], [991, 824, 1876, 888], [451, 986, 2099, 1023], [451, 1031, 2099, 1068], [451, 1077, 2097, 1114], [450, 1123, 2099, 1160], [451, 1168, 1239, 1205], [451, 1363, 780, 1398], [451, 1510, 2098, 1547], [451, 1556, 2099, 1593], [451, 1601, 2099, 1638], [451, 1647, 2099, 1684], [451, 1693, 2097, 1730], [451, 1738, 2099, 1775], [452, 1784, 2097, 1821], [451, 1830, 977, 1867], [451, 1900, 2098, 1937], [451, 1946, 2099, 1983], [450, 1992, 2099, 2029], [451, 2037, 2067, 2074], [451, 2108, 2099, 2145], [452, 2154, 2099, 2191], [450, 2199, 2099, 2236], [452, 2245, 810, 2282], [451, 2315, 2098, 2352], [451, 2361, 2099, 2398], [451, 2407, 2100, 2444], [451, 2452, 2099, 2489], [451, 2498, 2100, 2535], [451, 2544, 1879, 2581], [450, 2729, 860, 2773], [451, 2876, 2097, 2913], [452, 2921, 2097, 2958], [450, 2967, 2099, 3004], [450, 3013, 878, 3041], [451, 348, 680, 383], [474, 426, 515, 460], [454, 1652, 515, 1686], [454, 1758, 515, 1792], [454, 1818, 515, 1852], [454, 1924, 515, 1958], [454, 2029, 515, 2063], [454, 2135, 515, 2169], [454, 2287, 515, 2321], [454, 2392, 515, 2426], [454, 2498, 515, 2532], [454, 2604, 515, 2638], [454, 2710, 515, 2744], [454, 2815, 515, 2849], [454, 2921, 515, 2955], [540, 426, 2098, 463], [540, 472, 1959, 509], [540, 532, 2098, 569], [540, 577, 1054, 611], [541, 637, 2098, 674], [540, 683, 2076, 720], [540, 743, 2098, 780], [539, 789, 2100, 826], [541, 835, 712, 869], [540, 895, 2099, 932], [540, 940, 2097, 977], [539, 986, 1444, 1023], [540, 1046, 2099, 1083], [540, 1092, 2100, 1129], [540, 1137, 1642, 1174], [540, 1198, 2096, 1235], [540, 1243, 1838, 1280], [539, 1303, 2099, 1340], [541, 1349, 2096, 1386], [540, 1395, 827, 1424], [540, 1455, 2097, 1492], [540, 1500, 2099, 1537], [540, 1546, 2106, 1583], [537, 1592, 725, 1626], [540, 1652, 2098, 1689], [540, 1698, 829, 1735], [539, 1758, 1758, 1795], [540, 1818, 2098, 1855], [539, 1863, 1822, 1900], [540, 1924, 2099, 1961], [540, 1969, 1729, 2006], [540, 2029, 2102, 2066], [540, 2075, 1480, 2112], [540, 2135, 2099, 2164], [540, 2181, 2101, 2218], [541, 2226, 1025, 2263], [540, 2287, 2099, 2324], [539, 2332, 1539, 2369], [541, 2392, 2098, 2429], [540, 2438, 1971, 2475], [540, 2498, 2099, 2535], [539, 2544, 1285, 2581], [540, 2604, 2100, 2641], [540, 2650, 1101, 2684], [540, 2700, 2098, 2747], [540, 2755, 2006, 2792], [539, 2815, 2098, 2852], [540, 2861, 923, 2898], [540, 2921, 2098, 2958], [540, 2967, 2096, 3002], [541, 3013, 671, 3042], [454, 354, 515, 388], [454, 462, 515, 496], [454, 616, 515, 650], [454, 769, 515, 803], [454, 877, 515, 911], [454, 985, 515, 1019], [454, 1139, 515, 1173], [540, 354, 2098, 391], [540, 400, 1637, 437], [540, 462, 2098, 499], [540, 508, 2098, 545], [540, 553, 985, 590], [540, 616, 2098, 653], [541, 661, 2097, 698], [544, 707, 837, 741], [540, 769, 2098, 806], [540, 815, 1173, 852], [540, 877, 2096, 914], [539, 923, 1615, 960], [540, 985, 2099, 1022], [540, 1031, 2099, 1068], [544, 1076, 726, 1105], [540, 1139, 2098, 1176], [539, 1184, 1888, 1221]]}}}}]}
{"name": "1406.2199v2", "contents": [{"tool_name": "djvu", "text": "Two-Stream Convolutional Networks for Action Recognition in Videos Karen Simonyan Andrew Zisserman Visual Geometry Group, University of Oxford {karen,az}@robots.ox.ac.uk Abstract We investigate architectures of discriminatively trained deep Convolutional Net- works (ConvNets) for action recognition in video. The challenge is to capture the complementary information on appearance from still frames and motion be- tween frames. We also aim to generalise the best performing hand-crafted features within a data-driven learning framework. Our contribution is three-fold. First, we propose a two-stream ConvNet architec- ture which incorporates spatial and temporal networks. Second, we demonstrate that a ConvNet trained on multi-frame dense optical flow is able to achieve very good performance in spite of limited training data. Finally, we show that multi- task learning, applied to two different action classification datasets, can be used to increase the amount of training data and improve the performance on both. Our architecture is trained and evaluated on the standard video actions bench- marks of UCF-101 and HMDB-51, where it is competitive with the state of the art. It also exceeds by a large margin previous attempts to use deep nets for video classification. 1 Introduction Recognition of human actions in videos is a challenging task which has received a significant amount of attention in the research community [11, 14, 17, 26]. Compared to still image classification, the temporal component of videos provides an additional (and important) clue for recognition, as a number of actions can be reliably recognised based on the motion information. Additionally, video provides natural data augmentation (jittering) for single image (video frame) classification. In this work, we aim at extending deep Convolutional Networks (ConvNets) [19], a state-of-the- art still image representation [15], to action recognition in video data. This task has recently been addressed in [14] by using stacked video frames as input to the network, but the results were signif- icantly worse than those of the best hand-crafted shallow representations [20, 26]. We investigate a different architecture based on two separate recognition streams (spatial and temporal), which are then combined by late fusion. The spatial stream performs action recognition from still video frames, whilst the temporal stream is trained to recognise action from motion in the form of dense optical flow. Both streams are implemented as ConvNets. Decoupling the spatial and temporal nets also allows us to exploit the availability of large amounts of annotated image data by pre-training the spatial net on the ImageNet challenge dataset [1]. Our proposed architecture is related to the two-streams hypothesis [9], according to which the human visual cortex contains two pathways: the ventral stream (which performs object recognition) and the dorsal stream (which recognises motion); though we do not investigate this connection any further here. The rest of the paper is organised as follows. In Sect. 1 .1 we review the related work on action recognition using both shallow and deep architectures. In Sect. 2 we introduce the two-stream architecture and specify the Spatial ConvNet. Sect. 3 introduces the Temporal ConvNet and in particular how it generalizes the previous architectures reviewed in Sect. 1 .1 . A mult-task learning framework is developed in Sect. 4 in order to allow effortless combination of training data over 1 a r X i v : 1 4 0 6 . 2 1 9 9 v 2 [ c s . C V ] 1 2 N o v 2 0 1 4 multiple datasets. Implementation details are given in Sect. 5, and the performance is evaluated in Sect. 6 and compared to the state of the art. Our experiments on two challenging datasets (UCF- 101 [24] and HMDB-51 [16]) show that the two recognition streams are complementary, and our deep architecture significantly outperforms that of [14] and is competitive with the state of the art shallow representations [20, 21, 26] in spite of being trained on relatively small datasets. 1.1 Related work Video recognition research has been largely driven by the advances in image recognition methods, which were often adapted and extended to deal with video data. A large family of video action recognition methods is based on shallow high-dimensional encodings of local spatio-temporal fea- tures. For instance, the algorithm of [17] consists in detecting sparse spatio-temporal interest points, which are then described using local spatio-temporal features: Histogram of Oriented Gradients (HOG) [7] and Histogram of Optical Flow (HOF). The features are then encoded into the Bag Of Features (BoF) representation, which is pooled over several spatio-temporal grids (similarly to spa- tial pyramid pooling) and combined with an SVM classifier. In a later work [28], it was shown that dense sampling of local features outperforms sparse interest points. Instead of computing local video features over spatio-temporal cuboids, state-of-the-art shallow video representations [20, 21, 26] make use of dense point trajectories. The approach, first in- troduced in [29], consists in adjusting local descriptor support regions, so that they follow dense trajectories, computed using optical flow. The best performance in the trajectory-based pipeline was achieved by the Motion Boundary Histogram (MBH) [8], which is a gradient-based feature, separately computed on the horizontal and vertical components of optical flow. A combination of several features was shown to further boost the accuracy. Recent improvements of trajectory-based hand-crafted representations include compensation of global (camera) motion [10, 16, 26], and the use of the Fisher vector encoding [22] (in [26]) or its deeper variant [23] (in [21]). There has also been a number of attempts to develop a deep architecture for video recognition. In the majority of these works, the input to the network is a stack of consecutive video frames, so the model is expected to implicitly learn spatio-temporal motion-dependent features in the first layers, which can be a difficult task. In [11], an HMAX architecture for video recognition was proposed with pre-defined spatio-temporal filters in the first layer. Later, it was combined [16] with a spatial HMAX model, thus forming spatial (ventral-like) and temporal (dorsal-like) recognition streams. Unlike our work, however, the streams were implemented as hand-crafted and rather shallow (3- layer) HMAX models. In [4, 18, 25], a convolutional RBM and ISA were used for unsupervised learning of spatio-temporal features, which were then plugged into a discriminative model for action classification. Discriminative end-to-end learning of video ConvNets has been addressed in [12] and, more recently, in [14], who compared several ConvNet architectures for action recognition. Training was carried out on a very large Sports-1M dataset, comprising 1.1M YouTube videos of sports activities. Interestingly, [14] found that a network, operating on individual video frames, performs similarly to the networks, whose input is a stack of frames. This might indicate that the learnt spatio-temporal features do not capture the motion well. The learnt representation, fine- tuned on the UCF-101 dataset, turned out to be 20% less accurate than hand-crafted state-of-the-art trajectory-based representation [20, 27]. Our temporal stream ConvNet operates on multiple-frame dense optical flow, which is typically computed in an energy minimisation framework by solving for a displacement field (typically at multiple image scales). We used a popular method of [2], which formulates the energy based on constancy assumptions for intensity and its gradient, as well as smoothness of the displacement field. Recently, [30] proposed an image patch matching scheme, which is reminiscent of deep ConvNets, but does not incorporate learning. 2 Two-stream architecture for video recognition Video can naturally be decomposed into spatial and temporal components. The spatial part, in the form of individual frame appearance, carries information about scenes and objects depicted in the video. The temporal part, in the form of motion across the frames, conveys the movement of the observer (the camera) and the objects. We devise our video recognition architecture accordingly, dividing it into two streams, as shown in Fig. 1 . Each stream is implemented using a deep ConvNet, softmax scores of which are combined by late fusion. We consider two fusion methods: averaging and training a multi-class linear SVM [6] on stacked L2 -normalised softmax scores as features. 2 conv1 7x7x96 stride 2 norm. pool 2x2 conv2 5x5x256 stride 2 norm. pool 2x2 conv3 3x3x512 stride 1 conv4 3x3x512 stride 1 conv5 3x3x512 stride 1 pool 2x2 full6 4096 dropout full7 2048 dropout softmax conv1 7x7x96 stride 2 norm. pool 2x2 conv2 5x5x256 stride 2 pool 2x2 conv3 3x3x512 stride 1 conv4 3x3x512 stride 1 conv5 3x3x512 stride 1 pool 2x2 full6 4096 dropout full7 2048 dropout softmax Spatial stream ConvNet Temporal stream ConvNet single frame input video multi-frame optical flow class score fusion Figure 1: Two-stream architecture for video classification. Spatial stream ConvNet operates on individual video frames, effectively performing action recog- nition from still images. The static appearance by itself is a useful clue, since some actions are strongly associated with particular objects. In fact, as will be shown in Sect. 6, action classification from still frames (the spatial recognition stream) is fairly competitive on its own. Since a spatial ConvNet is essentially an image classification architecture, we can build upon the recent advances in large-scale image recognition methods [15], and pre-train the network on a large image classifica- tion dataset, such as the ImageNet challenge dataset. The details are presented in Sect. 5 . Next, we describe the temporal stream ConvNet, which exploits motion and significantly improves accuracy. 3 Optical flow ConvNets In this section, we describe a ConvNet model, which forms the temporal recognition stream of our architecture (Sect. 2). Unlike the ConvNet models, reviewed in Sect. 1.1, the input to our model is formed by stacking optical flow displacement fields between several consecutive frames. Such input explicitly describes the motion between video frames, which makes the recognition easier, as the network does not need to estimate motion implicitly. We consider several variations of the optical flow-based input, which we describe below. (a) (b) (c) (d) (e) Figure 2: Optical flow. (a),(b): a pair of consecutive video frames with the area around a mov- ing hand outlined with a cyan rectangle. (c): a close-up of dense optical flow in the outlined area; (d): horizontal component dx of the displacement vector field (higher intensity corresponds to pos- itive values, lower intensity to negative values). (e): vertical component dy . Note how (d) and (e) highlight the moving hand and bow. The input to a ConvNet contains multiple flows (Sect. 3.1). 3.1 ConvNet input configurations Optical flow stacking. A dense optical flow can be seen as a set of displacement vector fields dt between the pairs of consecutive frames t and t + 1. By dt(u, v) we denote the displacement vector at the point (u, v) in frame t, which moves the point to the corresponding point in the following frame t + 1. The horizontal and vertical components of the vector field, d x t anddy t,canbeseen as image channels (shown in Fig. 2), well suited to recognition using a convolutional network. To represent the motion across a sequence of frames, we stack the flow channels d x,y t of L consecutive frames to form a total of 2L input channels. More formally, let w and h be the width and height of a video; a ConvNet input volume I\u03c4 \u2208 Rw\u00d7h\u00d72L for an arbitrary frame \u03c4 is then constructed as follows: I\u03c4(u,v,2k\u22121)=d x \u03c4 +k\u22121(u, v), (1) I\u03c4(u,v,2k)=d y \u03c4+k\u22121(u,v), u = [1;w],v = [1;h],k =[1;L]. For an arbitrary point (u, v), the channels I\u03c4 (u, v, c), c = [1; 2L] encode the motion at that point over a sequence of L frames (as illustrated in Fig. 3-left). 3 Trajectory stacking. An alternative motion representation, inspired by the trajectory-based de- scriptors [29], replaces the optical flow, sampled at the same locations across several frames, with the flow, sampled along the motion trajectories. In this case, the input volume I\u03c4 , corresponding to a frame \u03c4 , takes the following form: I\u03c4(u,v,2k\u22121)=d x \u03c4 +k\u22121(pk), (2) I\u03c4(u,v,2k)=d y \u03c4+k\u22121(pk), u = [1;w],v = [1;h],k =[1;L]. where pk is the k-th point along the trajectory, which starts at the location (u, v) in the frame \u03c4 and is defined by the following recurrence relation: p1 = (u, v); pk = pk\u22121 +d\u03c4+k\u22122(pk\u22121), k > 1. Compared to the input volume representation (1), where the channels I\u03c4 (u, v, c) store the displace- ment vectors at the locations (u, v), the input volume (2) stores the vectors sampled at the locations pk along the trajectory (as illustrated in Fig. 3-right). input volume channels at point input volume channels at point Figure 3: ConvNet input derivation from the multi-frame optical flow. Left: optical flow stack- ing (1) samples the displacement vectors d at the same location in multiple frames. Right: trajectory stacking (2) samples the vectors along the trajectory. The frames and the corresponding displace- ment vectors are shown with the same colour. Bi-directional optical flow. Optical flow representations (1) and (2) deal with the forward optical flow, i.e. the displacement field dt of the frame t specifies the location of its pixels in the following frame t + 1. It is natural to consider an extension to a bi-directional optical flow, which can be obtained by computing an additional set of displacement fields in the opposite direction. We then construct an input volume I\u03c4 by stacking L/2 forward flows between frames \u03c4 and \u03c4 + L/2 and L/2 backward flows between frames \u03c4 \u2212 L/2 and \u03c4 . The input I\u03c4 thus has the same number of channels (2L) as before. The flows can be represented using either of the two methods (1) and (2). Mean flow subtraction. It is generally beneficial to perform zero-centering of the network input, as it allows the model to better exploit the rectification non-linearities. In our case, the displacement vector field components can take on both positive and negative values, and are naturally centered in the sense that across a large variety of motions, the movement in one direction is as probable as the movement in the opposite one. However, given a pair of frames, the optical flow between them can be dominated by a particular displacement, e.g . caused by the camera movement. The importance of camera motion compensation has been previously highlighted in [10, 26], where a global motion component was estimated and subtracted from the dense flow. In our case, we consider a simpler approach: from each displacement field d we subtract its mean vector. Architecture. Above we have described different ways of combining multiple optical flow displace- ment fields into a single volume I\u03c4 \u2208 Rw\u00d7h\u00d72L . Considering that a ConvNet requires a fixed-size input, we sample a 224 \u00d7 224 \u00d7 2L sub-volume from I\u03c4 and pass it to the net as input. The hid- den layers configuration remains largely the same as that used in the spatial net, and is illustrated in Fig. 1 . Testing is similar to the spatial ConvNet, and is described in detail in Sect. 5. 3.2 Relation of the temporal ConvNet architecture to previous representations In this section, we put our temporal ConvNet architecture in the context of prior art, drawing con- nections to the video representations, reviewed in Sect. 1 .1 . Methods based on feature encod- ings [17, 29] typically combine several spatio-temporal local features. Such features are computed from the optical flow and are thus generalised by our temporal ConvNet. Indeed, the HOF and MBH 4 local descriptors are based on the histograms of orientations of optical flow or its gradient, which can be obtained from the displacement field input (1) using a single convolutional layer (containing orientation-sensitive filters), followed by the rectification and pooling layers. The kinematic features of [10] (divergence, curl and shear) are also computed from the optical flow gradient, and, again, can be captured by our convolutional model. Finally, the trajectory feature [29] is computed by stack- ing the displacement vectors along the trajectory, which corresponds to the trajectory stacking (2). In Sect. 3 .3 we visualise the convolutional filters, learnt in the first layer of the temporal network. This provides further evidence that our representation generalises hand-crafted features. As far as the deep networks are concerned, a two-stream video classification architecture of [16] contains two HMAX models which are hand-crafted and less deep than our discriminatively trained ConvNets, which can be seen as a learnable generalisation of HMAX. The convolutional models of [12, 14] do not decouple spatial and temporal recognition streams, and rely on the motion- sensitive convolutional filters, learnt from the data. In our case, motion is explicitly represented using the optical flow displacement field, computed based on the assumptions of constancy of the intensity and smoothness of the flow. Incorporating such assumptions into a ConvNet framework might be able to boost the performance of end-to-end ConvNet-based methods, and is an interesting direction for future research. 3.3 Visualisation of learnt convolutional filters 96 12 flow 1 flow 10 flow 1 flow 10 conv. filters on vertical flow components dy conv. fliters on horizontal flow components d x temporal derivative spatial derivative Figure 4: First-layer convolutional filters learnt on 10 stacked optical flows. The visualisation is split into 96 columns and 20 rows: each column corresponds to a filter, each row \u2013 to an input channel. In Fig. 4 we visualise the convolutional filters from the first layer of the temporal ConvNet, trained on the UCF-101 dataset. Each of the 96 filters has a spatial receptive field of 7 \u00d7 7 pixels, and spans 20 input channels, corresponding to the horizontal (dx) and vertical (dy ) components of 10 stacked optical flow displacement fields d. As can be seen, some filters compute spatial derivatives of the optical flow, capturing how mo- tion changes with image location, which generalises derivative-based hand-crafted descriptors (e.g . MBH). Other filters compute temporal derivatives, capturing changes in motion over time. 4 Multi-task learning Unlike the spatial stream ConvNet, which can be pre-trained on a large still image classification dataset (such as ImageNet), the temporal ConvNet needs to be trained on video data \u2013 and the available datasets for video action classification are still rather small. In our experiments (Sect. 6), training is performed on the UCF-101 and HMDB-51 datasets, which have only: 9.5K and 3.7K videos respectively. To decrease over-fitting, one could consider combining the two datasets into one; this, however, is not straightforward due to the intersection between the sets of classes. One option (which we evaluate later) is to only add the images from the classes, which do not appear in the original dataset. This, however, requires manual search for such classes and limits the amount of additional training data. A more principled way of combining several datasets is based on multi-task learning [5]. Its aim is to learn a (video) representation, which is applicable not only to the task in question (such as HMDB-51 classification), but also to other tasks (e.g . UCF-101 classification). Additional tasks act as a regulariser, and allow for the exploitation of additional training data. In our case, a ConvNet architecture is modified so that it has two softmax classification layers on top of the last fully- 5 connected layer: one softmax layer computes HMDB-51 classification scores, the other one \u2013 the UCF-101 scores. Each of the layers is equipped with its own loss function, which operates only on the videos, coming from the respective dataset. The overall training loss is computed as the sum of the individual tasks\u2019 losses, and the network weight derivatives can be found by back-propagation. 5 Implementation details ConvNets configuration. The layer configuration of our spatial and temporal ConvNets is schemat- ically shown in Fig. 1. It corresponds to CNN-M -2048 architecture of [3] and is similar to the network of [31]. All hidden weight layers use the rectification (ReLU) activation function; max- pooling is performed over 3 \u00d7 3 spatial windows with stride 2; local response normalisation uses the same settings as [15]. The only difference between spatial and temporal ConvNet configurations is that we removed the second normalisation layer from the latter to reduce memory consumption. Training. The training procedure can be seen as an adaptation of that of [15] to video frames, and is generally the same for both spatial and temporal nets. The network weights are learnt using the mini-batch stochastic gradient descent with momentum (set to 0.9). At each iteration, a mini-batch of 256 samples is constructed by sampling 256 training videos (uniformly across the classes), from each of which a single frame is randomly selected. In spatial net training, a 224 \u00d7 224 sub-image is randomly cropped from the selected frame; it then undergoes random horizontal flipping and RGB jittering. The videos are rescaled beforehand, so that the smallest side of the frame equals 256. We note that unlike [15], the sub-image is sampled from the whole frame, not just its 256 \u00d7 256 center. In the temporal net training, we compute an optical flow volume I for the selected training frame as described in Sect. 3 . From that volume, a fixed-size 224 \u00d7 224 \u00d7 2L input is randomly cropped and flipped. The learning rate is initially set to 10\u22122 , and then decreased according to a fixed schedule, which is kept the same for all training sets. Namely, when training a ConvNet from scratch, the rate is changed to 10\u22123 after 50K iterations, then to 10\u22124 after 70K iterations, and training is stopped after 80K iterations. In the fine-tuning scenario, the rate is changed to 10\u22123 after 14K iterations, and training stopped after 20K iterations. Testing. At test time, given a video, we sample a fixed number of frames (25 in our experiments) with equal temporal spacing between them. From each of the frames we then obtain 10 ConvNet inputs [15] by cropping and flipping four corners and the center of the frame. The class scores for the whole video are then obtained by averaging the scores across the sampled frames and crops therein. Pre-training on ImageNet ILSVRC-2012. When pre-training the spatial ConvNet, we use the same training and test data augmentation as described above (cropping, flipping, RGB jittering). This yields 13.5% top-5 error on ILSVRC-2012 validation set, which compares favourably to 16.0% reported in [31] for a similar network. We believe that the main reason for the improvement is sampling of ConvNet inputs from the whole image, rather than just its center. Multi-GPU training. Our implementation is derived from the publicly available Caffe toolbox [13], but contains a number of significant modifications, including parallel training on multiple GPUs installed in a single system. We exploit the data parallelism, and split each SGD batch across several GPUs. Training a single temporal ConvNet takes 1 day on a system with 4 NVIDIA Titan cards, which constitutes a 3.2 times speed-up over single-GPU training. Optical flow is computed using the off-the-shelf GPU implementation of [2] from the OpenCV toolbox. In spite of the fast computation time (0.06s for a pair of frames), it would still introduce a bottleneck if done on-the-fly, so we pre-computed the flow before training. To avoid storing the displacement fields as floats, the horizontal and vertical components of the flow were linearly rescaled to a [0, 255] range and compressed using JPEG (after decompression, the flow is rescaled back to its original range). This reduced the flow size for the UCF-101 dataset from 1.5TB to 27GB. 6 Evaluation Datasets and evaluation protocol. The evaluation is performed on UCF-101 [24] and HMDB-51 [16] action recognition benchmarks, which are among the largest available annotated video datasets1 . UCF-101 contains 13K videos (180 frames/video on average), annotated into 101 action classes; HMDB-51 includes 6.8K videos of 51 actions. The evaluation protocol is the same 1 Very recently, [14] released the Sports-1M dataset of 1.1M automatically annotated YouTube sports videos. Processing the dataset of such scale is very challenging, and we plan to address it in future work. 6 for both datasets: the organisers provide three splits into training and test data, and the performance is measured by the mean classification accuracy across the splits. Each UCF-101 split contains 9.5K training videos; an HMDB-51 split contains 3.7K training videos. We begin by comparing different architectures on the first split of the UCF-101 dataset. For comparison with the state of the art, we follow the standard evaluation protocol and report the average accuracy over three splits on both UCF-101 and HMDB-51. Spatial ConvNets. First, we measure the performance of the spatial stream ConvNet. Three sce- narios are considered: (i) training from scratch on UCF-101, (ii) pre-training on ILSVRC-2012 followed by fine-tuning on UCF-101, (iii) keeping the pre-trained network fixed and only training the last (classification) layer. For each of the settings, we experiment with setting the dropout regu- larisation ratio to 0.5 or to 0.9. From the results, presented in Table 1a, it is clear that training the ConvNet solely on the UCF-101 dataset leads to over-fitting (even with high dropout), and is inferior to pre-training on a large ILSVRC-2012 dataset. Interestingly, fine-tuning the whole network gives only marginal improvement over training the last layer only. In the latter setting, higher dropout over-regularises learning and leads to worse accuracy. In the following experiments we opted for training the last layer on top of a pre-trained ConvNet. Table 1: Individual ConvNets accuracy on UCF-101 (split 1). (a) Spatial ConvNet. Training setting Dropout ratio 0.5 0.9 From scratch 42.5% 52.3% Pre-trained + fine-tuning 70.8% 72.8% Pre-trained + last layer 72.7% 59.9% (b) Temporal ConvNet. Input configuration Mean subtraction off on Single-frame optical flow (L = 1) - 73.9% Optical flow stacking (1) (L = 5) - 80.4% Optical flow stacking (1) (L = 10) 79.9% 81.0% Trajectory stacking (2)(L = 10) 79.6% 80.2% Optical flow stacking (1)(L = 10), bi-dir. - 81.2% Temporal ConvNets. Having evaluated spatial ConvNet variants, we now turn to the temporal ConvNet architectures, and assess the effect of the input configurations, described in Sect. 3 .1 . In particular, we measure the effect of: using multiple (L = {5, 10}) stacked optical flows; trajectory stacking; mean displacement subtraction; using the bi-directional optical flow. The architectures are trained on the UCF-101 dataset from scratch, so we used an aggressive dropout ratio of 0.9 to help improve generalisation. The results are shown in Table 1b. First, we can conclude that stacking multiple (L > 1) displacement fields in the input is highly beneficial, as it provides the network with long-term motion information, which is more discriminative than the flow between a pair of frames (L = 1 setting). Increasing the number of input flows from 5 to 10 leads to a smaller improvement, so we kept L fixed to 10 in the following experiments. Second, we find that mean subtraction is helpful, as it reduces the effect of global motion between the frames. We use it in the following experiments as default. The difference between different stacking techniques is marginal; it turns out that optical flow stacking performs better than trajectory stacking, and using the bi-directional optical flow is only slightly better than a uni-directional forward flow. Finally, we note that temporal ConvNets significantly outperform the spatial ConvNets (Table 1a), which confirms the importance of motion information for action recognition. We also implemented the \u201cslow fusion\u201d architecture of [14], which amounts to applying a ConvNet to a stack of RGB frames (11 frames in our case). When trained from scratch on UCF-101, it achieved 56.4% accuracy, which is better than a single-frame architecture trained from scratch (52.3%), but is still far off the network trained from scratch on optical flow. This shows that while multi-frame information is important, it is also important to present it to a ConvNet in an appropriate manner. Multi-task learning of temporal ConvNets. Training temporal ConvNets on UCF-101 is challeng- ing due to the small size of the training set. An even bigger challenge is to train the ConvNet on HMDB-51, where each training split is 2.6 times smaller than that of UCF-101. Here we evaluate different options for increasing the effective training set size of HMDB-51: (i) fine-tuning a temporal network pre-trained on UCF-101; (ii) adding 78 classes from UCF-101, which are manually selected so that there is no intersection between these classes and the native HMDB-51 classes; (iii) using the multi-task formulation (Sect. 4) to learn a video representation, shared between the UCF-101 and HMDB-51 classification tasks. The results are reported in Table 2. As expected, it is beneficial to 7 Table 2: Temporal ConvNet accuracy on HMDB-51 (split 1 with additional training data). Training setting Accuracy Training on HMDB-51 without additional data 46.6% Fine-tuning a ConvNet, pre-trained on UCF-101 49.0% Training on HMDB-51 with classes added from UCF-101 52.8% Multi-task learning on HMDB-51 and UCF-101 55.4% utilise full (all splits combined) UCF-101 data for training (either explicitly by borrowing images, or implicitly by pre-training). Multi-task learning performs the best, as it allows the training procedure to exploit all available training data. We have also experimented with multi-task learning on the UCF-101 dataset, by training a network to classify both the full HMDB-51 data (all splits combined) and the UCF-101 data (a single split). On the first split of UCF-101, the accuracy was measured to be 81.5%, which improves on 81.0% achieved using the same settings, but without the additional HMDB classification task (Table 1b). Two-stream ConvNets. Here we evaluate the complete two-stream model, which combines the two recognition streams. One way of combining the networks would be to train a joint stack of fully-connected layers on top of full6 or full7 layers of the two nets. This, however, was not feasible in our case due to over-fitting. We therefore fused the softmax scores using either averaging or a linear SVM. From Table 3 we conclude that: (i) temporal and spatial recognition streams are complementary, as their fusion significantly improves on both (6% over temporal and 14% over spatial nets); (ii) SVM-based fusion of softmax scores outperforms fusion by averaging; (iii) using bi-directional flow is not beneficial in the case of ConvNet fusion; (iv) temporal ConvNet, trained using multi-task learning, performs the best both alone and when fused with a spatial net. Table 3: Two-stream ConvNet accuracy on UCF-101 (split 1). Spatial ConvNet Temporal ConvNet Fusion Method Accuracy Pre-trained + last layer bi-directional averaging 85.6% Pre-trained + last layer uni-directional averaging 85.9% Pre-trained + last layer uni-directional, multi-task averaging 86.2% Pre-trained + last layer uni-directional, multi-task SVM 87.0% Comparison with the state of the art. We conclude the experimental evaluation with the com- parison against the state of the art on three splits of UCF-101 and HMDB-51. For that we used a spatial net, pre-trained on ILSVRC, with the last layer trained on UCF or HMDB. The temporal net was trained on UCF and HMDB using multi-task learning, and the input was computed using uni-directional optical flow stacking with mean subtraction. The softmax scores of the two nets were combined using averaging or SVM. As can be seen from Table 4, both our spatial and temporal nets alone outperform the deep architectures of [14, 16] by a large margin. The combination of the two nets further improves the results (in line with the single-split experiments above), and is comparable to the very recent state-of-the-art hand-crafted models [20, 21, 26]. Table 4: Mean accuracy (over three splits) on UCF-101 and HMDB-51. Method UCF-101 HMDB-51 Improved dense trajectories (IDT) [26, 27] 85.9% 57.2% IDT with higher-dimensional encodings [20] 87.9% 61.1% IDT with stacked Fisher encoding [21] (based on Deep Fisher Net [23]) - 66.8% Spatio-temporal HMAX network [11, 16] - 22.8% \u201cSlow fusion\u201d spatio-temporal ConvNet [14] 65.4% - Spatial stream ConvNet 73.0% 40.5% Temporal stream ConvNet 83.7% 54.6% Two-stream model (fusion by averaging) 86.9% 58.0% Two-stream model (fusion by SVM) 88.0% 59.4% Confusion matrix and per-class recall for UCF-101 classification. In Fig. 5 we show the confu- sion matrix for UCF-101 classification using our two-stream model, which achieves 87.0% accuracy on the first dataset split (the last row of Table 3). We also visualise the corresponding per-class recall inFig.6. 8 The worst class recall corresponds to Hammering class, which is confused with HeadMassage and BrushingTeeth classes. We found that this is due to two reasons. First, the spatial ConvNet confuses Hammering with HeadMassage, which can be caused by the significant presence of human faces in both classes. Second, the temporal ConvNet confuses Hammering with BrushingTeeth, as both actions contain recurring motion patterns (hand moving up and down). Figure 5: Confusion matrix of a two-stream model on the first split of UCF-101. 7 Conclusions and directions for improvement We proposed a deep video classification model with competitive performance, which incorporates separate spatial and temporal recognition streams based on ConvNets. Currently it appears that training a temporal ConvNet on optical flow (as here) is significantly better than training on raw stacked frames [14]. The latter is probably too challenging, and might require architectural changes (for example, a combination with the deep matching approach of [30]). Despite using optical flow as input, our temporal model does not require significant hand-crafting, since the flow is computed using a method based on the generic assumptions of constancy and smoothness. As we have shown, extra training data is beneficial for our temporal ConvNet, so we are planning to train it on large video datasets, such as the recently released collection of [14]. This, however, poses a significant challenge on its own due to the gigantic amount of training data (multiple TBs). There still remain some essential ingredients of the state-of-the-art shallow representation [26], which are missed in our current architecture. The most prominent one is local feature pooling over spatio-temporal tubes, centered at the trajectories. Even though the input (2) captures the opti- cal flow along the trajectories, the spatial pooling in our network does not take the trajectories into account. Another potential area of improvement is explicit handling of camera motion, which in our case is compensated by mean displacement subtraction. 9 Figure 6: Per-class recall of a two-stream model on the first split of UCF-101. Acknowledgements This work was supported by ERC grant VisRec no. 228180. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used for this research. References [1] A. Berg, J. Deng, and L. Fei-Fei. Large scale visual recognition challenge (ILSVRC), 2010. URL http://www.image- net.org/challenges/LSVRC/2010/. [2] T. Brox, A. Bruhn, N. Papenberg, and J. Weickert. High accuracy optical flow estimation based on a theory for warping. In Proc. ECCV, pages 25\u201336, 2004. [3] K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In Proc. BMVC., 2014. [4] B. Chen, J. A . Ting, B. Marlin, and N. de Freitas. Deep learning of invariant spatio-temporal features from video. In NIPS Deep Learning and Unsupervised Feature Learning Workshop, 2010. [5] R. Collobert and J. Weston. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proc. ICML, pages 160\u2013167, 2008. [6] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector ma- chines. JMLR, 2:265\u2013292, 2001. [7] N. Dalal and B Triggs. Histogram of Oriented Gradients for Human Detection. In Proc. CVPR, volume 2, pages 886\u2013893, 2005. [8] N. Dalal, B. Triggs, and C. Schmid. Human detection using oriented histograms of flow and appearance. In Proc. ECCV, pages 428\u2013441, 2006. [9] M. A . Goodale and A. D . Milner. Separate visual pathways for perception and action. Trends in Neuro- sciences, 15(1):20\u201325, 1992. [10] M. Jain, H. Jegou, and P. Bouthemy. Better exploiting motion for better action recognition. In Proc. CVPR, pages 2555\u20132562, 2013. [11] H. Jhuang, T. Serre, L. Wolf, and T. Poggio. A biologically inspired system for action recognition. In Proc. ICCV, pages 1\u20138, 2007. [12] S. Ji, W. Xu, M. Yang, and K. Yu. 3D convolutional neural networks for human action recognition. IEEE PAMI, 35(1):221\u2013231, 2013. [13] Y. Jia. Caffe: An open source convolutional architecture for fast feature embedding. http://caffe. berkeleyvision.org/, 2013. [14] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei. Large-scale video classifi- cation with convolutional neural networks. In Proc. CVPR, 2014. [15] A. Krizhevsky, I. Sutskever, and G. E . Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, pages 1106\u20131114, 2012. 10 [16] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre. HMDB: A large video database for human motion recognition. In Proc. ICCV, pages 2556\u20132563, 2011. [17] I. Laptev, M. Marsza\u0142ek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In Proc. CVPR, 2008. [18] Q. V. Le, W. Y. Zou, S. Y. Yeung, and A. Y. Ng. Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis. In Proc. CVPR, pages 3361\u20133368, 2011. [19] Y. LeCun, B. Boser, J. S . Denker, D. Henderson, R. E . Howard, W. Hubbard, and L. D . Jackel. Backprop- agation applied to handwritten zip code recognition. Neural Computation, 1(4):541\u2013551, 1989. [20] X. Peng, L. Wang, X. Wang, and Y. Qiao. Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice. CoRR, abs/1405.4506, 2014. [21] X. Peng, C. Zou, Y. Qiao, and Q. Peng. Action recognition with stacked fisher vectors. In Proc. ECCV, pages 581\u2013595, 2014. [22] F. Perronnin, J. S \u0301anchez, and T. Mensink. Improving the Fisher kernel for large-scale image classification. In Proc. ECCV, 2010. [23] K. Simonyan, A. Vedaldi, and A. Zisserman. Deep Fisher networks for large-scale image classification. In NIPS, 2013. [24] K. Soomro, A. R . Zamir, and M. Shah. UCF101: A dataset of 101 human actions classes from videos in the wild. CoRR, abs/1212.0402, 2012. [25] G. W. Taylor, R. Fergus, Y. LeCun, and C. Bregler. Convolutional learning of spatio-temporal features. In Proc. ECCV, pages 140\u2013153, 2010. [26] H. Wang and C. Schmid. Action recognition with improved trajectories. In Proc. ICCV, pages 3551\u20133558, 2013. [27] H. Wang and C. Schmid. LEAR -INRIA submission for the THUMOS workshop. In ICCV Workshop on Action Recognition with a Large Number of Classes, 2013. [28] H. Wang, M. M. Ullah, A. Kl\u0308aser, I. Laptev, and C. Schmid. Evaluation of local spatio-temporal features for action recognition. In Proc. BMVC., pages 1\u201311, 2009. [29] H. Wang, A. Kl\u0308aser, C. Schmid, and C.- L . Liu. Action recognition by dense trajectories. In Proc. CVPR, pages 3169\u20133176, 2011. [30] P. Weinzaepfel, J. Revaud, Z. Harchaoui, and C. Schmid. DeepFlow: Large displacement optical flow with deep matching. In Proc. ICCV, pages 1385\u20131392, 2013. [31] M. D . Zeiler and R. Fergus. Visualizing and understanding convolutional networks. CoRR, abs/1311.2901, 2013. 11", "common_format": {"doc_id": "./1406.2199v2.hocr", "tokens": ["Two-Stream", "Convolutional", "Networks", "for", "Action", "Recognition", "in", "Videos", "Karen", "Simonyan", "Andrew", "Zisserman", "Visual", "Geometry", "Group,", "University", "of", "Oxford", "{karen,az}@robots.ox.ac.uk", "Abstract", "We", "investigate", "architectures", "of", "discriminatively", "trained", "deep", "Convolutional", "Net-", "works", "(ConvNets)", "for", "action", "recognition", "in", "video.", "The", "challenge", "is", "to", "capture", "the", "complementary", "information", "on", "appearance", "from", "still", "frames", "and", "motion", "be-", "tween", "frames.", "We", "also", "aim", "to", "generalise", "the", "best", "performing", "hand-crafted", "features", "within", "a", "data-driven", "learning", "framework.", "Our", "contribution", "is", "three-fold.", "First,", "we", "propose", "a", "two-stream", "ConvNet", "architec-", "ture", "which", "incorporates", "spatial", "and", "temporal", "networks.", "Second,", "we", "demonstrate", "that", "a", "ConvNet", "trained", "on", "multi-frame", "dense", "optical", "flow", "is", "able", "to", "achieve", "very", "good", "performance", "in", "spite", "of", "limited", "training", "data.", "Finally,", "we", "show", "that", "multi-", "task", "learning,", "applied", "to", "two", "different", "action", "classification", "datasets,", "can", "be", "used", "to", "increase", "the", "amount", "of", "training", "data", "and", "improve", "the", "performance", "on", "both.", "Our", "architecture", "is", "trained", "and", "evaluated", "on", "the", "standard", "video", "actions", "bench-", "marks", "of", "UCF-101", "and", "HMDB-51,", "where", "it", "is", "competitive", "with", "the", "state", "of", "the", "art.", "It", "also", "exceeds", "by", "a", "large", "margin", "previous", "attempts", "to", "use", "deep", "nets", "for", "video", "classification.", "1", "Introduction", "Recognition", "of", "human", "actions", "in", "videos", "is", "a", "challenging", "task", "which", "has", "received", "a", "significant", "amount", "of", "attention", "in", "the", "research", "community", "[11,", "14,", "17,", "26].", "Compared", "to", "still", "image", "classification,", "the", "temporal", "component", "of", "videos", "provides", "an", "additional", "(and", "important)", "clue", "for", "recognition,", "as", "a", "number", "of", "actions", "can", "be", "reliably", "recognised", "based", "on", "the", "motion", "information.", "Additionally,", "video", "provides", "natural", "data", "augmentation", "(jittering)", "for", "single", "image", "(video", "frame)", "classification.", "In", "this", "work,", "we", "aim", "at", "extending", "deep", "Convolutional", "Networks", "(ConvNets)", "[19],", "a", "state-of-the-", "art", "still", "image", "representation", "[15],", "to", "action", "recognition", "in", "video", "data.", "This", "task", "has", "recently", "been", "addressed", "in", "[14]", "by", "using", "stacked", "video", "frames", "as", "input", "to", "the", "network,", "but", "the", "results", "were", "signif-", "icantly", "worse", "than", "those", "of", "the", "best", "hand-crafted", "shallow", "representations", "[20,", "26].", "We", "investigate", "a", "different", "architecture", "based", "on", "two", "separate", "recognition", "streams", "(spatial", "and", "temporal),", "which", "are", "then", "combined", "by", "late", "fusion.", "The", "spatial", "stream", "performs", "action", "recognition", "from", "still", "video", "frames,", "whilst", "the", "temporal", "stream", "is", "trained", "to", "recognise", "action", "from", "motion", "in", "the", "form", "of", "dense", "optical", "flow.", "Both", "streams", "are", "implemented", "as", "ConvNets.", "Decoupling", "the", "spatial", "and", "temporal", "nets", "also", "allows", "us", "to", "exploit", "the", "availability", "of", "large", "amounts", "of", "annotated", "image", "data", "by", "pre-training", "the", "spatial", "net", "on", "the", "ImageNet", "challenge", "dataset", "[1].", "Our", "proposed", "architecture", "is", "related", "to", "the", "two-streams", "hypothesis", "[9],", "according", "to", "which", "the", "human", "visual", "cortex", "contains", "two", "pathways:", "the", "ventral", "stream", "(which", "performs", "object", "recognition)", "and", "the", "dorsal", "stream", "(which", "recognises", "motion);", "though", "we", "do", "not", "investigate", "this", "connection", "any", "further", "here.", "The", "rest", "of", "the", "paper", "is", "organised", "as", "follows.", "In", "Sect.", "1", ".1", "we", "review", "the", "related", "work", "on", "action", "recognition", "using", "both", "shallow", "and", "deep", "architectures.", "In", "Sect.", "2", "we", "introduce", "the", "two-stream", "architecture", "and", "specify", "the", "Spatial", "ConvNet.", "Sect.", "3", "introduces", "the", "Temporal", "ConvNet", "and", "in", "particular", "how", "it", "generalizes", "the", "previous", "architectures", "reviewed", "in", "Sect.", "1", ".1", ".", "A", "mult-task", "learning", "framework", "is", "developed", "in", "Sect.", "4", "in", "order", "to", "allow", "effortless", "combination", "of", "training", "data", "over", "1", "a", "r", "X", "i", "v", ":", "1", "4", "0", "6", ".", "2", "1", "9", "9", "v", "2", "[", "c", "s", ".", "C", "V", "]", "1", "2", "N", "o", "v", "2", "0", "1", "4", "multiple", "datasets.", "Implementation", "details", "are", "given", "in", "Sect.", "5,", "and", "the", "performance", "is", "evaluated", "in", "Sect.", "6", "and", "compared", "to", "the", "state", "of", "the", "art.", "Our", "experiments", "on", "two", "challenging", "datasets", "(UCF-", "101", "[24]", "and", "HMDB-51", "[16])", "show", "that", "the", "two", "recognition", "streams", "are", "complementary,", "and", "our", "deep", "architecture", "significantly", "outperforms", "that", "of", "[14]", "and", "is", "competitive", "with", "the", "state", "of", "the", "art", "shallow", "representations", "[20,", "21,", "26]", "in", "spite", "of", "being", "trained", "on", "relatively", "small", "datasets.", "1.1", "Related", "work", "Video", "recognition", "research", "has", "been", "largely", "driven", "by", "the", "advances", "in", "image", "recognition", "methods,", "which", "were", "often", "adapted", "and", "extended", "to", "deal", "with", "video", "data.", "A", "large", "family", "of", "video", "action", "recognition", "methods", "is", "based", "on", "shallow", "high-dimensional", "encodings", "of", "local", "spatio-temporal", "fea-", "tures.", "For", "instance,", "the", "algorithm", "of", "[17]", "consists", "in", "detecting", "sparse", "spatio-temporal", "interest", "points,", "which", "are", "then", "described", "using", "local", "spatio-temporal", "features:", "Histogram", "of", "Oriented", "Gradients", "(HOG)", "[7]", "and", "Histogram", "of", "Optical", "Flow", "(HOF).", "The", "features", "are", "then", "encoded", "into", "the", "Bag", "Of", "Features", "(BoF)", "representation,", "which", "is", "pooled", "over", "several", "spatio-temporal", "grids", "(similarly", "to", "spa-", "tial", "pyramid", "pooling)", "and", "combined", "with", "an", "SVM", "classifier.", "In", "a", "later", "work", "[28],", "it", "was", "shown", "that", "dense", "sampling", "of", "local", "features", "outperforms", "sparse", "interest", "points.", "Instead", "of", "computing", "local", "video", "features", "over", "spatio-temporal", "cuboids,", "state-of-the-art", "shallow", "video", "representations", "[20,", "21,", "26]", "make", "use", "of", "dense", "point", "trajectories.", "The", "approach,", "first", "in-", "troduced", "in", "[29],", "consists", "in", "adjusting", "local", "descriptor", "support", "regions,", "so", "that", "they", "follow", "dense", "trajectories,", "computed", "using", "optical", "flow.", "The", "best", "performance", "in", "the", "trajectory-based", "pipeline", "was", "achieved", "by", "the", "Motion", "Boundary", "Histogram", "(MBH)", "[8],", "which", "is", "a", "gradient-based", "feature,", "separately", "computed", "on", "the", "horizontal", "and", "vertical", "components", "of", "optical", "flow.", "A", "combination", "of", "several", "features", "was", "shown", "to", "further", "boost", "the", "accuracy.", "Recent", "improvements", "of", "trajectory-based", "hand-crafted", "representations", "include", "compensation", "of", "global", "(camera)", "motion", "[10,", "16,", "26],", "and", "the", "use", "of", "the", "Fisher", "vector", "encoding", "[22]", "(in", "[26])", "or", "its", "deeper", "variant", "[23]", "(in", "[21]).", "There", "has", "also", "been", "a", "number", "of", "attempts", "to", "develop", "a", "deep", "architecture", "for", "video", "recognition.", "In", "the", "majority", "of", "these", "works,", "the", "input", "to", "the", "network", "is", "a", "stack", "of", "consecutive", "video", "frames,", "so", "the", "model", "is", "expected", "to", "implicitly", "learn", "spatio-temporal", "motion-dependent", "features", "in", "the", "first", "layers,", "which", "can", "be", "a", "difficult", "task.", "In", "[11],", "an", "HMAX", "architecture", "for", "video", "recognition", "was", "proposed", "with", "pre-defined", "spatio-temporal", "filters", "in", "the", "first", "layer.", "Later,", "it", "was", "combined", "[16]", "with", "a", "spatial", "HMAX", "model,", "thus", "forming", "spatial", "(ventral-like)", "and", "temporal", "(dorsal-like)", "recognition", "streams.", "Unlike", "our", "work,", "however,", "the", "streams", "were", "implemented", "as", "hand-crafted", "and", "rather", "shallow", "(3-", "layer)", "HMAX", "models.", "In", "[4,", "18,", "25],", "a", "convolutional", "RBM", "and", "ISA", "were", "used", "for", "unsupervised", "learning", "of", "spatio-temporal", "features,", "which", "were", "then", "plugged", "into", "a", "discriminative", "model", "for", "action", "classification.", "Discriminative", "end-to-end", "learning", "of", "video", "ConvNets", "has", "been", "addressed", "in", "[12]", "and,", "more", "recently,", "in", "[14],", "who", "compared", "several", "ConvNet", "architectures", "for", "action", "recognition.", "Training", "was", "carried", "out", "on", "a", "very", "large", "Sports-1M", "dataset,", "comprising", "1.1M", "YouTube", "videos", "of", "sports", "activities.", "Interestingly,", "[14]", "found", "that", "a", "network,", "operating", "on", "individual", "video", "frames,", "performs", "similarly", "to", "the", "networks,", "whose", "input", "is", "a", "stack", "of", "frames.", "This", "might", "indicate", "that", "the", "learnt", "spatio-temporal", "features", "do", "not", "capture", "the", "motion", "well.", "The", "learnt", "representation,", "fine-", "tuned", "on", "the", "UCF-101", "dataset,", "turned", "out", "to", "be", "20%", "less", "accurate", "than", "hand-crafted", "state-of-the-art", "trajectory-based", "representation", "[20,", "27].", "Our", "temporal", "stream", "ConvNet", "operates", "on", "multiple-frame", "dense", "optical", "flow,", "which", "is", "typically", "computed", "in", "an", "energy", "minimisation", "framework", "by", "solving", "for", "a", "displacement", "field", "(typically", "at", "multiple", "image", "scales).", "We", "used", "a", "popular", "method", "of", "[2],", "which", "formulates", "the", "energy", "based", "on", "constancy", "assumptions", "for", "intensity", "and", "its", "gradient,", "as", "well", "as", "smoothness", "of", "the", "displacement", "field.", "Recently,", "[30]", "proposed", "an", "image", "patch", "matching", "scheme,", "which", "is", "reminiscent", "of", "deep", "ConvNets,", "but", "does", "not", "incorporate", "learning.", "2", "Two-stream", "architecture", "for", "video", "recognition", "Video", "can", "naturally", "be", "decomposed", "into", "spatial", "and", "temporal", "components.", "The", "spatial", "part,", "in", "the", "form", "of", "individual", "frame", "appearance,", "carries", "information", "about", "scenes", "and", "objects", "depicted", "in", "the", "video.", "The", "temporal", "part,", "in", "the", "form", "of", "motion", "across", "the", "frames,", "conveys", "the", "movement", "of", "the", "observer", "(the", "camera)", "and", "the", "objects.", "We", "devise", "our", "video", "recognition", "architecture", "accordingly,", "dividing", "it", "into", "two", "streams,", "as", "shown", "in", "Fig.", "1", ".", "Each", "stream", "is", "implemented", "using", "a", "deep", "ConvNet,", "softmax", "scores", "of", "which", "are", "combined", "by", "late", "fusion.", "We", "consider", "two", "fusion", "methods:", "averaging", "and", "training", "a", "multi-class", "linear", "SVM", "[6]", "on", "stacked", "L2", "-normalised", "softmax", "scores", "as", "features.", "2", "conv1", "7x7x96", "stride", "2", "norm.", "pool", "2x2", "conv2", "5x5x256", "stride", "2", "norm.", "pool", "2x2", "conv3", "3x3x512", "stride", "1", "conv4", "3x3x512", "stride", "1", "conv5", "3x3x512", "stride", "1", "pool", "2x2", "full6", "4096", "dropout", "full7", "2048", "dropout", "softmax", "conv1", "7x7x96", "stride", "2", "norm.", "pool", "2x2", "conv2", "5x5x256", "stride", "2", "pool", "2x2", "conv3", "3x3x512", "stride", "1", "conv4", "3x3x512", "stride", "1", "conv5", "3x3x512", "stride", "1", "pool", "2x2", "full6", "4096", "dropout", "full7", "2048", "dropout", "softmax", "Spatial", "stream", "ConvNet", "Temporal", "stream", "ConvNet", "single", "frame", "input", "video", "multi-frame", "optical", "flow", "class", "score", "fusion", "Figure", "1:", "Two-stream", "architecture", "for", "video", "classification.", "Spatial", "stream", "ConvNet", "operates", "on", "individual", "video", "frames,", "effectively", "performing", "action", "recog-", "nition", "from", "still", "images.", "The", "static", "appearance", "by", "itself", "is", "a", "useful", "clue,", "since", "some", "actions", "are", "strongly", "associated", "with", "particular", "objects.", "In", "fact,", "as", "will", "be", "shown", "in", "Sect.", "6,", "action", "classification", "from", "still", "frames", "(the", "spatial", "recognition", "stream)", "is", "fairly", "competitive", "on", "its", "own.", "Since", "a", "spatial", "ConvNet", "is", "essentially", "an", "image", "classification", "architecture,", "we", "can", "build", "upon", "the", "recent", "advances", "in", "large-scale", "image", "recognition", "methods", "[15],", "and", "pre-train", "the", "network", "on", "a", "large", "image", "classifica-", "tion", "dataset,", "such", "as", "the", "ImageNet", "challenge", "dataset.", "The", "details", "are", "presented", "in", "Sect.", "5", ".", "Next,", "we", "describe", "the", "temporal", "stream", "ConvNet,", "which", "exploits", "motion", "and", "significantly", "improves", "accuracy.", "3", "Optical", "flow", "ConvNets", "In", "this", "section,", "we", "describe", "a", "ConvNet", "model,", "which", "forms", "the", "temporal", "recognition", "stream", "of", "our", "architecture", "(Sect.", "2).", "Unlike", "the", "ConvNet", "models,", "reviewed", "in", "Sect.", "1.1,", "the", "input", "to", "our", "model", "is", "formed", "by", "stacking", "optical", "flow", "displacement", "fields", "between", "several", "consecutive", "frames.", "Such", "input", "explicitly", "describes", "the", "motion", "between", "video", "frames,", "which", "makes", "the", "recognition", "easier,", "as", "the", "network", "does", "not", "need", "to", "estimate", "motion", "implicitly.", "We", "consider", "several", "variations", "of", "the", "optical", "flow-based", "input,", "which", "we", "describe", "below.", "(a)", "(b)", "(c)", "(d)", "(e)", "Figure", "2:", "Optical", "flow.", "(a),(b):", "a", "pair", "of", "consecutive", "video", "frames", "with", "the", "area", "around", "a", "mov-", "ing", "hand", "outlined", "with", "a", "cyan", "rectangle.", "(c):", "a", "close-up", "of", "dense", "optical", "flow", "in", "the", "outlined", "area;", "(d):", "horizontal", "component", "dx", "of", "the", "displacement", "vector", "field", "(higher", "intensity", "corresponds", "to", "pos-", "itive", "values,", "lower", "intensity", "to", "negative", "values).", "(e):", "vertical", "component", "dy", ".", "Note", "how", "(d)", "and", "(e)", "highlight", "the", "moving", "hand", "and", "bow.", "The", "input", "to", "a", "ConvNet", "contains", "multiple", "flows", "(Sect.", "3.1).", "3.1", "ConvNet", "input", "configurations", "Optical", "flow", "stacking.", "A", "dense", "optical", "flow", "can", "be", "seen", "as", "a", "set", "of", "displacement", "vector", "fields", "dt", "between", "the", "pairs", "of", "consecutive", "frames", "t", "and", "t", "+", "1.", "By", "dt(u,", "v)", "we", "denote", "the", "displacement", "vector", "at", "the", "point", "(u,", "v)", "in", "frame", "t,", "which", "moves", "the", "point", "to", "the", "corresponding", "point", "in", "the", "following", "frame", "t", "+", "1.", "The", "horizontal", "and", "vertical", "components", "of", "the", "vector", "field,", "d", "x", "t", "anddy", "t,canbeseen", "as", "image", "channels", "(shown", "in", "Fig.", "2),", "well", "suited", "to", "recognition", "using", "a", "convolutional", "network.", "To", "represent", "the", "motion", "across", "a", "sequence", "of", "frames,", "we", "stack", "the", "flow", "channels", "d", "x,y", "t", "of", "L", "consecutive", "frames", "to", "form", "a", "total", "of", "2L", "input", "channels.", "More", "formally,", "let", "w", "and", "h", "be", "the", "width", "and", "height", "of", "a", "video;", "a", "ConvNet", "input", "volume", "I\u03c4", "\u2208", "Rw\u00d7h\u00d72L", "for", "an", "arbitrary", "frame", "\u03c4", "is", "then", "constructed", "as", "follows:", "I\u03c4(u,v,2k\u22121)=d", "x", "\u03c4", "+k\u22121(u,", "v),", "(1)", "I\u03c4(u,v,2k)=d", "y", "\u03c4+k\u22121(u,v),", "u", "=", "[1;w],v", "=", "[1;h],k", "=[1;L].", "For", "an", "arbitrary", "point", "(u,", "v),", "the", "channels", "I\u03c4", "(u,", "v,", "c),", "c", "=", "[1;", "2L]", "encode", "the", "motion", "at", "that", "point", "over", "a", "sequence", "of", "L", "frames", "(as", "illustrated", "in", "Fig.", "3-left).", "3", "Trajectory", "stacking.", "An", "alternative", "motion", "representation,", "inspired", "by", "the", "trajectory-based", "de-", "scriptors", "[29],", "replaces", "the", "optical", "flow,", "sampled", "at", "the", "same", "locations", "across", "several", "frames,", "with", "the", "flow,", "sampled", "along", "the", "motion", "trajectories.", "In", "this", "case,", "the", "input", "volume", "I\u03c4", ",", "corresponding", "to", "a", "frame", "\u03c4", ",", "takes", "the", "following", "form:", "I\u03c4(u,v,2k\u22121)=d", "x", "\u03c4", "+k\u22121(pk),", "(2)", "I\u03c4(u,v,2k)=d", "y", "\u03c4+k\u22121(pk),", "u", "=", "[1;w],v", "=", "[1;h],k", "=[1;L].", "where", "pk", "is", "the", "k-th", "point", "along", "the", "trajectory,", "which", "starts", "at", "the", "location", "(u,", "v)", "in", "the", "frame", "\u03c4", "and", "is", "defined", "by", "the", "following", "recurrence", "relation:", "p1", "=", "(u,", "v);", "pk", "=", "pk\u22121", "+d\u03c4+k\u22122(pk\u22121),", "k", ">", "1.", "Compared", "to", "the", "input", "volume", "representation", "(1),", "where", "the", "channels", "I\u03c4", "(u,", "v,", "c)", "store", "the", "displace-", "ment", "vectors", "at", "the", "locations", "(u,", "v),", "the", "input", "volume", "(2)", "stores", "the", "vectors", "sampled", "at", "the", "locations", "pk", "along", "the", "trajectory", "(as", "illustrated", "in", "Fig.", "3-right).", "input", "volume", "channels", "at", "point", "input", "volume", "channels", "at", "point", "Figure", "3:", "ConvNet", "input", "derivation", "from", "the", "multi-frame", "optical", "flow.", "Left:", "optical", "flow", "stack-", "ing", "(1)", "samples", "the", "displacement", "vectors", "d", "at", "the", "same", "location", "in", "multiple", "frames.", "Right:", "trajectory", "stacking", "(2)", "samples", "the", "vectors", "along", "the", "trajectory.", "The", "frames", "and", "the", "corresponding", "displace-", "ment", "vectors", "are", "shown", "with", "the", "same", "colour.", "Bi-directional", "optical", "flow.", "Optical", "flow", "representations", "(1)", "and", "(2)", "deal", "with", "the", "forward", "optical", "flow,", "i.e.", "the", "displacement", "field", "dt", "of", "the", "frame", "t", "specifies", "the", "location", "of", "its", "pixels", "in", "the", "following", "frame", "t", "+", "1.", "It", "is", "natural", "to", "consider", "an", "extension", "to", "a", "bi-directional", "optical", "flow,", "which", "can", "be", "obtained", "by", "computing", "an", "additional", "set", "of", "displacement", "fields", "in", "the", "opposite", "direction.", "We", "then", "construct", "an", "input", "volume", "I\u03c4", "by", "stacking", "L/2", "forward", "flows", "between", "frames", "\u03c4", "and", "\u03c4", "+", "L/2", "and", "L/2", "backward", "flows", "between", "frames", "\u03c4", "\u2212", "L/2", "and", "\u03c4", ".", "The", "input", "I\u03c4", "thus", "has", "the", "same", "number", "of", "channels", "(2L)", "as", "before.", "The", "flows", "can", "be", "represented", "using", "either", "of", "the", "two", "methods", "(1)", "and", "(2).", "Mean", "flow", "subtraction.", "It", "is", "generally", "beneficial", "to", "perform", "zero-centering", "of", "the", "network", "input,", "as", "it", "allows", "the", "model", "to", "better", "exploit", "the", "rectification", "non-linearities.", "In", "our", "case,", "the", "displacement", "vector", "field", "components", "can", "take", "on", "both", "positive", "and", "negative", "values,", "and", "are", "naturally", "centered", "in", "the", "sense", "that", "across", "a", "large", "variety", "of", "motions,", "the", "movement", "in", "one", "direction", "is", "as", "probable", "as", "the", "movement", "in", "the", "opposite", "one.", "However,", "given", "a", "pair", "of", "frames,", "the", "optical", "flow", "between", "them", "can", "be", "dominated", "by", "a", "particular", "displacement,", "e.g", ".", "caused", "by", "the", "camera", "movement.", "The", "importance", "of", "camera", "motion", "compensation", "has", "been", "previously", "highlighted", "in", "[10,", "26],", "where", "a", "global", "motion", "component", "was", "estimated", "and", "subtracted", "from", "the", "dense", "flow.", "In", "our", "case,", "we", "consider", "a", "simpler", "approach:", "from", "each", "displacement", "field", "d", "we", "subtract", "its", "mean", "vector.", "Architecture.", "Above", "we", "have", "described", "different", "ways", "of", "combining", "multiple", "optical", "flow", "displace-", "ment", "fields", "into", "a", "single", "volume", "I\u03c4", "\u2208", "Rw\u00d7h\u00d72L", ".", "Considering", "that", "a", "ConvNet", "requires", "a", "fixed-size", "input,", "we", "sample", "a", "224", "\u00d7", "224", "\u00d7", "2L", "sub-volume", "from", "I\u03c4", "and", "pass", "it", "to", "the", "net", "as", "input.", "The", "hid-", "den", "layers", "configuration", "remains", "largely", "the", "same", "as", "that", "used", "in", "the", "spatial", "net,", "and", "is", "illustrated", "in", "Fig.", "1", ".", "Testing", "is", "similar", "to", "the", "spatial", "ConvNet,", "and", "is", "described", "in", "detail", "in", "Sect.", "5.", "3.2", "Relation", "of", "the", "temporal", "ConvNet", "architecture", "to", "previous", "representations", "In", "this", "section,", "we", "put", "our", "temporal", "ConvNet", "architecture", "in", "the", "context", "of", "prior", "art,", "drawing", "con-", "nections", "to", "the", "video", "representations,", "reviewed", "in", "Sect.", "1", ".1", ".", "Methods", "based", "on", "feature", "encod-", "ings", "[17,", "29]", "typically", "combine", "several", "spatio-temporal", "local", "features.", "Such", "features", "are", "computed", "from", "the", "optical", "flow", "and", "are", "thus", "generalised", "by", "our", "temporal", "ConvNet.", "Indeed,", "the", "HOF", "and", "MBH", "4", "local", "descriptors", "are", "based", "on", "the", "histograms", "of", "orientations", "of", "optical", "flow", "or", "its", "gradient,", "which", "can", "be", "obtained", "from", "the", "displacement", "field", "input", "(1)", "using", "a", "single", "convolutional", "layer", "(containing", "orientation-sensitive", "filters),", "followed", "by", "the", "rectification", "and", "pooling", "layers.", "The", "kinematic", "features", "of", "[10]", "(divergence,", "curl", "and", "shear)", "are", "also", "computed", "from", "the", "optical", "flow", "gradient,", "and,", "again,", "can", "be", "captured", "by", "our", "convolutional", "model.", "Finally,", "the", "trajectory", "feature", "[29]", "is", "computed", "by", "stack-", "ing", "the", "displacement", "vectors", "along", "the", "trajectory,", "which", "corresponds", "to", "the", "trajectory", "stacking", "(2).", "In", "Sect.", "3", ".3", "we", "visualise", "the", "convolutional", "filters,", "learnt", "in", "the", "first", "layer", "of", "the", "temporal", "network.", "This", "provides", "further", "evidence", "that", "our", "representation", "generalises", "hand-crafted", "features.", "As", "far", "as", "the", "deep", "networks", "are", "concerned,", "a", "two-stream", "video", "classification", "architecture", "of", "[16]", "contains", "two", "HMAX", "models", "which", "are", "hand-crafted", "and", "less", "deep", "than", "our", "discriminatively", "trained", "ConvNets,", "which", "can", "be", "seen", "as", "a", "learnable", "generalisation", "of", "HMAX.", "The", "convolutional", "models", "of", "[12,", "14]", "do", "not", "decouple", "spatial", "and", "temporal", "recognition", "streams,", "and", "rely", "on", "the", "motion-", "sensitive", "convolutional", "filters,", "learnt", "from", "the", "data.", "In", "our", "case,", "motion", "is", "explicitly", "represented", "using", "the", "optical", "flow", "displacement", "field,", "computed", "based", "on", "the", "assumptions", "of", "constancy", "of", "the", "intensity", "and", "smoothness", "of", "the", "flow.", "Incorporating", "such", "assumptions", "into", "a", "ConvNet", "framework", "might", "be", "able", "to", "boost", "the", "performance", "of", "end-to-end", "ConvNet-based", "methods,", "and", "is", "an", "interesting", "direction", "for", "future", "research.", "3.3", "Visualisation", "of", "learnt", "convolutional", "filters", "96", "12", "flow", "1", "flow", "10", "flow", "1", "flow", "10", "conv.", "filters", "on", "vertical", "flow", "components", "dy", "conv.", "fliters", "on", "horizontal", "flow", "components", "d", "x", "temporal", "derivative", "spatial", "derivative", "Figure", "4:", "First-layer", "convolutional", "filters", "learnt", "on", "10", "stacked", "optical", "flows.", "The", "visualisation", "is", "split", "into", "96", "columns", "and", "20", "rows:", "each", "column", "corresponds", "to", "a", "filter,", "each", "row", "\u2013", "to", "an", "input", "channel.", "In", "Fig.", "4", "we", "visualise", "the", "convolutional", "filters", "from", "the", "first", "layer", "of", "the", "temporal", "ConvNet,", "trained", "on", "the", "UCF-101", "dataset.", "Each", "of", "the", "96", "filters", "has", "a", "spatial", "receptive", "field", "of", "7", "\u00d7", "7", "pixels,", "and", "spans", "20", "input", "channels,", "corresponding", "to", "the", "horizontal", "(dx)", "and", "vertical", "(dy", ")", "components", "of", "10", "stacked", "optical", "flow", "displacement", "fields", "d.", "As", "can", "be", "seen,", "some", "filters", "compute", "spatial", "derivatives", "of", "the", "optical", "flow,", "capturing", "how", "mo-", "tion", "changes", "with", "image", "location,", "which", "generalises", "derivative-based", "hand-crafted", "descriptors", "(e.g", ".", "MBH).", "Other", "filters", "compute", "temporal", "derivatives,", "capturing", "changes", "in", "motion", "over", "time.", "4", "Multi-task", "learning", "Unlike", "the", "spatial", "stream", "ConvNet,", "which", "can", "be", "pre-trained", "on", "a", "large", "still", "image", "classification", "dataset", "(such", "as", "ImageNet),", "the", "temporal", "ConvNet", "needs", "to", "be", "trained", "on", "video", "data", "\u2013", "and", "the", "available", "datasets", "for", "video", "action", "classification", "are", "still", "rather", "small.", "In", "our", "experiments", "(Sect.", "6),", "training", "is", "performed", "on", "the", "UCF-101", "and", "HMDB-51", "datasets,", "which", "have", "only:", "9.5K", "and", "3.7K", "videos", "respectively.", "To", "decrease", "over-fitting,", "one", "could", "consider", "combining", "the", "two", "datasets", "into", "one;", "this,", "however,", "is", "not", "straightforward", "due", "to", "the", "intersection", "between", "the", "sets", "of", "classes.", "One", "option", "(which", "we", "evaluate", "later)", "is", "to", "only", "add", "the", "images", "from", "the", "classes,", "which", "do", "not", "appear", "in", "the", "original", "dataset.", "This,", "however,", "requires", "manual", "search", "for", "such", "classes", "and", "limits", "the", "amount", "of", "additional", "training", "data.", "A", "more", "principled", "way", "of", "combining", "several", "datasets", "is", "based", "on", "multi-task", "learning", "[5].", "Its", "aim", "is", "to", "learn", "a", "(video)", "representation,", "which", "is", "applicable", "not", "only", "to", "the", "task", "in", "question", "(such", "as", "HMDB-51", "classification),", "but", "also", "to", "other", "tasks", "(e.g", ".", "UCF-101", "classification).", "Additional", "tasks", "act", "as", "a", "regulariser,", "and", "allow", "for", "the", "exploitation", "of", "additional", "training", "data.", "In", "our", "case,", "a", "ConvNet", "architecture", "is", "modified", "so", "that", "it", "has", "two", "softmax", "classification", "layers", "on", "top", "of", "the", "last", "fully-", "5", "connected", "layer:", "one", "softmax", "layer", "computes", "HMDB-51", "classification", "scores,", "the", "other", "one", "\u2013", "the", "UCF-101", "scores.", "Each", "of", "the", "layers", "is", "equipped", "with", "its", "own", "loss", "function,", "which", "operates", "only", "on", "the", "videos,", "coming", "from", "the", "respective", "dataset.", "The", "overall", "training", "loss", "is", "computed", "as", "the", "sum", "of", "the", "individual", "tasks\u2019", "losses,", "and", "the", "network", "weight", "derivatives", "can", "be", "found", "by", "back-propagation.", "5", "Implementation", "details", "ConvNets", "configuration.", "The", "layer", "configuration", "of", "our", "spatial", "and", "temporal", "ConvNets", "is", "schemat-", "ically", "shown", "in", "Fig.", "1.", "It", "corresponds", "to", "CNN-M", "-2048", "architecture", "of", "[3]", "and", "is", "similar", "to", "the", "network", "of", "[31].", "All", "hidden", "weight", "layers", "use", "the", "rectification", "(ReLU)", "activation", "function;", "max-", "pooling", "is", "performed", "over", "3", "\u00d7", "3", "spatial", "windows", "with", "stride", "2;", "local", "response", "normalisation", "uses", "the", "same", "settings", "as", "[15].", "The", "only", "difference", "between", "spatial", "and", "temporal", "ConvNet", "configurations", "is", "that", "we", "removed", "the", "second", "normalisation", "layer", "from", "the", "latter", "to", "reduce", "memory", "consumption.", "Training.", "The", "training", "procedure", "can", "be", "seen", "as", "an", "adaptation", "of", "that", "of", "[15]", "to", "video", "frames,", "and", "is", "generally", "the", "same", "for", "both", "spatial", "and", "temporal", "nets.", "The", "network", "weights", "are", "learnt", "using", "the", "mini-batch", "stochastic", "gradient", "descent", "with", "momentum", "(set", "to", "0.9).", "At", "each", "iteration,", "a", "mini-batch", "of", "256", "samples", "is", "constructed", "by", "sampling", "256", "training", "videos", "(uniformly", "across", "the", "classes),", "from", "each", "of", "which", "a", "single", "frame", "is", "randomly", "selected.", "In", "spatial", "net", "training,", "a", "224", "\u00d7", "224", "sub-image", "is", "randomly", "cropped", "from", "the", "selected", "frame;", "it", "then", "undergoes", "random", "horizontal", "flipping", "and", "RGB", "jittering.", "The", "videos", "are", "rescaled", "beforehand,", "so", "that", "the", "smallest", "side", "of", "the", "frame", "equals", "256.", "We", "note", "that", "unlike", "[15],", "the", "sub-image", "is", "sampled", "from", "the", "whole", "frame,", "not", "just", "its", "256", "\u00d7", "256", "center.", "In", "the", "temporal", "net", "training,", "we", "compute", "an", "optical", "flow", "volume", "I", "for", "the", "selected", "training", "frame", "as", "described", "in", "Sect.", "3", ".", "From", "that", "volume,", "a", "fixed-size", "224", "\u00d7", "224", "\u00d7", "2L", "input", "is", "randomly", "cropped", "and", "flipped.", "The", "learning", "rate", "is", "initially", "set", "to", "10\u22122", ",", "and", "then", "decreased", "according", "to", "a", "fixed", "schedule,", "which", "is", "kept", "the", "same", "for", "all", "training", "sets.", "Namely,", "when", "training", "a", "ConvNet", "from", "scratch,", "the", "rate", "is", "changed", "to", "10\u22123", "after", "50K", "iterations,", "then", "to", "10\u22124", "after", "70K", "iterations,", "and", "training", "is", "stopped", "after", "80K", "iterations.", "In", "the", "fine-tuning", "scenario,", "the", "rate", "is", "changed", "to", "10\u22123", "after", "14K", "iterations,", "and", "training", "stopped", "after", "20K", "iterations.", "Testing.", "At", "test", "time,", "given", "a", "video,", "we", "sample", "a", "fixed", "number", "of", "frames", "(25", "in", "our", "experiments)", "with", "equal", "temporal", "spacing", "between", "them.", "From", "each", "of", "the", "frames", "we", "then", "obtain", "10", "ConvNet", "inputs", "[15]", "by", "cropping", "and", "flipping", "four", "corners", "and", "the", "center", "of", "the", "frame.", "The", "class", "scores", "for", "the", "whole", "video", "are", "then", "obtained", "by", "averaging", "the", "scores", "across", "the", "sampled", "frames", "and", "crops", "therein.", "Pre-training", "on", "ImageNet", "ILSVRC-2012.", "When", "pre-training", "the", "spatial", "ConvNet,", "we", "use", "the", "same", "training", "and", "test", "data", "augmentation", "as", "described", "above", "(cropping,", "flipping,", "RGB", "jittering).", "This", "yields", "13.5%", "top-5", "error", "on", "ILSVRC-2012", "validation", "set,", "which", "compares", "favourably", "to", "16.0%", "reported", "in", "[31]", "for", "a", "similar", "network.", "We", "believe", "that", "the", "main", "reason", "for", "the", "improvement", "is", "sampling", "of", "ConvNet", "inputs", "from", "the", "whole", "image,", "rather", "than", "just", "its", "center.", "Multi-GPU", "training.", "Our", "implementation", "is", "derived", "from", "the", "publicly", "available", "Caffe", "toolbox", "[13],", "but", "contains", "a", "number", "of", "significant", "modifications,", "including", "parallel", "training", "on", "multiple", "GPUs", "installed", "in", "a", "single", "system.", "We", "exploit", "the", "data", "parallelism,", "and", "split", "each", "SGD", "batch", "across", "several", "GPUs.", "Training", "a", "single", "temporal", "ConvNet", "takes", "1", "day", "on", "a", "system", "with", "4", "NVIDIA", "Titan", "cards,", "which", "constitutes", "a", "3.2", "times", "speed-up", "over", "single-GPU", "training.", "Optical", "flow", "is", "computed", "using", "the", "off-the-shelf", "GPU", "implementation", "of", "[2]", "from", "the", "OpenCV", "toolbox.", "In", "spite", "of", "the", "fast", "computation", "time", "(0.06s", "for", "a", "pair", "of", "frames),", "it", "would", "still", "introduce", "a", "bottleneck", "if", "done", "on-the-fly,", "so", "we", "pre-computed", "the", "flow", "before", "training.", "To", "avoid", "storing", "the", "displacement", "fields", "as", "floats,", "the", "horizontal", "and", "vertical", "components", "of", "the", "flow", "were", "linearly", "rescaled", "to", "a", "[0,", "255]", "range", "and", "compressed", "using", "JPEG", "(after", "decompression,", "the", "flow", "is", "rescaled", "back", "to", "its", "original", "range).", "This", "reduced", "the", "flow", "size", "for", "the", "UCF-101", "dataset", "from", "1.5TB", "to", "27GB.", "6", "Evaluation", "Datasets", "and", "evaluation", "protocol.", "The", "evaluation", "is", "performed", "on", "UCF-101", "[24]", "and", "HMDB-51", "[16]", "action", "recognition", "benchmarks,", "which", "are", "among", "the", "largest", "available", "annotated", "video", "datasets1", ".", "UCF-101", "contains", "13K", "videos", "(180", "frames/video", "on", "average),", "annotated", "into", "101", "action", "classes;", "HMDB-51", "includes", "6.8K", "videos", "of", "51", "actions.", "The", "evaluation", "protocol", "is", "the", "same", "1", "Very", "recently,", "[14]", "released", "the", "Sports-1M", "dataset", "of", "1.1M", "automatically", "annotated", "YouTube", "sports", "videos.", "Processing", "the", "dataset", "of", "such", "scale", "is", "very", "challenging,", "and", "we", "plan", "to", "address", "it", "in", "future", "work.", "6", "for", "both", "datasets:", "the", "organisers", "provide", "three", "splits", "into", "training", "and", "test", "data,", "and", "the", "performance", "is", "measured", "by", "the", "mean", "classification", "accuracy", "across", "the", "splits.", "Each", "UCF-101", "split", "contains", "9.5K", "training", "videos;", "an", "HMDB-51", "split", "contains", "3.7K", "training", "videos.", "We", "begin", "by", "comparing", "different", "architectures", "on", "the", "first", "split", "of", "the", "UCF-101", "dataset.", "For", "comparison", "with", "the", "state", "of", "the", "art,", "we", "follow", "the", "standard", "evaluation", "protocol", "and", "report", "the", "average", "accuracy", "over", "three", "splits", "on", "both", "UCF-101", "and", "HMDB-51.", "Spatial", "ConvNets.", "First,", "we", "measure", "the", "performance", "of", "the", "spatial", "stream", "ConvNet.", "Three", "sce-", "narios", "are", "considered:", "(i)", "training", "from", "scratch", "on", "UCF-101,", "(ii)", "pre-training", "on", "ILSVRC-2012", "followed", "by", "fine-tuning", "on", "UCF-101,", "(iii)", "keeping", "the", "pre-trained", "network", "fixed", "and", "only", "training", "the", "last", "(classification)", "layer.", "For", "each", "of", "the", "settings,", "we", "experiment", "with", "setting", "the", "dropout", "regu-", "larisation", "ratio", "to", "0.5", "or", "to", "0.9.", "From", "the", "results,", "presented", "in", "Table", "1a,", "it", "is", "clear", "that", "training", "the", "ConvNet", "solely", "on", "the", "UCF-101", "dataset", "leads", "to", "over-fitting", "(even", "with", "high", "dropout),", "and", "is", "inferior", "to", "pre-training", "on", "a", "large", "ILSVRC-2012", "dataset.", "Interestingly,", "fine-tuning", "the", "whole", "network", "gives", "only", "marginal", "improvement", "over", "training", "the", "last", "layer", "only.", "In", "the", "latter", "setting,", "higher", "dropout", "over-regularises", "learning", "and", "leads", "to", "worse", "accuracy.", "In", "the", "following", "experiments", "we", "opted", "for", "training", "the", "last", "layer", "on", "top", "of", "a", "pre-trained", "ConvNet.", "Table", "1:", "Individual", "ConvNets", "accuracy", "on", "UCF-101", "(split", "1).", "(a)", "Spatial", "ConvNet.", "Training", "setting", "Dropout", "ratio", "0.5", "0.9", "From", "scratch", "42.5%", "52.3%", "Pre-trained", "+", "fine-tuning", "70.8%", "72.8%", "Pre-trained", "+", "last", "layer", "72.7%", "59.9%", "(b)", "Temporal", "ConvNet.", "Input", "configuration", "Mean", "subtraction", "off", "on", "Single-frame", "optical", "flow", "(L", "=", "1)", "-", "73.9%", "Optical", "flow", "stacking", "(1)", "(L", "=", "5)", "-", "80.4%", "Optical", "flow", "stacking", "(1)", "(L", "=", "10)", "79.9%", "81.0%", "Trajectory", "stacking", "(2)(L", "=", "10)", "79.6%", "80.2%", "Optical", "flow", "stacking", "(1)(L", "=", "10),", "bi-dir.", "-", "81.2%", "Temporal", "ConvNets.", "Having", "evaluated", "spatial", "ConvNet", "variants,", "we", "now", "turn", "to", "the", "temporal", "ConvNet", "architectures,", "and", "assess", "the", "effect", "of", "the", "input", "configurations,", "described", "in", "Sect.", "3", ".1", ".", "In", "particular,", "we", "measure", "the", "effect", "of:", "using", "multiple", "(L", "=", "{5,", "10})", "stacked", "optical", "flows;", "trajectory", "stacking;", "mean", "displacement", "subtraction;", "using", "the", "bi-directional", "optical", "flow.", "The", "architectures", "are", "trained", "on", "the", "UCF-101", "dataset", "from", "scratch,", "so", "we", "used", "an", "aggressive", "dropout", "ratio", "of", "0.9", "to", "help", "improve", "generalisation.", "The", "results", "are", "shown", "in", "Table", "1b.", "First,", "we", "can", "conclude", "that", "stacking", "multiple", "(L", ">", "1)", "displacement", "fields", "in", "the", "input", "is", "highly", "beneficial,", "as", "it", "provides", "the", "network", "with", "long-term", "motion", "information,", "which", "is", "more", "discriminative", "than", "the", "flow", "between", "a", "pair", "of", "frames", "(L", "=", "1", "setting).", "Increasing", "the", "number", "of", "input", "flows", "from", "5", "to", "10", "leads", "to", "a", "smaller", "improvement,", "so", "we", "kept", "L", "fixed", "to", "10", "in", "the", "following", "experiments.", "Second,", "we", "find", "that", "mean", "subtraction", "is", "helpful,", "as", "it", "reduces", "the", "effect", "of", "global", "motion", "between", "the", "frames.", "We", "use", "it", "in", "the", "following", "experiments", "as", "default.", "The", "difference", "between", "different", "stacking", "techniques", "is", "marginal;", "it", "turns", "out", "that", "optical", "flow", "stacking", "performs", "better", "than", "trajectory", "stacking,", "and", "using", "the", "bi-directional", "optical", "flow", "is", "only", "slightly", "better", "than", "a", "uni-directional", "forward", "flow.", "Finally,", "we", "note", "that", "temporal", "ConvNets", "significantly", "outperform", "the", "spatial", "ConvNets", "(Table", "1a),", "which", "confirms", "the", "importance", "of", "motion", "information", "for", "action", "recognition.", "We", "also", "implemented", "the", "\u201cslow", "fusion\u201d", "architecture", "of", "[14],", "which", "amounts", "to", "applying", "a", "ConvNet", "to", "a", "stack", "of", "RGB", "frames", "(11", "frames", "in", "our", "case).", "When", "trained", "from", "scratch", "on", "UCF-101,", "it", "achieved", "56.4%", "accuracy,", "which", "is", "better", "than", "a", "single-frame", "architecture", "trained", "from", "scratch", "(52.3%),", "but", "is", "still", "far", "off", "the", "network", "trained", "from", "scratch", "on", "optical", "flow.", "This", "shows", "that", "while", "multi-frame", "information", "is", "important,", "it", "is", "also", "important", "to", "present", "it", "to", "a", "ConvNet", "in", "an", "appropriate", "manner.", "Multi-task", "learning", "of", "temporal", "ConvNets.", "Training", "temporal", "ConvNets", "on", "UCF-101", "is", "challeng-", "ing", "due", "to", "the", "small", "size", "of", "the", "training", "set.", "An", "even", "bigger", "challenge", "is", "to", "train", "the", "ConvNet", "on", "HMDB-51,", "where", "each", "training", "split", "is", "2.6", "times", "smaller", "than", "that", "of", "UCF-101.", "Here", "we", "evaluate", "different", "options", "for", "increasing", "the", "effective", "training", "set", "size", "of", "HMDB-51:", "(i)", "fine-tuning", "a", "temporal", "network", "pre-trained", "on", "UCF-101;", "(ii)", "adding", "78", "classes", "from", "UCF-101,", "which", "are", "manually", "selected", "so", "that", "there", "is", "no", "intersection", "between", "these", "classes", "and", "the", "native", "HMDB-51", "classes;", "(iii)", "using", "the", "multi-task", "formulation", "(Sect.", "4)", "to", "learn", "a", "video", "representation,", "shared", "between", "the", "UCF-101", "and", "HMDB-51", "classification", "tasks.", "The", "results", "are", "reported", "in", "Table", "2.", "As", "expected,", "it", "is", "beneficial", "to", "7", "Table", "2:", "Temporal", "ConvNet", "accuracy", "on", "HMDB-51", "(split", "1", "with", "additional", "training", "data).", "Training", "setting", "Accuracy", "Training", "on", "HMDB-51", "without", "additional", "data", "46.6%", "Fine-tuning", "a", "ConvNet,", "pre-trained", "on", "UCF-101", "49.0%", "Training", "on", "HMDB-51", "with", "classes", "added", "from", "UCF-101", "52.8%", "Multi-task", "learning", "on", "HMDB-51", "and", "UCF-101", "55.4%", "utilise", "full", "(all", "splits", "combined)", "UCF-101", "data", "for", "training", "(either", "explicitly", "by", "borrowing", "images,", "or", "implicitly", "by", "pre-training).", "Multi-task", "learning", "performs", "the", "best,", "as", "it", "allows", "the", "training", "procedure", "to", "exploit", "all", "available", "training", "data.", "We", "have", "also", "experimented", "with", "multi-task", "learning", "on", "the", "UCF-101", "dataset,", "by", "training", "a", "network", "to", "classify", "both", "the", "full", "HMDB-51", "data", "(all", "splits", "combined)", "and", "the", "UCF-101", "data", "(a", "single", "split).", "On", "the", "first", "split", "of", "UCF-101,", "the", "accuracy", "was", "measured", "to", "be", "81.5%,", "which", "improves", "on", "81.0%", "achieved", "using", "the", "same", "settings,", "but", "without", "the", "additional", "HMDB", "classification", "task", "(Table", "1b).", "Two-stream", "ConvNets.", "Here", "we", "evaluate", "the", "complete", "two-stream", "model,", "which", "combines", "the", "two", "recognition", "streams.", "One", "way", "of", "combining", "the", "networks", "would", "be", "to", "train", "a", "joint", "stack", "of", "fully-connected", "layers", "on", "top", "of", "full6", "or", "full7", "layers", "of", "the", "two", "nets.", "This,", "however,", "was", "not", "feasible", "in", "our", "case", "due", "to", "over-fitting.", "We", "therefore", "fused", "the", "softmax", "scores", "using", "either", "averaging", "or", "a", "linear", "SVM.", "From", "Table", "3", "we", "conclude", "that:", "(i)", "temporal", "and", "spatial", "recognition", "streams", "are", "complementary,", "as", "their", "fusion", "significantly", "improves", "on", "both", "(6%", "over", "temporal", "and", "14%", "over", "spatial", "nets);", "(ii)", "SVM-based", "fusion", "of", "softmax", "scores", "outperforms", "fusion", "by", "averaging;", "(iii)", "using", "bi-directional", "flow", "is", "not", "beneficial", "in", "the", "case", "of", "ConvNet", "fusion;", "(iv)", "temporal", "ConvNet,", "trained", "using", "multi-task", "learning,", "performs", "the", "best", "both", "alone", "and", "when", "fused", "with", "a", "spatial", "net.", "Table", "3:", "Two-stream", "ConvNet", "accuracy", "on", "UCF-101", "(split", "1).", "Spatial", "ConvNet", "Temporal", "ConvNet", "Fusion", "Method", "Accuracy", "Pre-trained", "+", "last", "layer", "bi-directional", "averaging", "85.6%", "Pre-trained", "+", "last", "layer", "uni-directional", "averaging", "85.9%", "Pre-trained", "+", "last", "layer", "uni-directional,", "multi-task", "averaging", "86.2%", "Pre-trained", "+", "last", "layer", "uni-directional,", "multi-task", "SVM", "87.0%", "Comparison", "with", "the", "state", "of", "the", "art.", "We", "conclude", "the", "experimental", "evaluation", "with", "the", "com-", "parison", "against", "the", "state", "of", "the", "art", "on", "three", "splits", "of", "UCF-101", "and", "HMDB-51.", "For", "that", "we", "used", "a", "spatial", "net,", "pre-trained", "on", "ILSVRC,", "with", "the", "last", "layer", "trained", "on", "UCF", "or", "HMDB.", "The", "temporal", "net", "was", "trained", "on", "UCF", "and", "HMDB", "using", "multi-task", "learning,", "and", "the", "input", "was", "computed", "using", "uni-directional", "optical", "flow", "stacking", "with", "mean", "subtraction.", "The", "softmax", "scores", "of", "the", "two", "nets", "were", "combined", "using", "averaging", "or", "SVM.", "As", "can", "be", "seen", "from", "Table", "4,", "both", "our", "spatial", "and", "temporal", "nets", "alone", "outperform", "the", "deep", "architectures", "of", "[14,", "16]", "by", "a", "large", "margin.", "The", "combination", "of", "the", "two", "nets", "further", "improves", "the", "results", "(in", "line", "with", "the", "single-split", "experiments", "above),", "and", "is", "comparable", "to", "the", "very", "recent", "state-of-the-art", "hand-crafted", "models", "[20,", "21,", "26].", "Table", "4:", "Mean", "accuracy", "(over", "three", "splits)", "on", "UCF-101", "and", "HMDB-51.", "Method", "UCF-101", "HMDB-51", "Improved", "dense", "trajectories", "(IDT)", "[26,", "27]", "85.9%", "57.2%", "IDT", "with", "higher-dimensional", "encodings", "[20]", "87.9%", "61.1%", "IDT", "with", "stacked", "Fisher", "encoding", "[21]", "(based", "on", "Deep", "Fisher", "Net", "[23])", "-", "66.8%", "Spatio-temporal", "HMAX", "network", "[11,", "16]", "-", "22.8%", "\u201cSlow", "fusion\u201d", "spatio-temporal", "ConvNet", "[14]", "65.4%", "-", "Spatial", "stream", "ConvNet", "73.0%", "40.5%", "Temporal", "stream", "ConvNet", "83.7%", "54.6%", "Two-stream", "model", "(fusion", "by", "averaging)", "86.9%", "58.0%", "Two-stream", "model", "(fusion", "by", "SVM)", "88.0%", "59.4%", "Confusion", "matrix", "and", "per-class", "recall", "for", "UCF-101", "classification.", "In", "Fig.", "5", "we", "show", "the", "confu-", "sion", "matrix", "for", "UCF-101", "classification", "using", "our", "two-stream", "model,", "which", "achieves", "87.0%", "accuracy", "on", "the", "first", "dataset", "split", "(the", "last", "row", "of", "Table", "3).", "We", "also", "visualise", "the", "corresponding", "per-class", "recall", "inFig.6.", "8", "The", "worst", "class", "recall", "corresponds", "to", "Hammering", "class,", "which", "is", "confused", "with", "HeadMassage", "and", "BrushingTeeth", "classes.", "We", "found", "that", "this", "is", "due", "to", "two", "reasons.", "First,", "the", "spatial", "ConvNet", "confuses", "Hammering", "with", "HeadMassage,", "which", "can", "be", "caused", "by", "the", "significant", "presence", "of", "human", "faces", "in", "both", "classes.", "Second,", "the", "temporal", "ConvNet", "confuses", "Hammering", "with", "BrushingTeeth,", "as", "both", "actions", "contain", "recurring", "motion", "patterns", "(hand", "moving", "up", "and", "down).", "Figure", "5:", "Confusion", "matrix", "of", "a", "two-stream", "model", "on", "the", "first", "split", "of", "UCF-101.", "7", "Conclusions", "and", "directions", "for", "improvement", "We", "proposed", "a", "deep", "video", "classification", "model", "with", "competitive", "performance,", "which", "incorporates", "separate", "spatial", "and", "temporal", "recognition", "streams", "based", "on", "ConvNets.", "Currently", "it", "appears", "that", "training", "a", "temporal", "ConvNet", "on", "optical", "flow", "(as", "here)", "is", "significantly", "better", "than", "training", "on", "raw", "stacked", "frames", "[14].", "The", "latter", "is", "probably", "too", "challenging,", "and", "might", "require", "architectural", "changes", "(for", "example,", "a", "combination", "with", "the", "deep", "matching", "approach", "of", "[30]).", "Despite", "using", "optical", "flow", "as", "input,", "our", "temporal", "model", "does", "not", "require", "significant", "hand-crafting,", "since", "the", "flow", "is", "computed", "using", "a", "method", "based", "on", "the", "generic", "assumptions", "of", "constancy", "and", "smoothness.", "As", "we", "have", "shown,", "extra", "training", "data", "is", "beneficial", "for", "our", "temporal", "ConvNet,", "so", "we", "are", "planning", "to", "train", "it", "on", "large", "video", "datasets,", "such", "as", "the", "recently", "released", "collection", "of", "[14].", "This,", "however,", "poses", "a", "significant", "challenge", "on", "its", "own", "due", "to", "the", "gigantic", "amount", "of", "training", "data", "(multiple", "TBs).", "There", "still", "remain", "some", "essential", "ingredients", "of", "the", "state-of-the-art", "shallow", "representation", "[26],", "which", "are", "missed", "in", "our", "current", "architecture.", "The", "most", "prominent", "one", "is", "local", "feature", "pooling", "over", "spatio-temporal", "tubes,", "centered", "at", "the", "trajectories.", "Even", "though", "the", "input", "(2)", "captures", "the", "opti-", "cal", "flow", "along", "the", "trajectories,", "the", "spatial", "pooling", "in", "our", "network", "does", "not", "take", "the", "trajectories", "into", "account.", "Another", "potential", "area", "of", "improvement", "is", "explicit", "handling", "of", "camera", "motion,", "which", "in", "our", "case", "is", "compensated", "by", "mean", "displacement", "subtraction.", "9", "Figure", "6:", "Per-class", "recall", "of", "a", "two-stream", "model", "on", "the", "first", "split", "of", "UCF-101.", "Acknowledgements", "This", "work", "was", "supported", "by", "ERC", "grant", "VisRec", "no.", "228180.", "We", "gratefully", "acknowledge", "the", "support", "of", "NVIDIA", "Corporation", "with", "the", "donation", "of", "the", "GPUs", "used", "for", "this", "research.", "References", "[1]", "A.", "Berg,", "J.", "Deng,", "and", "L.", "Fei-Fei.", "Large", "scale", "visual", "recognition", "challenge", "(ILSVRC),", "2010.", "URL", "http://www.image-", "net.org/challenges/LSVRC/2010/.", "[2]", "T.", "Brox,", "A.", "Bruhn,", "N.", "Papenberg,", "and", "J.", "Weickert.", "High", "accuracy", "optical", "flow", "estimation", "based", "on", "a", "theory", "for", "warping.", "In", "Proc.", "ECCV,", "pages", "25\u201336,", "2004.", "[3]", "K.", "Chatfield,", "K.", "Simonyan,", "A.", "Vedaldi,", "and", "A.", "Zisserman.", "Return", "of", "the", "devil", "in", "the", "details:", "Delving", "deep", "into", "convolutional", "nets.", "In", "Proc.", "BMVC.,", "2014.", "[4]", "B.", "Chen,", "J.", "A", ".", "Ting,", "B.", "Marlin,", "and", "N.", "de", "Freitas.", "Deep", "learning", "of", "invariant", "spatio-temporal", "features", "from", "video.", "In", "NIPS", "Deep", "Learning", "and", "Unsupervised", "Feature", "Learning", "Workshop,", "2010.", "[5]", "R.", "Collobert", "and", "J.", "Weston.", "A", "unified", "architecture", "for", "natural", "language", "processing:", "deep", "neural", "networks", "with", "multitask", "learning.", "In", "Proc.", "ICML,", "pages", "160\u2013167,", "2008.", "[6]", "K.", "Crammer", "and", "Y.", "Singer.", "On", "the", "algorithmic", "implementation", "of", "multiclass", "kernel-based", "vector", "ma-", "chines.", "JMLR,", "2:265\u2013292,", "2001.", "[7]", "N.", "Dalal", "and", "B", "Triggs.", "Histogram", "of", "Oriented", "Gradients", "for", "Human", "Detection.", "In", "Proc.", "CVPR,", "volume", "2,", "pages", "886\u2013893,", "2005.", "[8]", "N.", "Dalal,", "B.", "Triggs,", "and", "C.", "Schmid.", "Human", "detection", "using", "oriented", "histograms", "of", "flow", "and", "appearance.", "In", "Proc.", "ECCV,", "pages", "428\u2013441,", "2006.", "[9]", "M.", "A", ".", "Goodale", "and", "A.", "D", ".", "Milner.", "Separate", "visual", "pathways", "for", "perception", "and", "action.", "Trends", "in", "Neuro-", "sciences,", "15(1):20\u201325,", "1992.", "[10]", "M.", "Jain,", "H.", "Jegou,", "and", "P.", "Bouthemy.", "Better", "exploiting", "motion", "for", "better", "action", "recognition.", "In", "Proc.", "CVPR,", "pages", "2555\u20132562,", "2013.", "[11]", "H.", "Jhuang,", "T.", "Serre,", "L.", "Wolf,", "and", "T.", "Poggio.", "A", "biologically", "inspired", "system", "for", "action", "recognition.", "In", "Proc.", "ICCV,", "pages", "1\u20138,", "2007.", "[12]", "S.", "Ji,", "W.", "Xu,", "M.", "Yang,", "and", "K.", "Yu.", "3D", "convolutional", "neural", "networks", "for", "human", "action", "recognition.", "IEEE", "PAMI,", "35(1):221\u2013231,", "2013.", "[13]", "Y.", "Jia.", "Caffe:", "An", "open", "source", "convolutional", "architecture", "for", "fast", "feature", "embedding.", "http://caffe.", "berkeleyvision.org/,", "2013.", "[14]", "A.", "Karpathy,", "G.", "Toderici,", "S.", "Shetty,", "T.", "Leung,", "R.", "Sukthankar,", "and", "L.", "Fei-Fei.", "Large-scale", "video", "classifi-", "cation", "with", "convolutional", "neural", "networks.", "In", "Proc.", "CVPR,", "2014.", "[15]", "A.", "Krizhevsky,", "I.", "Sutskever,", "and", "G.", "E", ".", "Hinton.", "ImageNet", "classification", "with", "deep", "convolutional", "neural", "networks.", "In", "NIPS,", "pages", "1106\u20131114,", "2012.", "10", "[16]", "H.", "Kuehne,", "H.", "Jhuang,", "E.", "Garrote,", "T.", "Poggio,", "and", "T.", "Serre.", "HMDB:", "A", "large", "video", "database", "for", "human", "motion", "recognition.", "In", "Proc.", "ICCV,", "pages", "2556\u20132563,", "2011.", "[17]", "I.", "Laptev,", "M.", "Marsza\u0142ek,", "C.", "Schmid,", "and", "B.", "Rozenfeld.", "Learning", "realistic", "human", "actions", "from", "movies.", "In", "Proc.", "CVPR,", "2008.", "[18]", "Q.", "V.", "Le,", "W.", "Y.", "Zou,", "S.", "Y.", "Yeung,", "and", "A.", "Y.", "Ng.", "Learning", "hierarchical", "invariant", "spatio-temporal", "features", "for", "action", "recognition", "with", "independent", "subspace", "analysis.", "In", "Proc.", "CVPR,", "pages", "3361\u20133368,", "2011.", "[19]", "Y.", "LeCun,", "B.", "Boser,", "J.", "S", ".", "Denker,", "D.", "Henderson,", "R.", "E", ".", "Howard,", "W.", "Hubbard,", "and", "L.", "D", ".", "Jackel.", "Backprop-", "agation", "applied", "to", "handwritten", "zip", "code", "recognition.", "Neural", "Computation,", "1(4):541\u2013551,", "1989.", "[20]", "X.", "Peng,", "L.", "Wang,", "X.", "Wang,", "and", "Y.", "Qiao.", "Bag", "of", "visual", "words", "and", "fusion", "methods", "for", "action", "recognition:", "Comprehensive", "study", "and", "good", "practice.", "CoRR,", "abs/1405.4506,", "2014.", "[21]", "X.", "Peng,", "C.", "Zou,", "Y.", "Qiao,", "and", "Q.", "Peng.", "Action", "recognition", "with", "stacked", "fisher", "vectors.", "In", "Proc.", "ECCV,", "pages", "581\u2013595,", "2014.", "[22]", "F.", "Perronnin,", "J.", "S", "\u0301anchez,", "and", "T.", "Mensink.", "Improving", "the", "Fisher", "kernel", "for", "large-scale", "image", "classification.", "In", "Proc.", "ECCV,", "2010.", "[23]", "K.", "Simonyan,", "A.", "Vedaldi,", "and", "A.", "Zisserman.", "Deep", "Fisher", "networks", "for", "large-scale", "image", "classification.", "In", "NIPS,", "2013.", "[24]", "K.", "Soomro,", "A.", "R", ".", "Zamir,", "and", "M.", "Shah.", "UCF101:", "A", "dataset", "of", "101", "human", "actions", "classes", "from", "videos", "in", "the", "wild.", "CoRR,", "abs/1212.0402,", "2012.", "[25]", "G.", "W.", "Taylor,", "R.", "Fergus,", "Y.", "LeCun,", "and", "C.", "Bregler.", "Convolutional", "learning", "of", "spatio-temporal", "features.", "In", "Proc.", "ECCV,", "pages", "140\u2013153,", "2010.", "[26]", "H.", "Wang", "and", "C.", "Schmid.", "Action", "recognition", "with", "improved", "trajectories.", "In", "Proc.", "ICCV,", "pages", "3551\u20133558,", "2013.", "[27]", "H.", "Wang", "and", "C.", "Schmid.", "LEAR", "-INRIA", "submission", "for", "the", "THUMOS", "workshop.", "In", "ICCV", "Workshop", "on", "Action", "Recognition", "with", "a", "Large", "Number", "of", "Classes,", "2013.", "[28]", "H.", "Wang,", "M.", "M.", "Ullah,", "A.", "Kl\u0308aser,", "I.", "Laptev,", "and", "C.", "Schmid.", "Evaluation", "of", "local", "spatio-temporal", "features", "for", "action", "recognition.", "In", "Proc.", "BMVC.,", "pages", "1\u201311,", "2009.", "[29]", "H.", "Wang,", "A.", "Kl\u0308aser,", "C.", "Schmid,", "and", "C.-", "L", ".", "Liu.", "Action", "recognition", "by", "dense", "trajectories.", "In", "Proc.", "CVPR,", "pages", "3169\u20133176,", "2011.", "[30]", "P.", "Weinzaepfel,", "J.", "Revaud,", "Z.", "Harchaoui,", "and", "C.", "Schmid.", "DeepFlow:", "Large", "displacement", "optical", "flow", "with", "deep", "matching.", "In", "Proc.", "ICCV,", "pages", "1385\u20131392,", "2013.", "[31]", "M.", "D", ".", "Zeiler", "and", "R.", "Fergus.", "Visualizing", "and", "understanding", "convolutional", "networks.", "CoRR,", "abs/1311.2901,", "2013.", "11"], "positions": [[709, 462, 1080, 513], [1104, 462, 1529, 513], [1549, 464, 1841, 513], [778, 545, 866, 596], [885, 545, 1087, 596], [1108, 545, 1471, 610], [1491, 545, 1549, 595], [1569, 545, 1770, 596], [786, 799, 896, 828], [909, 798, 1084, 836], [1435, 798, 1576, 828], [1589, 798, 1773, 828], [891, 844, 996, 872], [1008, 844, 1172, 881], [1184, 844, 1297, 881], [1311, 844, 1483, 881], [1495, 844, 1531, 872], [1540, 844, 1658, 873], [958, 887, 1591, 928], [1182, 1010, 1368, 1045], [599, 1113, 653, 1140], [667, 1112, 843, 1149], [858, 1112, 1066, 1140], [1082, 1112, 1118, 1140], [1129, 1112, 1396, 1149], [1410, 1112, 1524, 1140], [1538, 1112, 1615, 1149], [1629, 1112, 1863, 1141], [1877, 1113, 1948, 1140], [600, 1157, 698, 1186], [717, 1157, 905, 1192], [923, 1157, 971, 1185], [988, 1157, 1086, 1185], [1102, 1157, 1291, 1194], [1308, 1157, 1338, 1185], [1355, 1157, 1454, 1186], [1485, 1157, 1548, 1185], [1564, 1157, 1722, 1194], [1739, 1157, 1763, 1185], [1781, 1161, 1812, 1185], [1829, 1161, 1950, 1194], [600, 1203, 649, 1231], [664, 1203, 920, 1240], [935, 1203, 1129, 1231], [1144, 1212, 1184, 1231], [1200, 1212, 1384, 1240], [1399, 1203, 1478, 1231], [1494, 1203, 1553, 1231], [1568, 1203, 1678, 1231], [1695, 1203, 1752, 1231], [1767, 1203, 1883, 1231], [1897, 1203, 1948, 1231], [600, 1253, 697, 1278], [708, 1249, 828, 1277], [842, 1250, 896, 1277], [907, 1249, 971, 1277], [983, 1249, 1043, 1277], [1053, 1253, 1083, 1277], [1094, 1249, 1261, 1286], [1271, 1249, 1320, 1277], [1329, 1249, 1397, 1277], [1405, 1249, 1591, 1286], [1600, 1249, 1809, 1277], [1820, 1249, 1948, 1277], [600, 1294, 704, 1323], [717, 1303, 733, 1322], [745, 1294, 931, 1323], [943, 1294, 1077, 1331], [1089, 1294, 1277, 1323], [600, 1347, 664, 1376], [676, 1347, 876, 1375], [889, 1347, 914, 1375], [928, 1347, 1099, 1375], [1118, 1347, 1201, 1381], [1216, 1356, 1263, 1376], [1275, 1356, 1406, 1384], [1420, 1356, 1436, 1375], [1449, 1351, 1634, 1376], [1646, 1347, 1794, 1376], [1807, 1347, 1948, 1375], [600, 1397, 663, 1421], [677, 1393, 777, 1422], [791, 1393, 993, 1430], [1009, 1393, 1115, 1430], [1130, 1393, 1187, 1421], [1201, 1393, 1347, 1430], [1361, 1393, 1520, 1422], [1543, 1393, 1671, 1427], [1687, 1402, 1734, 1422], [1748, 1393, 1950, 1421], [600, 1439, 662, 1467], [675, 1448, 691, 1467], [705, 1439, 853, 1468], [866, 1439, 979, 1467], [993, 1448, 1033, 1467], [1047, 1439, 1244, 1467], [1258, 1439, 1351, 1467], [1364, 1439, 1476, 1476], [1490, 1439, 1560, 1468], [1575, 1439, 1599, 1467], [1616, 1439, 1682, 1467], [1696, 1443, 1727, 1467], [1742, 1439, 1864, 1468], [1878, 1448, 1949, 1476], [600, 1484, 681, 1521], [695, 1484, 904, 1521], [918, 1484, 949, 1512], [965, 1484, 1041, 1521], [1055, 1484, 1091, 1512], [1102, 1484, 1218, 1512], [1233, 1484, 1360, 1521], [1375, 1484, 1451, 1512], [1475, 1484, 1597, 1521], [1614, 1493, 1661, 1513], [1676, 1484, 1760, 1513], [1774, 1484, 1836, 1512], [1850, 1484, 1948, 1512], [600, 1530, 666, 1558], [676, 1530, 819, 1567], [833, 1530, 953, 1567], [964, 1534, 995, 1558], [1006, 1534, 1066, 1559], [1077, 1530, 1219, 1558], [1230, 1530, 1328, 1558], [1340, 1530, 1555, 1558], [1566, 1530, 1704, 1564], [1717, 1539, 1773, 1558], [1783, 1530, 1822, 1558], [1832, 1530, 1908, 1558], [1919, 1534, 1949, 1558], [600, 1576, 735, 1604], [746, 1576, 796, 1604], [808, 1580, 931, 1604], [942, 1576, 978, 1604], [987, 1576, 1115, 1613], [1127, 1576, 1195, 1604], [1207, 1576, 1265, 1604], [1277, 1576, 1412, 1613], [1424, 1576, 1473, 1604], [1484, 1576, 1694, 1613], [1705, 1585, 1745, 1604], [1756, 1576, 1838, 1604], [600, 1629, 664, 1658], [681, 1629, 875, 1657], [892, 1629, 917, 1657], [936, 1629, 1049, 1657], [1068, 1629, 1125, 1657], [1143, 1629, 1298, 1658], [1316, 1638, 1356, 1657], [1373, 1629, 1423, 1657], [1441, 1629, 1579, 1657], [1596, 1629, 1687, 1658], [1706, 1629, 1819, 1657], [1837, 1629, 1948, 1657], [600, 1674, 698, 1702], [715, 1674, 751, 1702], [763, 1674, 914, 1703], [934, 1674, 991, 1702], [1007, 1673, 1193, 1708], [1211, 1674, 1311, 1703], [1326, 1674, 1348, 1702], [1362, 1674, 1387, 1702], [1404, 1674, 1596, 1711], [1611, 1674, 1683, 1703], [1699, 1674, 1748, 1702], [1764, 1678, 1837, 1702], [1852, 1674, 1888, 1702], [1900, 1674, 1950, 1702], [601, 1724, 651, 1748], [667, 1721, 692, 1748], [704, 1720, 768, 1748], [780, 1720, 908, 1748], [920, 1720, 961, 1757], [974, 1729, 990, 1748], [1002, 1720, 1083, 1757], [1095, 1720, 1210, 1757], [1221, 1720, 1361, 1757], [1375, 1724, 1512, 1757], [1525, 1724, 1556, 1748], [1567, 1729, 1622, 1748], [1634, 1720, 1711, 1757], [1723, 1724, 1786, 1748], [1800, 1720, 1848, 1748], [1859, 1720, 1949, 1749], [600, 1766, 824, 1794], [453, 1877, 472, 1911], [525, 1877, 794, 1912], [451, 1958, 652, 1995], [662, 1958, 697, 1986], [703, 1958, 816, 1986], [827, 1958, 940, 1986], [951, 1958, 982, 1986], [992, 1958, 1097, 1987], [1108, 1958, 1133, 1986], [1145, 1967, 1161, 1986], [1171, 1958, 1363, 1995], [1373, 1958, 1439, 1986], [1448, 1958, 1548, 1987], [1557, 1958, 1610, 1986], [1620, 1958, 1758, 1987], [1769, 1967, 1785, 1986], [1796, 1958, 1967, 1995], [1977, 1962, 2100, 1986], [451, 2004, 486, 2032], [498, 2004, 640, 2032], [653, 2004, 684, 2032], [697, 2004, 746, 2032], [758, 2004, 896, 2032], [909, 2004, 1097, 2041], [1113, 2004, 1172, 2038], [1191, 2004, 1236, 2038], [1254, 2004, 1299, 2038], [1314, 2004, 1376, 2038], [1396, 2004, 1567, 2041], [1580, 2008, 1611, 2032], [1625, 2004, 1685, 2032], [1698, 2004, 1798, 2041], [1811, 2004, 2035, 2038], [2050, 2004, 2099, 2032], [451, 2050, 597, 2087], [614, 2054, 798, 2087], [814, 2050, 850, 2078], [865, 2050, 970, 2079], [988, 2050, 1128, 2087], [1148, 2059, 1185, 2078], [1204, 2050, 1367, 2078], [1386, 2050, 1457, 2085], [1474, 2050, 1647, 2087], [1665, 2050, 1733, 2078], [1750, 2050, 1798, 2078], [1814, 2050, 2011, 2087], [2033, 2059, 2063, 2078], [2083, 2059, 2099, 2078], [451, 2095, 576, 2123], [588, 2095, 624, 2123], [635, 2095, 748, 2123], [762, 2104, 818, 2123], [830, 2095, 869, 2123], [880, 2095, 1006, 2132], [1018, 2095, 1197, 2132], [1209, 2095, 1303, 2123], [1316, 2104, 1355, 2123], [1368, 2095, 1417, 2123], [1430, 2095, 1546, 2123], [1558, 2095, 1761, 2123], [1780, 2095, 1994, 2132], [2008, 2095, 2099, 2124], [450, 2141, 590, 2178], [603, 2141, 717, 2169], [729, 2141, 797, 2169], [809, 2141, 1033, 2178], [1046, 2141, 1201, 2178], [1214, 2141, 1262, 2169], [1274, 2141, 1371, 2178], [1383, 2141, 1483, 2178], [1495, 2141, 1599, 2176], [1611, 2141, 1719, 2176], [1732, 2141, 1956, 2169], [451, 2212, 483, 2239], [499, 2211, 556, 2239], [574, 2211, 666, 2245], [685, 2220, 732, 2240], [748, 2211, 808, 2239], [825, 2215, 853, 2239], [868, 2211, 1030, 2248], [1046, 2211, 1122, 2248], [1139, 2211, 1372, 2240], [1388, 2211, 1546, 2240], [1564, 2211, 1753, 2246], [1773, 2211, 1846, 2245], [1866, 2220, 1882, 2239], [1899, 2211, 2098, 2239], [452, 2261, 494, 2285], [508, 2257, 567, 2285], [581, 2257, 681, 2294], [694, 2257, 929, 2294], [946, 2256, 1019, 2291], [1035, 2261, 1066, 2285], [1081, 2257, 1180, 2285], [1193, 2257, 1381, 2294], [1395, 2257, 1426, 2285], [1440, 2257, 1530, 2286], [1544, 2257, 1621, 2285], [1643, 2257, 1714, 2285], [1729, 2257, 1795, 2285], [1807, 2257, 1861, 2285], [1875, 2257, 2008, 2294], [2021, 2257, 2099, 2285], [452, 2303, 612, 2331], [624, 2303, 655, 2331], [670, 2303, 731, 2337], [745, 2303, 786, 2340], [797, 2303, 886, 2340], [900, 2303, 1021, 2331], [1033, 2303, 1123, 2332], [1135, 2303, 1245, 2331], [1260, 2312, 1290, 2331], [1303, 2303, 1388, 2340], [1399, 2307, 1430, 2331], [1442, 2303, 1491, 2331], [1503, 2303, 1645, 2337], [1658, 2303, 1711, 2331], [1722, 2303, 1771, 2331], [1781, 2303, 1888, 2331], [1901, 2312, 1980, 2332], [1993, 2303, 2098, 2340], [451, 2348, 562, 2385], [576, 2357, 674, 2377], [688, 2348, 758, 2376], [772, 2348, 858, 2376], [873, 2348, 909, 2376], [920, 2348, 970, 2376], [983, 2348, 1050, 2376], [1063, 2348, 1272, 2376], [1287, 2348, 1412, 2377], [1426, 2348, 1675, 2385], [1694, 2348, 1754, 2382], [1770, 2348, 1832, 2382], [1855, 2349, 1909, 2376], [1923, 2348, 2099, 2385], [452, 2403, 468, 2422], [485, 2394, 626, 2422], [643, 2394, 837, 2422], [853, 2394, 946, 2422], [964, 2403, 1003, 2422], [1021, 2398, 1081, 2423], [1099, 2398, 1233, 2431], [1249, 2394, 1437, 2431], [1456, 2398, 1578, 2422], [1598, 2394, 1718, 2431], [1736, 2394, 1793, 2422], [1810, 2394, 1979, 2431], [1999, 2394, 2099, 2423], [452, 2449, 500, 2468], [514, 2440, 584, 2468], [599, 2440, 761, 2468], [774, 2440, 815, 2477], [830, 2440, 888, 2468], [903, 2440, 1013, 2468], [1038, 2440, 1101, 2468], [1116, 2440, 1222, 2477], [1237, 2444, 1346, 2468], [1359, 2440, 1507, 2477], [1524, 2440, 1623, 2468], [1636, 2440, 1825, 2477], [1839, 2440, 1919, 2468], [1934, 2440, 1994, 2468], [2008, 2440, 2099, 2469], [451, 2485, 570, 2519], [586, 2485, 687, 2514], [699, 2485, 749, 2513], [762, 2485, 908, 2522], [922, 2489, 1031, 2513], [1044, 2485, 1068, 2513], [1083, 2485, 1197, 2513], [1210, 2489, 1241, 2513], [1253, 2485, 1412, 2522], [1426, 2485, 1525, 2513], [1538, 2485, 1618, 2513], [1631, 2485, 1747, 2513], [1760, 2485, 1791, 2513], [1805, 2485, 1854, 2513], [1867, 2485, 1947, 2513], [1960, 2485, 1995, 2513], [2006, 2485, 2099, 2513], [451, 2531, 562, 2568], [574, 2531, 651, 2560], [668, 2531, 747, 2559], [761, 2535, 883, 2559], [898, 2540, 947, 2559], [959, 2531, 1174, 2568], [1187, 2540, 1218, 2559], [1231, 2531, 1403, 2560], [1420, 2531, 1612, 2568], [1624, 2531, 1674, 2559], [1687, 2531, 1793, 2568], [1806, 2531, 1863, 2559], [1875, 2531, 2021, 2568], [2034, 2535, 2097, 2559], [452, 2577, 516, 2605], [531, 2577, 635, 2606], [650, 2586, 684, 2605], [701, 2581, 731, 2605], [746, 2577, 860, 2614], [873, 2577, 923, 2605], [938, 2577, 1120, 2614], [1135, 2577, 1171, 2605], [1183, 2577, 1263, 2614], [1279, 2581, 1415, 2605], [1432, 2577, 1467, 2605], [1480, 2577, 1639, 2605], [1653, 2577, 1754, 2614], [1768, 2577, 1836, 2605], [1849, 2577, 1890, 2614], [1904, 2577, 2099, 2614], [451, 2622, 500, 2650], [516, 2622, 622, 2659], [637, 2626, 687, 2650], [701, 2631, 741, 2650], [757, 2622, 806, 2650], [821, 2623, 984, 2659], [999, 2622, 1156, 2659], [1171, 2622, 1286, 2650], [1303, 2622, 1356, 2656], [1382, 2622, 1446, 2651], [1459, 2622, 1611, 2659], [1627, 2622, 1821, 2650], [1836, 2622, 1860, 2650], [1876, 2622, 1988, 2650], [2004, 2626, 2034, 2650], [2050, 2622, 2099, 2650], [451, 2672, 650, 2697], [662, 2668, 837, 2705], [853, 2668, 905, 2702], [919, 2668, 1080, 2705], [1092, 2672, 1122, 2696], [1134, 2668, 1233, 2697], [1245, 2668, 1294, 2696], [1304, 2668, 1417, 2696], [1428, 2668, 1526, 2697], [1537, 2672, 1638, 2696], [1650, 2668, 1785, 2696], [1798, 2672, 1858, 2697], [1868, 2668, 2033, 2705], [2050, 2668, 2099, 2696], [451, 2714, 564, 2743], [574, 2718, 683, 2742], [693, 2714, 806, 2749], [815, 2714, 963, 2751], [974, 2714, 1075, 2751], [1083, 2714, 1284, 2751], [1296, 2714, 1353, 2742], [1363, 2714, 1412, 2742], [1422, 2714, 1522, 2742], [1533, 2718, 1641, 2742], [1652, 2714, 1764, 2749], [1773, 2714, 1946, 2751], [1958, 2714, 2097, 2749], [451, 2759, 564, 2796], [576, 2768, 623, 2788], [635, 2759, 675, 2787], [687, 2763, 739, 2787], [750, 2759, 926, 2796], [938, 2759, 995, 2787], [1008, 2759, 1189, 2787], [1202, 2768, 1258, 2796], [1271, 2759, 1383, 2787], [1393, 2759, 1472, 2787], [451, 2830, 514, 2858], [529, 2834, 589, 2858], [604, 2830, 640, 2858], [653, 2830, 702, 2858], [717, 2839, 810, 2867], [825, 2830, 850, 2858], [867, 2830, 1026, 2867], [1043, 2839, 1074, 2858], [1091, 2830, 1222, 2859], [1251, 2831, 1283, 2858], [1301, 2830, 1378, 2859], [1400, 2830, 1411, 2858], [1419, 2830, 1442, 2858], [1463, 2839, 1510, 2859], [1524, 2830, 1634, 2859], [1651, 2830, 1700, 2858], [1715, 2830, 1827, 2858], [1844, 2830, 1928, 2859], [1943, 2839, 1983, 2858], [2000, 2830, 2099, 2858], [450, 2876, 638, 2913], [655, 2876, 744, 2913], [761, 2876, 835, 2904], [854, 2876, 979, 2905], [998, 2876, 1056, 2904], [1074, 2876, 1150, 2913], [1170, 2876, 1388, 2904], [1422, 2877, 1455, 2904], [1474, 2876, 1552, 2905], [1572, 2876, 1591, 2904], [1609, 2885, 1656, 2905], [1674, 2876, 1829, 2904], [1847, 2876, 1896, 2904], [1914, 2880, 2099, 2905], [452, 2921, 645, 2949], [664, 2921, 721, 2949], [740, 2921, 857, 2958], [875, 2921, 924, 2949], [943, 2921, 1055, 2958], [1073, 2921, 1228, 2950], [1263, 2921, 1341, 2950], [1361, 2921, 1377, 2950], [1397, 2921, 1567, 2949], [1586, 2921, 1635, 2949], [1653, 2921, 1810, 2958], [1828, 2921, 1975, 2950], [1993, 2921, 2050, 2949], [2068, 2921, 2099, 2949], [450, 2967, 609, 3004], [620, 2967, 690, 2996], [703, 2967, 726, 2995], [738, 2967, 922, 3004], [936, 2967, 986, 2995], [998, 2967, 1138, 3004], [1153, 2967, 1361, 2995], [1375, 2967, 1524, 2996], [1538, 2967, 1568, 2995], [1583, 2967, 1660, 2996], [1679, 2967, 1690, 2995], [1698, 2967, 1721, 2995], [1729, 2991, 1734, 2995], [1754, 2967, 1782, 2995], [1796, 2967, 1952, 2995], [1964, 2967, 2099, 3004], [451, 3013, 630, 3042], [646, 3013, 671, 3041], [689, 3013, 856, 3050], [873, 3013, 904, 3041], [922, 3013, 999, 3042], [1018, 3013, 1037, 3041], [1054, 3013, 1084, 3041], [1101, 3013, 1188, 3041], [1204, 3017, 1235, 3041], [1253, 3013, 1341, 3042], [1358, 3013, 1508, 3041], [1527, 3013, 1733, 3041], [1749, 3013, 1785, 3041], [1799, 3013, 1927, 3050], [1944, 3013, 2011, 3041], [2028, 3022, 2100, 3042], [1269, 3137, 1280, 3165], [97, 2265, 134, 2308], [97, 2235, 133, 2272], [83, 2188, 133, 2246], [83, 2162, 133, 2184], [98, 2117, 133, 2164], [103, 2102, 134, 2113], [82, 2058, 133, 2089], [82, 2008, 133, 2054], [82, 1969, 134, 2010], [82, 1926, 134, 1968], [125, 1913, 134, 1924], [82, 1867, 133, 1906], [82, 1829, 133, 1860], [82, 1781, 134, 1823], [82, 1740, 134, 1782], [98, 1698, 133, 1745], [82, 1658, 133, 1697], [81, 1594, 142, 1613], [97, 1549, 134, 1588], [97, 1517, 134, 1550], [125, 1504, 134, 1515], [82, 1443, 134, 1497], [83, 1385, 133, 1447], [81, 1361, 142, 1380], [82, 1276, 133, 1307], [82, 1230, 133, 1269], [83, 1144, 134, 1209], [97, 1106, 134, 1148], [98, 1064, 133, 1111], [82, 1003, 133, 1042], [82, 960, 134, 1001], [82, 924, 133, 955], [82, 874, 133, 920], [451, 354, 587, 391], [604, 354, 742, 382], [772, 354, 1033, 391], [1050, 354, 1155, 382], [1174, 363, 1223, 382], [1239, 354, 1328, 391], [1344, 354, 1375, 382], [1393, 354, 1470, 383], [1488, 353, 1516, 388], [1537, 354, 1594, 382], [1611, 354, 1660, 382], [1675, 354, 1885, 391], [1901, 354, 1925, 382], [1944, 354, 2099, 383], [451, 400, 481, 428], [495, 400, 572, 429], [586, 400, 604, 429], [619, 400, 676, 428], [689, 400, 851, 437], [864, 404, 894, 428], [907, 400, 956, 428], [969, 404, 1043, 428], [1055, 400, 1091, 428], [1101, 400, 1150, 428], [1164, 404, 1213, 428], [1231, 400, 1295, 429], [1307, 400, 1506, 437], [1520, 409, 1560, 428], [1572, 404, 1633, 429], [1645, 400, 1837, 437], [1850, 400, 1978, 428], [1993, 400, 2098, 435], [455, 445, 507, 474], [529, 445, 590, 479], [609, 445, 667, 473], [682, 444, 856, 474], [878, 445, 955, 480], [972, 445, 1056, 474], [1071, 445, 1133, 473], [1147, 445, 1196, 473], [1210, 449, 1271, 474], [1285, 445, 1473, 482], [1489, 449, 1612, 473], [1629, 454, 1677, 473], [1692, 445, 1955, 482], [1973, 445, 2030, 473], [2045, 454, 2100, 473], [451, 491, 527, 528], [543, 491, 736, 519], [751, 491, 954, 528], [968, 491, 1168, 528], [1184, 491, 1245, 519], [1259, 491, 1294, 519], [1309, 491, 1370, 525], [1389, 491, 1446, 519], [1460, 491, 1485, 519], [1501, 491, 1693, 528], [1707, 491, 1780, 520], [1794, 491, 1843, 519], [1858, 495, 1932, 519], [1946, 491, 1982, 519], [1993, 491, 2043, 519], [2058, 495, 2100, 519], [452, 537, 577, 566], [588, 537, 837, 574], [854, 537, 913, 571], [927, 537, 975, 571], [989, 537, 1040, 571], [1055, 537, 1085, 565], [1098, 537, 1174, 574], [1186, 537, 1222, 565], [1230, 537, 1322, 574], [1334, 537, 1447, 565], [1459, 546, 1499, 565], [1510, 537, 1665, 574], [1678, 537, 1765, 565], [1777, 537, 1916, 565], [453, 606, 499, 636], [544, 607, 678, 636], [690, 607, 781, 636], [451, 678, 548, 706], [560, 678, 749, 715], [761, 678, 899, 706], [911, 678, 964, 706], [978, 678, 1056, 706], [1070, 678, 1182, 715], [1196, 678, 1299, 707], [1311, 678, 1352, 715], [1366, 678, 1415, 706], [1429, 678, 1576, 707], [1591, 678, 1622, 706], [1635, 678, 1735, 715], [1748, 678, 1936, 715], [1949, 678, 2097, 712], [451, 724, 550, 753], [567, 733, 646, 753], [662, 724, 746, 752], [763, 724, 890, 761], [907, 724, 965, 752], [981, 724, 1129, 752], [1145, 728, 1176, 752], [1192, 724, 1260, 752], [1276, 724, 1348, 753], [1365, 724, 1455, 753], [1472, 724, 1548, 752], [1578, 724, 1606, 752], [1623, 724, 1703, 761], [1720, 724, 1826, 761], [1843, 724, 1878, 752], [1892, 724, 1982, 753], [2000, 724, 2099, 752], [450, 769, 638, 806], [651, 769, 789, 797], [804, 769, 828, 797], [842, 769, 936, 797], [949, 778, 989, 797], [1004, 769, 1129, 798], [1142, 769, 1432, 806], [1445, 769, 1610, 806], [1625, 769, 1661, 797], [1671, 769, 1750, 797], [1765, 769, 2023, 806], [2036, 769, 2098, 797], [451, 819, 538, 843], [554, 816, 610, 843], [621, 815, 764, 849], [777, 815, 826, 843], [838, 815, 997, 852], [1007, 815, 1043, 843], [1054, 815, 1116, 849], [1130, 815, 1258, 843], [1271, 815, 1301, 843], [1312, 815, 1463, 852], [1475, 824, 1576, 852], [1588, 815, 1846, 852], [1857, 815, 1979, 843], [1988, 815, 2097, 852], [451, 861, 550, 890], [568, 870, 617, 889], [633, 861, 703, 889], [720, 861, 878, 889], [894, 861, 983, 898], [1000, 861, 1079, 889], [1097, 861, 1355, 898], [1372, 861, 1510, 889], [1538, 861, 1712, 898], [1729, 861, 1764, 889], [1778, 861, 1922, 890], [1939, 861, 2097, 890], [452, 906, 565, 941], [584, 907, 624, 940], [643, 906, 700, 934], [715, 906, 889, 943], [903, 906, 938, 934], [950, 906, 1071, 943], [1085, 906, 1167, 935], [1183, 906, 1300, 941], [1316, 906, 1379, 934], [1393, 906, 1521, 934], [1538, 915, 1587, 934], [1601, 906, 1671, 934], [1685, 906, 1822, 934], [1836, 906, 1899, 934], [1914, 906, 1963, 934], [1977, 907, 2042, 943], [2057, 906, 2102, 935], [451, 953, 588, 980], [603, 952, 698, 987], [711, 952, 954, 989], [968, 952, 1068, 981], [1080, 952, 1104, 980], [1117, 952, 1229, 989], [1242, 961, 1314, 981], [1326, 952, 1439, 981], [1452, 952, 1711, 989], [1723, 952, 1803, 989], [1817, 952, 1976, 989], [1988, 956, 2019, 980], [2032, 961, 2098, 989], [451, 998, 502, 1026], [513, 998, 651, 1035], [662, 998, 801, 1035], [816, 998, 873, 1026], [886, 998, 1047, 1026], [1060, 998, 1132, 1027], [1146, 1007, 1182, 1026], [1196, 998, 1283, 1027], [1296, 998, 1448, 1026], [1466, 999, 1498, 1026], [1512, 1007, 1528, 1026], [1540, 998, 1613, 1026], [1625, 998, 1709, 1027], [1724, 998, 1797, 1032], [1811, 998, 1834, 1026], [1845, 1007, 1906, 1027], [1921, 998, 2026, 1027], [2038, 998, 2100, 1026], [451, 1043, 544, 1071], [556, 1043, 706, 1080], [718, 1043, 754, 1071], [763, 1043, 842, 1071], [854, 1043, 982, 1071], [996, 1043, 1196, 1080], [1210, 1052, 1311, 1080], [1323, 1043, 1445, 1071], [1455, 1043, 1564, 1080], [451, 1114, 569, 1142], [587, 1114, 623, 1142], [638, 1114, 814, 1151], [832, 1114, 911, 1142], [929, 1114, 1020, 1143], [1038, 1114, 1166, 1142], [1186, 1123, 1257, 1143], [1276, 1114, 1534, 1151], [1552, 1114, 1688, 1148], [1710, 1114, 1955, 1142], [1973, 1114, 2099, 1143], [451, 1159, 541, 1188], [558, 1159, 807, 1196], [829, 1159, 889, 1193], [908, 1159, 957, 1193], [976, 1159, 1027, 1193], [1048, 1159, 1136, 1187], [1152, 1168, 1207, 1187], [1225, 1159, 1261, 1187], [1276, 1159, 1369, 1187], [1385, 1159, 1471, 1196], [1488, 1159, 1679, 1196], [1713, 1159, 1776, 1187], [1795, 1159, 1953, 1196], [1974, 1159, 2038, 1187], [2054, 1159, 2098, 1187], [451, 1205, 594, 1233], [610, 1205, 641, 1233], [660, 1205, 733, 1239], [751, 1205, 880, 1233], [897, 1205, 928, 1233], [945, 1205, 1094, 1242], [1110, 1205, 1189, 1233], [1205, 1205, 1370, 1242], [1386, 1209, 1509, 1242], [1523, 1205, 1653, 1242], [1672, 1214, 1707, 1233], [1723, 1205, 1784, 1233], [1799, 1205, 1868, 1242], [1884, 1205, 1990, 1234], [2006, 1205, 2099, 1233], [451, 1251, 642, 1288], [662, 1251, 824, 1288], [840, 1251, 929, 1288], [946, 1251, 1058, 1288], [1075, 1251, 1152, 1280], [1183, 1251, 1246, 1279], [1262, 1251, 1329, 1279], [1344, 1251, 1553, 1288], [1570, 1251, 1601, 1279], [1618, 1251, 1667, 1279], [1684, 1251, 1950, 1288], [1966, 1251, 2099, 1288], [451, 1305, 511, 1325], [530, 1296, 673, 1325], [688, 1296, 729, 1333], [745, 1296, 794, 1324], [810, 1296, 931, 1324], [947, 1296, 1109, 1333], [1125, 1296, 1299, 1333], [1316, 1296, 1434, 1331], [1454, 1296, 1507, 1330], [1525, 1296, 1625, 1325], [1641, 1296, 1666, 1324], [1684, 1305, 1700, 1324], [1716, 1296, 1959, 1333], [1975, 1296, 2097, 1330], [452, 1342, 617, 1379], [632, 1342, 793, 1379], [808, 1351, 848, 1370], [862, 1342, 912, 1370], [925, 1342, 1093, 1370], [1108, 1342, 1165, 1370], [1179, 1342, 1302, 1371], [1316, 1346, 1514, 1379], [1529, 1342, 1565, 1370], [1577, 1342, 1688, 1379], [1703, 1342, 1780, 1371], [1803, 1342, 1831, 1370], [1846, 1342, 2051, 1370], [2066, 1342, 2102, 1370], [452, 1388, 565, 1417], [578, 1388, 706, 1416], [720, 1397, 781, 1417], [796, 1388, 901, 1417], [914, 1392, 944, 1416], [957, 1388, 1069, 1416], [1080, 1388, 1171, 1416], [1182, 1388, 1232, 1416], [1245, 1397, 1395, 1425], [1414, 1389, 1528, 1416], [1540, 1388, 1773, 1425], [1787, 1388, 1823, 1416], [1833, 1388, 2099, 1425], [450, 1433, 658, 1461], [671, 1433, 920, 1470], [935, 1433, 1055, 1461], [1068, 1433, 1297, 1470], [1310, 1433, 1346, 1461], [1357, 1433, 1459, 1470], [1473, 1433, 1617, 1468], [1631, 1433, 1747, 1461], [1763, 1433, 1822, 1467], [1841, 1433, 1886, 1467], [1901, 1433, 1963, 1467], [1979, 1433, 2036, 1461], [2050, 1433, 2099, 1461], [450, 1488, 504, 1507], [516, 1479, 552, 1507], [561, 1479, 610, 1507], [622, 1479, 725, 1507], [736, 1483, 839, 1508], [850, 1479, 1000, 1516], [1015, 1479, 1077, 1513], [1093, 1479, 1136, 1514], [1152, 1479, 1229, 1514], [1242, 1488, 1276, 1507], [1287, 1479, 1323, 1507], [1336, 1479, 1446, 1516], [1457, 1479, 1571, 1508], [1585, 1479, 1646, 1513], [1663, 1479, 1706, 1514], [1721, 1479, 1808, 1514], [451, 1550, 546, 1578], [559, 1550, 612, 1578], [628, 1550, 692, 1578], [705, 1550, 783, 1578], [798, 1559, 814, 1578], [828, 1550, 954, 1578], [967, 1550, 1003, 1578], [1015, 1554, 1151, 1587], [1167, 1554, 1197, 1578], [1211, 1550, 1339, 1587], [1354, 1559, 1370, 1578], [1384, 1550, 1460, 1587], [1476, 1550, 1669, 1578], [1683, 1550, 1730, 1578], [1743, 1550, 1834, 1579], [1847, 1550, 2044, 1587], [2066, 1551, 2099, 1578], [451, 1595, 500, 1623], [513, 1595, 652, 1632], [665, 1595, 701, 1623], [711, 1595, 795, 1623], [808, 1595, 916, 1629], [931, 1595, 981, 1623], [994, 1595, 1079, 1632], [1091, 1599, 1121, 1623], [1135, 1595, 1184, 1623], [1197, 1595, 1332, 1624], [1344, 1595, 1369, 1623], [1384, 1604, 1400, 1623], [1414, 1595, 1498, 1623], [1510, 1595, 1546, 1623], [1556, 1595, 1749, 1624], [1762, 1595, 1853, 1624], [1866, 1595, 1986, 1629], [2002, 1604, 2036, 1623], [2050, 1595, 2099, 1623], [451, 1641, 553, 1669], [566, 1641, 591, 1669], [606, 1641, 751, 1678], [765, 1645, 795, 1669], [809, 1641, 969, 1678], [983, 1641, 1064, 1669], [1078, 1641, 1337, 1678], [1350, 1641, 1652, 1678], [1664, 1641, 1792, 1669], [1807, 1641, 1838, 1669], [1852, 1641, 1901, 1669], [1914, 1641, 1978, 1669], [1991, 1641, 2097, 1678], [451, 1687, 550, 1716], [565, 1696, 621, 1715], [635, 1687, 673, 1715], [689, 1696, 705, 1715], [719, 1687, 849, 1715], [863, 1687, 937, 1715], [961, 1688, 993, 1715], [1011, 1687, 1084, 1721], [1102, 1696, 1139, 1715], [1154, 1687, 1278, 1715], [1295, 1687, 1488, 1715], [1502, 1687, 1550, 1715], [1564, 1687, 1654, 1716], [1668, 1687, 1856, 1724], [1871, 1696, 1932, 1716], [1947, 1687, 2099, 1724], [451, 1732, 523, 1761], [535, 1732, 723, 1769], [737, 1732, 995, 1769], [1008, 1732, 1100, 1760], [1114, 1732, 1145, 1760], [1158, 1732, 1207, 1760], [1220, 1732, 1284, 1760], [1296, 1732, 1384, 1769], [1403, 1733, 1496, 1766], [1511, 1732, 1534, 1760], [1546, 1741, 1607, 1761], [1621, 1732, 1783, 1760], [1799, 1732, 1861, 1766], [1877, 1732, 1949, 1761], [1963, 1741, 1979, 1760], [1993, 1732, 2099, 1769], [451, 1778, 575, 1806], [591, 1778, 702, 1812], [720, 1778, 786, 1806], [804, 1778, 936, 1815], [952, 1778, 1058, 1815], [1075, 1778, 1289, 1813], [1307, 1778, 1364, 1806], [1380, 1778, 1526, 1815], [1542, 1778, 1743, 1813], [1759, 1778, 1948, 1815], [1964, 1782, 2097, 1806], [451, 1824, 562, 1853], [577, 1833, 632, 1852], [647, 1824, 739, 1858], [756, 1824, 902, 1858], [921, 1824, 970, 1852], [987, 1828, 1109, 1852], [1127, 1833, 1206, 1853], [1221, 1824, 1436, 1861], [1453, 1833, 1484, 1852], [1500, 1824, 1709, 1852], [1726, 1824, 1783, 1852], [1798, 1824, 1895, 1852], [1911, 1824, 2036, 1853], [2053, 1824, 2098, 1859], [451, 1869, 544, 1906], [561, 1869, 686, 1897], [701, 1869, 828, 1897], [853, 1870, 886, 1897], [905, 1869, 943, 1903], [964, 1869, 1008, 1903], [1025, 1868, 1088, 1903], [1106, 1878, 1122, 1897], [1137, 1869, 1361, 1898], [1376, 1870, 1467, 1897], [1483, 1869, 1540, 1897], [1556, 1869, 1620, 1898], [1636, 1878, 1715, 1898], [1729, 1869, 1804, 1897], [1820, 1869, 1867, 1897], [1880, 1869, 2099, 1906], [451, 1915, 585, 1952], [596, 1915, 631, 1943], [640, 1915, 898, 1952], [909, 1915, 1047, 1949], [1060, 1915, 1159, 1944], [1170, 1924, 1249, 1944], [1260, 1915, 1330, 1943], [1339, 1915, 1472, 1952], [1483, 1915, 1546, 1943], [1558, 1924, 1574, 1943], [1584, 1915, 1818, 1944], [1829, 1915, 1931, 1943], [1942, 1915, 1989, 1943], [2000, 1915, 2099, 1943], [451, 1961, 674, 1989], [703, 1961, 947, 1990], [963, 1961, 1141, 1989], [1157, 1961, 1292, 1998], [1308, 1961, 1344, 1989], [1357, 1961, 1448, 1990], [1464, 1961, 1625, 1990], [1642, 1961, 1695, 1989], [1712, 1961, 1790, 1989], [1807, 1961, 1968, 1989], [1984, 1961, 2015, 1989], [2034, 1961, 2096, 1995], [452, 2006, 517, 2040], [537, 2015, 621, 2034], [636, 2006, 775, 2043], [794, 2006, 825, 2034], [844, 2006, 917, 2040], [936, 2006, 1006, 2035], [1023, 2006, 1185, 2043], [1202, 2006, 1315, 2035], [1332, 2006, 1480, 2035], [1496, 2006, 1704, 2034], [1722, 2006, 1769, 2034], [1786, 2006, 1885, 2034], [1900, 2006, 2097, 2043], [451, 2052, 590, 2089], [605, 2061, 666, 2081], [683, 2052, 796, 2080], [812, 2056, 864, 2080], [878, 2061, 918, 2080], [934, 2061, 950, 2080], [965, 2061, 1036, 2089], [1051, 2052, 1132, 2089], [1148, 2052, 1323, 2089], [1338, 2052, 1460, 2086], [1478, 2052, 1663, 2089], [1682, 2052, 1765, 2080], [1780, 2052, 1929, 2080], [1944, 2052, 2049, 2081], [2066, 2052, 2102, 2080], [452, 2102, 547, 2135], [566, 2098, 721, 2127], [753, 2098, 967, 2135], [989, 2098, 1050, 2132], [1070, 2098, 1165, 2126], [1183, 2098, 1244, 2126], [1262, 2107, 1278, 2126], [1294, 2098, 1437, 2132], [1457, 2098, 1612, 2135], [1630, 2107, 1669, 2126], [1687, 2098, 1852, 2127], [1869, 2098, 1960, 2127], [1977, 2098, 2097, 2132], [450, 2143, 597, 2180], [618, 2143, 763, 2180], [781, 2147, 811, 2171], [829, 2143, 879, 2171], [897, 2143, 1055, 2177], [1077, 2143, 1181, 2172], [1199, 2143, 1284, 2180], [1301, 2143, 1325, 2171], [1346, 2152, 1362, 2171], [1381, 2143, 1464, 2171], [1482, 2143, 1517, 2171], [1533, 2143, 1653, 2171], [1687, 2143, 1758, 2171], [1777, 2143, 1873, 2180], [1890, 2143, 2020, 2171], [2038, 2143, 2100, 2171], [451, 2189, 500, 2217], [513, 2189, 607, 2217], [621, 2189, 879, 2226], [893, 2189, 1021, 2217], [1036, 2189, 1076, 2217], [1090, 2193, 1143, 2217], [1155, 2193, 1276, 2226], [1290, 2189, 1339, 2217], [1353, 2189, 1469, 2217], [1483, 2189, 1561, 2218], [1583, 2189, 1646, 2217], [1660, 2189, 1753, 2217], [1765, 2189, 2008, 2226], [2024, 2189, 2098, 2217], [451, 2235, 541, 2263], [553, 2244, 593, 2263], [605, 2235, 655, 2263], [667, 2235, 818, 2264], [834, 2235, 956, 2269], [970, 2235, 1075, 2263], [1087, 2239, 1139, 2263], [1151, 2239, 1181, 2263], [1192, 2235, 1231, 2263], [1244, 2232, 1316, 2265], [1330, 2235, 1389, 2263], [1404, 2239, 1539, 2263], [1551, 2235, 1621, 2263], [1633, 2235, 1842, 2263], [1855, 2235, 2100, 2263], [451, 2280, 716, 2317], [727, 2280, 962, 2317], [977, 2280, 1036, 2314], [1050, 2280, 1112, 2314], [451, 2351, 514, 2380], [531, 2351, 677, 2388], [695, 2355, 803, 2379], [820, 2351, 968, 2380], [984, 2355, 1119, 2388], [1138, 2360, 1177, 2379], [1195, 2351, 1442, 2388], [1459, 2351, 1552, 2379], [1569, 2351, 1681, 2388], [1698, 2351, 1775, 2385], [1795, 2351, 1895, 2380], [1912, 2351, 1937, 2379], [1955, 2351, 2099, 2388], [451, 2396, 612, 2433], [629, 2396, 659, 2424], [677, 2405, 713, 2424], [730, 2405, 840, 2433], [856, 2396, 1074, 2424], [1090, 2396, 1270, 2425], [1285, 2396, 1325, 2433], [1343, 2396, 1462, 2433], [1479, 2396, 1526, 2424], [1543, 2405, 1559, 2424], [1575, 2396, 1793, 2433], [1808, 2396, 1880, 2424], [1898, 2396, 2054, 2433], [2072, 2400, 2100, 2424], [451, 2442, 587, 2479], [603, 2442, 703, 2479], [719, 2442, 838, 2477], [863, 2443, 917, 2470], [931, 2442, 1006, 2470], [1023, 2451, 1039, 2470], [1053, 2442, 1180, 2479], [1194, 2442, 1317, 2470], [1333, 2442, 1368, 2470], [1384, 2442, 1436, 2476], [1454, 2442, 1554, 2471], [1569, 2442, 1744, 2470], [1760, 2442, 1810, 2470], [1825, 2451, 1935, 2479], [1950, 2442, 2044, 2470], [2059, 2451, 2099, 2470], [451, 2492, 614, 2525], [625, 2488, 827, 2525], [838, 2488, 886, 2516], [895, 2488, 1036, 2525], [1048, 2488, 1105, 2516], [1115, 2488, 1151, 2516], [1163, 2488, 1306, 2525], [1319, 2497, 1349, 2516], [1361, 2488, 1431, 2517], [1442, 2497, 1473, 2516], [1485, 2488, 1675, 2516], [1686, 2488, 1722, 2516], [1730, 2488, 1779, 2516], [1789, 2488, 2007, 2525], [2016, 2488, 2097, 2516], [451, 2533, 602, 2570], [620, 2533, 681, 2567], [696, 2533, 847, 2570], [861, 2542, 897, 2561], [910, 2533, 1010, 2570], [1022, 2533, 1111, 2570], [1124, 2533, 1276, 2570], [1290, 2533, 1421, 2567], [1435, 2533, 1535, 2562], [1547, 2533, 1572, 2561], [1585, 2533, 1779, 2561], [1791, 2533, 1827, 2561], [1836, 2533, 1913, 2570], [1926, 2533, 2097, 2567], [450, 2579, 502, 2607], [513, 2579, 586, 2607], [600, 2583, 652, 2607], [663, 2579, 851, 2616], [862, 2579, 1005, 2616], [451, 2656, 474, 2690], [526, 2656, 776, 2691], [790, 2656, 1046, 2691], [1061, 2656, 1122, 2691], [1135, 2656, 1247, 2691], [1261, 2656, 1499, 2700], [451, 2737, 548, 2765], [562, 2746, 617, 2765], [631, 2737, 777, 2774], [790, 2737, 829, 2765], [842, 2737, 1048, 2774], [1062, 2737, 1125, 2765], [1140, 2737, 1246, 2774], [1260, 2737, 1318, 2765], [1332, 2737, 1478, 2774], [1491, 2741, 1699, 2774], [1721, 2737, 1784, 2765], [1798, 2737, 1904, 2774], [1917, 2741, 1989, 2774], [2005, 2737, 2036, 2765], [2050, 2737, 2099, 2765], [451, 2783, 530, 2811], [544, 2783, 580, 2811], [591, 2783, 757, 2812], [771, 2783, 866, 2811], [882, 2792, 1074, 2820], [1091, 2783, 1198, 2811], [1214, 2783, 1408, 2811], [1424, 2783, 1514, 2811], [1529, 2792, 1633, 2811], [1650, 2783, 1707, 2811], [1721, 2783, 1836, 2820], [1852, 2783, 1990, 2820], [2005, 2783, 2035, 2811], [2050, 2783, 2099, 2811], [451, 2828, 550, 2857], [575, 2828, 638, 2856], [653, 2828, 799, 2865], [813, 2832, 885, 2865], [903, 2828, 933, 2856], [948, 2828, 998, 2856], [1012, 2828, 1092, 2856], [1106, 2828, 1142, 2856], [1154, 2828, 1270, 2856], [1286, 2837, 1386, 2856], [1402, 2828, 1452, 2856], [1467, 2828, 1586, 2862], [1604, 2837, 1734, 2865], [1750, 2828, 1800, 2856], [1815, 2832, 1988, 2857], [2002, 2828, 2038, 2856], [2050, 2828, 2099, 2856], [451, 2874, 592, 2903], [608, 2874, 670, 2909], [685, 2874, 816, 2909], [833, 2874, 891, 2902], [906, 2874, 956, 2902], [971, 2874, 1095, 2911], [1121, 2875, 1175, 2902], [1190, 2874, 1294, 2903], [1309, 2883, 1363, 2902], [1378, 2874, 1469, 2903], [1483, 2874, 1672, 2911], [1688, 2874, 1882, 2902], [1898, 2874, 2097, 2911], [451, 2920, 586, 2957], [598, 2920, 620, 2948], [631, 2920, 694, 2948], [705, 2924, 765, 2949], [778, 2924, 911, 2954], [925, 2929, 956, 2948], [970, 2920, 1074, 2949], [1086, 2920, 1116, 2948], [1128, 2920, 1191, 2957], [1208, 2920, 1219, 2948], [1227, 2944, 1232, 2948], [1248, 2920, 1329, 2948], [1342, 2924, 1450, 2948], [1461, 2920, 1486, 2948], [1499, 2920, 1714, 2957], [1724, 2920, 1814, 2957], [1826, 2929, 1842, 2948], [1854, 2920, 1930, 2957], [1942, 2920, 2097, 2954], [452, 2965, 582, 2993], [597, 2974, 696, 2993], [711, 2965, 747, 2993], [757, 2965, 857, 2994], [872, 2974, 920, 2993], [933, 2965, 1095, 2993], [1107, 2965, 1148, 3002], [1161, 2965, 1220, 2993], [1233, 2965, 1344, 2993], [1363, 2966, 1416, 2993], [1430, 2965, 1569, 2993], [1582, 2969, 1642, 2994], [1655, 2965, 1757, 2993], [1771, 2965, 1918, 2993], [1939, 2965, 2099, 3002], [452, 3011, 509, 3039], [521, 3011, 648, 3048], [661, 3020, 677, 3039], [689, 3011, 868, 3039], [882, 3011, 975, 3039], [988, 3011, 1075, 3040], [1090, 3011, 1131, 3045], [1146, 3020, 1185, 3039], [1199, 3011, 1320, 3039], [1333, 3011, 1374, 3045], [1380, 3011, 1575, 3039], [1589, 3011, 1720, 3039], [1733, 3020, 1832, 3039], [1847, 3020, 1877, 3039], [1891, 3011, 2029, 3039], [1265, 3137, 1284, 3165], [990, 423, 1064, 442], [991, 453, 1064, 471], [989, 481, 1044, 499], [1053, 481, 1063, 499], [999, 515, 1055, 528], [985, 538, 1026, 561], [1035, 538, 1069, 556], [1104, 423, 1178, 442], [1098, 453, 1184, 471], [1103, 481, 1158, 499], [1167, 481, 1177, 499], [1112, 515, 1168, 528], [1098, 538, 1140, 561], [1148, 538, 1183, 556], [1217, 423, 1291, 442], [1212, 453, 1296, 471], [1216, 481, 1271, 499], [1282, 482, 1291, 499], [1331, 423, 1405, 442], [1325, 453, 1410, 471], [1330, 481, 1385, 499], [1395, 482, 1404, 499], [1444, 423, 1519, 442], [1439, 453, 1523, 471], [1444, 481, 1499, 499], [1509, 482, 1518, 499], [1439, 510, 1481, 533], [1489, 510, 1523, 528], [1568, 422, 1621, 442], [1569, 453, 1620, 471], [1556, 481, 1635, 504], [1681, 422, 1735, 442], [1683, 453, 1733, 471], [1669, 481, 1749, 504], [1773, 422, 1871, 442], [990, 683, 1064, 702], [991, 713, 1064, 731], [989, 741, 1044, 759], [1053, 741, 1063, 759], [999, 775, 1055, 788], [985, 798, 1026, 821], [1035, 798, 1069, 816], [1104, 683, 1178, 702], [1098, 713, 1184, 731], [1103, 741, 1158, 759], [1167, 741, 1177, 759], [1098, 770, 1140, 793], [1148, 770, 1183, 788], [1217, 683, 1291, 702], [1212, 713, 1296, 731], [1216, 741, 1271, 759], [1282, 742, 1291, 759], [1331, 683, 1405, 702], [1325, 713, 1410, 731], [1330, 741, 1385, 759], [1395, 742, 1404, 759], [1444, 683, 1519, 702], [1439, 713, 1523, 731], [1444, 741, 1499, 759], [1509, 742, 1518, 759], [1439, 770, 1481, 793], [1489, 770, 1523, 788], [1568, 682, 1621, 702], [1569, 713, 1620, 731], [1556, 741, 1635, 764], [1681, 682, 1735, 702], [1683, 713, 1733, 731], [1669, 741, 1749, 764], [1773, 682, 1871, 702], [1163, 353, 1312, 399], [1330, 356, 1479, 390], [1498, 354, 1691, 390], [1133, 605, 1339, 651], [1357, 608, 1507, 642], [1525, 606, 1718, 642], [779, 545, 853, 571], [860, 545, 931, 565], [587, 767, 651, 792], [585, 799, 652, 819], [785, 789, 926, 809], [784, 820, 866, 845], [874, 820, 926, 840], [1937, 546, 1999, 566], [1935, 582, 2003, 597], [1930, 609, 2006, 629], [769, 870, 876, 907], [891, 870, 915, 898], [933, 870, 1141, 899], [1153, 869, 1367, 899], [1379, 869, 1429, 899], [1441, 869, 1534, 899], [1546, 869, 1780, 899], [451, 939, 574, 977], [586, 942, 706, 969], [719, 939, 872, 969], [884, 944, 1019, 977], [1032, 949, 1072, 968], [1085, 940, 1250, 969], [1263, 940, 1353, 969], [1366, 940, 1485, 974], [1500, 940, 1673, 977], [1684, 940, 1870, 977], [1883, 940, 1982, 968], [1994, 949, 2098, 977], [451, 986, 546, 1014], [562, 986, 642, 1014], [659, 986, 719, 1014], [735, 986, 860, 1023], [889, 986, 952, 1014], [970, 986, 1054, 1014], [1072, 995, 1256, 1023], [1272, 986, 1313, 1023], [1329, 986, 1413, 1014], [1427, 986, 1452, 1014], [1471, 995, 1487, 1014], [1502, 986, 1603, 1014], [1619, 986, 1695, 1020], [1716, 986, 1799, 1014], [1816, 995, 1901, 1014], [1918, 986, 2032, 1014], [2051, 995, 2099, 1014], [452, 1032, 585, 1069], [598, 1032, 766, 1060], [779, 1032, 851, 1061], [863, 1032, 1022, 1069], [1033, 1032, 1158, 1069], [1176, 1033, 1209, 1060], [1221, 1032, 1290, 1066], [1305, 1041, 1336, 1060], [1350, 1032, 1413, 1061], [1424, 1032, 1463, 1060], [1476, 1032, 1581, 1061], [1593, 1032, 1624, 1060], [1638, 1032, 1715, 1061], [1729, 1032, 1757, 1066], [1772, 1032, 1871, 1060], [1884, 1032, 2099, 1060], [451, 1077, 530, 1105], [546, 1077, 606, 1105], [621, 1077, 731, 1105], [749, 1077, 811, 1112], [827, 1077, 933, 1114], [947, 1077, 1135, 1114], [1152, 1077, 1273, 1112], [1289, 1077, 1314, 1105], [1331, 1077, 1418, 1114], [1434, 1077, 1627, 1114], [1642, 1086, 1682, 1105], [1697, 1077, 1733, 1105], [1750, 1086, 1828, 1106], [1855, 1077, 1945, 1106], [1961, 1086, 1977, 1105], [1993, 1077, 2099, 1114], [451, 1123, 598, 1152], [611, 1123, 635, 1151], [651, 1123, 824, 1160], [839, 1132, 876, 1151], [889, 1123, 989, 1160], [1003, 1123, 1218, 1151], [1233, 1123, 1435, 1157], [1451, 1132, 1498, 1152], [1511, 1132, 1567, 1151], [1580, 1123, 1664, 1151], [1677, 1132, 1759, 1160], [1773, 1123, 1822, 1151], [1835, 1127, 1937, 1151], [1950, 1123, 2097, 1152], [451, 1169, 481, 1197], [492, 1169, 670, 1206], [680, 1169, 780, 1206], [790, 1169, 978, 1206], [989, 1169, 1127, 1197], [1142, 1168, 1215, 1203], [1229, 1169, 1286, 1197], [1296, 1169, 1438, 1206], [1449, 1169, 1499, 1197], [1509, 1169, 1644, 1198], [1654, 1178, 1694, 1197], [1706, 1178, 1722, 1197], [1732, 1169, 1813, 1206], [1824, 1169, 1924, 1206], [1935, 1169, 2098, 1197], [451, 1214, 513, 1242], [526, 1214, 648, 1248], [664, 1214, 737, 1242], [751, 1223, 781, 1242], [795, 1214, 845, 1242], [857, 1215, 1020, 1251], [1032, 1214, 1189, 1251], [1202, 1214, 1324, 1242], [1342, 1214, 1405, 1242], [1418, 1214, 1523, 1242], [1538, 1223, 1586, 1242], [1598, 1214, 1756, 1251], [1769, 1214, 1799, 1242], [1813, 1214, 1890, 1243], [1905, 1213, 1922, 1243], [1928, 1238, 1933, 1242], [1951, 1215, 2038, 1248], [2052, 1223, 2099, 1243], [451, 1260, 587, 1288], [599, 1260, 648, 1288], [660, 1260, 806, 1297], [819, 1264, 928, 1288], [939, 1260, 1095, 1294], [1108, 1260, 1208, 1289], [1220, 1260, 1348, 1297], [1361, 1260, 1477, 1288], [1490, 1260, 1548, 1288], [1561, 1260, 1763, 1297], [1775, 1260, 1925, 1297], [1940, 1269, 2090, 1297], [451, 1337, 473, 1372], [526, 1337, 681, 1381], [695, 1337, 782, 1372], [797, 1337, 999, 1372], [451, 1419, 483, 1446], [497, 1418, 553, 1446], [569, 1418, 693, 1452], [708, 1427, 755, 1447], [768, 1418, 905, 1446], [919, 1427, 935, 1446], [948, 1418, 1095, 1447], [1107, 1418, 1218, 1452], [1233, 1418, 1333, 1447], [1346, 1418, 1440, 1446], [1455, 1418, 1504, 1446], [1517, 1418, 1663, 1455], [1675, 1418, 1864, 1455], [1878, 1422, 1986, 1446], [1999, 1418, 2035, 1446], [2045, 1427, 2100, 1446], [452, 1463, 645, 1491], [659, 1463, 750, 1498], [765, 1463, 807, 1498], [826, 1463, 938, 1492], [951, 1463, 1000, 1491], [1013, 1463, 1161, 1492], [1173, 1463, 1300, 1497], [1314, 1463, 1463, 1492], [1476, 1463, 1507, 1491], [1521, 1463, 1599, 1492], [1618, 1463, 1672, 1497], [1688, 1463, 1737, 1491], [1750, 1463, 1835, 1500], [1847, 1467, 1877, 1491], [1891, 1472, 1945, 1491], [1958, 1463, 2060, 1491], [2073, 1463, 2097, 1491], [451, 1509, 569, 1537], [579, 1509, 619, 1546], [632, 1509, 767, 1546], [778, 1509, 890, 1546], [901, 1509, 971, 1538], [983, 1509, 1201, 1546], [1211, 1509, 1298, 1537], [1309, 1509, 1447, 1538], [1459, 1509, 1572, 1538], [1583, 1509, 1776, 1538], [1787, 1509, 1907, 1537], [1924, 1509, 2004, 1538], [2015, 1509, 2100, 1546], [451, 1555, 605, 1592], [620, 1555, 772, 1583], [789, 1555, 838, 1583], [853, 1555, 969, 1583], [983, 1555, 1121, 1584], [1136, 1555, 1227, 1584], [1242, 1555, 1362, 1589], [1380, 1555, 1480, 1584], [1495, 1555, 1598, 1583], [1614, 1555, 1664, 1583], [1678, 1555, 1866, 1592], [1882, 1555, 1984, 1589], [2003, 1564, 2033, 1583], [2050, 1555, 2099, 1583], [451, 1600, 585, 1629], [598, 1600, 671, 1628], [687, 1604, 739, 1628], [752, 1600, 829, 1628], [843, 1604, 873, 1628], [887, 1600, 1024, 1628], [1038, 1600, 1154, 1628], [1168, 1600, 1333, 1637], [1354, 1601, 1408, 1628], [1422, 1600, 1562, 1628], [1576, 1600, 1689, 1629], [1703, 1600, 1862, 1629], [1878, 1600, 1913, 1628], [1925, 1600, 1974, 1628], [1988, 1600, 2099, 1637], [451, 1646, 630, 1675], [642, 1646, 734, 1683], [748, 1646, 848, 1675], [860, 1655, 907, 1675], [919, 1646, 1056, 1674], [1066, 1646, 1172, 1675], [608, 1977, 646, 2009], [931, 1976, 971, 2009], [1256, 1977, 1294, 2009], [1579, 1976, 1619, 2009], [1904, 1977, 1942, 2009], [451, 2035, 557, 2072], [573, 2035, 601, 2063], [626, 2034, 756, 2072], [771, 2034, 850, 2064], [877, 2035, 988, 2070], [1014, 2044, 1030, 2063], [1045, 2035, 1110, 2072], [1125, 2035, 1160, 2063], [1173, 2035, 1366, 2064], [1382, 2035, 1472, 2064], [1488, 2035, 1598, 2063], [1615, 2035, 1687, 2064], [1703, 2035, 1753, 2063], [1769, 2044, 1836, 2063], [1852, 2035, 1965, 2063], [1982, 2044, 1998, 2063], [2014, 2044, 2098, 2064], [451, 2081, 502, 2118], [515, 2081, 595, 2109], [608, 2081, 743, 2109], [757, 2081, 829, 2110], [844, 2090, 860, 2109], [873, 2090, 949, 2118], [962, 2081, 1122, 2118], [1145, 2081, 1197, 2116], [1219, 2090, 1235, 2109], [1248, 2081, 1387, 2118], [1401, 2081, 1437, 2109], [1448, 2081, 1541, 2109], [1554, 2081, 1666, 2118], [1679, 2081, 1750, 2110], [1764, 2081, 1795, 2109], [1809, 2081, 1858, 2109], [1872, 2081, 2006, 2109], [2021, 2090, 2097, 2115], [452, 2126, 506, 2161], [524, 2126, 691, 2154], [704, 2130, 888, 2163], [900, 2125, 937, 2154], [953, 2126, 989, 2154], [998, 2126, 1048, 2154], [1060, 2126, 1279, 2163], [1290, 2130, 1393, 2155], [1404, 2126, 1476, 2154], [1490, 2126, 1608, 2163], [1620, 2126, 1761, 2163], [1774, 2126, 1972, 2163], [1986, 2130, 2016, 2154], [2028, 2135, 2098, 2163], [451, 2172, 521, 2201], [535, 2172, 647, 2206], [663, 2172, 756, 2201], [769, 2172, 910, 2209], [924, 2176, 955, 2200], [969, 2172, 1106, 2209], [1119, 2172, 1245, 2207], [1268, 2172, 1321, 2207], [1342, 2172, 1464, 2201], [1478, 2176, 1662, 2209], [1676, 2171, 1712, 2200], [1718, 2196, 1723, 2200], [1746, 2173, 1825, 2200], [1838, 2172, 1907, 2201], [1922, 2172, 1967, 2207], [1983, 2172, 2040, 2200], [2055, 2172, 2098, 2207], [450, 2218, 600, 2255], [611, 2218, 660, 2246], [672, 2218, 796, 2255], [808, 2218, 887, 2246], [901, 2218, 958, 2246], [969, 2218, 1045, 2247], [1061, 2218, 1124, 2246], [1136, 2218, 1221, 2255], [1232, 2222, 1262, 2246], [1275, 2227, 1291, 2246], [1303, 2218, 1451, 2247], [1462, 2218, 1597, 2246], [1610, 2218, 1747, 2255], [1759, 2218, 1845, 2247], [1859, 2218, 1951, 2253], [1966, 2218, 2037, 2253], [451, 2336, 499, 2366], [545, 2336, 698, 2366], [709, 2336, 803, 2374], [814, 2336, 1066, 2374], [451, 2406, 580, 2444], [595, 2406, 666, 2436], [681, 2406, 836, 2444], [858, 2407, 886, 2435], [901, 2407, 994, 2435], [1008, 2407, 1119, 2444], [1134, 2407, 1204, 2436], [1219, 2416, 1275, 2435], [1289, 2407, 1327, 2435], [1342, 2416, 1413, 2435], [1429, 2416, 1459, 2435], [1476, 2416, 1492, 2435], [1507, 2411, 1552, 2435], [1565, 2407, 1601, 2435], [1613, 2407, 1831, 2444], [1844, 2411, 1947, 2436], [1960, 2407, 2047, 2435], [2063, 2407, 2096, 2442], [450, 2453, 587, 2482], [599, 2453, 648, 2481], [659, 2453, 737, 2490], [751, 2453, 786, 2481], [795, 2453, 988, 2482], [1000, 2453, 1109, 2481], [1123, 2455, 1136, 2481], [1149, 2453, 1206, 2481], [1218, 2455, 1231, 2481], [1242, 2457, 1270, 2484], [1285, 2453, 1309, 2481], [1326, 2454, 1372, 2490], [1384, 2450, 1469, 2491], [1480, 2450, 1513, 2491], [1528, 2462, 1575, 2482], [1587, 2453, 1696, 2481], [1707, 2453, 1757, 2481], [1768, 2453, 1987, 2490], [1997, 2457, 2100, 2482], [451, 2503, 480, 2527], [495, 2499, 544, 2527], [558, 2499, 644, 2536], [662, 2496, 706, 2537], [717, 2496, 750, 2537], [769, 2499, 799, 2527], [815, 2499, 910, 2527], [926, 2501, 948, 2533], [966, 2499, 1066, 2528], [1082, 2508, 1186, 2528], [1203, 2499, 1252, 2527], [1267, 2499, 1352, 2536], [1367, 2503, 1398, 2527], [1413, 2499, 1463, 2527], [1478, 2499, 1714, 2536], [1729, 2499, 1814, 2536], [1829, 2499, 1860, 2527], [1875, 2499, 1925, 2527], [1940, 2499, 2099, 2536], [450, 2544, 546, 2572], [561, 2546, 574, 2572], [589, 2548, 617, 2575], [635, 2544, 660, 2572], [687, 2544, 751, 2572], [765, 2544, 933, 2572], [949, 2544, 1007, 2572], [1022, 2544, 1145, 2573], [1160, 2548, 1358, 2581], [1375, 2544, 1411, 2572], [1423, 2544, 1473, 2572], [1488, 2548, 1591, 2573], [1605, 2544, 1686, 2578], [1705, 2543, 1724, 2572], [1726, 2544, 1742, 2557], [1726, 2565, 1736, 2583], [1762, 2539, 1872, 2572], [1857, 2544, 2099, 2583], [451, 2599, 482, 2618], [497, 2590, 597, 2627], [611, 2590, 753, 2618], [769, 2590, 888, 2625], [902, 2590, 932, 2618], [946, 2590, 1009, 2627], [1024, 2590, 1066, 2625], [1082, 2590, 1152, 2619], [1166, 2590, 1263, 2618], [1277, 2594, 1307, 2618], [1320, 2590, 1509, 2627], [1522, 2590, 1611, 2627], [1626, 2599, 1642, 2618], [1655, 2590, 1880, 2619], [1893, 2590, 2036, 2619], [2058, 2591, 2099, 2618], [449, 2640, 602, 2673], [613, 2636, 662, 2664], [674, 2636, 790, 2664], [803, 2645, 903, 2664], [918, 2645, 934, 2664], [946, 2645, 1096, 2673], [1108, 2636, 1144, 2664], [1153, 2636, 1273, 2670], [1287, 2645, 1334, 2665], [1347, 2636, 1430, 2664], [1442, 2636, 1491, 2664], [1503, 2636, 1574, 2665], [1586, 2636, 1728, 2664], [1743, 2635, 1762, 2664], [1763, 2631, 1807, 2650], [1763, 2656, 1773, 2674], [1822, 2636, 1858, 2664], [1868, 2636, 1893, 2664], [1906, 2636, 2099, 2665], [450, 2681, 560, 2709], [577, 2685, 607, 2709], [622, 2681, 702, 2709], [717, 2690, 733, 2709], [748, 2681, 820, 2709], [835, 2681, 871, 2709], [884, 2681, 930, 2709], [946, 2681, 1030, 2718], [1044, 2681, 1196, 2709], [1222, 2682, 1310, 2709], [1325, 2681, 1472, 2718], [1490, 2681, 1530, 2709], [1544, 2691, 1572, 2709], [1589, 2681, 1647, 2709], [1663, 2680, 1684, 2709], [1698, 2681, 1737, 2709], [1752, 2681, 1801, 2709], [1816, 2681, 1908, 2710], [1924, 2681, 1982, 2709], [1996, 2681, 2100, 2718], [450, 2733, 486, 2761], [497, 2742, 513, 2761], [526, 2733, 626, 2767], [643, 2742, 659, 2761], [671, 2733, 819, 2762], [831, 2733, 916, 2770], [928, 2733, 1050, 2762], [1063, 2733, 1097, 2767], [1117, 2739, 1138, 2763], [1156, 2723, 1319, 2761], [1335, 2733, 1382, 2761], [1395, 2742, 1432, 2761], [1446, 2733, 1586, 2770], [1599, 2733, 1695, 2761], [1707, 2743, 1727, 2761], [1741, 2733, 1766, 2761], [1780, 2733, 1850, 2761], [1863, 2733, 2053, 2761], [2067, 2742, 2097, 2761], [451, 2779, 581, 2808], [731, 2836, 1075, 2877], [1076, 2836, 1092, 2849], [1076, 2864, 1092, 2877], [1096, 2836, 1230, 2880], [1242, 2836, 1286, 2877], [2053, 2839, 2098, 2874], [731, 2898, 1003, 2939], [1005, 2896, 1020, 2915], [1005, 2898, 1215, 2945], [1268, 2911, 1290, 2929], [1304, 2914, 1332, 2923], [1351, 2898, 1477, 2939], [1493, 2914, 1521, 2923], [1540, 2898, 1660, 2939], [1676, 2898, 1816, 2939], [451, 2968, 507, 2995], [522, 2976, 558, 2995], [574, 2967, 715, 3004], [729, 2967, 814, 3004], [831, 2964, 875, 3005], [887, 2964, 931, 3005], [949, 2967, 998, 2995], [1013, 2967, 1155, 2995], [1172, 2967, 1206, 3001], [1214, 2964, 1257, 3005], [1269, 2977, 1297, 3003], [1310, 2964, 1350, 3005], [1362, 2977, 1378, 2995], [1397, 2980, 1425, 2989], [1450, 2964, 1485, 3005], [1497, 2964, 1551, 3005], [1570, 2967, 1686, 2995], [1701, 2967, 1751, 2995], [1765, 2967, 1881, 2995], [1897, 2971, 1926, 2995], [1940, 2967, 2001, 2995], [2014, 2967, 2100, 3004], [451, 3022, 522, 3042], [534, 3022, 550, 3041], [563, 3022, 713, 3050], [725, 3013, 760, 3041], [771, 3013, 796, 3041], [808, 3013, 918, 3041], [933, 3013, 977, 3048], [990, 3013, 1155, 3041], [1167, 3013, 1197, 3041], [1210, 3013, 1272, 3050], [1287, 3013, 1396, 3048], [1266, 3137, 1282, 3166], [451, 353, 637, 391], [654, 353, 809, 391], [840, 354, 889, 382], [908, 354, 1079, 383], [1096, 354, 1212, 382], [1228, 354, 1471, 391], [1492, 354, 1624, 391], [1640, 354, 1681, 391], [1698, 354, 1747, 382], [1764, 354, 2030, 391], [2047, 354, 2098, 382], [452, 400, 590, 437], [609, 400, 682, 434], [697, 400, 831, 437], [847, 400, 896, 428], [910, 400, 1022, 437], [1036, 400, 1113, 434], [1130, 400, 1266, 437], [1281, 404, 1309, 428], [1322, 400, 1372, 428], [1387, 409, 1469, 428], [1483, 400, 1630, 428], [1647, 409, 1746, 428], [1763, 400, 1876, 429], [1890, 400, 2010, 434], [2027, 400, 2099, 429], [451, 445, 500, 473], [512, 445, 589, 479], [605, 445, 740, 482], [754, 445, 844, 482], [857, 445, 906, 473], [918, 445, 1034, 473], [1047, 445, 1238, 482], [1257, 446, 1289, 473], [1302, 445, 1359, 473], [1373, 454, 1452, 479], [1466, 445, 1516, 473], [1528, 445, 1613, 482], [1624, 445, 1747, 474], [1759, 445, 1793, 480], [1799, 469, 1805, 479], [1820, 445, 2055, 482], [2068, 449, 2099, 473], [452, 500, 468, 519], [479, 491, 575, 519], [586, 501, 606, 519], [610, 515, 616, 525], [630, 491, 712, 519], [725, 491, 775, 519], [786, 491, 945, 528], [957, 491, 1045, 519], [741, 563, 1085, 604], [1086, 564, 1102, 577], [1086, 592, 1102, 605], [1106, 563, 1276, 608], [2053, 566, 2098, 601], [741, 626, 1013, 667], [1015, 624, 1030, 643], [1015, 626, 1205, 673], [1258, 639, 1280, 657], [1294, 642, 1322, 651], [1341, 626, 1466, 667], [1483, 642, 1511, 651], [1529, 626, 1650, 667], [1665, 626, 1806, 667], [451, 710, 550, 739], [562, 718, 601, 748], [617, 710, 641, 738], [655, 710, 704, 738], [717, 709, 783, 738], [795, 710, 880, 747], [892, 710, 982, 747], [994, 710, 1044, 738], [1056, 710, 1219, 747], [1233, 710, 1333, 739], [1346, 714, 1429, 738], [1444, 714, 1472, 738], [1484, 710, 1533, 738], [1545, 710, 1677, 738], [1692, 707, 1736, 748], [1747, 707, 1780, 748], [1796, 710, 1826, 738], [1839, 710, 1888, 738], [1900, 710, 1995, 738], [2007, 720, 2027, 738], [2042, 710, 2099, 738], [451, 756, 475, 784], [489, 756, 609, 784], [620, 756, 661, 793], [673, 756, 722, 784], [734, 756, 893, 793], [904, 765, 1079, 784], [1089, 756, 1224, 784], [830, 839, 866, 869], [885, 844, 913, 853], [930, 828, 974, 869], [986, 828, 1030, 869], [1101, 839, 1139, 869], [1157, 844, 1185, 853], [1200, 839, 1280, 869], [1294, 828, 1587, 869], [1611, 830, 1630, 859], [1647, 837, 1673, 861], [1691, 831, 1716, 859], [451, 906, 622, 943], [634, 910, 665, 934], [677, 906, 727, 934], [739, 906, 824, 943], [835, 906, 957, 935], [969, 906, 1203, 943], [1217, 906, 1271, 941], [1285, 906, 1385, 935], [1398, 906, 1447, 934], [1459, 906, 1601, 934], [1615, 906, 1649, 940], [1657, 903, 1701, 944], [1713, 916, 1741, 942], [1754, 903, 1782, 944], [1799, 910, 1877, 934], [1889, 906, 1938, 934], [1951, 906, 2098, 943], [451, 956, 533, 980], [544, 956, 660, 981], [675, 956, 703, 980], [714, 952, 763, 980], [775, 952, 922, 980], [938, 949, 982, 990], [994, 949, 1039, 990], [1052, 952, 1102, 980], [1114, 952, 1198, 989], [1209, 952, 1332, 981], [1344, 952, 1389, 987], [1403, 956, 1496, 980], [1509, 952, 1559, 980], [1571, 956, 1687, 981], [1701, 952, 1837, 989], [1850, 956, 1879, 980], [1889, 952, 1939, 980], [1951, 952, 2097, 980], [451, 1005, 489, 1036], [505, 997, 595, 1034], [607, 997, 656, 1025], [668, 997, 825, 1034], [839, 997, 883, 1032], [896, 997, 1061, 1025], [1073, 997, 1103, 1025], [1115, 997, 1178, 1034], [1193, 997, 1325, 1034], [119, 627, 181, 651], [186, 627, 275, 646], [282, 627, 389, 646], [272, 658, 295, 676], [302, 657, 363, 681], [1474, 627, 1535, 651], [1541, 627, 1629, 646], [1637, 627, 1743, 646], [1627, 658, 1650, 676], [1657, 657, 1718, 681], [451, 1529, 557, 1566], [571, 1529, 598, 1558], [618, 1528, 771, 1558], [784, 1528, 877, 1566], [889, 1528, 1069, 1558], [1082, 1528, 1167, 1558], [1180, 1529, 1234, 1558], [1247, 1528, 1460, 1558], [1472, 1528, 1591, 1566], [1604, 1528, 1682, 1558], [1699, 1529, 1775, 1566], [1793, 1529, 1905, 1566], [1917, 1529, 1988, 1558], [2002, 1529, 2098, 1557], [451, 1575, 502, 1612], [514, 1575, 558, 1610], [572, 1575, 701, 1612], [714, 1575, 763, 1603], [774, 1575, 992, 1612], [1002, 1579, 1118, 1604], [1131, 1575, 1152, 1604], [1164, 1579, 1193, 1603], [1202, 1575, 1252, 1603], [1263, 1584, 1346, 1603], [1357, 1575, 1489, 1603], [1500, 1575, 1531, 1603], [1542, 1575, 1679, 1612], [1689, 1575, 1809, 1603], [1823, 1575, 1925, 1612], [1941, 1575, 2099, 1612], [451, 1621, 587, 1658], [603, 1621, 647, 1656], [664, 1621, 794, 1658], [810, 1621, 859, 1649], [873, 1625, 989, 1650], [1006, 1621, 1096, 1658], [1110, 1621, 1160, 1649], [1174, 1621, 1337, 1658], [1361, 1621, 1424, 1649], [1438, 1621, 1548, 1649], [1565, 1621, 1622, 1649], [1637, 1621, 1686, 1649], [1700, 1621, 1936, 1658], [1951, 1621, 2098, 1658], [450, 1670, 533, 1694], [544, 1670, 660, 1695], [675, 1675, 723, 1694], [736, 1666, 840, 1695], [852, 1666, 924, 1695], [937, 1666, 986, 1694], [999, 1675, 1081, 1694], [1093, 1666, 1204, 1694], [450, 1764, 693, 1794], [706, 1764, 825, 1802], [839, 1764, 917, 1794], [938, 1765, 1058, 1802], [1072, 1765, 1143, 1794], [1156, 1765, 1405, 1802], [1422, 1765, 1466, 1800], [1482, 1765, 1539, 1793], [1554, 1765, 1599, 1800], [1614, 1765, 1682, 1793], [1695, 1765, 1767, 1794], [1781, 1765, 1831, 1793], [1844, 1765, 1974, 1794], [1987, 1765, 2099, 1802], [450, 1811, 528, 1845], [542, 1811, 589, 1839], [604, 1811, 653, 1839], [665, 1811, 884, 1848], [895, 1811, 967, 1839], [980, 1811, 1013, 1845], [1029, 1811, 1065, 1839], [1074, 1811, 1124, 1839], [1136, 1811, 1231, 1839], [1244, 1813, 1257, 1839], [1271, 1811, 1410, 1848], [1424, 1811, 1473, 1839], [1485, 1811, 1617, 1839], [1630, 1811, 1666, 1839], [1676, 1811, 1712, 1839], [1725, 1811, 1821, 1848], [1835, 1811, 1866, 1839], [1878, 1811, 1928, 1839], [1940, 1811, 2099, 1848], [450, 1857, 546, 1885], [562, 1859, 575, 1885], [590, 1861, 618, 1888], [637, 1857, 662, 1885], [690, 1858, 715, 1885], [730, 1857, 755, 1885], [773, 1857, 886, 1885], [902, 1861, 933, 1885], [949, 1857, 1089, 1885], [1106, 1866, 1142, 1885], [1158, 1857, 1315, 1885], [1331, 1861, 1362, 1885], [1379, 1866, 1395, 1885], [1410, 1857, 1633, 1885], [1649, 1857, 1761, 1894], [1777, 1857, 1854, 1891], [1873, 1857, 1973, 1886], [1989, 1866, 2045, 1885], [2060, 1857, 2099, 1885], [450, 1902, 592, 1930], [605, 1902, 646, 1939], [660, 1902, 836, 1939], [852, 1911, 888, 1930], [904, 1902, 1067, 1930], [1083, 1906, 1127, 1930], [1140, 1902, 1176, 1930], [1188, 1902, 1406, 1939], [1419, 1902, 1506, 1930], [1522, 1902, 1553, 1930], [1567, 1902, 1616, 1930], [1631, 1902, 1770, 1939], [1784, 1902, 1939, 1930], [1961, 1903, 2015, 1930], [2029, 1902, 2099, 1930], [450, 1952, 602, 1976], [613, 1957, 649, 1976], [660, 1948, 745, 1985], [754, 1948, 877, 1977], [887, 1948, 921, 1982], [934, 1948, 975, 1985], [986, 1948, 1122, 1985], [1134, 1945, 1200, 1986], [1212, 1948, 1341, 1977], [1352, 1948, 1437, 1977], [1448, 1948, 1586, 1977], [1597, 1948, 1707, 1976], [1719, 1958, 1739, 1976], [1752, 1948, 1809, 1976], [1820, 1958, 1840, 1976], [1848, 1952, 1876, 1979], [1884, 1945, 1950, 1986], [1963, 1948, 2020, 1976], [2032, 1945, 2098, 1986], [449, 1994, 610, 2023], [621, 1994, 707, 2023], [719, 1994, 857, 2023], [868, 1994, 978, 2022], [991, 2004, 1011, 2022], [1023, 2011, 1049, 2012], [1062, 1991, 1128, 2032], [1141, 1994, 1198, 2022], [1210, 2004, 1230, 2022], [1235, 2018, 1240, 2022], [1256, 1994, 1319, 2022], [1330, 1994, 1415, 2031], [1425, 1994, 1460, 2028], [1474, 1994, 1540, 2022], [1552, 1994, 1605, 2022], [1618, 1994, 1668, 2022], [1680, 2003, 1763, 2022], [1774, 1994, 1900, 2022], [1911, 1994, 1947, 2022], [1955, 1994, 2097, 2022], [451, 2039, 524, 2074], [539, 2048, 569, 2067], [581, 2039, 696, 2067], [712, 2039, 775, 2067], [787, 2039, 872, 2068], [886, 2048, 942, 2067], [953, 2039, 992, 2067], [1003, 2039, 1193, 2076], [1204, 2039, 1293, 2076], [1306, 2039, 1399, 2067], [1410, 2039, 1446, 2067], [1455, 2039, 1505, 2067], [1517, 2043, 1577, 2068], [1589, 2039, 1726, 2067], [1741, 2039, 1785, 2074], [1800, 2039, 1857, 2067], [1870, 2039, 1924, 2074], [450, 2110, 550, 2139], [565, 2109, 636, 2139], [651, 2109, 861, 2139], [883, 2111, 908, 2138], [921, 2110, 946, 2138], [962, 2110, 1114, 2147], [1128, 2110, 1288, 2138], [1303, 2114, 1333, 2138], [1346, 2110, 1480, 2147], [1494, 2110, 1732, 2147], [1746, 2110, 1782, 2138], [1793, 2110, 1843, 2138], [1857, 2110, 1991, 2139], [2005, 2110, 2097, 2147], [451, 2165, 482, 2184], [495, 2156, 517, 2184], [529, 2156, 632, 2185], [645, 2156, 694, 2184], [705, 2156, 807, 2184], [818, 2160, 849, 2184], [859, 2156, 954, 2184], [965, 2156, 1079, 2193], [1089, 2156, 1138, 2184], [1148, 2156, 1346, 2184], [1357, 2156, 1604, 2184], [1620, 2157, 1653, 2184], [1664, 2165, 1719, 2184], [1729, 2165, 1808, 2190], [1821, 2156, 1870, 2184], [1881, 2156, 2100, 2193], [450, 2205, 553, 2230], [564, 2201, 636, 2229], [648, 2205, 846, 2238], [859, 2210, 915, 2229], [927, 2201, 995, 2229], [1007, 2210, 1046, 2229], [1057, 2201, 1131, 2229], [1142, 2201, 1271, 2238], [1284, 2201, 1341, 2229], [1353, 2201, 1490, 2238], [1502, 2201, 1614, 2235], [1629, 2201, 1686, 2229], [1699, 2210, 1747, 2229], [1759, 2201, 1905, 2238], [1917, 2201, 2056, 2229], [2068, 2201, 2099, 2229], [450, 2247, 500, 2275], [513, 2256, 600, 2275], [613, 2247, 674, 2275], [686, 2256, 786, 2275], [801, 2256, 817, 2275], [829, 2247, 910, 2284], [922, 2247, 1034, 2284], [1047, 2247, 1083, 2275], [1092, 2247, 1233, 2281], [1247, 2247, 1296, 2275], [1308, 2251, 1482, 2276], [1493, 2247, 1524, 2275], [1536, 2256, 1595, 2275], [1607, 2247, 1753, 2275], [1765, 2247, 1789, 2275], [1804, 2256, 1835, 2275], [1848, 2247, 1992, 2284], [2005, 2256, 2036, 2275], [2050, 2247, 2099, 2275], [450, 2297, 624, 2322], [635, 2293, 666, 2321], [678, 2293, 728, 2321], [740, 2293, 879, 2330], [892, 2302, 958, 2321], [976, 2294, 1131, 2327], [1145, 2293, 1234, 2330], [1248, 2302, 1264, 2321], [1275, 2293, 1340, 2330], [1351, 2293, 1387, 2321], [1397, 2293, 1517, 2327], [1531, 2293, 1580, 2321], [1592, 2293, 1704, 2330], [1716, 2293, 1787, 2322], [1799, 2293, 1936, 2322], [1949, 2293, 2031, 2321], [2043, 2302, 2099, 2321], [449, 2338, 488, 2366], [502, 2338, 675, 2366], [689, 2338, 729, 2375], [744, 2347, 760, 2366], [773, 2338, 932, 2375], [945, 2338, 1171, 2375], [1188, 2347, 1235, 2375], [1239, 2362, 1244, 2366], [1260, 2338, 1371, 2366], [1384, 2338, 1425, 2375], [1439, 2338, 1488, 2366], [1502, 2347, 1620, 2366], [1634, 2342, 1815, 2367], [1837, 2338, 1900, 2366], [1914, 2338, 2099, 2375], [450, 2384, 486, 2412], [495, 2393, 614, 2412], [626, 2384, 742, 2412], [754, 2384, 983, 2421], [994, 2384, 1047, 2412], [1059, 2384, 1137, 2412], [1148, 2384, 1322, 2421], [1333, 2384, 1521, 2421], [1533, 2384, 1564, 2412], [1579, 2384, 1638, 2418], [1652, 2384, 1714, 2418], [1728, 2384, 1828, 2413], [1841, 2393, 1857, 2412], [1869, 2384, 1971, 2421], [1983, 2384, 2099, 2412], [450, 2434, 634, 2467], [648, 2439, 709, 2459], [725, 2430, 882, 2458], [898, 2430, 955, 2458], [971, 2430, 1139, 2458], [1153, 2430, 1233, 2458], [1247, 2430, 1296, 2458], [1310, 2430, 1404, 2458], [1418, 2430, 1495, 2459], [1519, 2431, 1552, 2458], [1566, 2439, 1621, 2458], [1634, 2439, 1713, 2464], [1730, 2439, 1777, 2459], [1791, 2430, 1931, 2458], [1946, 2439, 1962, 2458], [1977, 2430, 2100, 2467], [451, 2475, 610, 2512], [627, 2475, 706, 2503], [718, 2475, 792, 2503], [805, 2475, 1023, 2512], [1034, 2475, 1106, 2503], [1118, 2475, 1139, 2504], [1152, 2484, 1199, 2504], [1211, 2475, 1341, 2503], [1352, 2475, 1388, 2503], [1402, 2484, 1490, 2503], [1502, 2479, 1610, 2504], [449, 2545, 683, 2575], [698, 2546, 806, 2575], [816, 2555, 863, 2575], [872, 2546, 948, 2575], [959, 2546, 1116, 2574], [1126, 2546, 1268, 2574], [1277, 2555, 1359, 2583], [1371, 2546, 1406, 2574], [1414, 2546, 1590, 2583], [1600, 2546, 1737, 2583], [1747, 2546, 1859, 2583], [1869, 2546, 1940, 2575], [1951, 2546, 2098, 2583], [450, 2601, 533, 2625], [545, 2597, 632, 2625], [647, 2597, 709, 2625], [724, 2606, 740, 2625], [754, 2597, 850, 2634], [863, 2597, 986, 2626], [998, 2597, 1033, 2632], [1053, 2603, 1074, 2627], [1092, 2587, 1255, 2625], [1262, 2621, 1267, 2625], [1287, 2597, 1488, 2634], [1501, 2597, 1563, 2625], [1576, 2606, 1592, 2625], [1605, 2597, 1752, 2626], [1764, 2597, 1895, 2634], [1911, 2606, 1927, 2625], [1940, 2597, 2099, 2625], [450, 2643, 543, 2680], [559, 2652, 606, 2672], [622, 2643, 737, 2680], [752, 2652, 768, 2671], [783, 2643, 842, 2671], [860, 2651, 880, 2671], [899, 2643, 959, 2671], [977, 2651, 997, 2671], [1016, 2643, 1062, 2671], [1077, 2643, 1270, 2672], [1284, 2643, 1364, 2671], [1378, 2643, 1412, 2677], [1430, 2643, 1488, 2671], [1501, 2652, 1570, 2680], [1586, 2643, 1609, 2671], [1622, 2647, 1652, 2671], [1667, 2643, 1716, 2671], [1730, 2647, 1780, 2671], [1795, 2652, 1825, 2671], [1841, 2643, 1933, 2680], [1956, 2643, 2020, 2671], [2033, 2643, 2098, 2671], [450, 2689, 509, 2717], [523, 2689, 619, 2726], [636, 2689, 855, 2726], [869, 2689, 998, 2717], [1014, 2689, 1127, 2726], [1142, 2689, 1191, 2717], [1207, 2698, 1289, 2717], [1305, 2698, 1335, 2717], [1351, 2689, 1413, 2717], [1426, 2689, 1501, 2717], [1516, 2689, 1546, 2717], [1561, 2689, 1610, 2717], [1626, 2689, 1732, 2726], [1746, 2693, 1804, 2723], [1822, 2689, 1879, 2717], [1894, 2689, 1918, 2717], [1934, 2689, 2099, 2717], [450, 2734, 481, 2762], [493, 2734, 556, 2771], [573, 2734, 584, 2762], [592, 2758, 597, 2762], [613, 2734, 733, 2771], [745, 2734, 770, 2762], [784, 2734, 898, 2762], [909, 2738, 940, 2762], [952, 2734, 1001, 2762], [1014, 2734, 1120, 2771], [1132, 2734, 1287, 2768], [1302, 2734, 1359, 2762], [1371, 2734, 1395, 2762], [1409, 2734, 1566, 2762], [1578, 2734, 1609, 2762], [1621, 2734, 1712, 2762], [1724, 2734, 1754, 2762], [1767, 2734, 1845, 2763], [1859, 2733, 1886, 2763], [450, 2804, 501, 2834], [544, 2804, 692, 2834], [704, 2804, 740, 2834], [749, 2805, 803, 2834], [815, 2805, 975, 2842], [988, 2804, 1141, 2834], [1152, 2804, 1366, 2834], [1378, 2807, 1411, 2834], [1423, 2804, 1571, 2842], [1584, 2804, 1855, 2842], [450, 2877, 483, 2904], [497, 2876, 554, 2904], [570, 2876, 694, 2910], [710, 2885, 757, 2905], [770, 2880, 823, 2913], [836, 2885, 890, 2904], [903, 2876, 1049, 2913], [1063, 2876, 1211, 2905], [1224, 2876, 1418, 2904], [1432, 2876, 1462, 2904], [1476, 2876, 1525, 2904], [1539, 2880, 1660, 2904], [1673, 2876, 1709, 2904], [1718, 2876, 1799, 2913], [1813, 2880, 1863, 2910], [1879, 2876, 2013, 2913], [2027, 2885, 2098, 2904], [450, 2921, 586, 2949], [606, 2925, 636, 2949], [655, 2921, 704, 2949], [723, 2921, 813, 2950], [831, 2921, 1090, 2958], [1112, 2921, 1261, 2950], [1280, 2921, 1310, 2949], [1330, 2921, 1407, 2950], [1432, 2921, 1443, 2949], [1451, 2921, 1474, 2949], [1482, 2945, 1487, 2949], [1523, 2921, 1665, 2949], [1684, 2921, 1778, 2949], [1797, 2930, 1837, 2949], [1855, 2921, 1969, 2949], [1988, 2921, 2098, 2949], [450, 2967, 517, 3004], [534, 2967, 594, 3001], [609, 2967, 659, 3001], [675, 2967, 819, 3004], [832, 2967, 974, 2995], [988, 2967, 1101, 2996], [1115, 2967, 1373, 3004], [1386, 2967, 1466, 2995], [1479, 2967, 1617, 2995], [1638, 2967, 1718, 2996], [1732, 2967, 1860, 2995], [1876, 2976, 1924, 2995], [1937, 2967, 2099, 3004], [450, 3013, 530, 3041], [540, 3013, 590, 3041], [600, 3013, 712, 3050], [722, 3013, 793, 3042], [805, 3013, 862, 3041], [874, 3022, 922, 3041], [933, 3013, 999, 3041], [1011, 3013, 1199, 3050], [1208, 3013, 1249, 3050], [1260, 3022, 1315, 3041], [1325, 3013, 1471, 3050], [1481, 3013, 1636, 3042], [1652, 3013, 1772, 3047], [1785, 3013, 1834, 3041], [1845, 3013, 1927, 3042], [1938, 3013, 1995, 3041], [2006, 3014, 2099, 3041], [1265, 3137, 1284, 3165], [451, 354, 530, 382], [544, 354, 723, 391], [740, 363, 789, 382], [802, 354, 896, 382], [910, 363, 950, 382], [965, 354, 1014, 382], [1027, 354, 1208, 391], [1224, 354, 1259, 382], [1271, 354, 1464, 382], [1480, 354, 1516, 382], [1528, 354, 1639, 391], [1654, 354, 1724, 383], [1739, 363, 1773, 382], [1787, 354, 1823, 382], [1839, 354, 1982, 391], [1999, 354, 2099, 383], [451, 409, 506, 428], [518, 400, 556, 428], [568, 400, 709, 428], [722, 400, 801, 428], [813, 400, 862, 428], [874, 400, 1093, 437], [1104, 400, 1176, 428], [1188, 400, 1273, 437], [1285, 400, 1329, 435], [1342, 400, 1431, 437], [1444, 409, 1460, 428], [1473, 400, 1570, 437], [1582, 400, 1806, 429], [1818, 400, 1900, 437], [1912, 400, 2099, 437], [451, 445, 786, 474], [797, 445, 912, 480], [925, 445, 1069, 474], [1079, 445, 1120, 482], [1130, 445, 1180, 473], [1189, 445, 1386, 473], [1398, 445, 1455, 473], [1465, 445, 1591, 482], [1601, 445, 1707, 482], [1723, 445, 1786, 473], [1796, 445, 1958, 473], [1969, 445, 2097, 473], [451, 491, 486, 519], [497, 491, 558, 525], [573, 491, 773, 528], [785, 491, 848, 519], [860, 491, 917, 519], [928, 491, 1026, 526], [1039, 500, 1087, 519], [1098, 491, 1162, 519], [1173, 491, 1335, 528], [1346, 491, 1425, 519], [1435, 491, 1485, 519], [1495, 491, 1606, 528], [1617, 491, 1688, 520], [1698, 491, 1842, 528], [1855, 491, 1921, 525], [1935, 491, 2030, 528], [2043, 500, 2099, 519], [450, 537, 488, 565], [502, 537, 643, 574], [656, 537, 697, 574], [711, 546, 766, 565], [779, 537, 1003, 566], [1017, 537, 1128, 565], [1150, 537, 1272, 574], [1288, 537, 1337, 565], [1351, 537, 1508, 574], [1522, 537, 1636, 565], [1653, 537, 1714, 571], [1731, 537, 1756, 565], [1771, 537, 1933, 574], [1947, 537, 1987, 574], [2002, 537, 2098, 565], [451, 582, 502, 619], [516, 582, 565, 610], [578, 582, 797, 619], [809, 586, 926, 611], [942, 582, 1031, 619], [1045, 582, 1094, 610], [1108, 582, 1271, 619], [1287, 582, 1387, 611], [1400, 582, 1598, 619], [1613, 586, 1644, 610], [1657, 582, 1707, 610], [1720, 582, 1878, 619], [1892, 582, 2028, 619], [2043, 582, 2097, 617], [451, 629, 483, 656], [499, 628, 576, 657], [593, 628, 609, 657], [615, 628, 640, 657], [657, 637, 704, 657], [718, 628, 862, 657], [876, 628, 925, 656], [939, 628, 1163, 657], [1177, 628, 1279, 662], [1296, 628, 1390, 656], [1403, 628, 1433, 656], [1448, 628, 1497, 656], [1511, 628, 1575, 656], [1588, 628, 1670, 665], [1684, 628, 1720, 656], [1731, 628, 1780, 656], [1794, 628, 1940, 665], [1955, 628, 2097, 657], [451, 674, 521, 702], [534, 674, 674, 711], [687, 674, 800, 702], [811, 674, 956, 703], [968, 674, 1029, 702], [1040, 683, 1095, 702], [1105, 674, 1339, 711], [1351, 674, 1533, 711], [1545, 674, 1754, 702], [1766, 674, 1905, 702], [451, 744, 493, 772], [511, 744, 556, 772], [571, 753, 602, 772], [619, 744, 668, 772], [684, 744, 760, 781], [776, 744, 925, 773], [943, 753, 991, 772], [1007, 744, 1184, 778], [1204, 753, 1220, 772], [1235, 748, 1420, 773], [1436, 744, 1526, 773], [1542, 744, 1757, 772], [1774, 744, 1967, 772], [1983, 744, 2018, 772], [2034, 744, 2096, 778], [451, 790, 586, 818], [599, 794, 659, 819], [671, 790, 796, 818], [808, 790, 924, 818], [938, 790, 1037, 819], [1050, 799, 1098, 818], [1109, 790, 1318, 818], [1331, 790, 1388, 818], [1399, 790, 1459, 818], [1472, 790, 1548, 827], [1560, 790, 1630, 818], [1642, 799, 1696, 818], [1707, 790, 1973, 827], [1985, 790, 2099, 818], [451, 836, 622, 870], [640, 836, 740, 865], [756, 845, 812, 864], [826, 836, 865, 864], [882, 845, 953, 864], [969, 845, 1000, 864], [1018, 845, 1034, 864], [1049, 836, 1200, 864], [1215, 836, 1447, 873], [1462, 836, 1498, 864], [1511, 836, 1645, 864], [1662, 836, 1725, 864], [1741, 836, 1965, 865], [1981, 836, 2097, 864], [451, 881, 486, 909], [505, 881, 565, 915], [589, 881, 636, 915], [658, 881, 697, 909], [716, 885, 769, 909], [787, 881, 935, 918], [955, 881, 1061, 918], [1080, 881, 1137, 909], [1156, 881, 1302, 918], [1320, 881, 1509, 918], [1528, 885, 1661, 915], [1685, 881, 1742, 909], [1760, 881, 1823, 918], [1842, 890, 1882, 909], [1901, 881, 1950, 909], [1969, 881, 2098, 909], [452, 927, 593, 956], [609, 927, 833, 956], [850, 927, 951, 961], [970, 927, 1064, 955], [1080, 927, 1159, 955], [1175, 927, 1224, 955], [1241, 927, 1317, 955], [1346, 928, 1379, 955], [1396, 936, 1450, 955], [1466, 936, 1544, 961], [1563, 927, 1679, 955], [1696, 927, 1720, 955], [1738, 927, 1893, 964], [1908, 927, 2099, 964], [450, 973, 539, 1010], [553, 973, 603, 1001], [617, 973, 728, 1010], [742, 973, 813, 1002], [828, 973, 1047, 1010], [1060, 973, 1141, 1007], [1157, 973, 1319, 1010], [1333, 973, 1427, 1001], [1441, 982, 1481, 1001], [1495, 973, 1545, 1001], [1560, 973, 1761, 1010], [1777, 973, 1813, 1001], [1824, 977, 1988, 1010], [2002, 973, 2038, 1001], [2050, 973, 2099, 1001], [451, 1018, 592, 1055], [608, 1018, 665, 1046], [681, 1018, 871, 1046], [887, 1018, 923, 1046], [935, 1018, 984, 1046], [999, 1018, 1076, 1047], [1101, 1018, 1325, 1055], [1342, 1018, 1415, 1046], [1431, 1018, 1632, 1055], [1649, 1018, 1711, 1046], [1728, 1027, 1744, 1046], [1758, 1018, 1906, 1047], [1920, 1018, 2100, 1047], [451, 1064, 547, 1101], [556, 1064, 595, 1092], [607, 1064, 674, 1092], [685, 1068, 716, 1092], [726, 1064, 817, 1092], [827, 1064, 877, 1092], [887, 1064, 1096, 1101], [1107, 1064, 1143, 1092], [1152, 1064, 1330, 1092], [1341, 1064, 1596, 1093], [1608, 1064, 1756, 1098], [1770, 1064, 1827, 1092], [1839, 1064, 1863, 1092], [1877, 1073, 1914, 1092], [1925, 1064, 2099, 1101], [451, 1110, 596, 1138], [608, 1110, 656, 1138], [667, 1110, 765, 1138], [776, 1110, 922, 1138], [451, 1179, 500, 1209], [544, 1179, 771, 1209], [783, 1179, 819, 1209], [828, 1180, 933, 1209], [944, 1179, 1180, 1209], [1192, 1179, 1292, 1209], [2082, 1272, 2101, 1285], [655, 1272, 681, 1285], [598, 1292, 635, 1305], [639, 1292, 648, 1305], [589, 1425, 625, 1438], [629, 1425, 648, 1438], [598, 1445, 635, 1458], [639, 1445, 648, 1458], [589, 1578, 625, 1591], [629, 1578, 648, 1591], [453, 1480, 512, 1494], [522, 1474, 580, 1494], [591, 1480, 616, 1494], [453, 1505, 533, 1525], [542, 1505, 585, 1525], [453, 1538, 591, 1561], [600, 1534, 632, 1557], [453, 1332, 512, 1346], [522, 1326, 580, 1346], [591, 1332, 616, 1346], [454, 1357, 563, 1377], [572, 1357, 616, 1377], [453, 1390, 591, 1413], [601, 1388, 616, 1410], [618, 1386, 631, 1398], [879, 1669, 977, 1694], [874, 1700, 981, 1720], [1060, 1669, 1132, 1694], [1042, 1700, 1149, 1720], [451, 1751, 557, 1788], [572, 1751, 599, 1779], [621, 1750, 808, 1788], [822, 1750, 1059, 1780], [1073, 1750, 1172, 1780], [1187, 1751, 1291, 1780], [1305, 1759, 1347, 1780], [1363, 1750, 1401, 1780], [1415, 1751, 1547, 1780], [1561, 1750, 1680, 1788], [1694, 1750, 1792, 1780], [1813, 1751, 1877, 1779], [1891, 1751, 2099, 1780], [451, 1797, 475, 1825], [492, 1797, 562, 1834], [576, 1797, 639, 1825], [654, 1797, 692, 1826], [708, 1797, 846, 1825], [863, 1797, 920, 1825], [935, 1797, 975, 1826], [989, 1806, 1076, 1826], [1099, 1797, 1174, 1825], [1189, 1797, 1311, 1825], [1326, 1797, 1524, 1834], [1540, 1801, 1570, 1825], [1586, 1806, 1602, 1825], [1617, 1797, 1701, 1831], [1718, 1797, 1792, 1825], [1806, 1806, 1868, 1826], [1883, 1815, 1904, 1817], [1917, 1801, 1948, 1825], [1964, 1806, 2000, 1825], [2015, 1797, 2100, 1834], [451, 1842, 587, 1870], [451, 1938, 483, 1965], [496, 1937, 559, 1974], [573, 1937, 592, 1965], [605, 1946, 652, 1966], [665, 1937, 808, 1966], [821, 1937, 870, 1965], [883, 1937, 1107, 1966], [1120, 1937, 1211, 1965], [1225, 1937, 1305, 1965], [1317, 1937, 1367, 1965], [1379, 1937, 1443, 1965], [1455, 1937, 1537, 1974], [1549, 1937, 1585, 1965], [1595, 1937, 1644, 1965], [1657, 1937, 1803, 1974], [1815, 1937, 1971, 1971], [1985, 1937, 2099, 1965], [451, 1992, 490, 2011], [502, 1983, 551, 2011], [562, 1983, 714, 2012], [729, 1983, 851, 2011], [867, 1983, 949, 2011], [960, 1983, 996, 2011], [1005, 1983, 1054, 2011], [1066, 1983, 1104, 2012], [1117, 1983, 1208, 2011], [1220, 1983, 1273, 2011], [1287, 1992, 1303, 2011], [1316, 1983, 1421, 2020], [1432, 1983, 1582, 2020], [1593, 1983, 1665, 2011], [1677, 1983, 1713, 2011], [1722, 1983, 1740, 2012], [1754, 1991, 1774, 2011], [1790, 1983, 1808, 2012], [1819, 1983, 1925, 2020], [1939, 1983, 1997, 2011], [2009, 1992, 2097, 2020], [451, 2029, 490, 2058], [503, 2029, 588, 2066], [599, 2029, 752, 2063], [766, 2029, 1002, 2066], [1015, 2033, 1045, 2057], [1058, 2029, 1107, 2057], [1119, 2029, 1287, 2057], [1300, 2028, 1367, 2064], [1381, 2029, 1439, 2057], [1451, 2029, 1574, 2058], [1587, 2028, 1637, 2064], [1642, 2029, 1653, 2064], [1667, 2033, 1864, 2066], [1878, 2029, 1914, 2057], [1927, 2029, 1963, 2058], [1977, 2029, 2099, 2057], [451, 2074, 562, 2111], [574, 2074, 645, 2103], [657, 2074, 876, 2111], [886, 2074, 973, 2102], [987, 2074, 1017, 2103], [451, 2145, 493, 2173], [512, 2154, 568, 2173], [585, 2145, 623, 2173], [642, 2154, 721, 2179], [743, 2154, 828, 2173], [845, 2145, 936, 2173], [955, 2149, 1097, 2182], [1115, 2145, 1221, 2182], [1238, 2145, 1413, 2174], [1432, 2145, 1468, 2173], [1482, 2145, 1532, 2173], [1549, 2145, 1660, 2182], [1678, 2145, 1755, 2179], [1775, 2145, 1930, 2182], [1946, 2145, 2016, 2174], [2034, 2154, 2098, 2173], [451, 2191, 513, 2219], [526, 2191, 657, 2228], [671, 2191, 743, 2220], [756, 2191, 856, 2228], [868, 2191, 1009, 2225], [1023, 2191, 1123, 2220], [1136, 2191, 1317, 2228], [1331, 2191, 1600, 2220], [1612, 2191, 1821, 2219], [1834, 2191, 2013, 2228], [2028, 2191, 2088, 2228], [2092, 2215, 2097, 2219], [451, 2236, 566, 2271], [580, 2236, 673, 2265], [685, 2236, 776, 2264], [789, 2240, 931, 2273], [943, 2236, 1089, 2273], [1101, 2236, 1286, 2270], [1300, 2236, 1455, 2273], [1467, 2236, 1598, 2273], [1611, 2236, 1642, 2264], [1654, 2236, 1770, 2264], [1782, 2245, 1854, 2265], [1865, 2236, 1946, 2264], [451, 2313, 474, 2347], [525, 2313, 748, 2348], [762, 2313, 936, 2357], [451, 2394, 562, 2423], [578, 2394, 627, 2422], [644, 2394, 750, 2431], [767, 2398, 875, 2422], [891, 2394, 1047, 2428], [1066, 2394, 1165, 2423], [1182, 2403, 1238, 2422], [1253, 2394, 1292, 2422], [1307, 2394, 1488, 2431], [1505, 2403, 1544, 2422], [1562, 2403, 1578, 2422], [1594, 2394, 1675, 2431], [1692, 2394, 1751, 2422], [1768, 2394, 1868, 2431], [1884, 2394, 2099, 2422], [451, 2440, 565, 2468], [583, 2440, 670, 2475], [689, 2449, 719, 2468], [739, 2440, 923, 2477], [944, 2440, 994, 2468], [1011, 2440, 1157, 2477], [1175, 2440, 1323, 2469], [1339, 2440, 1431, 2468], [1450, 2444, 1481, 2468], [1497, 2440, 1536, 2468], [1554, 2440, 1667, 2468], [1685, 2449, 1725, 2468], [1743, 2440, 1833, 2469], [1851, 2440, 1919, 2468], [1936, 2458, 1957, 2460], [1975, 2440, 2032, 2468], [2050, 2440, 2099, 2468], [452, 2485, 597, 2514], [610, 2485, 738, 2513], [753, 2485, 801, 2513], [813, 2485, 904, 2514], [918, 2485, 1017, 2513], [1030, 2485, 1245, 2513], [1260, 2494, 1308, 2513], [1322, 2485, 1382, 2513], [1394, 2485, 1491, 2513], [1505, 2485, 1601, 2513], [1621, 2486, 1654, 2513], [1667, 2494, 1722, 2513], [1734, 2485, 1933, 2522], [1949, 2485, 2040, 2520], [2056, 2485, 2097, 2520], [451, 2531, 578, 2568], [594, 2531, 618, 2559], [634, 2531, 806, 2568], [822, 2540, 862, 2559], [878, 2531, 927, 2559], [942, 2531, 1093, 2560], [1114, 2531, 1171, 2559], [1187, 2530, 1361, 2560], [1381, 2531, 1519, 2565], [1537, 2531, 1637, 2560], [1652, 2531, 1728, 2560], [1744, 2531, 1824, 2568], [1849, 2530, 1930, 2560], [1946, 2531, 2003, 2559], [2020, 2531, 2100, 2560], [451, 2577, 556, 2606], [572, 2577, 776, 2614], [802, 2578, 843, 2605], [859, 2577, 1000, 2605], [1015, 2577, 1207, 2614], [1225, 2586, 1284, 2605], [1299, 2577, 1389, 2605], [1405, 2577, 1545, 2605], [1559, 2577, 1735, 2614], [1751, 2577, 1800, 2605], [1815, 2581, 1875, 2606], [1891, 2577, 2019, 2605], [2036, 2577, 2099, 2605], [451, 2631, 518, 2656], [536, 2622, 603, 2656], [619, 2622, 766, 2656], [783, 2622, 808, 2650], [824, 2626, 876, 2650], [891, 2622, 1143, 2659], [1158, 2622, 1217, 2650], [1231, 2626, 1262, 2650], [1277, 2622, 1326, 2650], [1340, 2622, 1532, 2650], [1546, 2622, 1684, 2651], [1698, 2622, 1748, 2650], [1763, 2626, 1821, 2650], [1837, 2622, 1873, 2650], [1885, 2622, 2007, 2650], [2031, 2622, 2099, 2651], [451, 2668, 555, 2705], [569, 2668, 681, 2703], [694, 2677, 741, 2697], [753, 2668, 888, 2697], [901, 2668, 985, 2703], [999, 2668, 1024, 2696], [1038, 2672, 1068, 2696], [1081, 2668, 1153, 2705], [1167, 2668, 1224, 2696], [1237, 2668, 1286, 2696], [1299, 2668, 1413, 2705], [1427, 2668, 1507, 2696], [1519, 2668, 1568, 2696], [1581, 2668, 1703, 2702], [1718, 2668, 1817, 2697], [1830, 2668, 1870, 2696], [1882, 2672, 1935, 2696], [1948, 2677, 2056, 2705], [2068, 2668, 2099, 2696], [451, 2714, 500, 2742], [514, 2714, 641, 2751], [655, 2714, 777, 2742], [799, 2714, 880, 2748], [895, 2714, 1042, 2748], [1057, 2714, 1189, 2751], [1204, 2714, 1325, 2742], [1340, 2714, 1443, 2742], [1457, 2714, 1505, 2742], [1519, 2714, 1592, 2742], [1606, 2714, 1718, 2742], [1735, 2714, 1792, 2742], [1806, 2714, 1897, 2742], [1913, 2714, 1962, 2742], [1977, 2718, 2100, 2742], [451, 2759, 486, 2787], [496, 2759, 660, 2787], [672, 2759, 799, 2796], [811, 2759, 888, 2787], [451, 2830, 479, 2858], [494, 2839, 578, 2858], [591, 2830, 759, 2867], [774, 2839, 841, 2867], [856, 2830, 892, 2858], [904, 2830, 1080, 2867], [1096, 2830, 1209, 2859], [1224, 2830, 1352, 2858], [1369, 2830, 1393, 2858], [1409, 2830, 1502, 2858], [1517, 2839, 1557, 2858], [1572, 2830, 1740, 2858], [1754, 2830, 1888, 2867], [1906, 2829, 1958, 2864], [1983, 2831, 2022, 2858], [2039, 2830, 2099, 2858], [451, 2876, 475, 2904], [493, 2880, 523, 2904], [540, 2876, 621, 2904], [638, 2885, 654, 2904], [671, 2876, 787, 2911], [804, 2876, 1047, 2913], [1066, 2876, 1166, 2905], [1182, 2876, 1207, 2904], [1225, 2876, 1393, 2913], [1409, 2880, 1462, 2904], [1477, 2876, 1549, 2913], [1566, 2880, 1596, 2904], [1612, 2876, 1662, 2904], [1678, 2876, 1744, 2904], [1759, 2876, 1790, 2904], [1806, 2876, 1945, 2913], [1962, 2876, 2050, 2911], [2067, 2885, 2097, 2904], [451, 2920, 625, 2950], [641, 2921, 878, 2956], [891, 2921, 944, 2949], [956, 2921, 1020, 2949], [1032, 2925, 1063, 2949], [1075, 2921, 1160, 2949], [1171, 2921, 1251, 2949], [1266, 2921, 1326, 2958], [1330, 2945, 1335, 2949], [1349, 2921, 1500, 2950], [1516, 2921, 1754, 2956], [1770, 2921, 1947, 2949], [1959, 2921, 2038, 2949], [2053, 2925, 2100, 2949], [452, 2976, 482, 2995], [499, 2976, 515, 2995], [528, 2967, 712, 3004], [730, 2967, 787, 2995], [802, 2967, 891, 2996], [906, 2967, 953, 2995], [967, 2967, 1016, 2995], [1030, 2967, 1226, 3004], [1241, 2967, 1277, 2995], [1290, 2967, 1453, 2995], [1468, 2967, 1595, 3004], [1610, 2967, 1686, 2995], [1710, 2968, 1743, 2995], [1757, 2976, 1812, 2995], [1826, 2976, 1904, 3001], [1922, 2976, 1938, 2995], [1952, 2967, 2100, 2996], [452, 3013, 645, 3041], [663, 3013, 687, 3041], [707, 3013, 853, 3041], [872, 3022, 906, 3041], [924, 3013, 986, 3041], [1003, 3013, 1025, 3041], [1041, 3013, 1094, 3041], [1115, 3018, 1171, 3042], [1191, 3013, 1322, 3041], [1340, 3013, 1555, 3041], [1573, 3013, 1669, 3050], [1689, 3022, 1729, 3041], [1747, 3017, 1798, 3050], [1816, 3013, 1852, 3041], [1867, 3013, 1916, 3041], [1934, 3013, 1991, 3041], [2008, 3013, 2098, 3050], [1265, 3136, 1282, 3166], [451, 354, 617, 382], [632, 354, 722, 391], [744, 363, 803, 382], [818, 354, 949, 382], [964, 354, 1046, 391], [1059, 358, 1215, 391], [1231, 353, 1406, 383], [1424, 354, 1639, 382], [1655, 363, 1765, 388], [1781, 354, 1831, 382], [1845, 354, 1930, 382], [1943, 363, 2002, 382], [2015, 372, 2036, 374], [2050, 354, 2099, 382], [451, 400, 602, 429], [619, 409, 729, 428], [747, 400, 828, 428], [841, 400, 877, 428], [887, 400, 936, 428], [948, 400, 1044, 437], [1059, 400, 1083, 428], [1097, 400, 1248, 437], [1260, 400, 1333, 429], [1345, 400, 1381, 428], [1395, 409, 1464, 429], [1477, 400, 1538, 428], [1553, 400, 1698, 434], [1712, 400, 1812, 429], [1825, 404, 1960, 437], [1974, 400, 2046, 437], [2059, 409, 2099, 428], [451, 445, 500, 473], [512, 445, 628, 479], [642, 445, 765, 482], [778, 445, 857, 473], [869, 445, 919, 473], [930, 445, 1096, 482], [1109, 445, 1231, 473], [1249, 445, 1312, 473], [1324, 445, 1437, 474], [1449, 445, 1577, 482], [1590, 445, 1651, 473], [1665, 445, 1690, 473], [1704, 445, 1866, 482], [1879, 454, 1910, 473], [1924, 445, 1973, 473], [1987, 454, 2054, 473], [2066, 445, 2102, 473], [451, 491, 500, 519], [512, 491, 677, 520], [689, 491, 780, 519], [797, 491, 903, 525], [917, 491, 975, 519], [987, 491, 1036, 519], [1048, 491, 1183, 520], [1194, 491, 1306, 528], [1317, 491, 1493, 520], [1506, 500, 1562, 519], [1573, 491, 1612, 519], [1624, 491, 1719, 519], [1730, 491, 1771, 528], [1782, 491, 2080, 528], [451, 568, 473, 602], [525, 568, 864, 612], [878, 568, 1014, 603], [452, 648, 620, 678], [631, 648, 877, 686], [891, 649, 955, 677], [965, 649, 1047, 686], [1057, 649, 1277, 686], [1288, 649, 1324, 677], [1332, 658, 1386, 677], [1397, 649, 1503, 686], [1515, 649, 1572, 677], [1583, 649, 1729, 686], [1740, 649, 1901, 678], [1914, 649, 1938, 677], [1952, 649, 2098, 677], [451, 695, 541, 732], [559, 695, 664, 724], [681, 695, 712, 723], [729, 695, 792, 732], [815, 695, 838, 723], [870, 696, 895, 723], [911, 695, 1109, 732], [1128, 699, 1158, 723], [1175, 695, 1312, 724], [1315, 695, 1407, 724], [1427, 695, 1621, 723], [1638, 695, 1674, 723], [1691, 695, 1732, 729], [1753, 695, 1810, 723], [1828, 695, 1852, 723], [1872, 695, 1985, 723], [2002, 699, 2032, 723], [2050, 695, 2099, 723], [451, 741, 585, 770], [600, 741, 636, 769], [651, 741, 725, 775], [751, 741, 803, 769], [817, 741, 930, 769], [945, 741, 1058, 778], [1072, 741, 1168, 778], [1184, 750, 1239, 769], [1254, 741, 1304, 769], [1318, 741, 1515, 769], [1532, 741, 1657, 776], [1675, 741, 1834, 770], [1850, 741, 1996, 775], [2015, 750, 2098, 769], [450, 786, 576, 823], [587, 786, 611, 814], [623, 786, 795, 823], [806, 795, 878, 815], [889, 786, 906, 815], [920, 794, 940, 814], [954, 786, 971, 815], [984, 786, 1090, 823], [1101, 786, 1247, 815], [1259, 786, 1331, 815], [1343, 786, 1433, 814], [1444, 786, 1473, 820], [1486, 786, 1565, 814], [1575, 795, 1720, 823], [1731, 786, 1958, 814], [1968, 795, 2037, 814], [2050, 786, 2099, 814], [452, 841, 534, 860], [548, 832, 671, 869], [686, 841, 717, 860], [734, 831, 807, 866], [826, 832, 889, 860], [902, 832, 974, 869], [987, 832, 1153, 860], [1164, 832, 1302, 861], [1316, 832, 1422, 869], [1436, 832, 1493, 860], [1506, 832, 1652, 869], [1665, 832, 1812, 861], [1824, 832, 2058, 869], [2073, 832, 2097, 860], [451, 878, 512, 906], [523, 887, 570, 907], [581, 878, 724, 907], [736, 878, 786, 906], [798, 878, 911, 906], [923, 878, 1150, 906], [1162, 878, 1244, 915], [1255, 878, 1335, 906], [1346, 878, 1395, 906], [1407, 878, 1492, 906], [1503, 882, 1534, 906], [1545, 878, 1655, 906], [1667, 887, 1803, 915], [1815, 878, 2037, 915], [451, 947, 612, 985], [630, 948, 694, 976], [706, 948, 834, 985], [846, 948, 1012, 985], [1025, 957, 1080, 976], [1093, 948, 1132, 976], [1145, 957, 1217, 976], [1231, 957, 1261, 976], [1277, 957, 1313, 976], [1328, 948, 1498, 985], [1511, 948, 1547, 976], [1557, 948, 1619, 976], [1631, 948, 1667, 976], [1680, 947, 1741, 982], [1758, 952, 1788, 976], [1802, 948, 1892, 977], [1905, 948, 2025, 982], [2042, 948, 2099, 976], [451, 994, 475, 1022], [490, 994, 643, 1031], [657, 994, 706, 1022], [721, 1003, 804, 1022], [817, 994, 865, 1022], [877, 994, 950, 1022], [965, 994, 1071, 1031], [1086, 994, 1143, 1022], [1157, 994, 1303, 1031], [1317, 998, 1390, 1022], [1412, 994, 1475, 1022], [1489, 994, 1624, 1023], [1637, 994, 1763, 1031], [1779, 1003, 1827, 1022], [1841, 994, 1935, 1022], [1947, 994, 2036, 1031], [2050, 994, 2099, 1022], [451, 1039, 629, 1067], [643, 1039, 803, 1067], [817, 1039, 952, 1076], [964, 1039, 1088, 1067], [1099, 1039, 1171, 1068], [1184, 1043, 1372, 1067], [1386, 1039, 1444, 1074], [1456, 1043, 1486, 1067], [1499, 1039, 1572, 1074], [1591, 1039, 1632, 1067], [1644, 1039, 1718, 1067], [1731, 1039, 1876, 1073], [1892, 1048, 1908, 1067], [1921, 1039, 2099, 1067], [451, 1085, 486, 1113], [496, 1084, 555, 1114], [570, 1085, 700, 1122], [714, 1085, 738, 1113], [752, 1085, 942, 1113], [954, 1085, 994, 1122], [1008, 1085, 1157, 1122], [1170, 1084, 1229, 1114], [1243, 1085, 1370, 1122], [1383, 1085, 1488, 1114], [1503, 1085, 1680, 1122], [1694, 1094, 1794, 1113], [1808, 1085, 1857, 1113], [1869, 1085, 2005, 1120], [2020, 1085, 2099, 1113], [451, 1131, 525, 1159], [537, 1131, 573, 1159], [582, 1131, 681, 1160], [694, 1140, 710, 1159], [723, 1131, 820, 1168], [831, 1131, 927, 1159], [938, 1131, 963, 1159], [975, 1131, 1134, 1168], [1147, 1131, 1286, 1159], [1302, 1132, 1335, 1159], [1348, 1131, 1454, 1168], [1466, 1135, 1516, 1159], [1527, 1131, 1663, 1168], [1678, 1140, 1694, 1159], [1706, 1131, 1766, 1159], [1781, 1139, 1801, 1159], [1818, 1131, 1878, 1159], [1891, 1131, 2061, 1168], [2073, 1131, 2097, 1159], [450, 1176, 608, 1213], [621, 1176, 753, 1213], [766, 1176, 846, 1204], [858, 1176, 908, 1204], [922, 1176, 1053, 1204], [1066, 1176, 1171, 1210], [1186, 1176, 1209, 1204], [1221, 1176, 1290, 1204], [1303, 1176, 1470, 1213], [1484, 1176, 1611, 1204], [1622, 1176, 1790, 1204], [1803, 1176, 1931, 1213], [1945, 1176, 2002, 1204], [2015, 1176, 2097, 1205], [447, 1222, 589, 1259], [607, 1222, 670, 1250], [683, 1222, 788, 1251], [803, 1231, 851, 1250], [863, 1222, 998, 1250], [1010, 1222, 1204, 1256], [1220, 1231, 1254, 1250], [1267, 1222, 1328, 1250], [1340, 1222, 1389, 1250], [1403, 1222, 1537, 1250], [1550, 1222, 1614, 1250], [1627, 1222, 1662, 1250], [1672, 1222, 1722, 1250], [1734, 1222, 1829, 1250], [1842, 1222, 1945, 1259], [1959, 1221, 2028, 1251], [2045, 1223, 2099, 1250], [451, 1272, 521, 1296], [532, 1268, 594, 1296], [604, 1268, 707, 1296], [722, 1267, 795, 1302], [809, 1268, 858, 1296], [871, 1268, 1041, 1305], [1053, 1268, 1078, 1296], [1092, 1268, 1228, 1305], [1240, 1268, 1320, 1296], [1331, 1268, 1380, 1296], [1392, 1268, 1492, 1297], [1504, 1268, 1608, 1302], [1622, 1272, 1674, 1296], [1681, 1268, 1745, 1305], [1756, 1268, 1792, 1296], [1806, 1268, 1865, 1297], [1882, 1276, 1902, 1296], [1919, 1268, 1978, 1297], [1991, 1272, 2097, 1296], [451, 1314, 483, 1341], [495, 1313, 545, 1341], [556, 1313, 702, 1350], [714, 1317, 764, 1341], [775, 1313, 911, 1350], [924, 1322, 971, 1342], [983, 1317, 1124, 1350], [1137, 1322, 1173, 1341], [1185, 1313, 1297, 1350], [1308, 1313, 1379, 1342], [1391, 1313, 1513, 1342], [1525, 1313, 1545, 1341], [1557, 1313, 1604, 1341], [1615, 1313, 1664, 1341], [1677, 1313, 1808, 1341], [1820, 1313, 1947, 1350], [1959, 1313, 2054, 1341], [2067, 1322, 2097, 1341], [451, 1359, 608, 1387], [620, 1359, 650, 1387], [663, 1359, 740, 1388], [755, 1359, 771, 1388], [777, 1383, 782, 1387], [798, 1360, 887, 1387], [898, 1359, 960, 1387], [970, 1359, 1101, 1393], [1115, 1368, 1131, 1387], [1143, 1359, 1302, 1387], [1315, 1359, 1374, 1387], [1389, 1367, 1409, 1387], [1426, 1359, 1485, 1387], [1500, 1367, 1520, 1387], [1536, 1359, 1582, 1387], [1594, 1359, 1679, 1396], [1690, 1359, 1714, 1387], [1727, 1359, 1885, 1396], [1897, 1359, 2029, 1396], [2042, 1359, 2099, 1387], [451, 1405, 573, 1442], [591, 1405, 654, 1433], [667, 1405, 801, 1442], [813, 1409, 875, 1433], [888, 1405, 912, 1433], [926, 1405, 1054, 1442], [1068, 1409, 1112, 1433], [1124, 1409, 1154, 1433], [1170, 1399, 1249, 1434], [1254, 1429, 1260, 1439], [1276, 1405, 1333, 1433], [1346, 1405, 1416, 1433], [1429, 1405, 1591, 1433], [1605, 1405, 1765, 1442], [1778, 1409, 1809, 1433], [1823, 1414, 1839, 1433], [1851, 1405, 1932, 1433], [1946, 1405, 2097, 1439], [451, 1450, 550, 1479], [562, 1450, 587, 1478], [599, 1450, 671, 1487], [681, 1450, 731, 1478], [743, 1459, 826, 1478], [838, 1450, 885, 1478], [897, 1450, 936, 1478], [948, 1450, 1075, 1487], [1088, 1454, 1156, 1478], [1173, 1450, 1308, 1487], [1322, 1450, 1410, 1479], [1422, 1450, 1549, 1487], [1562, 1459, 1578, 1478], [1590, 1450, 1738, 1479], [1748, 1450, 1828, 1478], [1840, 1450, 1964, 1484], [1977, 1450, 2027, 1478], [2037, 1454, 2099, 1478], [451, 1496, 475, 1524], [491, 1496, 627, 1533], [642, 1500, 673, 1524], [690, 1490, 768, 1525], [787, 1496, 861, 1524], [875, 1495, 945, 1525], [959, 1496, 1120, 1530], [1137, 1496, 1207, 1524], [1221, 1500, 1252, 1524], [1269, 1489, 1348, 1525], [1366, 1496, 1440, 1524], [1454, 1496, 1524, 1525], [1538, 1496, 1700, 1530], [1717, 1496, 1775, 1524], [1789, 1496, 1916, 1533], [1931, 1496, 1955, 1524], [1972, 1496, 2099, 1533], [452, 1542, 526, 1570], [537, 1542, 606, 1571], [617, 1542, 778, 1570], [794, 1543, 827, 1570], [838, 1542, 887, 1570], [898, 1542, 1078, 1579], [1090, 1542, 1234, 1576], [1247, 1542, 1297, 1570], [1306, 1546, 1368, 1570], [1379, 1542, 1403, 1570], [1416, 1542, 1552, 1579], [1563, 1546, 1594, 1570], [1608, 1536, 1686, 1571], [1701, 1542, 1775, 1570], [1789, 1542, 1856, 1570], [1866, 1542, 2028, 1576], [2042, 1542, 2099, 1570], [451, 1587, 578, 1624], [591, 1587, 717, 1624], [731, 1587, 805, 1615], [816, 1587, 886, 1616], [898, 1587, 1059, 1615], [451, 1657, 586, 1695], [607, 1658, 648, 1686], [661, 1662, 718, 1686], [731, 1658, 811, 1692], [828, 1658, 916, 1695], [932, 1667, 948, 1686], [961, 1658, 1061, 1692], [1077, 1667, 1124, 1687], [1138, 1658, 1254, 1695], [1268, 1667, 1284, 1686], [1298, 1658, 1379, 1686], [1393, 1658, 1519, 1686], [1532, 1658, 1568, 1686], [1579, 1658, 1689, 1686], [1705, 1658, 1757, 1693], [1772, 1658, 1803, 1686], [1817, 1667, 1871, 1686], [1884, 1658, 2098, 1695], [451, 1704, 523, 1733], [537, 1704, 626, 1741], [640, 1704, 786, 1741], [802, 1704, 926, 1741], [940, 1704, 1077, 1733], [1092, 1704, 1182, 1732], [1206, 1705, 1295, 1732], [1309, 1704, 1383, 1732], [1398, 1704, 1434, 1732], [1445, 1704, 1495, 1732], [1509, 1704, 1619, 1732], [1635, 1713, 1682, 1733], [1697, 1704, 1766, 1732], [1781, 1704, 1883, 1732], [1902, 1704, 1938, 1733], [1952, 1704, 2100, 1733], [451, 1749, 549, 1786], [564, 1748, 625, 1783], [637, 1749, 678, 1786], [688, 1749, 834, 1786], [845, 1749, 902, 1777], [913, 1749, 1040, 1786], [1050, 1749, 1119, 1777], [1128, 1758, 1247, 1777], [1260, 1749, 1317, 1777], [1327, 1749, 1377, 1777], [1387, 1753, 1487, 1777], [1497, 1749, 1532, 1777], [1540, 1749, 1589, 1777], [1599, 1749, 1703, 1777], [1718, 1749, 1781, 1777], [1791, 1749, 1869, 1777], [1882, 1758, 1981, 1777], [1993, 1749, 2040, 1777], [2050, 1749, 2099, 1777], [451, 1795, 551, 1824], [562, 1795, 653, 1824], [665, 1804, 714, 1823], [725, 1795, 795, 1823], [807, 1795, 948, 1823], [959, 1795, 1000, 1832], [1013, 1795, 1172, 1832], [1184, 1795, 1233, 1823], [1246, 1804, 1345, 1823], [1360, 1804, 1459, 1823], [1472, 1795, 1522, 1823], [1534, 1795, 1670, 1832], [1682, 1795, 1792, 1823], [1806, 1795, 1863, 1823], [1875, 1804, 1962, 1832], [1975, 1795, 2097, 1823], [451, 1864, 667, 1902], [684, 1873, 726, 1894], [744, 1865, 916, 1902], [932, 1864, 1193, 1894], [1223, 1865, 1321, 1893], [1337, 1865, 1533, 1902], [1550, 1865, 1599, 1893], [1617, 1865, 1723, 1902], [1740, 1865, 1895, 1899], [1915, 1874, 1962, 1894], [1978, 1874, 2033, 1893], [2050, 1865, 2099, 1893], [452, 1920, 534, 1939], [551, 1911, 678, 1948], [695, 1911, 753, 1939], [769, 1915, 826, 1939], [841, 1911, 909, 1939], [926, 1911, 1150, 1948], [1167, 1920, 1197, 1939], [1215, 1911, 1373, 1939], [1390, 1911, 1486, 1940], [1503, 1911, 1670, 1948], [1689, 1911, 1826, 1948], [1845, 1911, 1926, 1940], [1941, 1911, 2097, 1948], [451, 1957, 521, 1985], [533, 1957, 629, 1994], [644, 1954, 746, 1987], [758, 1956, 842, 1994], [854, 1966, 934, 1985], [944, 1966, 984, 1985], [994, 1957, 1237, 1986], [1247, 1957, 1411, 1986], [1422, 1961, 1474, 1991], [1487, 1957, 1586, 1986], [1597, 1966, 1753, 1994], [1765, 1957, 1941, 1994], [1951, 1961, 1982, 1985], [1995, 1954, 2097, 1987], [450, 2002, 587, 2039], [604, 2002, 635, 2030], [655, 2002, 716, 2036], [736, 2002, 784, 2030], [801, 2011, 817, 2030], [835, 2002, 948, 2030], [965, 2002, 1107, 2031], [1137, 2003, 1191, 2030], [1207, 2002, 1325, 2031], [1342, 2002, 1403, 2030], [1419, 2002, 1469, 2030], [1485, 2002, 1567, 2030], [1583, 2011, 1690, 2030], [1707, 2002, 1755, 2030], [1771, 2002, 1821, 2030], [1837, 2002, 2057, 2039], [2073, 2002, 2097, 2030], [452, 2048, 601, 2085], [613, 2048, 649, 2076], [658, 2048, 806, 2077], [817, 2048, 915, 2085], [929, 2048, 1008, 2076], [1020, 2048, 1069, 2076], [1081, 2048, 1181, 2077], [1193, 2048, 1301, 2085], [1314, 2048, 1411, 2076], [1422, 2048, 1492, 2076], [1500, 2048, 1563, 2085], [1574, 2048, 1610, 2076], [1624, 2052, 1730, 2076], [451, 2118, 649, 2148], [660, 2118, 810, 2156], [825, 2119, 889, 2148], [898, 2119, 1157, 2156], [1167, 2119, 1192, 2147], [1204, 2119, 1325, 2148], [1335, 2119, 1415, 2147], [1425, 2119, 1474, 2147], [1483, 2119, 1618, 2156], [1630, 2119, 1775, 2148], [1786, 2119, 1875, 2148], [1885, 2119, 2011, 2147], [2024, 2119, 2097, 2153], [450, 2164, 502, 2192], [518, 2164, 653, 2192], [672, 2173, 688, 2192], [704, 2164, 830, 2192], [846, 2164, 882, 2192], [897, 2164, 1068, 2201], [1084, 2164, 1317, 2198], [1336, 2164, 1491, 2201], [1507, 2164, 1631, 2201], [1647, 2164, 1775, 2201], [1792, 2173, 1831, 2192], [1848, 2164, 1985, 2201], [2001, 2164, 2097, 2193], [451, 2210, 589, 2238], [600, 2210, 631, 2238], [643, 2219, 659, 2238], [670, 2210, 767, 2247], [779, 2214, 900, 2247], [915, 2211, 969, 2238], [979, 2210, 1093, 2247], [1103, 2210, 1152, 2238], [1163, 2210, 1231, 2238], [1240, 2210, 1433, 2247], [1447, 2210, 1504, 2238], [1516, 2210, 1586, 2247], [1595, 2210, 1670, 2238], [1682, 2210, 1761, 2239], [1772, 2210, 1861, 2238], [1873, 2219, 1972, 2238], [1986, 2210, 2099, 2239], [451, 2256, 557, 2285], [581, 2256, 721, 2293], [737, 2265, 753, 2284], [768, 2256, 865, 2293], [880, 2256, 1026, 2293], [1041, 2256, 1188, 2285], [1202, 2256, 1284, 2284], [1304, 2256, 1315, 2284], [1334, 2256, 1392, 2293], [1407, 2265, 1447, 2284], [1463, 2265, 1479, 2284], [1494, 2260, 1607, 2293], [1622, 2256, 1694, 2285], [1709, 2256, 1728, 2284], [1743, 2256, 1888, 2284], [1903, 2256, 1988, 2284], [2003, 2256, 2097, 2290], [451, 2301, 550, 2330], [562, 2301, 737, 2329], [751, 2310, 767, 2329], [780, 2301, 829, 2330], [843, 2301, 929, 2329], [944, 2301, 1091, 2338], [1103, 2310, 1175, 2330], [1187, 2301, 1380, 2338], [1392, 2301, 1529, 2338], [451, 2371, 580, 2409], [597, 2371, 669, 2401], [686, 2372, 711, 2400], [729, 2372, 891, 2409], [908, 2372, 997, 2409], [1014, 2372, 1063, 2400], [1080, 2372, 1288, 2400], [1302, 2372, 1383, 2401], [1401, 2372, 1659, 2409], [1677, 2372, 1712, 2400], [1730, 2372, 1770, 2406], [1791, 2372, 1870, 2400], [1887, 2372, 1936, 2400], [1953, 2372, 2099, 2409], [451, 2418, 584, 2446], [607, 2419, 640, 2446], [655, 2418, 731, 2455], [745, 2418, 781, 2446], [792, 2418, 842, 2446], [856, 2418, 915, 2446], [928, 2418, 1134, 2455], [1148, 2418, 1220, 2446], [1235, 2418, 1335, 2453], [1351, 2418, 1398, 2446], [1413, 2427, 1429, 2446], [1442, 2418, 1506, 2455], [1520, 2418, 1556, 2446], [1567, 2418, 1701, 2453], [1717, 2418, 1740, 2446], [1753, 2418, 1854, 2447], [1870, 2418, 1930, 2446], [1944, 2418, 2099, 2446], [452, 2472, 468, 2491], [484, 2463, 658, 2491], [675, 2463, 701, 2491], [717, 2463, 796, 2491], [814, 2463, 982, 2500], [1004, 2472, 1039, 2491], [1057, 2472, 1104, 2492], [1121, 2463, 1351, 2500], [1369, 2463, 1418, 2491], [1436, 2463, 1507, 2492], [1524, 2463, 1630, 2491], [1648, 2463, 1784, 2500], [1819, 2464, 1860, 2491], [1879, 2463, 1967, 2492], [1986, 2463, 2099, 2500], [451, 2509, 500, 2537], [514, 2509, 733, 2546], [747, 2509, 834, 2537], [851, 2518, 881, 2537], [898, 2509, 995, 2543], [1012, 2509, 1061, 2537], [1075, 2509, 1243, 2537], [1259, 2509, 1316, 2537], [1331, 2509, 1453, 2538], [1468, 2513, 1666, 2546], [1682, 2509, 1718, 2537], [1730, 2509, 1779, 2537], [1794, 2509, 1865, 2538], [1880, 2518, 1959, 2538], [1974, 2509, 2099, 2546], [450, 2555, 585, 2583], [599, 2559, 629, 2583], [644, 2564, 660, 2583], [677, 2552, 713, 2593], [725, 2552, 792, 2593], [809, 2564, 901, 2592], [915, 2555, 973, 2583], [986, 2555, 1181, 2592], [1193, 2555, 1283, 2592], [1296, 2555, 1389, 2584], [1404, 2555, 1492, 2590], [1505, 2555, 1761, 2592], [1777, 2555, 1826, 2583], [1840, 2555, 1911, 2584], [1925, 2555, 1949, 2583], [1964, 2555, 2099, 2583], [450, 2600, 528, 2628], [538, 2604, 569, 2628], [580, 2600, 616, 2628], [629, 2600, 756, 2637], [766, 2600, 880, 2637], [896, 2600, 967, 2628], [978, 2600, 1109, 2628], [1120, 2600, 1169, 2628], [1180, 2600, 1251, 2629], [1263, 2600, 1325, 2628], [1336, 2600, 1384, 2628], [1394, 2600, 1443, 2628], [1454, 2600, 1605, 2629], [1620, 2600, 1735, 2628], [1745, 2600, 1824, 2628], [1839, 2599, 1936, 2629], [1949, 2604, 1980, 2628], [1991, 2600, 2097, 2629], [451, 2677, 474, 2712], [525, 2677, 756, 2712], [451, 2758, 598, 2787], [627, 2758, 692, 2787], [721, 2757, 902, 2787], [931, 2758, 1086, 2795], [1150, 2758, 1213, 2786], [1241, 2758, 1410, 2787], [1439, 2758, 1463, 2786], [1492, 2758, 1664, 2795], [1693, 2767, 1733, 2786], [1761, 2758, 1912, 2787], [1948, 2758, 2009, 2792], [2042, 2758, 2099, 2786], [451, 2803, 625, 2833], [648, 2804, 710, 2838], [730, 2804, 829, 2832], [844, 2804, 1033, 2841], [1048, 2804, 1257, 2838], [1276, 2804, 1376, 2833], [1394, 2813, 1442, 2832], [1459, 2813, 1569, 2841], [1586, 2804, 1635, 2832], [1652, 2804, 1761, 2841], [1777, 2804, 1923, 2833], [1940, 2804, 2099, 2832], [451, 2850, 541, 2879], [555, 2843, 696, 2878], [705, 2874, 710, 2878], [731, 2850, 882, 2879], [900, 2850, 1035, 2878], [1054, 2850, 1120, 2879], [1133, 2850, 1239, 2879], [1255, 2850, 1328, 2885], [1342, 2850, 1557, 2879], [1571, 2859, 1610, 2878], [1625, 2850, 1773, 2887], [1789, 2850, 1948, 2878], [1962, 2850, 2024, 2878], [2042, 2850, 2095, 2879], [452, 2895, 550, 2923], [564, 2895, 687, 2929], [703, 2894, 877, 2924], [895, 2895, 1030, 2923], [1045, 2895, 1126, 2924], [1139, 2895, 1244, 2924], [1259, 2895, 1295, 2923], [1305, 2894, 1341, 2924], [1360, 2895, 1483, 2923], [1504, 2895, 1567, 2923], [1580, 2895, 1749, 2924], [1762, 2895, 1900, 2932], [1913, 2895, 1938, 2923], [1953, 2895, 2002, 2923], [2016, 2904, 2099, 2923], [505, 2966, 512, 2983], [518, 2974, 587, 3007], [595, 2973, 720, 3007], [733, 2974, 789, 3005], [800, 2973, 922, 2999], [930, 2973, 975, 2999], [985, 2974, 1142, 3007], [1152, 2973, 1254, 2999], [1263, 2973, 1295, 2999], [1305, 2974, 1380, 2999], [1390, 2973, 1591, 3007], [1601, 2973, 1744, 2999], [1754, 2973, 1887, 2999], [1898, 2977, 1983, 3007], [1994, 2973, 2097, 3000], [451, 3015, 611, 3049], [621, 3015, 666, 3041], [677, 3015, 779, 3041], [790, 3015, 821, 3041], [831, 3015, 897, 3041], [909, 3015, 981, 3041], [992, 3015, 1014, 3041], [1026, 3024, 1091, 3049], [1102, 3015, 1282, 3049], [1295, 3015, 1347, 3041], [1358, 3024, 1400, 3042], [1410, 3015, 1473, 3049], [1483, 3019, 1512, 3041], [1523, 3015, 1632, 3041], [1644, 3015, 1664, 3041], [1674, 3015, 1702, 3041], [1713, 3015, 1800, 3041], [1811, 3015, 1894, 3042], [1265, 3137, 1283, 3166], [451, 354, 498, 382], [508, 354, 581, 382], [593, 354, 732, 382], [749, 354, 798, 382], [810, 354, 976, 391], [989, 354, 1115, 391], [1126, 354, 1208, 382], [1221, 354, 1304, 391], [1317, 354, 1380, 382], [1392, 354, 1520, 391], [1533, 354, 1590, 382], [1602, 358, 1659, 382], [1670, 354, 1746, 388], [1761, 354, 1818, 382], [1830, 354, 1879, 382], [1890, 354, 2099, 391], [451, 400, 475, 428], [487, 400, 645, 428], [655, 400, 696, 437], [707, 400, 756, 428], [767, 409, 855, 428], [866, 400, 1081, 428], [1093, 409, 1237, 437], [1249, 409, 1349, 428], [1361, 400, 1410, 428], [1422, 400, 1516, 437], [1532, 400, 1613, 428], [1624, 400, 1775, 429], [1791, 400, 1861, 437], [1871, 400, 2006, 428], [2019, 399, 2100, 429], [451, 445, 578, 482], [590, 445, 706, 479], [721, 454, 757, 473], [769, 444, 944, 474], [961, 445, 1030, 482], [1041, 445, 1176, 473], [1191, 445, 1271, 474], [1282, 445, 1409, 482], [1421, 445, 1537, 474], [1552, 446, 1606, 473], [1616, 445, 1707, 482], [1718, 445, 1759, 482], [1771, 445, 1947, 482], [1959, 445, 2100, 473], [452, 491, 659, 519], [674, 500, 714, 519], [727, 491, 777, 519], [790, 491, 854, 519], [867, 491, 937, 528], [949, 491, 985, 519], [995, 491, 1044, 519], [1057, 491, 1209, 520], [1226, 491, 1348, 519], [1368, 492, 1424, 519], [1437, 491, 1629, 528], [1642, 491, 1714, 520], [1727, 491, 1777, 519], [1791, 495, 1864, 519], [1877, 491, 1913, 519], [1924, 491, 1973, 519], [1987, 495, 2037, 525], [2052, 500, 2099, 520], [451, 537, 556, 566], [572, 537, 621, 565], [638, 537, 776, 565], [792, 537, 961, 566], [976, 537, 1114, 574], [1131, 537, 1188, 565], [1203, 541, 1302, 574], [1317, 537, 1366, 565], [1383, 546, 1508, 574], [1525, 546, 1669, 574], [1685, 546, 1757, 566], [1772, 537, 1853, 565], [1870, 537, 1954, 574], [1971, 546, 2011, 565], [2026, 537, 2099, 565], [451, 582, 602, 611], [619, 582, 676, 610], [688, 581, 875, 611], [451, 652, 574, 690], [589, 652, 767, 682], [790, 653, 873, 687], [890, 662, 937, 682], [951, 662, 1088, 681], [1103, 653, 1152, 681], [1165, 653, 1375, 690], [1389, 653, 1425, 681], [1436, 653, 1486, 681], [1501, 653, 1607, 690], [1622, 657, 1731, 681], [1745, 653, 1900, 682], [1924, 653, 2019, 681], [2035, 662, 2098, 681], [451, 699, 549, 727], [569, 708, 617, 727], [634, 699, 821, 727], [850, 699, 886, 734], [904, 699, 1032, 736], [1049, 699, 1128, 727], [1147, 699, 1261, 727], [1279, 708, 1319, 727], [1336, 699, 1500, 733], [1522, 699, 1568, 734], [1586, 699, 1781, 736], [1799, 708, 1839, 727], [1856, 699, 2099, 728], [451, 744, 595, 773], [609, 744, 649, 781], [664, 744, 844, 781], [858, 753, 898, 772], [913, 744, 1076, 778], [1094, 744, 1152, 779], [1167, 744, 1297, 781], [1311, 744, 1361, 772], [1374, 744, 1555, 781], [1569, 744, 1704, 773], [1717, 744, 1798, 772], [1813, 744, 1871, 772], [1885, 744, 1957, 781], [1971, 744, 2099, 781], [451, 790, 500, 818], [512, 790, 569, 818], [581, 790, 822, 825], [836, 790, 923, 827], [941, 791, 997, 818], [1008, 790, 1083, 818], [1095, 790, 1131, 818], [1141, 790, 1190, 818], [1203, 790, 1336, 827], [1350, 799, 1397, 819], [1409, 790, 1595, 827], [1606, 790, 1678, 819], [1692, 790, 1800, 827], [1812, 790, 1861, 818], [1874, 790, 2002, 827], [2013, 799, 2098, 827], [451, 836, 603, 864], [616, 836, 692, 864], [705, 840, 736, 864], [751, 836, 800, 865], [815, 845, 849, 864], [862, 840, 893, 864], [907, 836, 966, 865], [988, 837, 1077, 864], [1090, 836, 1140, 864], [1152, 836, 1269, 870], [1284, 836, 1442, 873], [1456, 836, 1486, 864], [1500, 836, 1590, 864], [1608, 836, 1650, 870], [1666, 836, 1689, 864], [1701, 836, 1726, 864], [1741, 836, 1821, 864], [1834, 836, 1896, 864], [1908, 836, 2036, 873], [2050, 836, 2099, 864], [450, 881, 598, 910], [609, 881, 705, 918], [716, 890, 755, 909], [766, 881, 815, 909], [825, 881, 976, 910], [991, 881, 1106, 909], [1115, 881, 1197, 909], [1209, 885, 1240, 909], [1250, 881, 1433, 918], [1445, 881, 1533, 916], [1543, 881, 1615, 910], [1625, 881, 1698, 918], [1708, 881, 1858, 918], [1872, 881, 1929, 909], [1940, 881, 1964, 909], [1976, 881, 2100, 909], [450, 931, 481, 955], [493, 927, 688, 964], [701, 936, 741, 955], [754, 936, 770, 955], [783, 927, 864, 964], [876, 927, 1119, 956], [1131, 927, 1254, 955], [1272, 927, 1486, 964], [1501, 927, 1681, 964], [1694, 927, 1743, 955], [1755, 927, 1855, 956], [1868, 927, 2003, 956], [2015, 927, 2097, 964], [450, 973, 523, 1010], [538, 973, 684, 1010], [699, 973, 919, 1010], [933, 982, 1005, 1002], [1020, 973, 1147, 1010], [1163, 973, 1213, 1001], [1228, 973, 1285, 1001], [1300, 973, 1382, 1010], [1397, 973, 1475, 1010], [1502, 974, 1535, 1001], [1551, 973, 1600, 1001], [1616, 973, 1700, 1001], [1716, 973, 1833, 1010], [1850, 973, 1956, 1010], [1971, 973, 2100, 1010], [450, 1018, 712, 1055], [729, 1018, 863, 1055], [879, 1018, 936, 1046], [951, 1018, 1033, 1046], [1050, 1022, 1080, 1046], [1095, 1027, 1193, 1047], [1208, 1027, 1359, 1055], [1384, 1019, 1416, 1046], [1431, 1018, 1481, 1046], [1496, 1018, 1654, 1055], [1669, 1018, 1868, 1055], [1885, 1027, 1932, 1047], [1947, 1018, 2037, 1055], [2052, 1018, 2100, 1046], [450, 1064, 578, 1101], [590, 1064, 639, 1092], [651, 1064, 708, 1092], [719, 1064, 801, 1101], [813, 1073, 852, 1092], [864, 1068, 916, 1101], [928, 1064, 964, 1092], [974, 1073, 990, 1092], [1001, 1064, 1182, 1101], [1194, 1064, 1349, 1093], [744, 1152, 833, 1180], [849, 1152, 873, 1180], [890, 1151, 1073, 1181], [1086, 1151, 1254, 1181], [1267, 1160, 1424, 1189], [1436, 1160, 1478, 1181], [1490, 1151, 1648, 1181], [1663, 1151, 1751, 1189], [1764, 1151, 1805, 1187], [621, 1218, 659, 1250], [671, 1217, 781, 1251], [793, 1217, 939, 1244], [469, 1285, 594, 1319], [606, 1285, 703, 1319], [892, 1265, 1015, 1298], [1025, 1264, 1093, 1290], [901, 1307, 946, 1333], [1039, 1307, 1085, 1333], [468, 1350, 549, 1375], [560, 1349, 663, 1375], [875, 1349, 970, 1376], [1014, 1349, 1107, 1376], [469, 1392, 633, 1418], [644, 1399, 663, 1418], [675, 1392, 837, 1426], [876, 1393, 970, 1419], [1011, 1392, 1108, 1419], [469, 1435, 633, 1461], [644, 1442, 663, 1461], [675, 1435, 725, 1461], [736, 1435, 810, 1469], [873, 1435, 971, 1462], [1014, 1435, 1107, 1462], [1459, 1213, 1499, 1246], [1511, 1214, 1664, 1247], [1676, 1213, 1821, 1240], [1173, 1282, 1251, 1315], [1262, 1281, 1459, 1315], [1828, 1262, 1913, 1287], [1925, 1261, 2088, 1287], [1856, 1302, 1900, 1328], [2007, 1311, 2042, 1328], [1174, 1345, 1367, 1379], [1378, 1345, 1478, 1379], [1489, 1345, 1552, 1372], [1565, 1345, 1600, 1378], [1614, 1357, 1640, 1366], [1655, 1346, 1683, 1378], [1871, 1361, 1881, 1364], [1977, 1346, 2070, 1372], [1173, 1388, 1282, 1422], [1293, 1388, 1356, 1415], [1369, 1388, 1490, 1422], [1502, 1389, 1543, 1421], [1555, 1388, 1591, 1421], [1605, 1400, 1631, 1409], [1645, 1389, 1673, 1421], [1871, 1404, 1881, 1407], [1978, 1389, 2070, 1415], [1173, 1432, 1282, 1466], [1293, 1432, 1356, 1459], [1369, 1432, 1490, 1466], [1502, 1433, 1543, 1465], [1555, 1432, 1591, 1465], [1605, 1444, 1631, 1453], [1646, 1433, 1692, 1465], [1829, 1433, 1923, 1459], [1974, 1432, 2071, 1459], [1173, 1475, 1326, 1509], [1338, 1475, 1460, 1509], [1472, 1475, 1551, 1508], [1565, 1487, 1591, 1496], [1606, 1476, 1653, 1508], [1829, 1475, 1923, 1502], [1978, 1476, 2070, 1502], [1173, 1518, 1282, 1552], [1293, 1518, 1356, 1545], [1369, 1518, 1490, 1552], [1502, 1518, 1581, 1551], [1595, 1530, 1621, 1539], [1637, 1519, 1692, 1551], [1703, 1518, 1791, 1544], [1871, 1534, 1881, 1537], [1974, 1518, 2071, 1545], [451, 1639, 620, 1676], [639, 1638, 817, 1668], [849, 1639, 968, 1676], [986, 1639, 1141, 1668], [1160, 1639, 1266, 1676], [1283, 1639, 1431, 1668], [1447, 1639, 1584, 1673], [1605, 1648, 1652, 1668], [1669, 1648, 1738, 1668], [1756, 1643, 1821, 1667], [1838, 1643, 1869, 1667], [1886, 1639, 1936, 1667], [1953, 1639, 2099, 1676], [451, 1684, 598, 1713], [612, 1684, 830, 1718], [848, 1684, 905, 1712], [921, 1693, 1018, 1712], [1034, 1684, 1083, 1712], [1097, 1684, 1190, 1712], [1203, 1684, 1239, 1712], [1250, 1684, 1300, 1712], [1314, 1684, 1399, 1721], [1412, 1684, 1656, 1721], [1673, 1684, 1830, 1712], [1845, 1684, 1875, 1712], [1891, 1684, 1968, 1713], [1985, 1684, 2001, 1713], [2007, 1684, 2030, 1712], [2038, 1708, 2043, 1712], [2066, 1685, 2099, 1712], [450, 1730, 615, 1767], [630, 1739, 677, 1759], [690, 1739, 827, 1758], [840, 1730, 889, 1758], [902, 1730, 995, 1758], [1007, 1730, 1049, 1758], [1067, 1730, 1156, 1767], [1170, 1730, 1307, 1767], [1321, 1730, 1359, 1765], [1376, 1743, 1404, 1752], [1423, 1727, 1470, 1768], [1484, 1727, 1554, 1768], [1570, 1730, 1691, 1758], [1704, 1730, 1816, 1767], [1829, 1730, 1926, 1764], [1941, 1730, 2099, 1767], [451, 1776, 597, 1813], [617, 1785, 705, 1804], [722, 1776, 940, 1813], [956, 1776, 1148, 1810], [1167, 1776, 1256, 1813], [1272, 1776, 1322, 1804], [1337, 1776, 1560, 1804], [1576, 1776, 1687, 1813], [1703, 1776, 1780, 1805], [1809, 1776, 1872, 1804], [1889, 1776, 2097, 1804], [451, 1830, 500, 1849], [514, 1821, 627, 1849], [641, 1830, 681, 1849], [695, 1821, 745, 1849], [758, 1821, 909, 1850], [928, 1821, 1042, 1849], [1055, 1821, 1135, 1849], [1150, 1821, 1273, 1855], [1290, 1830, 1324, 1849], [1339, 1830, 1386, 1850], [1399, 1821, 1474, 1849], [1489, 1830, 1525, 1849], [1541, 1821, 1712, 1858], [1726, 1821, 1854, 1858], [1866, 1821, 1942, 1849], [1956, 1821, 1991, 1849], [2004, 1821, 2053, 1850], [2068, 1825, 2099, 1849], [449, 1867, 520, 1904], [531, 1867, 667, 1904], [678, 1867, 918, 1904], [934, 1867, 997, 1895], [1007, 1867, 1113, 1895], [1127, 1876, 1175, 1895], [1187, 1867, 1292, 1896], [1303, 1867, 1333, 1895], [1345, 1867, 1434, 1895], [1449, 1867, 1494, 1895], [1510, 1867, 1593, 1901], [1606, 1876, 1653, 1896], [1664, 1876, 1720, 1895], [1731, 1867, 1879, 1895], [1890, 1867, 1952, 1895], [1963, 1867, 2099, 1904], [450, 1913, 587, 1950], [599, 1913, 638, 1948], [654, 1919, 680, 1943], [698, 1913, 727, 1948], [739, 1913, 958, 1950], [967, 1913, 1054, 1941], [1066, 1913, 1097, 1941], [1108, 1913, 1157, 1941], [1167, 1913, 1252, 1950], [1262, 1913, 1286, 1941], [1298, 1913, 1403, 1950], [1413, 1913, 1582, 1947], [1596, 1922, 1626, 1941], [1639, 1913, 1661, 1941], [1670, 1913, 1810, 1950], [1822, 1913, 1871, 1941], [1882, 1913, 2017, 1942], [2027, 1913, 2099, 1942], [450, 1958, 613, 1995], [625, 1958, 741, 1986], [753, 1958, 956, 1992], [970, 1958, 1070, 1987], [1082, 1958, 1107, 1986], [1120, 1967, 1204, 1986], [1216, 1958, 1451, 1987], [1463, 1958, 1532, 1986], [1545, 1958, 1594, 1986], [1606, 1958, 1677, 1987], [1688, 1958, 1826, 1987], [1839, 1967, 1855, 1986], [1866, 1958, 1931, 1995], [1942, 1958, 1978, 1986], [1988, 1958, 2097, 1986], [451, 2004, 490, 2039], [506, 2017, 534, 2026], [552, 2004, 565, 2032], [581, 2004, 712, 2041], [729, 2004, 900, 2041], [912, 2004, 961, 2032], [973, 2004, 1099, 2032], [1111, 2004, 1147, 2032], [1156, 2004, 1241, 2041], [1252, 2004, 1338, 2033], [1352, 2004, 1431, 2032], [1444, 2004, 1461, 2033], [1474, 2008, 1505, 2032], [1520, 2004, 1556, 2033], [1569, 2004, 1651, 2032], [1665, 2008, 1696, 2032], [1709, 2013, 1725, 2032], [1738, 2004, 1859, 2032], [1870, 2004, 2097, 2041], [451, 2059, 486, 2078], [501, 2059, 548, 2079], [562, 2050, 634, 2087], [649, 2050, 674, 2078], [690, 2050, 771, 2078], [786, 2054, 817, 2078], [835, 2050, 871, 2079], [887, 2050, 918, 2078], [933, 2050, 983, 2078], [998, 2050, 1156, 2087], [1172, 2050, 1381, 2087], [1408, 2050, 1537, 2084], [1555, 2059, 1602, 2079], [1617, 2050, 1680, 2078], [1695, 2050, 1757, 2078], [1771, 2059, 1859, 2078], [1876, 2050, 2057, 2078], [2073, 2050, 2097, 2078], [449, 2095, 575, 2132], [594, 2104, 625, 2123], [642, 2095, 665, 2123], [678, 2095, 803, 2123], [820, 2095, 869, 2123], [885, 2095, 978, 2123], [992, 2095, 1028, 2123], [1041, 2095, 1143, 2132], [1158, 2095, 1274, 2123], [1289, 2095, 1427, 2124], [1442, 2095, 1492, 2123], [1507, 2095, 1627, 2123], [1653, 2096, 1707, 2123], [1722, 2104, 1777, 2123], [1792, 2095, 1815, 2123], [1829, 2095, 1860, 2123], [1875, 2095, 1925, 2123], [1940, 2095, 2099, 2132], [450, 2141, 650, 2178], [667, 2150, 697, 2169], [714, 2141, 836, 2169], [860, 2141, 923, 2169], [938, 2141, 1104, 2169], [1117, 2141, 1255, 2170], [1270, 2141, 1411, 2169], [1426, 2141, 1562, 2178], [1577, 2141, 1751, 2178], [1767, 2141, 1792, 2169], [1808, 2141, 1963, 2178], [1981, 2141, 2004, 2169], [2017, 2145, 2097, 2169], [450, 2191, 503, 2215], [516, 2187, 578, 2215], [591, 2187, 702, 2224], [716, 2187, 787, 2216], [802, 2187, 938, 2224], [951, 2187, 1099, 2224], [1114, 2187, 1208, 2215], [1222, 2187, 1291, 2215], [1306, 2187, 1463, 2224], [1478, 2187, 1622, 2224], [1640, 2187, 1697, 2215], [1710, 2187, 1799, 2224], [1814, 2187, 1863, 2215], [1876, 2187, 2099, 2215], [450, 2232, 562, 2269], [573, 2232, 644, 2261], [655, 2232, 679, 2260], [692, 2232, 764, 2269], [776, 2232, 898, 2269], [908, 2232, 1003, 2260], [1013, 2232, 1082, 2260], [1094, 2241, 1110, 2260], [1120, 2232, 1364, 2260], [1375, 2232, 1504, 2261], [1515, 2232, 1592, 2261], [1608, 2232, 1730, 2269], [1743, 2241, 1790, 2261], [1801, 2236, 1871, 2260], [1881, 2232, 1943, 2260], [1953, 2232, 2099, 2269], [450, 2278, 612, 2307], [627, 2278, 829, 2315], [841, 2278, 1027, 2315], [1039, 2278, 1088, 2306], [1101, 2278, 1207, 2315], [1219, 2278, 1381, 2307], [1395, 2278, 1498, 2313], [1514, 2278, 1570, 2313], [1584, 2278, 1684, 2307], [1696, 2278, 1839, 2306], [1852, 2278, 1902, 2306], [1914, 2278, 2099, 2315], [450, 2324, 486, 2352], [495, 2324, 611, 2352], [623, 2324, 818, 2352], [830, 2324, 877, 2352], [890, 2324, 988, 2352], [999, 2324, 1197, 2361], [449, 2395, 503, 2422], [516, 2394, 580, 2422], [593, 2394, 808, 2431], [820, 2394, 869, 2422], [882, 2394, 975, 2423], [987, 2394, 1107, 2422], [1121, 2394, 1315, 2422], [1327, 2394, 1362, 2422], [1375, 2394, 1448, 2428], [1462, 2394, 1561, 2423], [1575, 2398, 1711, 2422], [1725, 2398, 1755, 2422], [1769, 2394, 1911, 2431], [1924, 2403, 1940, 2422], [1952, 2394, 2100, 2423], [450, 2444, 481, 2468], [500, 2449, 516, 2468], [534, 2440, 618, 2468], [634, 2440, 670, 2468], [685, 2440, 766, 2469], [786, 2440, 896, 2468], [916, 2440, 965, 2475], [986, 2440, 1096, 2468], [1115, 2440, 1145, 2468], [1163, 2449, 1218, 2468], [1234, 2440, 1327, 2475], [1358, 2440, 1457, 2468], [1474, 2440, 1588, 2468], [1605, 2440, 1685, 2468], [1703, 2440, 1818, 2468], [1836, 2449, 1875, 2468], [1893, 2440, 2057, 2474], [2077, 2440, 2100, 2468], [451, 2485, 595, 2514], [615, 2482, 718, 2515], [740, 2494, 890, 2522], [913, 2485, 1012, 2514], [1031, 2485, 1056, 2513], [1075, 2485, 1170, 2513], [1188, 2485, 1258, 2513], [1278, 2494, 1294, 2513], [1313, 2485, 1521, 2522], [1540, 2485, 1734, 2513], [1753, 2485, 1866, 2513], [1885, 2485, 1964, 2513], [1984, 2485, 2099, 2513], [451, 2528, 594, 2566], [608, 2531, 661, 2559], [673, 2531, 697, 2559], [713, 2531, 773, 2559], [786, 2531, 831, 2559], [843, 2531, 892, 2559], [902, 2531, 951, 2559], [964, 2531, 1099, 2560], [1112, 2531, 1225, 2559], [1239, 2531, 1318, 2559], [1332, 2531, 1447, 2559], [1460, 2540, 1500, 2559], [1513, 2531, 1625, 2568], [1638, 2531, 1715, 2560], [1735, 2531, 1805, 2559], [1821, 2531, 1920, 2560], [1934, 2531, 1996, 2559], [2008, 2531, 2099, 2560], [450, 2577, 647, 2605], [658, 2577, 852, 2605], [863, 2577, 887, 2605], [899, 2577, 1068, 2614], [1080, 2577, 1103, 2605], [1112, 2577, 1137, 2605], [1150, 2577, 1214, 2605], [1224, 2577, 1385, 2614], [1395, 2581, 1425, 2605], [1435, 2581, 1555, 2614], [1565, 2577, 1587, 2605], [1597, 2581, 1627, 2605], [1639, 2586, 1655, 2605], [1665, 2577, 1813, 2606], [1822, 2577, 1853, 2605], [1864, 2586, 1901, 2605], [1912, 2577, 2099, 2614], [450, 2631, 580, 2650], [450, 2692, 636, 2722], [647, 2692, 792, 2730], [803, 2692, 838, 2722], [847, 2693, 1006, 2730], [1018, 2692, 1196, 2722], [1211, 2693, 1351, 2730], [1362, 2693, 1508, 2730], [1519, 2693, 1680, 2722], [1692, 2702, 1732, 2721], [1743, 2693, 1894, 2722], [1909, 2693, 1934, 2721], [1946, 2693, 2098, 2730], [450, 2739, 502, 2776], [517, 2739, 575, 2767], [590, 2743, 620, 2767], [635, 2739, 685, 2767], [700, 2739, 788, 2767], [804, 2739, 866, 2767], [880, 2739, 916, 2767], [928, 2739, 977, 2767], [992, 2739, 1119, 2776], [1135, 2743, 1188, 2767], [1212, 2739, 1261, 2767], [1276, 2748, 1351, 2768], [1365, 2739, 1472, 2776], [1486, 2739, 1643, 2776], [1658, 2739, 1682, 2767], [1699, 2743, 1729, 2767], [1744, 2739, 1819, 2767], [1834, 2739, 1883, 2767], [1898, 2739, 2045, 2768], [2059, 2748, 2099, 2767], [450, 2783, 637, 2818], [653, 2784, 753, 2813], [767, 2784, 841, 2812], [855, 2784, 982, 2821], [997, 2784, 1067, 2821], [1080, 2784, 1104, 2812], [1121, 2784, 1170, 2813], [1185, 2784, 1272, 2812], [1288, 2784, 1408, 2812], [1421, 2784, 1491, 2812], [1505, 2784, 1566, 2812], [1579, 2784, 1615, 2812], [1626, 2784, 1790, 2813], [1811, 2785, 1890, 2812], [1904, 2793, 1951, 2813], [1964, 2784, 2099, 2813], [451, 2830, 592, 2858], [601, 2830, 720, 2867], [731, 2830, 779, 2858], [788, 2830, 957, 2867], [967, 2830, 1016, 2858], [1026, 2830, 1167, 2859], [1177, 2830, 1304, 2867], [1316, 2834, 1360, 2858], [1370, 2830, 1432, 2858], [1442, 2830, 1478, 2858], [1485, 2829, 1672, 2859], [1689, 2830, 1724, 2865], [1736, 2830, 1916, 2867], [1927, 2839, 1943, 2858], [1953, 2830, 2099, 2867], [451, 2876, 585, 2905], [594, 2876, 775, 2913], [786, 2885, 825, 2904], [836, 2876, 1001, 2910], [1014, 2876, 1061, 2911], [1074, 2876, 1184, 2913], [1195, 2876, 1233, 2905], [1245, 2876, 1357, 2904], [1369, 2876, 1448, 2904], [1458, 2876, 1622, 2910], [1634, 2876, 1734, 2905], [1745, 2885, 1794, 2904], [1804, 2876, 1956, 2913], [1968, 2876, 2099, 2904], [452, 2930, 486, 2949], [496, 2921, 558, 2949], [568, 2921, 649, 2949], [660, 2921, 684, 2949], [697, 2930, 736, 2949], [747, 2921, 939, 2949], [949, 2921, 1087, 2950], [1098, 2921, 1181, 2949], [1192, 2921, 1304, 2949], [1317, 2921, 1374, 2949], [1385, 2921, 1435, 2949], [1445, 2921, 1544, 2950], [1554, 2920, 1728, 2950], [1743, 2921, 1866, 2955], [1880, 2921, 1939, 2956], [1950, 2921, 2039, 2958], [2050, 2921, 2099, 2949], [451, 2967, 618, 2995], [632, 2967, 826, 2995], [842, 2967, 933, 3002], [950, 2967, 981, 3002], [997, 2971, 1028, 2995], [1042, 2967, 1124, 2995], [1139, 2976, 1155, 2995], [1170, 2967, 1260, 2996], [1274, 2967, 1517, 3004], [1535, 2967, 1641, 2995], [1655, 2967, 1792, 2996], [1807, 2967, 1856, 2995], [1871, 2967, 2022, 2996], [2042, 2967, 2099, 2995], [451, 3012, 625, 3042], [643, 3013, 858, 3041], [872, 3013, 962, 3041], [983, 3013, 1046, 3041], [1059, 3013, 1165, 3041], [1182, 3022, 1230, 3041], [1242, 3013, 1380, 3050], [1394, 3013, 1424, 3041], [1438, 3013, 1528, 3041], [1542, 3013, 1570, 3041], [1591, 3013, 1634, 3041], [1650, 3013, 1803, 3050], [1819, 3013, 1842, 3041], [1855, 3013, 1879, 3041], [1894, 3013, 2054, 3041], [2068, 3017, 2099, 3041], [1265, 3138, 1283, 3165], [486, 345, 576, 373], [588, 345, 615, 373], [633, 345, 803, 382], [815, 344, 969, 374], [980, 353, 1137, 382], [1149, 353, 1191, 374], [1204, 344, 1384, 373], [1400, 344, 1488, 382], [1501, 344, 1516, 373], [1530, 344, 1606, 374], [1619, 344, 1797, 374], [1809, 344, 1950, 382], [1962, 344, 2063, 380], [741, 408, 867, 442], [879, 408, 976, 442], [1658, 409, 1799, 442], [741, 451, 867, 485], [878, 460, 914, 477], [925, 451, 1082, 478], [1096, 451, 1209, 478], [1219, 451, 1367, 477], [1378, 451, 1440, 477], [1680, 451, 1774, 478], [740, 494, 914, 528], [925, 503, 941, 520], [951, 495, 1090, 525], [1102, 494, 1265, 528], [1276, 503, 1312, 520], [1323, 495, 1459, 521], [1680, 495, 1774, 521], [741, 537, 867, 571], [878, 546, 914, 563], [925, 537, 1082, 564], [1096, 537, 1161, 564], [1172, 537, 1273, 563], [1285, 537, 1372, 563], [1383, 537, 1455, 563], [1465, 538, 1602, 564], [1681, 537, 1774, 564], [740, 580, 896, 606], [906, 580, 1027, 614], [1038, 589, 1074, 606], [1085, 580, 1242, 607], [1256, 580, 1308, 606], [1319, 581, 1456, 607], [1678, 580, 1775, 607], [450, 657, 551, 685], [561, 657, 617, 685], [629, 657, 681, 692], [693, 657, 776, 694], [789, 657, 963, 692], [975, 657, 1126, 686], [1141, 657, 1209, 685], [1219, 657, 1267, 685], [1277, 657, 1404, 694], [1416, 657, 1522, 692], [1532, 657, 1687, 694], [1696, 657, 1737, 694], [1747, 657, 1918, 694], [1929, 657, 2053, 694], [2066, 666, 2100, 685], [451, 703, 610, 740], [621, 703, 661, 740], [672, 703, 890, 740], [906, 703, 1078, 731], [1088, 703, 1223, 740], [1233, 703, 1381, 740], [1394, 703, 1443, 731], [1453, 703, 1528, 737], [1542, 712, 1573, 731], [1585, 703, 1608, 731], [1619, 703, 1722, 732], [1735, 703, 1785, 731], [1796, 703, 1923, 740], [1934, 703, 2099, 740], [451, 752, 481, 776], [493, 748, 607, 785], [619, 748, 658, 776], [671, 748, 817, 777], [828, 748, 956, 785], [968, 748, 1044, 776], [450, 820, 503, 847], [514, 819, 591, 848], [604, 819, 668, 847], [681, 819, 904, 856], [916, 819, 989, 848], [1001, 819, 1169, 847], [1180, 819, 1314, 856], [1327, 828, 1366, 847], [1379, 819, 1428, 847], [1440, 819, 1591, 848], [1608, 819, 1730, 853], [1743, 819, 1784, 856], [1796, 819, 1923, 856], [1937, 828, 1953, 847], [1965, 819, 2100, 848], [451, 868, 481, 892], [494, 864, 619, 901], [631, 864, 704, 892], [716, 864, 766, 892], [778, 864, 834, 892], [847, 863, 1021, 893], [1037, 864, 1105, 892], [1119, 864, 1171, 899], [1185, 864, 1268, 901], [1282, 864, 1457, 899], [1472, 864, 1529, 892], [1542, 864, 1591, 892], [1604, 864, 1755, 893], [1771, 864, 1839, 892], [1852, 864, 1882, 899], [1896, 864, 1992, 901], [2006, 864, 2097, 901], [451, 910, 499, 939], [513, 910, 563, 938], [576, 910, 640, 938], [654, 910, 724, 947], [737, 910, 773, 938], [784, 910, 947, 944], [964, 910, 1013, 938], [1027, 919, 1172, 947], [1186, 919, 1247, 939], [1262, 910, 1419, 938], [1433, 914, 1464, 938], [1477, 910, 1515, 938], [1530, 909, 1643, 944], [1659, 910, 1759, 939], [1773, 910, 1923, 947], [1938, 919, 1978, 938], [1993, 907, 2097, 940], [452, 956, 595, 985], [606, 956, 695, 993], [707, 956, 756, 984], [769, 965, 852, 984], [865, 956, 998, 993], [1010, 956, 1063, 984], [1074, 956, 1200, 985], [1211, 956, 1261, 984], [1273, 956, 1437, 984], [1449, 957, 1570, 984], [1584, 956, 1799, 984], [1811, 956, 1877, 984], [1889, 956, 1992, 991], [2008, 956, 2066, 991], [451, 1026, 659, 1055], [677, 1025, 855, 1055], [884, 1027, 963, 1054], [980, 1035, 1027, 1055], [1043, 1026, 1178, 1055], [1195, 1026, 1244, 1054], [1260, 1026, 1411, 1063], [1427, 1030, 1612, 1055], [1629, 1026, 1740, 1060], [1759, 1026, 1859, 1055], [1876, 1026, 2032, 1054], [2050, 1026, 2099, 1054], [451, 1076, 511, 1101], [526, 1072, 714, 1109], [732, 1076, 864, 1100], [893, 1072, 961, 1101], [977, 1081, 1044, 1109], [1060, 1072, 1096, 1100], [1109, 1072, 1285, 1109], [1302, 1072, 1351, 1100], [1367, 1072, 1515, 1101], [1533, 1072, 1635, 1101], [1650, 1072, 1689, 1100], [1705, 1076, 1735, 1100], [1752, 1072, 1826, 1100], [1843, 1081, 1859, 1100], [1871, 1072, 1951, 1109], [1967, 1072, 2051, 1100], [2066, 1072, 2102, 1100], [451, 1118, 709, 1155], [721, 1118, 817, 1155], [829, 1127, 869, 1146], [881, 1122, 932, 1155], [943, 1118, 979, 1146], [987, 1118, 1063, 1147], [1075, 1127, 1109, 1146], [1120, 1118, 1195, 1146], [1208, 1118, 1304, 1155], [1316, 1118, 1352, 1146], [1361, 1118, 1410, 1146], [1421, 1122, 1481, 1147], [1492, 1122, 1566, 1146], [1582, 1118, 1663, 1152], [1675, 1118, 1822, 1152], [1835, 1127, 1896, 1147], [1909, 1122, 1961, 1146], [1971, 1118, 2099, 1146], [451, 1163, 481, 1191], [498, 1172, 552, 1191], [569, 1172, 639, 1191], [655, 1163, 714, 1191], [730, 1167, 761, 1191], [778, 1163, 969, 1200], [999, 1164, 1053, 1191], [1070, 1163, 1218, 1191], [1235, 1163, 1323, 1191], [1340, 1163, 1389, 1191], [1407, 1163, 1538, 1191], [1556, 1172, 1655, 1191], [1673, 1163, 1762, 1200], [1779, 1163, 1872, 1191], [1890, 1163, 2049, 1200], [2066, 1172, 2100, 1191], [452, 1218, 468, 1237], [484, 1209, 577, 1237], [594, 1209, 690, 1238], [708, 1210, 797, 1237], [813, 1209, 902, 1237], [920, 1209, 936, 1238], [954, 1218, 1001, 1238], [1017, 1209, 1166, 1237], [1182, 1209, 1251, 1237], [1278, 1209, 1314, 1244], [1332, 1209, 1480, 1246], [1495, 1209, 1558, 1238], [1572, 1209, 1685, 1246], [1701, 1210, 1888, 1246], [1904, 1214, 2030, 1238], [2047, 1219, 2098, 1237], [451, 1255, 709, 1292], [731, 1265, 766, 1284], [785, 1255, 862, 1283], [871, 1255, 977, 1292], [995, 1255, 1196, 1292], [1214, 1256, 1361, 1292], [1379, 1265, 1418, 1283], [1436, 1255, 1508, 1283], [1526, 1252, 1591, 1290], [1610, 1264, 1681, 1284], [1698, 1255, 1844, 1292], [1862, 1255, 1919, 1283], [1939, 1252, 2009, 1285], [2028, 1264, 2100, 1284], [452, 1300, 557, 1337], [570, 1300, 659, 1335], [676, 1300, 723, 1335], [738, 1300, 933, 1329], [947, 1300, 1049, 1328], [1062, 1300, 1098, 1328], [1109, 1300, 1240, 1328], [1254, 1309, 1354, 1328], [1368, 1300, 1568, 1337], [1583, 1300, 1685, 1328], [1697, 1300, 1738, 1337], [1752, 1300, 1921, 1337], [1938, 1300, 1996, 1335], [2010, 1300, 2099, 1337], [450, 1346, 673, 1374], [687, 1346, 758, 1375], [772, 1346, 797, 1374], [813, 1350, 865, 1374], [877, 1346, 1038, 1374], [1052, 1346, 1083, 1374], [1097, 1346, 1146, 1374], [1160, 1355, 1230, 1374], [1245, 1346, 1280, 1374], [1292, 1346, 1439, 1375], [1453, 1346, 1564, 1380], [1583, 1346, 1638, 1381], [1653, 1346, 1799, 1383], [1813, 1346, 1969, 1380], [1985, 1346, 2099, 1374], [450, 1392, 539, 1429], [551, 1392, 718, 1420], [730, 1392, 873, 1429], [885, 1392, 1033, 1429], [1047, 1392, 1096, 1420], [1107, 1392, 1174, 1420], [1184, 1392, 1257, 1420], [1270, 1392, 1358, 1420], [1370, 1392, 1428, 1420], [1440, 1392, 1528, 1421], [1540, 1392, 1628, 1420], [1640, 1392, 1712, 1421], [1726, 1401, 1742, 1420], [1754, 1392, 1860, 1429], [1872, 1396, 1930, 1420], [739, 1487, 829, 1515], [841, 1487, 868, 1516], [885, 1487, 1094, 1516], [1107, 1486, 1260, 1516], [1272, 1495, 1429, 1524], [1441, 1495, 1483, 1516], [1495, 1486, 1653, 1516], [1668, 1486, 1756, 1524], [1769, 1486, 1810, 1522], [644, 1550, 745, 1584], [756, 1551, 888, 1577], [1036, 1550, 1177, 1584], [1188, 1551, 1320, 1577], [1477, 1550, 1578, 1576], [1588, 1550, 1703, 1576], [1756, 1551, 1897, 1584], [643, 1593, 807, 1619], [818, 1600, 837, 1619], [849, 1593, 899, 1619], [910, 1593, 984, 1627], [1035, 1593, 1236, 1619], [1478, 1593, 1622, 1627], [1780, 1593, 1873, 1620], [643, 1636, 807, 1662], [818, 1643, 837, 1662], [849, 1636, 899, 1662], [910, 1636, 984, 1670], [1035, 1636, 1254, 1662], [1478, 1636, 1622, 1670], [1780, 1636, 1873, 1663], [643, 1679, 807, 1705], [818, 1686, 837, 1705], [849, 1679, 899, 1705], [910, 1679, 984, 1713], [1035, 1679, 1262, 1710], [1275, 1679, 1425, 1705], [1478, 1679, 1622, 1713], [1780, 1679, 1873, 1706], [643, 1723, 807, 1749], [818, 1730, 837, 1749], [849, 1723, 899, 1749], [910, 1723, 984, 1757], [1035, 1723, 1262, 1754], [1275, 1723, 1425, 1749], [1479, 1724, 1556, 1750], [1776, 1723, 1874, 1750], [452, 1850, 668, 1888], [684, 1850, 760, 1880], [776, 1851, 830, 1880], [846, 1853, 928, 1880], [943, 1850, 979, 1880], [992, 1851, 1046, 1880], [1062, 1853, 1123, 1880], [1148, 1852, 1202, 1879], [1218, 1851, 1366, 1879], [1382, 1851, 1431, 1879], [1447, 1851, 1661, 1888], [1677, 1851, 1846, 1880], [1862, 1851, 1934, 1880], [1950, 1851, 2000, 1879], [2015, 1860, 2098, 1879], [449, 1896, 571, 1933], [587, 1896, 702, 1933], [716, 1896, 765, 1924], [780, 1900, 854, 1924], [868, 1896, 904, 1924], [916, 1896, 965, 1924], [980, 1900, 1023, 1924], [1036, 1905, 1076, 1924], [1090, 1896, 1172, 1924], [1187, 1896, 1271, 1933], [1287, 1896, 1322, 1924], [1334, 1896, 1485, 1925], [1505, 1896, 1562, 1924], [1576, 1895, 1763, 1925], [1787, 1897, 1843, 1924], [1857, 1896, 1919, 1924], [1932, 1905, 1979, 1925], [1992, 1896, 2067, 1924], [2083, 1905, 2099, 1924], [451, 1942, 557, 1979], [573, 1946, 631, 1976], [648, 1942, 830, 1979], [846, 1951, 886, 1970], [902, 1942, 1056, 1976], [1074, 1942, 1146, 1971], [1162, 1942, 1211, 1970], [1227, 1942, 1284, 1970], [1299, 1942, 1381, 1979], [1396, 1942, 1509, 1970], [1525, 1951, 1565, 1970], [1581, 1942, 1661, 1971], [1676, 1951, 1710, 1970], [1725, 1943, 1856, 1970], [1874, 1942, 1937, 1970], [1953, 1942, 2099, 1979], [450, 1991, 501, 2015], [514, 1996, 575, 2016], [591, 1987, 705, 2015], [719, 1996, 759, 2015], [774, 1987, 854, 2016], [869, 1987, 926, 2015], [940, 1988, 1061, 2015], [1077, 1987, 1166, 2024], [1181, 1987, 1348, 2015], [1362, 1987, 1505, 2024], [1523, 1987, 1580, 2015], [1595, 1987, 1644, 2015], [1659, 1987, 1743, 2024], [1757, 1996, 1818, 2016], [1834, 1987, 1996, 2024], [2010, 1987, 2099, 2024], [449, 2033, 693, 2061], [704, 2033, 815, 2070], [825, 2033, 896, 2062], [908, 2033, 1044, 2070], [1054, 2033, 1126, 2062], [1137, 2042, 1225, 2061], [1236, 2033, 1427, 2061], [1442, 2033, 1506, 2061], [1517, 2033, 1648, 2061], [1659, 2042, 1759, 2061], [1771, 2033, 1807, 2061], [1814, 2033, 1863, 2061], [1874, 2037, 1934, 2062], [1944, 2037, 2008, 2061], [2020, 2042, 2099, 2062], [450, 2079, 612, 2107], [623, 2079, 712, 2116], [725, 2079, 884, 2116], [896, 2088, 930, 2107], [941, 2079, 1037, 2108], [1051, 2079, 1094, 2107], [1107, 2088, 1162, 2107], [1173, 2079, 1212, 2107], [1224, 2088, 1295, 2107], [1307, 2079, 1386, 2107], [1397, 2079, 1487, 2107], [1498, 2079, 1526, 2113], [1538, 2079, 1611, 2107], [1623, 2088, 1678, 2107], [1689, 2079, 1795, 2116], [1807, 2079, 1865, 2107], [1876, 2079, 2022, 2116], [2034, 2083, 2097, 2107], [451, 2124, 539, 2152], [552, 2124, 737, 2161], [750, 2124, 799, 2152], [812, 2124, 889, 2161], [903, 2124, 1111, 2152], [1126, 2124, 1161, 2152], [1175, 2124, 1234, 2158], [1253, 2124, 1299, 2158], [1315, 2124, 1355, 2161], [1370, 2133, 1386, 2152], [1398, 2124, 1479, 2161], [1492, 2124, 1616, 2161], [1635, 2124, 1699, 2152], [1711, 2124, 1917, 2152], [1930, 2124, 1966, 2152], [1976, 2124, 2026, 2152], [2039, 2128, 2099, 2153], [450, 2174, 514, 2198], [527, 2170, 639, 2198], [650, 2170, 800, 2207], [812, 2170, 862, 2198], [872, 2170, 978, 2198], [992, 2170, 1035, 2205], [1046, 2170, 1107, 2198], [1118, 2170, 1190, 2199], [1202, 2170, 1251, 2198], [1263, 2170, 1446, 2207], [1456, 2170, 1655, 2207], [1669, 2170, 1787, 2205], [1801, 2170, 1858, 2198], [1870, 2170, 1894, 2198], [1907, 2170, 2099, 2207], [450, 2220, 481, 2244], [493, 2216, 542, 2244], [554, 2225, 626, 2253], [637, 2220, 739, 2244], [751, 2216, 996, 2244], [1006, 2216, 1215, 2244], [1227, 2216, 1344, 2244], [1360, 2216, 1419, 2250], [1433, 2216, 1482, 2250], [1495, 2216, 1558, 2250], [652, 2311, 742, 2339], [754, 2311, 782, 2339], [799, 2311, 899, 2340], [911, 2319, 1068, 2348], [1081, 2310, 1170, 2346], [1182, 2311, 1272, 2340], [1284, 2310, 1387, 2348], [1400, 2319, 1442, 2340], [1455, 2310, 1612, 2340], [1626, 2311, 1691, 2340], [1704, 2310, 1896, 2340], [1009, 2374, 1124, 2400], [1655, 2375, 1791, 2401], [1848, 2374, 2005, 2401], [532, 2417, 675, 2451], [686, 2417, 769, 2443], [779, 2417, 943, 2451], [956, 2418, 1040, 2450], [1054, 2417, 1108, 2449], [1120, 2418, 1166, 2449], [1678, 2417, 1771, 2444], [1880, 2417, 1974, 2444], [532, 2461, 593, 2486], [604, 2460, 668, 2487], [678, 2460, 968, 2494], [979, 2460, 1128, 2494], [1141, 2461, 1197, 2492], [1674, 2460, 1772, 2487], [1880, 2460, 1974, 2487], [532, 2505, 593, 2530], [604, 2504, 668, 2531], [680, 2504, 789, 2530], [800, 2504, 893, 2530], [903, 2504, 1039, 2538], [1052, 2505, 1107, 2536], [1122, 2504, 1217, 2537], [1228, 2513, 1264, 2530], [1275, 2505, 1352, 2538], [1362, 2504, 1456, 2530], [1465, 2505, 1518, 2530], [1531, 2505, 1601, 2537], [1719, 2520, 1729, 2523], [1877, 2504, 1975, 2531], [533, 2547, 772, 2581], [782, 2548, 894, 2573], [906, 2547, 1027, 2574], [1039, 2548, 1093, 2579], [1109, 2547, 1151, 2579], [1719, 2563, 1729, 2566], [1880, 2548, 1974, 2574], [533, 2590, 623, 2617], [634, 2590, 741, 2616], [754, 2590, 986, 2624], [997, 2591, 1129, 2617], [1142, 2591, 1198, 2622], [1677, 2590, 1771, 2617], [1922, 2606, 1932, 2609], [533, 2643, 635, 2677], [646, 2647, 744, 2669], [754, 2644, 886, 2670], [1677, 2644, 1771, 2670], [1879, 2643, 1974, 2670], [532, 2686, 673, 2720], [685, 2690, 783, 2712], [793, 2687, 925, 2713], [1678, 2687, 1771, 2713], [1880, 2686, 1974, 2713], [532, 2730, 708, 2756], [719, 2729, 811, 2755], [822, 2729, 926, 2762], [936, 2729, 972, 2763], [983, 2729, 1139, 2763], [1678, 2729, 1771, 2756], [1880, 2729, 1974, 2756], [532, 2774, 708, 2800], [719, 2773, 811, 2799], [822, 2773, 926, 2806], [936, 2773, 972, 2807], [984, 2774, 1074, 2806], [1674, 2773, 1772, 2800], [1877, 2773, 1975, 2800], [452, 2875, 631, 2905], [644, 2875, 762, 2905], [775, 2876, 840, 2905], [853, 2876, 1007, 2913], [1020, 2876, 1117, 2905], [1130, 2875, 1180, 2905], [1193, 2875, 1351, 2905], [1366, 2875, 1600, 2905], [1618, 2877, 1650, 2904], [1663, 2876, 1726, 2913], [1741, 2875, 1758, 2905], [1773, 2885, 1820, 2905], [1833, 2876, 1917, 2905], [1930, 2876, 1979, 2904], [1992, 2876, 2098, 2904], [452, 2921, 518, 2949], [529, 2921, 635, 2949], [646, 2921, 693, 2949], [703, 2921, 854, 2950], [869, 2921, 1084, 2949], [1093, 2921, 1183, 2958], [1193, 2930, 1248, 2949], [1257, 2925, 1442, 2950], [1453, 2921, 1563, 2955], [1576, 2921, 1676, 2950], [1687, 2921, 1824, 2950], [1837, 2918, 1941, 2951], [1955, 2930, 2099, 2958], [451, 2976, 490, 2995], [501, 2967, 550, 2995], [561, 2967, 625, 2995], [634, 2967, 749, 2995], [760, 2967, 830, 3004], [840, 2967, 902, 3002], [913, 2967, 970, 2995], [978, 2976, 1041, 2996], [1052, 2967, 1088, 2995], [1095, 2967, 1185, 2995], [1197, 2967, 1237, 3002], [1252, 2968, 1306, 2995], [1317, 2967, 1381, 2995], [1392, 2967, 1536, 2996], [1546, 2967, 1596, 2995], [1606, 2967, 1842, 3004], [1852, 2967, 1996, 3004], [2007, 2967, 2099, 2995], [451, 3013, 597, 3050], [1266, 3137, 1282, 3166], [451, 354, 514, 382], [527, 358, 618, 383], [630, 354, 707, 382], [721, 354, 813, 382], [826, 354, 1023, 391], [1038, 358, 1068, 382], [1080, 355, 1278, 391], [1291, 354, 1379, 388], [1394, 354, 1494, 383], [1507, 354, 1531, 382], [1546, 354, 1694, 382], [1707, 354, 1779, 383], [1791, 354, 2027, 391], [2042, 354, 2099, 382], [449, 400, 689, 437], [701, 400, 823, 428], [838, 401, 892, 428], [904, 400, 999, 428], [1010, 400, 1072, 428], [1083, 400, 1139, 428], [1153, 400, 1177, 428], [1190, 400, 1249, 428], [1260, 404, 1291, 428], [1302, 404, 1362, 429], [1373, 409, 1506, 428], [1522, 400, 1605, 434], [1618, 400, 1667, 428], [1680, 400, 1786, 437], [1797, 400, 1945, 429], [1955, 400, 2097, 428], [449, 446, 647, 482], [662, 445, 734, 474], [749, 445, 993, 482], [1011, 445, 1111, 474], [1126, 454, 1182, 473], [1196, 445, 1235, 473], [1250, 445, 1361, 473], [1375, 445, 1416, 482], [1431, 445, 1481, 473], [1497, 445, 1668, 482], [1681, 454, 1826, 482], [1841, 445, 1877, 473], [1888, 445, 2000, 473], [2016, 445, 2097, 473], [450, 491, 481, 519], [495, 491, 568, 519], [582, 491, 704, 519], [729, 491, 857, 525], [874, 491, 923, 519], [938, 491, 1084, 528], [1098, 491, 1246, 520], [1259, 491, 1401, 519], [1416, 492, 1614, 528], [1628, 491, 1700, 520], [1714, 491, 1962, 528], [1980, 500, 2011, 519], [2026, 491, 2099, 519], [451, 537, 565, 565], [578, 537, 699, 565], [710, 537, 861, 574], [874, 537, 989, 565], [1001, 541, 1130, 574], [1144, 537, 1236, 572], [1248, 537, 1373, 574], [1384, 546, 1425, 574], [1438, 537, 1495, 565], [1507, 537, 1619, 572], [577, 2038, 684, 2075], [696, 2037, 724, 2067], [742, 2037, 921, 2067], [934, 2037, 1052, 2067], [1064, 2037, 1100, 2067], [1109, 2046, 1128, 2067], [1140, 2040, 1338, 2067], [1350, 2038, 1457, 2067], [1469, 2046, 1510, 2067], [1523, 2038, 1577, 2067], [1589, 2037, 1659, 2067], [1670, 2037, 1746, 2075], [1757, 2037, 1793, 2067], [1802, 2037, 1971, 2067], [451, 2197, 474, 2231], [526, 2197, 780, 2232], [795, 2197, 874, 2232], [888, 2197, 1095, 2232], [1110, 2197, 1171, 2232], [1185, 2197, 1467, 2241], [450, 2279, 503, 2306], [516, 2278, 668, 2315], [683, 2287, 699, 2306], [713, 2278, 790, 2315], [804, 2278, 895, 2307], [909, 2278, 1124, 2306], [1138, 2278, 1241, 2306], [1255, 2278, 1327, 2307], [1341, 2278, 1534, 2315], [1547, 2278, 1765, 2315], [1781, 2278, 1881, 2307], [1895, 2278, 2097, 2315], [452, 2328, 585, 2361], [603, 2324, 709, 2361], [727, 2324, 784, 2352], [802, 2324, 948, 2361], [964, 2324, 1152, 2361], [1170, 2328, 1293, 2352], [1311, 2324, 1405, 2352], [1422, 2333, 1462, 2352], [1479, 2324, 1651, 2353], [1682, 2324, 1840, 2361], [1857, 2324, 1880, 2352], [1897, 2333, 2019, 2361], [2038, 2324, 2100, 2352], [451, 2369, 578, 2406], [595, 2378, 611, 2397], [627, 2369, 773, 2406], [789, 2369, 936, 2398], [951, 2378, 991, 2397], [1007, 2369, 1118, 2406], [1134, 2369, 1205, 2398], [1222, 2369, 1266, 2404], [1283, 2369, 1366, 2404], [1383, 2369, 1408, 2397], [1426, 2369, 1629, 2406], [1644, 2369, 1739, 2397], [1754, 2369, 1824, 2397], [1840, 2369, 1967, 2406], [1983, 2378, 2023, 2397], [2038, 2378, 2099, 2398], [452, 2415, 573, 2443], [585, 2415, 695, 2443], [711, 2415, 784, 2449], [800, 2415, 863, 2443], [875, 2415, 960, 2443], [971, 2415, 995, 2443], [1008, 2415, 1154, 2452], [1166, 2419, 1218, 2443], [1230, 2415, 1430, 2452], [1445, 2415, 1502, 2443], [1514, 2415, 1611, 2452], [1620, 2415, 1737, 2452], [1750, 2415, 1955, 2443], [1967, 2415, 2097, 2452], [452, 2460, 512, 2495], [525, 2460, 672, 2497], [688, 2469, 704, 2488], [717, 2460, 923, 2488], [937, 2460, 1009, 2489], [1022, 2460, 1072, 2488], [1085, 2460, 1162, 2497], [1175, 2460, 1328, 2497], [1343, 2460, 1492, 2497], [1505, 2460, 1541, 2488], [1555, 2460, 1642, 2495], [1662, 2460, 1788, 2497], [1800, 2460, 1889, 2497], [1903, 2460, 2014, 2497], [2028, 2460, 2099, 2489], [452, 2515, 482, 2534], [496, 2506, 589, 2543], [604, 2515, 658, 2534], [670, 2506, 816, 2543], [829, 2506, 932, 2534], [944, 2506, 1017, 2534], [1032, 2510, 1084, 2534], [1095, 2506, 1212, 2543], [1226, 2506, 1398, 2543], [1408, 2506, 1640, 2543], [1656, 2506, 1739, 2534], [1752, 2506, 1801, 2534], [1814, 2506, 1884, 2535], [1898, 2506, 1922, 2534], [1937, 2506, 2099, 2543], [450, 2552, 539, 2589], [552, 2561, 568, 2580], [580, 2552, 702, 2580], [714, 2552, 807, 2580], [819, 2561, 859, 2580], [871, 2552, 921, 2580], [932, 2552, 1052, 2589], [1066, 2552, 1267, 2589], [1281, 2552, 1316, 2580], [1326, 2556, 1489, 2589], [1502, 2552, 1560, 2580], [1573, 2552, 1772, 2580], [451, 2622, 493, 2650], [506, 2631, 553, 2651], [564, 2622, 640, 2651], [652, 2622, 766, 2656], [779, 2626, 860, 2650], [871, 2622, 999, 2659], [1010, 2622, 1078, 2650], [1089, 2622, 1114, 2650], [1126, 2622, 1287, 2650], [1298, 2622, 1346, 2650], [1356, 2631, 1411, 2650], [1422, 2622, 1568, 2659], [1579, 2622, 1734, 2656], [1749, 2631, 1783, 2650], [1794, 2631, 1841, 2651], [1854, 2631, 1902, 2650], [1912, 2622, 2057, 2659], [2068, 2626, 2099, 2650], [451, 2668, 525, 2696], [536, 2668, 559, 2696], [569, 2677, 609, 2696], [620, 2668, 701, 2705], [712, 2668, 803, 2697], [814, 2668, 953, 2702], [967, 2668, 1040, 2696], [1053, 2677, 1083, 2696], [1096, 2668, 1145, 2696], [1155, 2668, 1288, 2705], [1299, 2668, 1434, 2696], [1446, 2668, 1607, 2696], [1619, 2668, 1655, 2696], [1666, 2668, 1739, 2702], [1755, 2668, 1836, 2702], [1848, 2668, 1995, 2702], [2007, 2677, 2097, 2705], [452, 2723, 468, 2742], [480, 2714, 652, 2751], [663, 2714, 820, 2751], [832, 2723, 872, 2742], [884, 2714, 920, 2742], [934, 2723, 1002, 2743], [1014, 2714, 1073, 2742], [1085, 2718, 1115, 2742], [1127, 2714, 1177, 2742], [1189, 2714, 1320, 2751], [1333, 2718, 1456, 2742], [1467, 2714, 1503, 2742], [1512, 2714, 1640, 2751], [1652, 2714, 1720, 2742], [1732, 2714, 1882, 2751], [1894, 2714, 1984, 2749], [451, 2784, 546, 2812], [565, 2784, 625, 2812], [642, 2784, 757, 2812], [777, 2793, 862, 2812], [880, 2784, 1022, 2812], [1040, 2784, 1221, 2821], [1241, 2784, 1277, 2812], [1293, 2784, 1342, 2812], [1361, 2784, 1606, 2812], [1625, 2784, 1750, 2813], [1768, 2784, 2002, 2821], [2024, 2784, 2097, 2818], [451, 2830, 550, 2859], [569, 2839, 618, 2858], [636, 2830, 749, 2858], [767, 2830, 798, 2858], [816, 2839, 871, 2858], [888, 2834, 1005, 2858], [1023, 2830, 1225, 2858], [1259, 2830, 1322, 2858], [1340, 2834, 1420, 2858], [1436, 2830, 1607, 2867], [1624, 2839, 1683, 2858], [1701, 2830, 1725, 2858], [1745, 2830, 1824, 2858], [1842, 2830, 1956, 2858], [1973, 2830, 2099, 2867], [451, 2885, 522, 2905], [535, 2876, 793, 2913], [805, 2876, 899, 2910], [913, 2876, 1052, 2904], [1066, 2880, 1094, 2904], [1105, 2876, 1154, 2904], [1166, 2876, 1358, 2913], [1375, 2877, 1457, 2905], [1470, 2876, 1583, 2913], [1596, 2876, 1645, 2904], [1657, 2876, 1742, 2913], [1754, 2876, 1799, 2911], [1812, 2880, 1947, 2913], [1961, 2876, 2010, 2904], [2022, 2876, 2098, 2913], [451, 2921, 497, 2949], [510, 2921, 581, 2950], [596, 2921, 685, 2958], [698, 2921, 748, 2949], [761, 2921, 952, 2958], [967, 2921, 1016, 2949], [1030, 2921, 1136, 2958], [1148, 2921, 1274, 2958], [1288, 2921, 1318, 2949], [1331, 2930, 1386, 2949], [1398, 2921, 1533, 2950], [1545, 2921, 1618, 2949], [1633, 2925, 1685, 2949], [1698, 2921, 1765, 2949], [1778, 2921, 1827, 2949], [1840, 2921, 2021, 2958], [2036, 2921, 2099, 2949], [452, 2971, 587, 2995], [603, 2967, 738, 2995], [747, 2967, 892, 3004], [904, 2976, 971, 2995], [982, 2967, 1017, 2995], [1026, 2967, 1245, 3004], [1255, 2967, 1280, 2995], [1293, 2967, 1416, 3004], [1425, 2967, 1570, 3004], [1581, 2967, 1617, 2995], [1625, 2976, 1744, 2995], [1755, 2967, 1879, 3001], [1892, 2967, 1992, 2996], [2003, 2967, 2034, 2995], [2045, 2976, 2100, 2995], [451, 3022, 521, 3041], [532, 3013, 557, 3041], [570, 3013, 785, 3050], [796, 3013, 837, 3050], [849, 3022, 938, 3041], [950, 3013, 1168, 3050], [1180, 3013, 1371, 3041], [1265, 3137, 1283, 3166], [601, 1259, 708, 1296], [720, 1259, 747, 1288], [765, 1259, 919, 1288], [932, 1259, 1029, 1288], [1041, 1258, 1076, 1288], [1086, 1267, 1105, 1288], [1117, 1261, 1314, 1288], [1326, 1259, 1433, 1288], [1445, 1267, 1487, 1288], [1499, 1259, 1553, 1288], [1565, 1258, 1636, 1288], [1647, 1258, 1722, 1296], [1733, 1258, 1769, 1288], [1778, 1258, 1948, 1288], [450, 1325, 860, 1369], [451, 1406, 521, 1434], [534, 1406, 618, 1435], [628, 1415, 689, 1435], [703, 1406, 864, 1443], [874, 1406, 915, 1443], [927, 1406, 1005, 1435], [1017, 1410, 1102, 1443], [1112, 1406, 1229, 1434], [1241, 1415, 1290, 1434], [1306, 1406, 1437, 1435], [1452, 1407, 1506, 1434], [1517, 1406, 1677, 1443], [1689, 1406, 1905, 1443], [1916, 1406, 1965, 1434], [1977, 1410, 2100, 1443], [451, 1451, 486, 1479], [495, 1451, 641, 1479], [653, 1451, 852, 1488], [864, 1451, 936, 1480], [949, 1451, 998, 1479], [1010, 1451, 1153, 1479], [1165, 1451, 1201, 1479], [1210, 1451, 1260, 1479], [1271, 1451, 1367, 1480], [1380, 1451, 1455, 1479], [1467, 1451, 1515, 1479], [1526, 1451, 1583, 1479], [1596, 1451, 1742, 1479], [451, 1528, 680, 1563], [471, 1609, 508, 1640], [534, 1609, 566, 1634], [585, 1609, 663, 1642], [681, 1609, 703, 1635], [721, 1609, 808, 1642], [827, 1608, 879, 1634], [895, 1609, 925, 1634], [942, 1608, 1057, 1634], [1090, 1609, 1176, 1642], [1193, 1608, 1265, 1634], [1282, 1608, 1370, 1635], [1385, 1608, 1554, 1642], [1571, 1608, 1713, 1642], [1730, 1609, 1893, 1641], [1911, 1609, 1992, 1635], [2026, 1609, 2099, 1635], [534, 1651, 911, 1683], [918, 1651, 1595, 1683], [471, 1707, 508, 1738], [534, 1707, 560, 1732], [576, 1707, 657, 1737], [674, 1707, 707, 1732], [723, 1706, 823, 1737], [839, 1707, 873, 1732], [889, 1706, 1052, 1740], [1069, 1706, 1121, 1732], [1135, 1707, 1156, 1733], [1172, 1706, 1312, 1732], [1341, 1706, 1414, 1740], [1428, 1715, 1559, 1740], [1574, 1706, 1674, 1740], [1688, 1706, 1752, 1733], [1767, 1706, 1921, 1732], [1934, 1706, 2019, 1732], [2034, 1715, 2069, 1732], [2084, 1715, 2100, 1732], [532, 1747, 627, 1781], [638, 1747, 681, 1773], [691, 1747, 819, 1781], [836, 1748, 865, 1773], [875, 1749, 951, 1773], [965, 1748, 1068, 1778], [1079, 1756, 1163, 1781], [1175, 1747, 1274, 1778], [1287, 1748, 1368, 1774], [471, 1804, 508, 1835], [534, 1804, 566, 1829], [578, 1803, 721, 1834], [733, 1804, 766, 1829], [778, 1803, 934, 1837], [946, 1804, 979, 1829], [991, 1803, 1111, 1834], [1123, 1803, 1175, 1829], [1185, 1804, 1218, 1829], [1229, 1803, 1391, 1829], [1406, 1804, 1506, 1829], [1516, 1803, 1547, 1829], [1554, 1803, 1599, 1829], [1609, 1803, 1681, 1830], [1691, 1803, 1718, 1829], [1727, 1803, 1773, 1829], [1782, 1803, 1886, 1829], [1901, 1803, 2020, 1837], [2030, 1803, 2099, 1837], [533, 1845, 590, 1871], [601, 1845, 803, 1872], [814, 1849, 880, 1871], [897, 1846, 926, 1871], [936, 1847, 1012, 1871], [1026, 1846, 1144, 1876], [1156, 1846, 1237, 1872], [471, 1902, 508, 1933], [534, 1902, 564, 1927], [580, 1901, 665, 1932], [680, 1902, 702, 1928], [717, 1902, 742, 1927], [746, 1923, 750, 1927], [766, 1901, 841, 1935], [857, 1902, 888, 1927], [903, 1901, 1012, 1932], [1028, 1901, 1080, 1927], [1093, 1902, 1127, 1927], [1143, 1901, 1176, 1927], [1189, 1901, 1298, 1927], [1324, 1902, 1401, 1935], [1415, 1901, 1536, 1935], [1550, 1901, 1581, 1927], [1593, 1901, 1722, 1928], [1737, 1901, 1969, 1935], [1982, 1901, 2098, 1927], [533, 1942, 605, 1968], [615, 1942, 704, 1969], [721, 1943, 751, 1968], [760, 1943, 840, 1969], [849, 1944, 927, 1976], [937, 1944, 1073, 1976], [1084, 1942, 1141, 1968], [1153, 1942, 1356, 1976], [1364, 1944, 1476, 1968], [1487, 1944, 1623, 1976], [1636, 1942, 1788, 1976], [1801, 1943, 1882, 1969], [471, 1998, 508, 2030], [534, 1999, 564, 2024], [577, 1998, 717, 2025], [727, 1998, 779, 2024], [789, 1999, 811, 2025], [822, 1999, 940, 2024], [956, 1999, 981, 2024], [992, 1998, 1095, 2024], [1105, 1998, 1280, 2024], [1291, 1998, 1334, 2024], [1343, 1998, 1446, 2024], [1456, 1998, 1590, 2032], [1599, 1998, 1766, 2032], [1782, 1998, 1851, 2032], [1861, 1998, 1953, 2024], [1964, 1998, 2098, 2025], [533, 2040, 598, 2067], [609, 2040, 748, 2066], [758, 2040, 886, 2074], [903, 2041, 932, 2066], [942, 2042, 1018, 2066], [1032, 2041, 1128, 2071], [1140, 2049, 1223, 2074], [1238, 2040, 1372, 2071], [1385, 2041, 1465, 2067], [471, 2096, 508, 2128], [534, 2097, 566, 2122], [583, 2097, 723, 2123], [736, 2096, 789, 2122], [803, 2097, 831, 2122], [848, 2096, 949, 2130], [976, 2097, 1020, 2123], [1034, 2096, 1079, 2122], [1093, 2096, 1263, 2130], [1278, 2096, 1511, 2130], [1526, 2096, 1557, 2122], [1569, 2096, 1718, 2122], [1733, 2096, 1922, 2122], [1937, 2100, 2029, 2123], [2042, 2105, 2098, 2122], [533, 2137, 635, 2163], [651, 2139, 749, 2168], [762, 2137, 928, 2168], [940, 2138, 1021, 2164], [471, 2194, 508, 2225], [533, 2194, 566, 2219], [578, 2193, 658, 2219], [667, 2193, 720, 2219], [730, 2194, 751, 2219], [763, 2193, 865, 2227], [880, 2193, 1036, 2227], [1046, 2193, 1077, 2219], [1085, 2193, 1214, 2220], [1224, 2193, 1367, 2220], [1378, 2193, 1421, 2219], [1430, 2194, 1538, 2219], [1548, 2193, 1699, 2219], [1714, 2194, 1743, 2219], [1752, 2195, 1828, 2219], [1843, 2194, 1941, 2224], [1953, 2193, 2063, 2220], [2072, 2194, 2097, 2224], [532, 2244, 616, 2269], [629, 2235, 765, 2266], [777, 2235, 858, 2262], [471, 2292, 508, 2323], [533, 2292, 566, 2317], [579, 2291, 666, 2322], [679, 2292, 710, 2317], [723, 2291, 825, 2325], [838, 2291, 890, 2317], [901, 2292, 932, 2318], [946, 2291, 1065, 2318], [1082, 2292, 1191, 2317], [1202, 2291, 1337, 2317], [1347, 2291, 1428, 2325], [1439, 2291, 1560, 2317], [1570, 2291, 1732, 2325], [1744, 2291, 1776, 2317], [1785, 2291, 1848, 2318], [1860, 2291, 1912, 2317], [1923, 2300, 2097, 2325], [533, 2333, 563, 2358], [573, 2334, 649, 2358], [663, 2333, 765, 2363], [777, 2341, 860, 2366], [871, 2333, 1009, 2363], [1022, 2332, 1102, 2359], [471, 2389, 508, 2420], [533, 2389, 573, 2414], [586, 2389, 611, 2414], [615, 2410, 619, 2414], [633, 2388, 758, 2415], [770, 2388, 822, 2414], [834, 2389, 867, 2414], [881, 2389, 906, 2414], [910, 2410, 914, 2414], [927, 2388, 1033, 2414], [1054, 2389, 1180, 2422], [1192, 2388, 1280, 2415], [1291, 2388, 1430, 2422], [1443, 2388, 1486, 2414], [1496, 2388, 1653, 2422], [1665, 2388, 1717, 2414], [1729, 2388, 1826, 2414], [1847, 2388, 1945, 2414], [1958, 2390, 1984, 2414], [1994, 2390, 2098, 2415], [533, 2432, 664, 2461], [680, 2430, 867, 2463], [883, 2431, 961, 2457], [453, 2487, 508, 2518], [533, 2487, 573, 2512], [588, 2486, 655, 2517], [672, 2487, 705, 2512], [721, 2487, 814, 2520], [832, 2486, 884, 2512], [899, 2487, 921, 2512], [938, 2486, 1097, 2520], [1125, 2487, 1216, 2512], [1230, 2486, 1379, 2520], [1394, 2486, 1498, 2512], [1512, 2486, 1556, 2512], [1568, 2486, 1654, 2512], [1667, 2486, 1757, 2512], [1770, 2486, 1948, 2520], [1976, 2487, 2006, 2512], [2019, 2488, 2095, 2512], [534, 2528, 633, 2558], [645, 2536, 728, 2561], [740, 2527, 914, 2558], [927, 2528, 1008, 2554], [452, 2584, 508, 2615], [534, 2584, 566, 2609], [581, 2583, 693, 2617], [709, 2584, 735, 2609], [751, 2584, 835, 2614], [850, 2584, 880, 2609], [894, 2583, 975, 2614], [990, 2583, 1043, 2609], [1056, 2584, 1082, 2609], [1097, 2583, 1209, 2617], [1234, 2584, 1259, 2609], [1271, 2583, 1449, 2617], [1463, 2583, 1581, 2617], [1596, 2587, 1697, 2617], [1710, 2583, 1753, 2609], [1766, 2583, 1855, 2609], [1868, 2583, 2045, 2617], [2069, 2584, 2099, 2609], [532, 2627, 608, 2651], [622, 2626, 714, 2656], [726, 2634, 809, 2659], [824, 2626, 883, 2656], [896, 2626, 977, 2652], [453, 2682, 508, 2713], [535, 2682, 560, 2708], [572, 2681, 604, 2712], [615, 2682, 654, 2707], [665, 2682, 718, 2712], [729, 2682, 769, 2707], [782, 2682, 865, 2715], [877, 2681, 930, 2707], [940, 2682, 973, 2707], [985, 2682, 1033, 2707], [1050, 2682, 1093, 2708], [1104, 2681, 1306, 2708], [1316, 2681, 1408, 2707], [1418, 2681, 1552, 2708], [1564, 2681, 1607, 2707], [1615, 2681, 1716, 2707], [1727, 2681, 1817, 2707], [1826, 2681, 2004, 2715], [2019, 2683, 2101, 2707], [532, 2723, 625, 2753], [639, 2722, 866, 2755], [879, 2723, 959, 2749], [452, 2779, 508, 2810], [534, 2779, 562, 2804], [574, 2778, 622, 2805], [640, 2778, 728, 2805], [745, 2779, 789, 2804], [800, 2787, 871, 2812], [884, 2787, 979, 2804], [990, 2778, 1192, 2805], [1203, 2778, 1378, 2804], [1389, 2778, 1432, 2804], [1442, 2778, 1494, 2804], [1506, 2778, 1608, 2804], [1619, 2778, 1791, 2812], [1810, 2779, 2091, 2811], [533, 2821, 965, 2853], [978, 2821, 1059, 2847], [453, 2877, 508, 2908], [534, 2877, 566, 2902], [580, 2876, 722, 2910], [736, 2877, 769, 2903], [783, 2876, 912, 2907], [927, 2877, 953, 2903], [967, 2876, 1066, 2910], [1079, 2877, 1105, 2902], [1118, 2877, 1220, 2910], [1234, 2877, 1265, 2902], [1280, 2876, 1453, 2907], [1467, 2876, 1519, 2902], [1530, 2877, 1560, 2902], [1573, 2876, 1688, 2902], [1706, 2876, 1879, 2910], [1891, 2876, 1972, 2903], [1984, 2876, 2098, 2902], [533, 2917, 623, 2943], [634, 2917, 699, 2944], [710, 2917, 912, 2944], [922, 2917, 1014, 2943], [1025, 2917, 1168, 2944], [1185, 2918, 1214, 2943], [1224, 2919, 1300, 2943], [1316, 2918, 1414, 2948], [1427, 2918, 1507, 2944], [452, 2973, 508, 3005], [534, 2974, 566, 2999], [582, 2973, 756, 3007], [772, 2974, 790, 2999], [807, 2973, 956, 3004], [972, 2973, 1024, 2999], [1038, 2974, 1071, 3000], [1085, 2974, 1107, 2999], [1111, 2995, 1115, 2999], [1130, 2973, 1240, 2999], [1265, 2974, 1411, 3007], [1424, 2973, 1617, 2999], [1631, 2973, 1696, 3000], [1709, 2973, 1778, 3007], [1792, 2973, 1994, 3000], [2007, 2973, 2099, 2999], [533, 3015, 676, 3042], [693, 3016, 722, 3041], [731, 3016, 818, 3046], [830, 3024, 913, 3049], [928, 3015, 1099, 3046], [1112, 3016, 1193, 3042], [1259, 3137, 1295, 3166], [453, 356, 508, 388], [534, 357, 566, 382], [581, 356, 703, 387], [718, 357, 751, 382], [764, 356, 877, 390], [891, 357, 921, 382], [936, 357, 1056, 387], [1071, 357, 1097, 382], [1112, 356, 1224, 390], [1239, 356, 1291, 382], [1304, 357, 1330, 382], [1346, 357, 1429, 383], [1452, 357, 1571, 382], [1586, 357, 1611, 382], [1624, 356, 1697, 390], [1710, 356, 1791, 383], [1804, 356, 1931, 382], [1944, 356, 1987, 382], [1998, 356, 2099, 382], [533, 398, 638, 424], [648, 398, 825, 432], [842, 399, 871, 424], [881, 400, 957, 424], [971, 399, 1063, 429], [1075, 407, 1158, 432], [1170, 398, 1344, 429], [1357, 399, 1437, 425], [452, 457, 508, 488], [534, 457, 552, 482], [563, 457, 670, 490], [682, 457, 722, 482], [733, 456, 895, 487], [908, 457, 939, 483], [952, 456, 1071, 487], [1083, 456, 1135, 482], [1146, 457, 1177, 482], [1189, 456, 1348, 482], [1363, 456, 1497, 490], [1506, 456, 1623, 482], [1633, 456, 1734, 482], [1745, 456, 1848, 482], [1859, 456, 1931, 482], [1941, 456, 2054, 483], [2069, 457, 2099, 482], [532, 499, 608, 523], [624, 498, 723, 528], [735, 498, 816, 524], [452, 556, 508, 587], [534, 556, 566, 588], [580, 556, 608, 581], [620, 556, 666, 586], [678, 556, 717, 581], [730, 556, 758, 581], [770, 556, 838, 586], [852, 556, 878, 582], [891, 556, 919, 581], [932, 556, 1034, 589], [1047, 555, 1099, 581], [1110, 556, 1143, 581], [1156, 556, 1185, 581], [1197, 556, 1249, 589], [1266, 555, 1400, 589], [1411, 555, 1587, 581], [1598, 555, 1727, 582], [1739, 555, 1971, 589], [1982, 555, 2098, 581], [533, 597, 577, 623], [586, 597, 676, 623], [686, 597, 856, 631], [867, 597, 931, 624], [942, 597, 1124, 631], [1135, 597, 1268, 631], [1278, 597, 1405, 631], [1422, 598, 1451, 623], [1461, 599, 1537, 623], [1553, 598, 1651, 628], [1663, 606, 1746, 631], [1759, 597, 1932, 628], [1945, 598, 2026, 624], [453, 656, 508, 687], [534, 656, 562, 681], [573, 656, 681, 686], [693, 656, 724, 681], [736, 656, 828, 686], [839, 656, 860, 682], [873, 656, 889, 682], [895, 677, 899, 681], [911, 655, 1025, 686], [1037, 656, 1070, 681], [1082, 655, 1250, 686], [1262, 656, 1293, 681], [1303, 656, 1325, 681], [1329, 677, 1333, 681], [1345, 655, 1470, 686], [1481, 656, 1520, 681], [1532, 655, 1669, 686], [1681, 655, 1733, 681], [1742, 656, 1772, 681], [1784, 656, 1809, 681], [1813, 677, 1817, 681], [1828, 655, 1928, 682], [1943, 655, 2098, 689], [533, 696, 642, 730], [653, 696, 761, 730], [771, 700, 799, 722], [809, 696, 987, 723], [998, 696, 1042, 730], [1053, 696, 1122, 722], [1132, 696, 1309, 730], [1324, 696, 1428, 723], [1440, 697, 1640, 730], [1655, 696, 1862, 729], [1877, 697, 1955, 723], [453, 756, 508, 787], [533, 756, 566, 781], [578, 756, 659, 789], [670, 756, 700, 781], [711, 756, 804, 789], [815, 756, 849, 781], [860, 756, 954, 789], [966, 755, 1018, 781], [1028, 756, 1056, 781], [1068, 755, 1147, 788], [1162, 756, 1221, 789], [1231, 755, 1263, 781], [1271, 755, 1358, 782], [1369, 755, 1457, 782], [1468, 755, 1520, 781], [1531, 755, 1622, 781], [1633, 755, 1757, 781], [1768, 755, 1811, 781], [1820, 755, 1910, 781], [1919, 755, 2096, 789], [533, 796, 765, 830], [777, 796, 855, 830], [866, 796, 918, 822], [929, 796, 1002, 830], [1012, 796, 1138, 830], [1156, 797, 1250, 827], [1262, 796, 1487, 827], [1500, 797, 1581, 823], [452, 855, 508, 886], [533, 855, 566, 880], [580, 855, 661, 888], [675, 855, 706, 881], [718, 855, 786, 885], [800, 855, 828, 880], [841, 854, 920, 887], [934, 854, 986, 880], [998, 855, 1031, 887], [1045, 855, 1126, 888], [1146, 854, 1246, 880], [1257, 854, 1426, 888], [1438, 854, 1503, 881], [1516, 854, 1625, 880], [1637, 854, 1719, 880], [1730, 858, 1844, 881], [1864, 855, 1893, 880], [1904, 856, 1980, 880], [1995, 855, 2097, 885], [532, 905, 616, 930], [628, 896, 765, 927], [777, 897, 858, 923], [452, 955, 508, 986], [533, 955, 557, 980], [568, 954, 722, 985], [732, 955, 754, 981], [766, 955, 782, 981], [786, 954, 895, 985], [907, 954, 959, 980], [969, 955, 995, 980], [1005, 954, 1143, 980], [1156, 954, 1312, 988], [1320, 954, 1365, 980], [1374, 954, 1468, 980], [1475, 954, 1567, 980], [1577, 954, 1620, 980], [1628, 954, 1788, 988], [1797, 954, 1887, 988], [1896, 954, 2097, 980], [533, 996, 563, 1021], [573, 997, 649, 1021], [663, 996, 765, 1026], [778, 996, 858, 1022], [452, 1054, 508, 1085], [534, 1054, 566, 1079], [581, 1053, 737, 1087], [752, 1054, 785, 1079], [799, 1053, 919, 1084], [933, 1053, 985, 1079], [998, 1054, 1031, 1079], [1044, 1053, 1206, 1079], [1227, 1054, 1305, 1087], [1316, 1053, 1410, 1079], [1421, 1053, 1555, 1080], [1568, 1053, 1611, 1079], [1622, 1053, 1782, 1087], [1794, 1053, 1884, 1087], [1896, 1053, 2097, 1079], [533, 1096, 563, 1121], [572, 1096, 659, 1126], [672, 1096, 752, 1122], [452, 1154, 508, 1185], [534, 1154, 566, 1179], [581, 1154, 704, 1184], [717, 1154, 750, 1179], [763, 1154, 787, 1179], [790, 1175, 794, 1179], [807, 1153, 903, 1184], [917, 1153, 969, 1179], [979, 1154, 1020, 1179], [1034, 1153, 1114, 1180], [1132, 1154, 1267, 1180], [1284, 1154, 1309, 1179], [1320, 1153, 1423, 1179], [1434, 1153, 1466, 1179], [1478, 1154, 1526, 1180], [1540, 1153, 1641, 1179], [1652, 1153, 1756, 1179], [1768, 1153, 1869, 1179], [1882, 1153, 1953, 1179], [1964, 1153, 2059, 1180], [2071, 1153, 2099, 1179], [532, 1195, 578, 1221], [588, 1195, 661, 1222], [679, 1196, 773, 1226], [786, 1195, 1011, 1226], [1023, 1196, 1104, 1222], [452, 1253, 508, 1285], [534, 1254, 566, 1280], [580, 1254, 619, 1279], [633, 1253, 734, 1287], [749, 1254, 780, 1279], [793, 1254, 901, 1287], [916, 1254, 944, 1279], [958, 1254, 1066, 1284], [1081, 1253, 1133, 1279], [1146, 1254, 1177, 1280], [1191, 1253, 1307, 1287], [1329, 1253, 1539, 1280], [1552, 1253, 1672, 1287], [1685, 1253, 1717, 1279], [1728, 1253, 1960, 1287], [1973, 1253, 2097, 1279], [533, 1295, 563, 1320], [573, 1296, 649, 1320], [663, 1295, 765, 1325], [777, 1303, 860, 1328], [875, 1294, 1009, 1325], [1022, 1295, 1102, 1321], [452, 1352, 508, 1384], [534, 1353, 566, 1378], [576, 1353, 662, 1386], [671, 1352, 723, 1378], [732, 1353, 763, 1379], [775, 1352, 894, 1379], [907, 1352, 1007, 1378], [1015, 1352, 1185, 1386], [1194, 1352, 1259, 1379], [1268, 1352, 1408, 1386], [1416, 1352, 1589, 1386], [1602, 1353, 1632, 1378], [1640, 1354, 1716, 1378], [1728, 1353, 1820, 1383], [1829, 1361, 1913, 1386], [1924, 1352, 2097, 1383], [533, 1395, 614, 1421], [453, 1453, 508, 1484], [534, 1453, 566, 1478], [579, 1453, 664, 1486], [675, 1452, 728, 1478], [739, 1453, 770, 1479], [784, 1452, 903, 1479], [920, 1453, 1018, 1478], [1019, 1453, 1133, 1478], [1146, 1452, 1311, 1478], [1323, 1452, 1366, 1478], [1375, 1452, 1420, 1478], [1431, 1453, 1585, 1479], [1599, 1452, 1752, 1486], [1770, 1453, 1799, 1478], [1810, 1453, 1898, 1479], [1907, 1452, 2052, 1486], [2063, 1462, 2099, 1478], [530, 1495, 629, 1520], [639, 1496, 819, 1528], [830, 1494, 893, 1521], [904, 1504, 921, 1520], [931, 1496, 1017, 1528], [1026, 1494, 1148, 1521], [1158, 1495, 1192, 1528], [1198, 1494, 1317, 1525], [1329, 1495, 1410, 1521], [453, 1553, 508, 1584], [534, 1553, 566, 1578], [578, 1553, 671, 1586], [683, 1553, 723, 1578], [735, 1553, 775, 1578], [788, 1552, 877, 1583], [890, 1553, 923, 1578], [936, 1552, 1038, 1583], [1051, 1553, 1069, 1578], [1081, 1553, 1188, 1586], [1201, 1552, 1253, 1578], [1264, 1553, 1295, 1579], [1309, 1552, 1428, 1579], [1444, 1552, 1605, 1579], [1616, 1552, 1647, 1578], [1656, 1552, 1727, 1578], [1739, 1552, 1971, 1586], [1982, 1552, 2098, 1578], [533, 1593, 577, 1619], [586, 1593, 676, 1619], [686, 1593, 863, 1627], [880, 1594, 909, 1619], [919, 1595, 995, 1619], [1009, 1594, 1127, 1624], [1139, 1602, 1222, 1627], [1237, 1594, 1315, 1624], [1328, 1594, 1408, 1620], [452, 1652, 508, 1683], [534, 1652, 566, 1677], [578, 1652, 671, 1685], [684, 1652, 717, 1677], [730, 1651, 832, 1682], [844, 1652, 875, 1678], [889, 1651, 1008, 1682], [1021, 1651, 1073, 1677], [1084, 1652, 1128, 1678], [1130, 1652, 1152, 1677], [1156, 1673, 1160, 1677], [1171, 1651, 1230, 1677], [1247, 1651, 1347, 1677], [1357, 1651, 1527, 1685], [1537, 1651, 1573, 1685], [1584, 1651, 1668, 1677], [1678, 1651, 1851, 1685], [1868, 1652, 1897, 1677], [1907, 1653, 1983, 1677], [1999, 1652, 2097, 1682], [532, 1702, 616, 1727], [629, 1693, 802, 1724], [815, 1694, 895, 1720], [453, 1752, 508, 1783], [534, 1752, 556, 1777], [571, 1751, 763, 1785], [779, 1752, 800, 1778], [816, 1751, 934, 1782], [949, 1752, 979, 1777], [994, 1751, 1156, 1782], [1172, 1751, 1225, 1777], [1238, 1752, 1269, 1778], [1286, 1751, 1405, 1778], [1431, 1751, 1592, 1785], [1612, 1752, 1698, 1785], [1712, 1751, 1908, 1785], [1921, 1751, 2021, 1785], [2035, 1751, 2099, 1778], [533, 1792, 598, 1819], [609, 1792, 678, 1826], [689, 1792, 834, 1826], [851, 1793, 880, 1818], [890, 1794, 966, 1818], [980, 1793, 1072, 1823], [1084, 1801, 1167, 1826], [1182, 1792, 1353, 1823], [1366, 1793, 1447, 1819], [453, 1851, 508, 1882], [533, 1851, 573, 1876], [583, 1851, 608, 1876], [612, 1872, 616, 1876], [626, 1850, 715, 1876], [723, 1850, 775, 1876], [784, 1851, 815, 1876], [824, 1851, 932, 1884], [944, 1850, 1113, 1884], [1122, 1850, 1174, 1876], [1182, 1850, 1393, 1884], [1401, 1850, 1603, 1877], [1612, 1850, 1754, 1877], [1767, 1851, 1862, 1881], [1872, 1850, 2097, 1881], [533, 1893, 614, 1919], [1259, 3137, 1291, 3165]], "scores": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "structures": {"pages": {"version": "1.0", "structure_value": [[0, 562], [562, 1321], [1321, 1907], [1907, 2541], [2541, 3161], [3161, 3954], [3954, 4711], [4711, 5308], [5308, 5625], [5625, 6013], [6013, 6397]], "positions": [[0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300]]}, "lines": {"version": "1.0", "structure_value": [[0, 3], [3, 8], [8, 10], [10, 12], [12, 18], [18, 19], [19, 20], [20, 29], [29, 41], [41, 52], [52, 64], [64, 69], [69, 80], [80, 90], [90, 104], [104, 117], [117, 130], [130, 142], [142, 154], [154, 168], [168, 184], [184, 185], [185, 187], [187, 203], [203, 219], [219, 233], [233, 247], [247, 258], [258, 272], [272, 288], [288, 306], [306, 320], [320, 333], [333, 348], [348, 365], [365, 379], [379, 395], [395, 411], [411, 425], [425, 438], [438, 448], [448, 468], [468, 482], [482, 496], [496, 512], [512, 528], [528, 529], [529, 530], [530, 531], [531, 532], [532, 533], [533, 534], [534, 535], [535, 536], [536, 537], [537, 538], [538, 539], [539, 540], [540, 541], [541, 542], [542, 543], [543, 544], [544, 545], [545, 546], [546, 547], [547, 548], [548, 549], [549, 550], [550, 551], [551, 552], [552, 553], [553, 554], [554, 555], [555, 556], [556, 557], [557, 558], [558, 559], [559, 560], [560, 561], [561, 562], [562, 576], [576, 594], [594, 609], [609, 625], [625, 639], [639, 642], [642, 656], [656, 673], [673, 685], [685, 699], [699, 711], [711, 728], [728, 741], [741, 759], [759, 768], [768, 779], [779, 794], [794, 809], [809, 821], [821, 835], [835, 849], [849, 862], [862, 875], [875, 891], [891, 908], [908, 927], [927, 940], [940, 956], [956, 972], [972, 983], [983, 997], [997, 1013], [1013, 1027], [1027, 1039], [1039, 1052], [1052, 1067], [1067, 1080], [1080, 1096], [1096, 1110], [1110, 1125], [1125, 1129], [1129, 1142], [1142, 1156], [1156, 1172], [1172, 1187], [1187, 1201], [1201, 1206], [1206, 1212], [1212, 1227], [1227, 1241], [1241, 1258], [1258, 1271], [1271, 1290], [1290, 1305], [1305, 1320], [1320, 1321], [1321, 1322], [1322, 1323], [1323, 1325], [1325, 1326], [1326, 1328], [1328, 1329], [1329, 1330], [1330, 1332], [1332, 1333], [1333, 1335], [1335, 1336], [1336, 1337], [1337, 1339], [1339, 1340], [1340, 1341], [1341, 1343], [1343, 1344], [1344, 1345], [1345, 1347], [1347, 1349], [1349, 1350], [1350, 1351], [1351, 1352], [1352, 1353], [1353, 1354], [1354, 1355], [1355, 1356], [1356, 1357], [1357, 1358], [1358, 1360], [1360, 1361], [1361, 1363], [1363, 1364], [1364, 1365], [1365, 1367], [1367, 1369], [1369, 1370], [1370, 1371], [1371, 1373], [1373, 1374], [1374, 1375], [1375, 1377], [1377, 1378], [1378, 1379], [1379, 1381], [1381, 1383], [1383, 1384], [1384, 1385], [1385, 1386], [1386, 1387], [1387, 1388], [1388, 1389], [1389, 1390], [1390, 1393], [1393, 1396], [1396, 1398], [1398, 1399], [1399, 1400], [1400, 1401], [1401, 1403], [1403, 1404], [1404, 1405], [1405, 1406], [1406, 1413], [1413, 1425], [1425, 1442], [1442, 1458], [1458, 1474], [1474, 1488], [1488, 1503], [1503, 1521], [1521, 1533], [1533, 1537], [1537, 1553], [1553, 1570], [1570, 1583], [1583, 1597], [1597, 1612], [1612, 1618], [1618, 1619], [1619, 1620], [1620, 1621], [1621, 1622], [1622, 1623], [1623, 1640], [1640, 1658], [1658, 1672], [1672, 1689], [1689, 1705], [1705, 1709], [1709, 1727], [1727, 1746], [1746, 1765], [1765, 1779], [1779, 1780], [1780, 1782], [1782, 1783], [1783, 1799], [1799, 1813], [1813, 1814], [1814, 1818], [1818, 1838], [1838, 1848], [1848, 1857], [1857, 1858], [1858, 1859], [1859, 1860], [1860, 1863], [1863, 1864], [1864, 1865], [1865, 1866], [1866, 1873], [1873, 1895], [1895, 1906], [1906, 1907], [1907, 1918], [1918, 1933], [1933, 1950], [1950, 1958], [1958, 1959], [1959, 1960], [1960, 1962], [1962, 1963], [1963, 1964], [1964, 1965], [1965, 1972], [1972, 1993], [1993, 2000], [2000, 2011], [2011, 2028], [2028, 2046], [2046, 2055], [2055, 2058], [2058, 2060], [2060, 2063], [2063, 2065], [2065, 2079], [2079, 2095], [2095, 2109], [2109, 2117], [2117, 2131], [2131, 2150], [2150, 2169], [2169, 2184], [2184, 2203], [2203, 2223], [2223, 2240], [2240, 2254], [2254, 2270], [2270, 2286], [2286, 2305], [2305, 2322], [2322, 2337], [2337, 2352], [2352, 2368], [2368, 2379], [2379, 2392], [2392, 2401], [2401, 2402], [2402, 2409], [2409, 2431], [2431, 2448], [2448, 2467], [2467, 2477], [2477, 2494], [2494, 2510], [2510, 2523], [2523, 2540], [2540, 2541], [2541, 2557], [2557, 2572], [2572, 2584], [2584, 2601], [2601, 2616], [2616, 2630], [2630, 2648], [2648, 2658], [2658, 2673], [2673, 2687], [2687, 2701], [2701, 2717], [2717, 2731], [2731, 2746], [2746, 2759], [2759, 2774], [2774, 2778], [2778, 2784], [2784, 2785], [2785, 2786], [2786, 2788], [2788, 2790], [2790, 2792], [2792, 2794], [2794, 2797], [2797, 2799], [2799, 2801], [2801, 2804], [2804, 2806], [2806, 2808], [2808, 2809], [2809, 2810], [2810, 2811], [2811, 2812], [2812, 2813], [2813, 2826], [2826, 2846], [2846, 2847], [2847, 2864], [2864, 2885], [2885, 2901], [2901, 2906], [2906, 2922], [2922, 2934], [2934, 2946], [2946, 2949], [2949, 2964], [2964, 2981], [2981, 2996], [2996, 3011], [3011, 3024], [3024, 3040], [3040, 3059], [3059, 3074], [3074, 3078], [3078, 3094], [3094, 3112], [3112, 3126], [3126, 3143], [3143, 3160], [3160, 3161], [3161, 3175], [3175, 3192], [3192, 3209], [3209, 3223], [3223, 3226], [3226, 3239], [3239, 3257], [3257, 3271], [3271, 3288], [3288, 3302], [3302, 3316], [3316, 3334], [3334, 3351], [3351, 3365], [3365, 3380], [3380, 3399], [3399, 3413], [3413, 3430], [3430, 3449], [3449, 3467], [3467, 3487], [3487, 3496], [3496, 3505], [3505, 3523], [3523, 3540], [3540, 3557], [3557, 3562], [3562, 3580], [3580, 3596], [3596, 3615], [3615, 3631], [3631, 3643], [3643, 3656], [3656, 3670], [3670, 3687], [3687, 3700], [3700, 3713], [3713, 3726], [3726, 3743], [3743, 3760], [3760, 3769], [3769, 3783], [3783, 3801], [3801, 3816], [3816, 3831], [3831, 3847], [3847, 3865], [3865, 3867], [3867, 3879], [3879, 3891], [3891, 3905], [3905, 3920], [3920, 3921], [3921, 3935], [3935, 3953], [3953, 3954], [3954, 3970], [3970, 3985], [3985, 3999], [3999, 4017], [4017, 4032], [4032, 4035], [4035, 4049], [4049, 4062], [4062, 4076], [4076, 4092], [4092, 4112], [4112, 4128], [4128, 4141], [4141, 4156], [4156, 4170], [4170, 4180], [4180, 4189], [4189, 4192], [4192, 4194], [4194, 4196], [4196, 4197], [4197, 4198], [4198, 4200], [4200, 4202], [4202, 4207], [4207, 4213], [4213, 4216], [4216, 4218], [4218, 4220], [4220, 4221], [4221, 4222], [4222, 4228], [4228, 4229], [4229, 4230], [4230, 4237], [4237, 4238], [4238, 4239], [4239, 4246], [4246, 4248], [4248, 4253], [4253, 4255], [4255, 4262], [4262, 4263], [4263, 4264], [4264, 4277], [4277, 4294], [4294, 4310], [4310, 4321], [4321, 4339], [4339, 4355], [4355, 4373], [4373, 4388], [4388, 4407], [4407, 4425], [4425, 4443], [4443, 4456], [4456, 4470], [4470, 4486], [4486, 4498], [4498, 4504], [4504, 4519], [4519, 4537], [4537, 4550], [4550, 4568], [4568, 4585], [4585, 4586], [4586, 4598], [4598, 4618], [4618, 4634], [4634, 4649], [4649, 4663], [4663, 4680], [4680, 4694], [4694, 4710], [4710, 4711], [4711, 4724], [4724, 4726], [4726, 4727], [4727, 4733], [4733, 4734], [4734, 4740], [4740, 4741], [4741, 4750], [4750, 4756], [4756, 4757], [4757, 4772], [4772, 4786], [4786, 4792], [4792, 4807], [4807, 4824], [4824, 4841], [4841, 4855], [4855, 4867], [4867, 4884], [4884, 4902], [4902, 4918], [4918, 4934], [4934, 4948], [4948, 4962], [4962, 4977], [4977, 4992], [4992, 5001], [5001, 5003], [5003, 5005], [5005, 5008], [5008, 5013], [5013, 5014], [5014, 5015], [5015, 5020], [5020, 5021], [5021, 5022], [5022, 5029], [5029, 5030], [5030, 5037], [5037, 5038], [5038, 5053], [5053, 5072], [5072, 5088], [5088, 5104], [5104, 5119], [5119, 5137], [5137, 5154], [5154, 5169], [5169, 5179], [5179, 5190], [5190, 5191], [5191, 5193], [5193, 5199], [5199, 5200], [5200, 5201], [5201, 5206], [5206, 5207], [5207, 5208], [5208, 5220], [5220, 5221], [5221, 5222], [5222, 5227], [5227, 5228], [5228, 5229], [5229, 5234], [5234, 5235], [5235, 5236], [5236, 5239], [5239, 5240], [5240, 5241], [5241, 5244], [5244, 5245], [5245, 5246], [5246, 5251], [5251, 5252], [5252, 5253], [5253, 5258], [5258, 5259], [5259, 5260], [5260, 5275], [5275, 5288], [5288, 5306], [5306, 5307], [5307, 5308], [5308, 5322], [5322, 5338], [5338, 5352], [5352, 5365], [5365, 5375], [5375, 5389], [5389, 5395], [5395, 5407], [5407, 5420], [5420, 5436], [5436, 5450], [5450, 5465], [5465, 5480], [5480, 5492], [5492, 5510], [5510, 5527], [5527, 5543], [5543, 5555], [5555, 5570], [5570, 5585], [5585, 5602], [5602, 5617], [5617, 5624], [5624, 5625], [5625, 5639], [5639, 5640], [5640, 5655], [5655, 5668], [5668, 5669], [5669, 5685], [5685, 5687], [5687, 5705], [5705, 5714], [5714, 5733], [5733, 5740], [5740, 5759], [5759, 5771], [5771, 5787], [5787, 5796], [5796, 5811], [5811, 5815], [5815, 5833], [5833, 5836], [5836, 5853], [5853, 5859], [5859, 5879], [5879, 5882], [5882, 5899], [5899, 5903], [5903, 5921], [5921, 5926], [5926, 5945], [5945, 5948], [5948, 5962], [5962, 5964], [5964, 5981], [5981, 5990], [5990, 6006], [6006, 6012], [6012, 6013], [6013, 6032], [6032, 6040], [6040, 6057], [6057, 6060], [6060, 6079], [6079, 6092], [6092, 6115], [6115, 6126], [6126, 6146], [6146, 6154], [6154, 6173], [6173, 6176], [6176, 6193], [6193, 6197], [6197, 6212], [6212, 6215], [6215, 6236], [6236, 6241], [6241, 6257], [6257, 6263], [6263, 6279], [6279, 6280], [6280, 6297], [6297, 6306], [6306, 6324], [6324, 6333], [6333, 6353], [6353, 6356], [6356, 6371], [6371, 6380], [6380, 6395], [6395, 6396], [6396, 6397]], "positions": [[709, 462, 1841, 513], [778, 545, 1770, 610], [786, 798, 1084, 836], [1435, 798, 1773, 828], [891, 844, 1658, 881], [958, 887, 1591, 928], [1182, 1010, 1368, 1045], [599, 1112, 1948, 1149], [600, 1157, 1950, 1194], [600, 1203, 1948, 1240], [600, 1249, 1948, 1286], [600, 1294, 1277, 1331], [600, 1347, 1948, 1384], [600, 1393, 1950, 1430], [600, 1439, 1949, 1476], [600, 1484, 1948, 1521], [600, 1530, 1949, 1567], [600, 1576, 1838, 1613], [600, 1629, 1948, 1658], [600, 1673, 1950, 1711], [601, 1720, 1949, 1757], [600, 1766, 824, 1794], [453, 1877, 794, 1912], [451, 1958, 2100, 1995], [451, 2004, 2099, 2041], [451, 2050, 2099, 2087], [451, 2095, 2099, 2132], [450, 2141, 1956, 2178], [451, 2211, 2098, 2248], [452, 2256, 2099, 2294], [452, 2303, 2098, 2340], [451, 2348, 2099, 2385], [452, 2394, 2099, 2431], [452, 2440, 2099, 2477], [451, 2485, 2099, 2522], [451, 2531, 2097, 2568], [452, 2577, 2099, 2614], [451, 2622, 2099, 2659], [451, 2668, 2099, 2705], [451, 2714, 2097, 2751], [451, 2759, 1472, 2796], [451, 2830, 2099, 2867], [450, 2876, 2099, 2913], [452, 2921, 2099, 2958], [450, 2967, 2099, 3004], [451, 3013, 2100, 3050], [1269, 3137, 1280, 3165], [97, 2265, 134, 2308], [97, 2235, 133, 2272], [83, 2188, 133, 2246], [83, 2162, 133, 2184], [98, 2117, 133, 2164], [103, 2102, 134, 2113], [82, 2058, 133, 2089], [82, 2008, 133, 2054], [82, 1969, 134, 2010], [82, 1926, 134, 1968], [125, 1913, 134, 1924], [82, 1867, 133, 1906], [82, 1829, 133, 1860], [82, 1781, 134, 1823], [82, 1740, 134, 1782], [98, 1698, 133, 1745], [82, 1658, 133, 1697], [81, 1594, 142, 1613], [97, 1549, 134, 1588], [97, 1517, 134, 1550], [125, 1504, 134, 1515], [82, 1443, 134, 1497], [83, 1385, 133, 1447], [81, 1361, 142, 1380], [82, 1276, 133, 1307], [82, 1230, 133, 1269], [83, 1144, 134, 1209], [97, 1106, 134, 1148], [98, 1064, 133, 1111], [82, 1003, 133, 1042], [82, 960, 134, 1001], [82, 924, 133, 955], [82, 874, 133, 920], [451, 353, 2099, 391], [451, 400, 2098, 437], [455, 444, 2100, 482], [451, 491, 2100, 528], [452, 537, 1916, 574], [453, 606, 781, 636], [451, 678, 2097, 715], [451, 724, 2099, 761], [450, 769, 2098, 806], [451, 815, 2097, 852], [451, 861, 2097, 898], [452, 906, 2102, 943], [451, 952, 2098, 989], [451, 998, 2100, 1035], [451, 1043, 1564, 1080], [451, 1114, 2099, 1151], [451, 1159, 2098, 1196], [451, 1205, 2099, 1242], [451, 1251, 2099, 1288], [451, 1296, 2097, 1333], [452, 1342, 2102, 1379], [452, 1388, 2099, 1425], [450, 1433, 2099, 1470], [450, 1479, 1808, 1516], [451, 1550, 2099, 1587], [451, 1595, 2099, 1632], [451, 1641, 2097, 1678], [451, 1687, 2099, 1724], [451, 1732, 2099, 1769], [451, 1778, 2097, 1815], [451, 1824, 2098, 1861], [451, 1868, 2099, 1906], [451, 1915, 2099, 1952], [451, 1961, 2096, 1998], [452, 2006, 2097, 2043], [451, 2052, 2102, 2089], [452, 2098, 2097, 2135], [450, 2143, 2100, 2180], [451, 2189, 2098, 2226], [451, 2232, 2100, 2269], [451, 2280, 1112, 2317], [451, 2351, 2099, 2388], [451, 2396, 2100, 2433], [451, 2442, 2099, 2479], [451, 2488, 2097, 2525], [451, 2533, 2097, 2570], [450, 2579, 1005, 2616], [451, 2656, 1499, 2700], [451, 2737, 2099, 2774], [451, 2783, 2099, 2820], [451, 2828, 2099, 2865], [451, 2874, 2097, 2911], [451, 2920, 2097, 2957], [452, 2965, 2099, 3002], [452, 3011, 2029, 3048], [1265, 3137, 1284, 3165], [990, 423, 1064, 442], [991, 453, 1064, 471], [989, 481, 1063, 499], [999, 515, 1055, 528], [985, 538, 1069, 561], [1104, 423, 1178, 442], [1098, 453, 1184, 471], [1103, 481, 1177, 499], [1112, 515, 1168, 528], [1098, 538, 1183, 561], [1217, 423, 1291, 442], [1212, 453, 1296, 471], [1216, 481, 1291, 499], [1331, 423, 1405, 442], [1325, 453, 1410, 471], [1330, 481, 1404, 499], [1444, 423, 1519, 442], [1439, 453, 1523, 471], [1444, 481, 1518, 499], [1439, 510, 1523, 533], [1568, 422, 1621, 442], [1569, 453, 1620, 471], [1556, 481, 1635, 504], [1681, 422, 1735, 442], [1683, 453, 1733, 471], [1669, 481, 1749, 504], [1773, 422, 1871, 442], [990, 683, 1064, 702], [991, 713, 1064, 731], [989, 741, 1063, 759], [999, 775, 1055, 788], [985, 798, 1069, 821], [1104, 683, 1178, 702], [1098, 713, 1184, 731], [1103, 741, 1177, 759], [1098, 770, 1183, 793], [1217, 683, 1291, 702], [1212, 713, 1296, 731], [1216, 741, 1291, 759], [1331, 683, 1405, 702], [1325, 713, 1410, 731], [1330, 741, 1404, 759], [1444, 683, 1519, 702], [1439, 713, 1523, 731], [1444, 741, 1518, 759], [1439, 770, 1523, 793], [1568, 682, 1621, 702], [1569, 713, 1620, 731], [1556, 741, 1635, 764], [1681, 682, 1735, 702], [1683, 713, 1733, 731], [1669, 741, 1749, 764], [1773, 682, 1871, 702], [1163, 353, 1691, 399], [1133, 605, 1718, 651], [779, 545, 931, 571], [587, 767, 651, 792], [585, 799, 652, 819], [785, 789, 926, 809], [784, 820, 926, 845], [1937, 546, 1999, 566], [1935, 582, 2003, 597], [1930, 609, 2006, 629], [769, 869, 1780, 907], [451, 939, 2098, 977], [451, 986, 2099, 1023], [452, 1032, 2099, 1069], [451, 1077, 2099, 1114], [451, 1123, 2097, 1160], [451, 1168, 2098, 1206], [451, 1213, 2099, 1251], [451, 1260, 2090, 1297], [451, 1337, 999, 1381], [451, 1418, 2100, 1455], [452, 1463, 2097, 1500], [451, 1509, 2100, 1546], [451, 1555, 2099, 1592], [451, 1600, 2099, 1637], [451, 1646, 1172, 1683], [608, 1977, 646, 2009], [931, 1976, 971, 2009], [1256, 1977, 1294, 2009], [1579, 1976, 1619, 2009], [1904, 1977, 1942, 2009], [451, 2034, 2098, 2072], [451, 2081, 2097, 2118], [452, 2125, 2098, 2163], [451, 2171, 2098, 2209], [450, 2218, 2037, 2255], [451, 2336, 1066, 2374], [451, 2406, 2096, 2444], [450, 2450, 2100, 2491], [451, 2496, 2099, 2537], [450, 2543, 1724, 2581], [1726, 2544, 1742, 2557], [1726, 2539, 1872, 2583], [1857, 2544, 2099, 2583], [451, 2590, 2099, 2627], [449, 2635, 1762, 2673], [1763, 2631, 1807, 2650], [1763, 2636, 2099, 2674], [450, 2680, 2100, 2718], [450, 2723, 1319, 2770], [1335, 2733, 2097, 2770], [451, 2779, 581, 2808], [731, 2836, 1075, 2877], [1076, 2836, 1092, 2849], [1076, 2836, 1286, 2880], [2053, 2839, 2098, 2874], [731, 2898, 1003, 2939], [1005, 2896, 1020, 2915], [1005, 2898, 1816, 2945], [451, 2964, 2100, 3005], [451, 3013, 1396, 3050], [1266, 3137, 1282, 3166], [451, 353, 2098, 391], [452, 400, 2099, 437], [451, 445, 2099, 482], [452, 491, 1045, 528], [741, 563, 1085, 604], [1086, 564, 1102, 577], [1086, 563, 1276, 608], [2053, 566, 2098, 601], [741, 626, 1013, 667], [1015, 624, 1030, 643], [1015, 626, 1806, 673], [451, 707, 2099, 748], [451, 756, 1224, 793], [830, 828, 1716, 869], [451, 903, 2098, 944], [451, 949, 2097, 990], [451, 997, 1325, 1036], [119, 627, 389, 651], [272, 657, 363, 681], [1474, 627, 1743, 651], [1627, 657, 1718, 681], [451, 1528, 2098, 1566], [451, 1575, 2099, 1612], [451, 1621, 2098, 1658], [450, 1666, 1204, 1695], [450, 1764, 2099, 1802], [450, 1811, 2099, 1848], [450, 1857, 2099, 1894], [450, 1902, 2099, 1939], [450, 1945, 2098, 1986], [449, 1991, 2097, 2032], [451, 2039, 1924, 2076], [450, 2109, 2097, 2147], [451, 2156, 2100, 2193], [450, 2201, 2099, 2238], [450, 2247, 2099, 2284], [450, 2293, 2099, 2330], [449, 2338, 2099, 2375], [450, 2384, 2099, 2421], [450, 2430, 2100, 2467], [451, 2475, 1610, 2512], [449, 2545, 2098, 2583], [450, 2587, 1255, 2634], [1262, 2621, 1267, 2625], [1287, 2597, 2099, 2634], [450, 2643, 2098, 2680], [450, 2689, 2099, 2726], [450, 2733, 1886, 2771], [450, 2804, 1855, 2842], [450, 2876, 2098, 2913], [450, 2921, 2098, 2958], [450, 2967, 2099, 3004], [450, 3013, 2099, 3050], [1265, 3137, 1284, 3165], [451, 354, 2099, 391], [451, 400, 2099, 437], [451, 445, 2097, 482], [451, 491, 2099, 528], [450, 537, 2098, 574], [451, 582, 2097, 619], [451, 628, 2097, 665], [451, 674, 1905, 711], [451, 744, 2096, 781], [451, 790, 2099, 827], [451, 836, 2097, 873], [451, 881, 2098, 918], [452, 927, 2099, 964], [450, 973, 2099, 1010], [451, 1018, 2100, 1055], [451, 1064, 2099, 1101], [451, 1110, 922, 1138], [451, 1179, 1292, 1209], [2082, 1272, 2101, 1285], [655, 1272, 681, 1285], [598, 1292, 648, 1305], [589, 1425, 648, 1438], [598, 1445, 648, 1458], [589, 1578, 648, 1591], [453, 1474, 616, 1494], [453, 1505, 585, 1525], [453, 1534, 632, 1561], [453, 1326, 616, 1346], [454, 1357, 616, 1377], [453, 1388, 616, 1413], [618, 1386, 631, 1398], [879, 1669, 977, 1694], [874, 1700, 981, 1720], [1060, 1669, 1132, 1694], [1042, 1700, 1149, 1720], [451, 1750, 2099, 1788], [451, 1797, 2100, 1834], [451, 1842, 587, 1870], [451, 1937, 2099, 1974], [451, 1983, 2097, 2020], [451, 2028, 2099, 2066], [451, 2074, 1017, 2111], [451, 2145, 2098, 2182], [451, 2191, 2097, 2228], [451, 2236, 1946, 2273], [451, 2313, 936, 2357], [451, 2394, 2099, 2431], [451, 2440, 2099, 2477], [452, 2485, 2097, 2522], [451, 2530, 2100, 2568], [451, 2577, 2099, 2614], [451, 2622, 2099, 2659], [451, 2668, 2099, 2705], [451, 2714, 2100, 2751], [451, 2759, 888, 2796], [451, 2829, 2099, 2867], [451, 2876, 2097, 2913], [451, 2920, 2100, 2958], [452, 2967, 2100, 3004], [452, 3013, 2098, 3050], [1265, 3136, 1282, 3166], [451, 353, 2099, 391], [451, 400, 2099, 437], [451, 445, 2102, 482], [451, 491, 2080, 528], [451, 568, 1014, 612], [452, 648, 2098, 686], [451, 695, 2099, 732], [451, 741, 2098, 778], [450, 786, 2099, 823], [452, 831, 2097, 869], [451, 878, 2037, 915], [451, 947, 2099, 985], [451, 994, 2099, 1031], [451, 1039, 2099, 1076], [451, 1084, 2099, 1122], [451, 1131, 2097, 1168], [450, 1176, 2097, 1213], [447, 1221, 2099, 1259], [451, 1267, 2097, 1305], [451, 1313, 2097, 1350], [451, 1359, 2099, 1396], [451, 1399, 1249, 1442], [1254, 1405, 2097, 1442], [451, 1450, 2099, 1487], [451, 1489, 2099, 1533], [452, 1536, 2099, 1579], [451, 1587, 1059, 1624], [451, 1657, 2098, 1695], [451, 1704, 2100, 1741], [451, 1748, 2099, 1786], [451, 1795, 2097, 1832], [451, 1864, 2099, 1902], [452, 1911, 2097, 1948], [451, 1954, 2097, 1994], [450, 2002, 2097, 2039], [452, 2048, 1730, 2085], [451, 2118, 2097, 2156], [450, 2164, 2097, 2201], [451, 2210, 2099, 2247], [451, 2256, 2097, 2293], [451, 2301, 1529, 2338], [451, 2371, 2099, 2409], [451, 2418, 2099, 2455], [452, 2463, 2099, 2500], [451, 2509, 2099, 2546], [450, 2552, 2099, 2593], [450, 2599, 2097, 2637], [451, 2677, 756, 2712], [451, 2757, 2099, 2795], [451, 2803, 2099, 2841], [451, 2843, 2095, 2887], [452, 2894, 2099, 2932], [505, 2966, 512, 2983], [518, 2973, 2097, 3007], [451, 3015, 1894, 3049], [1265, 3137, 1283, 3166], [451, 354, 2099, 391], [451, 399, 2100, 437], [451, 444, 2100, 482], [452, 491, 2099, 528], [451, 537, 2099, 574], [451, 581, 875, 611], [451, 652, 2098, 690], [451, 699, 2099, 736], [451, 744, 2099, 781], [451, 790, 2098, 827], [451, 836, 2099, 873], [450, 881, 2100, 918], [450, 927, 2097, 964], [450, 973, 2100, 1010], [450, 1018, 2100, 1055], [450, 1064, 1349, 1101], [744, 1151, 1805, 1189], [621, 1217, 939, 1251], [469, 1285, 703, 1319], [892, 1264, 1093, 1298], [901, 1307, 946, 1333], [1039, 1307, 1085, 1333], [468, 1349, 663, 1375], [875, 1349, 1107, 1376], [469, 1392, 1108, 1426], [469, 1435, 1107, 1469], [1459, 1213, 1821, 1247], [1173, 1281, 1459, 1315], [1828, 1261, 2088, 1287], [1856, 1302, 1900, 1328], [2007, 1311, 2042, 1328], [1174, 1345, 1683, 1379], [1871, 1361, 1881, 1364], [1977, 1346, 2070, 1372], [1173, 1388, 1673, 1422], [1871, 1404, 1881, 1407], [1978, 1389, 2070, 1415], [1173, 1432, 1692, 1466], [1829, 1432, 2071, 1459], [1173, 1475, 1653, 1509], [1829, 1475, 2070, 1502], [1173, 1518, 1791, 1552], [1871, 1534, 1881, 1537], [1974, 1518, 2071, 1545], [451, 1638, 2099, 1676], [451, 1684, 2099, 1721], [450, 1727, 2099, 1768], [451, 1776, 2097, 1813], [451, 1821, 2099, 1858], [449, 1867, 2099, 1904], [450, 1913, 2099, 1950], [450, 1958, 2097, 1995], [451, 2004, 2097, 2041], [451, 2050, 2097, 2087], [449, 2095, 2099, 2132], [450, 2141, 2097, 2178], [450, 2187, 2099, 2224], [450, 2232, 2099, 2269], [450, 2278, 2099, 2315], [450, 2324, 1197, 2361], [449, 2394, 2100, 2431], [450, 2440, 2100, 2475], [451, 2482, 2099, 2522], [451, 2528, 2099, 2568], [450, 2577, 2099, 2614], [450, 2631, 580, 2650], [450, 2692, 2098, 2730], [450, 2739, 2099, 2776], [450, 2783, 2099, 2821], [451, 2829, 2099, 2867], [451, 2876, 2099, 2913], [452, 2920, 2099, 2958], [451, 2967, 2099, 3004], [451, 3012, 2099, 3050], [1265, 3138, 1283, 3165], [486, 344, 2063, 382], [741, 408, 976, 442], [1658, 409, 1799, 442], [741, 451, 1440, 485], [1680, 451, 1774, 478], [740, 494, 1459, 528], [1680, 495, 1774, 521], [741, 537, 1774, 571], [740, 580, 1456, 614], [1678, 580, 1775, 607], [450, 657, 2100, 694], [451, 703, 2099, 740], [451, 748, 1044, 785], [450, 819, 2100, 856], [451, 863, 2097, 901], [451, 907, 2097, 947], [452, 956, 2066, 993], [451, 1025, 2099, 1063], [451, 1072, 2102, 1109], [451, 1118, 2099, 1155], [451, 1163, 2100, 1200], [452, 1209, 2098, 1246], [451, 1252, 2100, 1292], [452, 1300, 2099, 1337], [450, 1346, 2099, 1383], [450, 1392, 1930, 1429], [739, 1486, 1810, 1524], [644, 1550, 888, 1584], [1036, 1550, 1320, 1584], [1477, 1550, 1897, 1584], [643, 1593, 1236, 1627], [1478, 1593, 1622, 1627], [1780, 1593, 1873, 1620], [643, 1636, 1254, 1670], [1478, 1636, 1622, 1670], [1780, 1636, 1873, 1663], [643, 1679, 1622, 1713], [1780, 1679, 1873, 1706], [643, 1723, 1556, 1757], [1776, 1723, 1874, 1750], [452, 1850, 2098, 1888], [449, 1895, 2099, 1933], [451, 1942, 2099, 1979], [450, 1987, 2099, 2024], [449, 2033, 2099, 2070], [450, 2079, 2097, 2116], [451, 2124, 2099, 2161], [450, 2170, 2099, 2207], [450, 2216, 1558, 2253], [652, 2310, 1896, 2348], [1009, 2374, 1124, 2400], [1655, 2374, 2005, 2401], [532, 2417, 1166, 2451], [1678, 2417, 1771, 2444], [1880, 2417, 1974, 2444], [532, 2460, 1197, 2494], [1674, 2460, 1772, 2487], [1880, 2460, 1974, 2487], [532, 2504, 1601, 2538], [1719, 2520, 1729, 2523], [1877, 2504, 1975, 2531], [533, 2547, 1151, 2581], [1719, 2563, 1729, 2566], [1880, 2548, 1974, 2574], [533, 2590, 1198, 2624], [1677, 2590, 1771, 2617], [1922, 2606, 1932, 2609], [533, 2643, 886, 2677], [1677, 2644, 1771, 2670], [1879, 2643, 1974, 2670], [532, 2686, 925, 2720], [1678, 2687, 1771, 2713], [1880, 2686, 1974, 2713], [532, 2729, 1139, 2763], [1678, 2729, 1771, 2756], [1880, 2729, 1974, 2756], [532, 2773, 1074, 2807], [1674, 2773, 1772, 2800], [1877, 2773, 1975, 2800], [452, 2875, 2098, 2913], [452, 2918, 2099, 2958], [451, 2967, 2099, 3004], [451, 3013, 597, 3050], [1266, 3137, 1282, 3166], [451, 354, 2099, 391], [449, 400, 2097, 437], [449, 445, 2097, 482], [450, 491, 2099, 528], [451, 537, 1619, 574], [577, 2037, 1971, 2075], [451, 2197, 1467, 2241], [450, 2278, 2097, 2315], [452, 2324, 2100, 2361], [451, 2369, 2099, 2406], [452, 2415, 2097, 2452], [452, 2460, 2099, 2497], [452, 2506, 2099, 2543], [450, 2552, 1772, 2589], [451, 2622, 2099, 2659], [451, 2668, 2097, 2705], [452, 2714, 1984, 2751], [451, 2784, 2097, 2821], [451, 2830, 2099, 2867], [451, 2876, 2098, 2913], [451, 2921, 2099, 2958], [452, 2967, 2100, 3004], [451, 3013, 1371, 3050], [1265, 3137, 1283, 3166], [601, 1258, 1948, 1296], [450, 1325, 860, 1369], [451, 1406, 2100, 1443], [451, 1451, 1742, 1488], [451, 1528, 680, 1563], [471, 1608, 2099, 1642], [534, 1651, 1595, 1683], [471, 1706, 2100, 1740], [532, 1747, 1368, 1781], [471, 1803, 2099, 1837], [533, 1845, 1237, 1876], [471, 1901, 2098, 1935], [533, 1942, 1882, 1976], [471, 1998, 2098, 2032], [533, 2040, 1465, 2074], [471, 2096, 2098, 2130], [533, 2137, 1021, 2168], [471, 2193, 2097, 2227], [532, 2235, 858, 2269], [471, 2291, 2097, 2325], [533, 2332, 1102, 2366], [471, 2388, 2098, 2422], [533, 2430, 961, 2463], [453, 2486, 2095, 2520], [534, 2527, 1008, 2561], [452, 2583, 2099, 2617], [532, 2626, 977, 2659], [453, 2681, 2101, 2715], [532, 2722, 959, 2755], [452, 2778, 2091, 2812], [533, 2821, 1059, 2853], [453, 2876, 2098, 2910], [533, 2917, 1507, 2948], [452, 2973, 2099, 3007], [533, 3015, 1193, 3049], [1259, 3137, 1295, 3166], [453, 356, 2099, 390], [533, 398, 1437, 432], [452, 456, 2099, 490], [532, 498, 816, 528], [452, 555, 2098, 589], [533, 597, 2026, 631], [453, 655, 2098, 689], [533, 696, 1955, 730], [453, 755, 2096, 789], [533, 796, 1581, 830], [452, 854, 2097, 888], [532, 896, 858, 930], [452, 954, 2097, 988], [533, 996, 858, 1026], [452, 1053, 2097, 1087], [533, 1096, 752, 1126], [452, 1153, 2099, 1185], [532, 1195, 1104, 1226], [452, 1253, 2097, 1287], [533, 1294, 1102, 1328], [452, 1352, 2097, 1386], [533, 1395, 614, 1421], [453, 1452, 2099, 1486], [530, 1494, 1410, 1528], [453, 1552, 2098, 1586], [533, 1593, 1408, 1627], [452, 1651, 2097, 1685], [532, 1693, 895, 1727], [453, 1751, 2099, 1785], [533, 1792, 1447, 1826], [453, 1850, 2097, 1884], [533, 1893, 614, 1919], [1259, 3137, 1291, 3165]]}}}}, {"tool_name": "tesseract", "text": "Two-Stream Convolutional Networks for Action Recognition in Videos Karen Simonyan Andrew Zisserman Visual Geometry Group, University of Oxford {karen, az}@robots.ox.ac.uk Abstract We investigate architectures of discriminatively trained deep Convolutional Net- works (ConvNets) for action recognition in video. The challenge is to capture the complementary information on appearance from still frames and motion be- tween frames. We also aim to generalise the best performing hand-crafted features within a data-driven learning framework. Our contribution is three-fold. First, we propose a two-stream ConvNet architec- ture which incorporates spatial and temporal networks. Second, we demonstrate that a ConvNet trained on multi-frame dense optical flow is able to achieve very good performance in spite of limited training data. Finally, we show that multi- task learning, applied to two different action classification datasets, can be used to increase the amount of training data and improve the performance on both. Our architecture is trained and evaluated on the standard video actions bench- marks of UCF-101 and HMDB-51, where it is competitive with the state of the art. It also exceeds by a large margin previous attempts to use deep nets for video classification. 1 Introduction Recognition of human actions in videos is a challenging task which has received a significant amount of attention in the research community [11, 14, 17, 26]. Compared to still image classification, the temporal component of videos provides an additional (and important) clue for recognition, as a number of actions can be reliably recognised based on the motion information. Additionally, video provides natural data augmentation (jittering) for single image (video frame) classification. In this work, we aim at extending deep Convolutional Networks (ConvNets) [19], a state-of-the- art still image representation [15], to action recognition in video data. This task has recently been addressed in [14] by using stacked video frames as input to the network, but the results were signif- icantly worse than those of the best hand-crafted shallow representations [20, 26]. We investigate a different architecture based on two separate recognition streams (spatial and temporal), which are then combined by late fusion. The spatial stream performs action recognition from still video frames, whilst the temporal stream is trained to recognise action from motion in the form of dense optical flow. Both streams are implemented as ConvNets. Decoupling the spatial and temporal nets also allows us to exploit the availability of large amounts of annotated image data by pre-training the spatial net on the ImageNet challenge dataset [1]. Our proposed architecture is related to the two-streams hypothesis [9], according to which the human visual cortex contains two pathways: the ventral stream (which performs object recognition) and the dorsal stream (which recognises motion); though we do not investigate this connection any further here. The rest of the paper is organised as follows. In Sect. 1.1 we review the related work on action recognition using both shallow and deep architectures. In Sect. 2 we introduce the two-stream architecture and specify the Spatial ConvNet. Sect. 3 introduces the Temporal ConvNet and in particular how it generalizes the previous architectures reviewed in Sect. 1.1. A mult-task learning framework is developed in Sect. 4 in order to allow effortless combination of training data over multiple datasets. Implementation details are given in Sect. 5, and the performance is evaluated in Sect. 6 and compared to the state of the art. Our experiments on two challenging datasets (UCF- 101 [24] and HMDB-51 [16]) show that the two recognition streams are complementary, and our deep architecture significantly outperforms that of [14] and is competitive with the state of the art shallow representations [20, 21, 26] in spite of being trained on relatively small datasets. 1.1 Related work Video recognition research has been largely driven by the advances in image recognition methods, which were often adapted and extended to deal with video data. A large family of video action recognition methods is based on shallow high-dimensional encodings of local spatio-temporal fea- tures. For instance, the algorithm of [17] consists in detecting sparse spatio-temporal interest points, which are then described using local spatio-temporal features: Histogram of Oriented Gradients (HOG) [7] and Histogram of Optical Flow (HOF). The features are then encoded into the Bag Of Features (BoF) representation, which is pooled over several spatio-temporal grids (similarly to spa- tial pyramid pooling) and combined with an SVM classifier. In a later work [28], it was shown that dense sampling of local features outperforms sparse interest points. Instead of computing local video features over spatio-temporal cuboids, state-of-the-art shallow video representations [20, 21, 26] make use of dense point trajectories. The approach, first in- troduced in [29], consists in adjusting local descriptor support regions, so that they follow dense trajectories, computed using optical flow. The best performance in the trajectory-based pipeline was achieved by the Motion Boundary Histogram (MBH) [8], which is a gradient-based feature, separately computed on the horizontal and vertical components of optical flow. A combination of several features was shown to further boost the accuracy. Recent improvements of trajectory-based hand-crafted representations include compensation of global (camera) motion [10, 16, 26], and the use of the Fisher vector encoding [22] (in [26]) or its deeper variant [23] (in [21]). There has also been a number of attempts to develop a deep architecture for video recognition. In the majority of these works, the input to the network is a stack of consecutive video frames, so the model is expected to implicitly learn spatio-temporal motion-dependent features in the first layers, which can be a difficult task. In [11], an HMAX architecture for video recognition was proposed with pre-defined spatio-temporal filters in the first layer. Later, it was combined [16] with a spatial HMAX model, thus forming spatial (ventral-like) and temporal (dorsal-like) recognition streams. Unlike our work, however, the streams were implemented as hand-crafted and rather shallow (3- layer) HMAX models. In [4, 18, 25], a convolutional RBM and ISA were used for unsupervised learning of spatio-temporal features, which were then plugged into a discriminative model for action classification. Discriminative end-to-end learning of video ConvNets has been addressed in [12] and, more recently, in [14], who compared several ConvNet architectures for action recognition. Training was carried out on a very large Sports-1M dataset, comprising 1.1M YouTube videos of sports activities. Interestingly, [14] found that a network, operating on individual video frames, performs similarly to the networks, whose input is a stack of frames. This might indicate that the learnt spatio-temporal features do not capture the motion well. The learnt representation, fine- tuned on the UCF-101 dataset, turned out to be 20% less accurate than hand-crafted state-of-the-art trajectory-based representation [20, 27]. Our temporal stream ConvNet operates on multiple-frame dense optical flow, which is typically computed in an energy minimisation framework by solving for a displacement field (typically at multiple image scales). We used a popular method of [2], which formulates the energy based on constancy assumptions for intensity and its gradient, as well as smoothness of the displacement field. Recently, [30] proposed an image patch matching scheme, which is reminiscent of deep ConvNets, but does not incorporate learning. 2 Two-stream architecture for video recognition Video can naturally be decomposed into spatial and temporal components. The spatial part, in the form of individual frame appearance, carries information about scenes and objects depicted in the video. The temporal part, in the form of motion across the frames, conveys the movement of the observer (the camera) and the objects. We devise our video recognition architecture accordingly, dividing it into two streams, as shown in Fig. 1. Each stream is implemented using a deep ConvNet, softmax scores of which are combined by late fusion. We consider two fusion methods: averaging and training a multi-class linear SVM [6] on stacked L2-normalised softmax scores as features. rE Spatial stream ConvNet convl || conv2 || conv3 || convd4 || conv5 || full6\u00e9 full7 | |softmax| 7x7x96 |} 5x5x256 || 3x3x512 || 3x3x512 || 3x3x512 4096 2048 stride 2 || stride 2 || stride 1 || stride 1 |] stride 1 || dropout || dropout norm. norm. pool 2x2 single frame pool 2x2 || pool 2x2 Temporal stream ConvNet Pal convl || conv2 || conv3 || convd4 || conv5 || full\u00e9 full7 | |softmax| 7x7x96 || 5x5x256 || 3x3x512 || 3x3x512 || 3x3x512 4096 2048 stride 2 || stride 2 || stride 1 }| stride 1 |] stride 1 || dropout || dropout - norm. |} pool 2x2 pool 2x2 multi-frame pool 2x2 optical flow Figure 1: Two-stream architecture for video classification. Spatial stream ConvNet operates on individual video frames, effectively performing action recog- nition from still images. The static appearance by itself is a useful clue, since some actions are strongly associated with particular objects. In fact, as will be shown in Sect. 6, action classification from still frames (the spatial recognition stream) is fairly competitive on its own. Since a spatial ConvNet is essentially an image classification architecture, we can build upon the recent advances in large-scale image recognition methods [15], and pre-train the network on a large image classifica- tion dataset, such as the ImageNet challenge dataset. The details are presented in Sect. 5. Next, we describe the temporal stream ConvNet, which exploits motion and significantly improves accuracy. 3. Optical flow ConvNets In this section, we describe a ConvNet model, which forms the temporal recognition stream of our architecture (Sect. 2). Unlike the ConvNet models, reviewed in Sect. 1.1, the input to our model is formed by stacking optical flow displacement fields between several consecutive frames. Such input explicitly describes the motion between video frames, which makes the recognition easier, as the network does not need to estimate motion implicitly. We consider several variations of the optical flow-based input, which we describe below. (a) (b) (c) (d) (e) Figure 2: Optical flow. (a),(b): a pair of consecutive video frames with the area around a mov- ing hand outlined with a cyan rectangle. (c): a close-up of dense optical flow in the outlined area; (d): horizontal component d* of the displacement vector field (higher intensity corresponds to pos- itive values, lower intensity to negative values). (e): vertical component d\u2019. Note how (d) and (e) highlight the moving hand and bow. The input to a ConvNet contains multiple flows (Sect. 3.1). 3.1 ConvNet input configurations Optical flow stacking. A dense optical flow can be seen as a set of displacement vector fields dy between the pairs of consecutive frames t and t + 1. By d:(u, v) we denote the displacement vector at the point (u,v) in frame \u00a2, which moves the point to the corresponding point in the following frame t + 1. The horizontal and vertical components of the vector field, d? and d/, can be seen as image channels (shown in Fig. 2), well suited to recognition using a convolutional network. To represent the motion across a sequence of frames, we stack the flow channels d;\"\u201d of L consecutive frames to form a total of 22 input channels. More formally, let w and fh be the width and height of a video; a ConvNet input volume J, \u20ac Rex? X28 for an arbitrary frame 7 is then constructed as follows: I-(u, v, 2k \u2014 1) = dry, \u20141(u, v), (1) T-(u,v, 2k) = di? ,(u,v), u=[bul,o=[LAj,& = [LL]. For an arbitrary point (u,v), the channels I,(u, v,c),c = [1;2\u00a3] encode the motion at that point over a sequence of LE frames (as illustrated in Fig. 3-left). Trajectory stacking. An alternative motion representation, inspired by the trajectory-based de- scriptors [29], replaces the optical flow, sampled at the same locations across several frames, with the flow, sampled along the motion trajectories. In this case, the input volume I, corresponding to a frame 7, takes the following form: I,(u,v, 2k \u2014 1) = de, \u20141 (Px), (2) T-(u,v, 2k) = 2, \\(Py), w= [Lu],0 = [LA], k= [LZ]. where p,, is the k-th point along the trajectory, which starts at the location (u,v) in the frame 7 and is defined by the following recurrence relation: Py = (U0); Pe = Pea + de+e\u20142(Py_1), > 1. Compared to the input volume representation (1), where the channels J(u, v, c) store the displace- ment vectors at the locations (u,v), the input volume (2) stores the vectors sampled at the locations p;, along the trajectory (as illustrated in Fig. 3-right). 7 P, = d,+2(P;) > \u2014 d,4:(p,) Pi, 7 r+3 3 \u2014 4-(p,) Ph | Vr +2 input volume channels r+] 7 Plu ceny. channels T(t, ve) at point [-(ucu, \u00a2) at point Pp; = (uv) / [. Pp; = (uv) Figure 3: ConvNet input derivation from the multi-frame optical flow. Left: optical flow stack- ing (1) samples the displacement vectors d at the same location in multiple frames. Right: trajectory stacking (2) samples the vectors along the trajectory. The frames and the corresponding displace- ment vectors are shown with the same colour. Bi-directional optical flow. Optical flow representations (1) and (2) deal with the forward optical flow, i.e. the displacement field d; of the frame \u00a2 specifies the location of its pixels in the following frame t+ 1. It is natural to consider an extension to a bi-directional optical flow, which can be obtained by computing an additional set of displacement fields in the opposite direction. We then construct an input volume I, by stacking L./2 forward flows between frames 7 and 7+ L/2 and L/2 backward flows between frames 7 \u2014 L./2 and 7. The input J, thus has the same number of channels (2L) as before. The flows can be represented using either of the two methods (1) and (2). Mean flow subtraction. It is generally beneficial to perform zero-centering of the network input, as it allows the model to better exploit the rectification non-linearities. In our case, the displacement vector field components can take on both positive and negative values, and are naturally centered in the sense that across a large variety of motions, the movement in one direction is as probable as the movement in the opposite one. However, given a pair of frames, the optical flow between them can be dominated by a particular displacement, e.g. caused by the camera movement. The importance of camera motion compensation has been previously highlighted in [10, 26], where a global motion component was estimated and subtracted from the dense flow. In our case, we consider a simpler approach: from each displacement field d we subtract its mean vector. Architecture. Above we have described different ways of combining multiple optical flow displace- ment fields into a single volume J, \u20ac exh x2b | Considering that a ConvNet requires a fixed-size input, we sample a 224 x 224 x 2L sub-volume from J, and pass it to the net as input. The hid- den layers configuration remains largely the same as that used in the spatial net, and is illustrated in Fig. 1. Testing is similar to the spatial ConvNet, and is described in detail in Sect. 5. 3.2 Relation of the temporal ConvNet architecture to previous representations In this section, we put our temporal ConvNet architecture in the context of prior art, drawing con- nections to the video representations, reviewed in Sect. 1.1. Methods based on feature encod- ings [17, 29] typically combine several spatio-temporal local features. Such features are computed from the optical flow and are thus generalised by our temporal ConvNet. Indeed, the HOF and MBH local descriptors are based on the histograms of orientations of optical flow or its gradient, which can be obtained from the displacement field input (1) using a single convolutional layer (containing orientation-sensitive filters), followed by the rectification and pooling layers. The kinematic features of [10] (divergence, curl and shear) are also computed from the optical flow gradient, and, again, can be captured by our convolutional model. Finally, the trajectory feature [29] is computed by stack- ing the displacement vectors along the trajectory, which corresponds to the trajectory stacking (2). In Sect. 3.3 we visualise the convolutional filters, learnt in the first layer of the temporal network. This provides further evidence that our representation generalises hand-crafted features. As far as the deep networks are concerned, a two-stream video classification architecture of [16] contains two HMAX models which are hand-crafted and less deep than our discriminatively trained ConvNets, which can be seen as a learnable generalisation of HMAX. The convolutional models of [12, 14] do not decouple spatial and temporal recognition streams, and rely on the motion- sensitive convolutional filters, learnt from the data. In our case, motion is explicitly represented using the optical flow displacement field, computed based on the assumptions of constancy of the intensity and smoothness of the flow. Incorporating such assumptions into a ConvNet framework might be able to boost the performance of end-to-end ConvNet-based methods, and is an interesting direction for future research. 3.3 Visualisation of learnt convolutional filters conv. fliters on horizontal flow components d* conv. filters on vertical flow components d\u00a5 flow 10) temporal spatial derivative derivative Figure 4: First-layer convolutional filters learnt on 10 stacked optical flows. The visualisation is split into 96 columns and 20 rows: each column corresponds to a filter, each row \u2014 to an input channel. In Fig. 4 we visualise the convolutional filters from the first layer of the temporal ConvNet, trained on the UCF-101 dataset. Each of the 96 filters has a spatial receptive field of 7 x 7 pixels, and spans 20 input channels, corresponding to the horizontal (d*) and vertical (d\u00a5) components of 10 stacked optical flow displacement fields d. As can be seen, some filters compute spatial derivatives of the optical flow, capturing how mo- tion changes with image location, which generalises derivative-based hand-crafted descriptors (e.g. MBH). Other filters compute temporal derivatives, capturing changes in motion over time. 4 Multi-task learning Unlike the spatial stream ConvNet, which can be pre-trained on a large still image classification dataset (such as ImageNet), the temporal ConvNet needs to be trained on video data \u2014 and the available datasets for video action classification are still rather small. In our experiments (Sect. 6), training is performed on the UCF-101 and HMDB-51 datasets, which have only: 9.5K and 3.7K videos respectively. To decrease over-fitting, one could consider combining the two datasets into one; this, however, is not straightforward due to the intersection between the sets of classes. One option (which we evaluate later) is to only add the images from the classes, which do not appear in the original dataset. This, however, requires manual search for such classes and limits the amount of additional training data. A more principled way of combining several datasets is based on multi-task learning [5]. Its aim is to learn a (video) representation, which is applicable not only to the task in question (such as HMDB-51 classification), but also to other tasks (e.g. UCF-101 classification). Additional tasks act as a regulariser, and allow for the exploitation of additional training data. In our case, a ConvNet architecture is modified so that it has two softmax classification layers on top of the last fully- connected layer: one softmax layer computes HMDB-51 classification scores, the other one \u2014 the UCF-101 scores. Each of the layers is equipped with its own loss function, which operates only on the videos, coming from the respective dataset. The overall training loss is computed as the sum of the individual tasks\u2019 losses, and the network weight derivatives can be found by back-propagation. 5 Implementation details ConvNets configuration. The layer configuration of our spatial and temporal ConvNets is schemat- ically shown in Fig. 1. It corresponds to CNN-M-2048 architecture of [3] and is similar to the network of [31]. All hidden weight layers use the rectification (ReLU) activation function; max- pooling is performed over 3 x 3 spatial windows with stride 2; local response normalisation uses the same settings as [15]. The only difference between spatial and temporal ConvNet configurations is that we removed the second normalisation layer from the latter to reduce memory consumption. Training. The training procedure can be seen as an adaptation of that of [15] to video frames, and is generally the same for both spatial and temporal nets. The network weights are learnt using the mini-batch stochastic gradient descent with momentum (set to 0.9). At each iteration, a mini-batch of 256 samples is constructed by sampling 256 training videos (uniformly across the classes), from each of which a single frame is randomly selected. In spatial net training, a 224 x 224 sub-image is randomly cropped from the selected frame; it then undergoes random horizontal flipping and RGB jittering. The videos are rescaled beforehand, so that the smallest side of the frame equals 256. We note that unlike [15], the sub-image is sampled from the whole frame, not just its 256 x 256 center. In the temporal net training, we compute an optical flow volume J for the selected training frame as described in Sect. 3. From that volume, a fixed-size 224 x 224 x 2 input is randomly cropped and flipped. The learning rate is initially set to 10~?, and then decreased according to a fixed schedule, which is kept the same for all training sets. Namely, when training a ConvNet from scratch, the rate is changed to 10~\u00b0 after 50K iterations, then to 10~4 after 70K iterations, and training is stopped after 80K iterations. In the fine-tuning scenario, the rate is changed to 10\u00b0 after 14K iterations, and training stopped after 20K iterations. Testing. At test time, given a video, we sample a fixed number of frames (25 in our experiments) with equal temporal spacing between them. From each of the frames we then obtain 10 ConvNet inputs [15] by cropping and flipping four corners and the center of the frame. The class scores for the whole video are then obtained by averaging the scores across the sampled frames and crops therein. Pre-training on ImageNet ILSVRC-2012. When pre-training the spatial ConvNet, we use the same training and test data augmentation as described above (cropping, flipping, RGB jittering). This yields 13.5% top-5 error on ILSVRC-2012 validation set, which compares favourably to 16.0% reported in [31] for a similar network. We believe that the main reason for the improvement is sampling of ConvNet inputs from the whole image, rather than just its center. Multi-GPU training. Our implementation is derived from the publicly available Caffe toolbox [13], but contains a number of significant modifications, including parallel training on multiple GPUs installed in a single system. We exploit the data parallelism, and split each SGD batch across several GPUs. Training a single temporal ConvNet takes | day on a system with 4 NVIDIA Titan cards, which constitutes a 3.2 times speed-up over single-GPU training. Optical flow is computed using the off-the-shelf GPU implementation of [2] from the OpenCV toolbox. In spite of the fast computation time (0.06s for a pair of frames), it would still introduce a bottleneck if done on-the-fly, so we pre-computed the flow before training. To avoid storing the displacement fields as floats, the horizontal and vertical components of the flow were linearly rescaled to a [0, 255] range and compressed using JPEG (after decompression, the flow is rescaled back to its original range). This reduced the flow size for the UCF-101 dataset from 1.5TB to 27GB. 6 Evaluation Datasets and evaluation protocol. The evaluation is performed on UCF-101 [24] and HMDB-51 [16] action recognition benchmarks, which are among the largest available annotated video datasets!. UCF-101 contains 13K videos (180 frames/video on average), annotated into 101 action classes; HMDB-51 includes 6.8K videos of 51 actions. The evaluation protocol is the same 'Very recently, [14] released the Sports-1M dataset of 1.1M automatically annotated YouTube sports videos. Processing the dataset of such scale is very challenging, and we plan to address it in future work. for both datasets: the organisers provide three splits into training and test data, and the performance is measured by the mean classification accuracy across the splits. Each UCF-101 split contains 9.5K training videos; an HMDB-51 split contains 3.7K training videos. We begin by comparing different architectures on the first split of the UCF-101 dataset. For comparison with the state of the art, we follow the standard evaluation protocol and report the average accuracy over three splits on both UCF-101 and HMDB-51. Spatial ConvNets. First, we measure the performance of the spatial stream ConvNet. Three sce- narios are considered: (i) training from scratch on UCF-101, (i1) pre-training on ILSVRC-2012 followed by fine-tuning on UCF-101, (iii) keeping the pre-trained network fixed and only training the last (classification) layer. For each of the settings, we experiment with setting the dropout regu- larisation ratio to 0.5 or to 0.9. From the results, presented in Table 1a, it is clear that training the ConvNet solely on the UCF-101 dataset leads to over-fitting (even with high dropout), and is inferior to pre-training on a large ILSVRC-2012 dataset. Interestingly, fine-tuning the whole network gives only marginal improvement over training the last layer only. In the latter setting, higher dropout over-regularises learning and leads to worse accuracy. In the following experiments we opted for training the last layer on top of a pre-trained ConvNet. Table 1: Individual ConvNets accuracy on UCF-101 (split 1). (a) Spatial ConvNet. (b) Temporal ConvNet. ean traction Oo on Training setting ratio Input configuration ow stac - ow stac trajectory ow stac Temporal ConvNets. Having evaluated spatial ConvNet variants, we now turn to the temporal ConvNet architectures, and assess the effect of the input configurations, described in Sect. 3.1. In particular, we measure the effect of: using multiple (1 = {5, 10}) stacked optical flows; trajectory stacking; mean displacement subtraction; using the bi-directional optical flow. The architectures are trained on the UCF-101 dataset from scratch, so we used an aggressive dropout ratio of 0.9 to help improve generalisation. The results are shown in Table 1b. First, we can conclude that stacking multiple (Z > 1) displacement fields in the input is highly beneficial, as it provides the network with long-term motion information, which is more discriminative than the flow between a pair of frames (Z = 1 setting). Increasing the number of input flows from 5 to 10 leads to a smaller improvement, so we kept LE fixed to 10 in the following experiments. Second, we find that mean subtraction is helpful, as it reduces the effect of global motion between the frames. We use it in the following experiments as default. The difference between different stacking techniques is marginal; it turns out that optical flow stacking performs better than trajectory stacking, and using the bi-directional optical flow is only slightly better than a uni-directional forward flow. Finally, we note that temporal ConvNets significantly outperform the spatial ConvNets (Table 1a), which confirms the importance of motion information for action recognition. We also implemented the \u201cslow fusion\u201d architecture of [14], which amounts to applying a ConvNet to a stack of RGB frames (11 frames in our case). When trained from scratch on UCF-101, it achieved 56.4% accuracy, which is better than a single-frame architecture trained from scratch (52.3%), but is still far off the network trained from scratch on optical flow. This shows that while multi-frame information is important, it is also important to present it to a ConvNet in an appropriate manner. Multi-task learning of temporal ConvNets. Training temporal ConvNets on UCF-101 is challeng- ing due to the small size of the training set. An even bigger challenge is to train the ConvNet on HMDB-51, where each training split is 2.6 times smaller than that of UCF-101. Here we evaluate different options for increasing the effective training set size of HMDB-51: (4) fine-tuning a temporal network pre-trained on UCF-101; (ii) adding 78 classes from UCF-101, which are manually selected so that there is no intersection between these classes and the native HMDB-51 classes; (ii1) using the multi-task formulation (Sect. 4) to learn a video representation, shared between the UCF-101 and HMDB-51 classification tasks. The results are reported in Table 2. As expected, it is beneficial to Table 2: Temporal ConvNet accuracy on HMDB-51 (split 1 with additional training data). raining setting raining on a et, raining on ti- earning on utilise full (all splits combined) UCF-101 data for training (either explicitly by borrowing images, or implicitly by pre-training). Multi-task learning performs the best, as it allows the training procedure to exploit all available training data. We have also experimented with multi-task learning on the UCF-101 dataset, by training a network to classify both the full HMDB-51 data (all splits combined) and the UCF-101 data (a single split). On the first split of UCF-101, the accuracy was measured to be 81.5%, which improves on 81.0% achieved using the same settings, but without the additional HMDB classification task (Table 1b). Two-stream ConvNets. Here we evaluate the complete two-stream model, which combines the two recognition streams. One way of combining the networks would be to train a joint stack of fully-connected layers on top of full6 or full7 layers of the two nets. This, however, was not feasible in our case due to over-fitting. We therefore fused the softmax scores using either averaging or a linear SVM. From Table 3 we conclude that: (i) temporal and spatial recognition streams are complementary, as their fusion significantly improves on both (6% over temporal and 14% over spatial nets); (ii) SVM-based fusion of softmax scores outperforms fusion by averaging; (iii) using bi-directional flow is not beneficial in the case of ConvNet fusion; (iv) temporal ConvNet, trained using multi-task learning, performs the best both alone and when fused with a spatial net. Table 3: Two-stream ConvNet accuracy on UCF-101 (split 1). pati et et yer averaging yer averaging yer averaging Comparison with the state of the art. We conclude the experimental evaluation with the com- parison against the state of the art on three splits of UCF-101 and HMDB-51. For that we used a spatial net, pre-trained on ILSVRC, with the last layer trained on UCF or HMDB. The temporal net was trained on UCF and HMDB using multi-task learning, and the input was computed using uni-directional optical flow stacking with mean subtraction. The softmax scores of the two nets were combined using averaging or SVM. As can be seen from Table 4, both our spatial and temporal nets alone outperform the deep architectures of [14, 16] by a large margin. The combination of the two nets further improves the results (in line with the single-split experiments above), and is comparable to the very recent state-of-the-art hand-crafted models [20, 21, 26]. Table 4: Mean accuracy (over three splits) on UCF-101 and HMDB-51. trajectories Confusion matrix and per-class recall for UCF-101 classification. In Fig. 5 we show the confu- sion matrix for UCF-101 classification using our two-stream model, which achieves 87.0% accuracy on the first dataset split (the last row of Table 3). We also visualise the corresponding per-class recall in Fig. 6. The worst class recall corresponds to Hammering class, which is confused with HeadMassage and BrushingTeeth classes. We found that this is due to two reasons. First, the spatial ConvNet confuses Hammering with HeadMassage, which can be caused by the significant presence of human faces in both classes. Second, the temporal ConvNet confuses Hammering with BrushingTeeth, as both actions contain recurring motion patterns (hand moving up and down). \u2018wasieiene Lee th n i ?: te i FERPA EN ORR RR ATT Figure 5: Confusion matrix of a two-stream model on the first split of UCF-101. 7 Conclusions and directions for improvement We proposed a deep video classification model with competitive performance, which incorporates separate spatial and temporal recognition streams based on ConyNets. Currently it appears that training a temporal ConvNet on optical flow (as here) is significantly better than training on raw stacked frames [14]. The latter is probably too challenging, and might require architectural changes (for example, a combination with the deep matching approach of [30]). Despite using optical flow as input, our temporal model does not require significant hand-crafting, since the flow is computed using a method based on the generic assumptions of constancy and smoothness. As we have shown, extra training data is beneficial for our temporal ConvNet, so we are planning to train it on large video datasets, such as the recently released collection of [14]. This, however, poses a significant challenge on its own due to the gigantic amount of training data (multiple TBs). There still remain some essential ingredients of the state-of-the-art shallow representation [26], which are missed in our current architecture. The most prominent one is local feature pooling over spatio-temporal tubes, centered at the trajectories. Even though the input (2) captures the opti- cal flow along the trajectories, the spatial pooling in our network does not take the trajectories into account. Another potential area of improvement is explicit handling of camera motion, which in our case is compensated by mean displacement subtraction. PPP PLAN TE Figure 6: Per-class recall of a two-stream model on the first split of ae Acknowledgements This work was supported by ERC grant VisRec no. 228180. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used for this research. References [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] A. Berg, J. Deng, and L. Fei-Fei. Large scale visual recognition challenge (ILSVRC), 2010. URL http: //www.image-net .org/challenges/LSVRC/2010/. T. Brox, A. Bruhn, N. Papenberg, and J. Weickert. High accuracy optical flow estimation based on a theory for warping. In Proc. ECCV, pages 25\u201436, 2004. K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In Proc. BMVC., 2014. B. Chen, J. A. Ting, B. Marlin, and N. de Freitas. Deep learning of invariant spatio-temporal features from video. In NIPS Deep Learning and Unsupervised Feature Learning Workshop, 2010. R. Collobert and J. Weston. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proc. ICML, pages 160-167, 2008. K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector ma- chines. JMLR, 2:265\u2014292, 2001. N. Dalal and B Triggs. Histogram of Oriented Gradients for Human Detection. In Proc. CVPR, volume 2, pages 886-893, 2005. N. Dalal, B. Triggs, and C. Schmid. Human detection using oriented histograms of flow and appearance. In Proc. ECCV, pages 428-441, 2006. M. A. Goodale and A. D. Milner. Separate visual pathways for perception and action. Trends in Neuro- sciences, 15(1):20-25, 1992. M. Jain, H. Jegou, and P. Bouthemy. Better exploiting motion for better action recognition. In Proc. CVPR, pages 2555-2562, 2013. H. Jhuang, T. Serre, L. Wolf, and T. Poggio. A biologically inspired system for action recognition. In Proc. ICCV, pages 1-8, 2007. S. Ji, W. Xu, M. Yang, and K. Yu. 3D convolutional neural networks for human action recognition. JEEE PAMTI, 35(1):221-231, 2013. Y. Jia. Caffe: An open source convolutional architecture for fast feature embedding. http: //caffe. berkeleyvision.org/, 2013. A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei. Large-scale video classifi- cation with convolutional neural networks. In Proc. CVPR, 2014. A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. In N/PS, pages 1106-1114, 2012. 10 [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre. HMDB: A large video database for human motion recognition. In Proc. ICCV, pages 2556-2563, 2011. I Laptev, M. Marszatek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In Proc. CVPR, 2008. Q. V. Le, W. Y. Zou, S. Y. Yeung, and A. Y. Ng. Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis. In Proc. CVPR, pages 3361-3368, 2011. Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backprop- agation applied to handwritten zip code recognition. Neural Computation, 1(4):541\u2014551, 1989. X. Peng, L. Wang, X. Wang, and Y. Qiao. Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice. CoRR, abs/1405.4506, 2014. X. Peng, C. Zou, Y. Qiao, and Q. Peng. Action recognition with stacked fisher vectors. In Proc. ECCV, pages 581-595, 2014. F. Perronnin, J. Sanchez, and T. Mensink. Improving the Fisher kernel for large-scale image classification. In Proc. ECCV, 2010. K. Simonyan, A. Vedaldi, and A. Zisserman. Deep Fisher networks for large-scale image classification. In NIPS, 2013. K. Soomro, A. R. Zamir, and M. Shah. UCF101: A dataset of 101 human actions classes from videos in the wild. CoRR, abs/1212.0402, 2012. G. W. Taylor, R. Fergus, Y. LeCun, and C. Bregler. Convolutional learning of spatio-temporal features. In Proc. ECCV, pages 140-153, 2010. H. Wang and C. Schmid. Action recognition with improved trajectories. In Proc. ICCV, pages 3551-3558, 2013. H. Wang and C. Schmid. LEAR-INRIA submission for the THUMOS workshop. In ICCV Workshop on Action Recognition with a Large Number of Classes, 2013. H. Wang, M. M. Ullah, A. Klaser, I. Laptev, and C. Schmid. Evaluation of local spatio-temporal features for action recognition. In Proc. BMVC., pages 1-11, 2009. H. Wang, A. Klaser, C. Schmid, and C.-L. Liu. Action recognition by dense trajectories. In Proc. CVPR, pages 3169-3176, 2011. P. Weinzaepfel, J. Revaud, Z. Harchaoui, and C. Schmid. DeepFlow: Large displacement optical flow with deep matching. In Proc. ICCV, pages 1385-1392, 2013. M.D. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. CoRR, abs/1311.2901, 2013. 11", "common_format": {"doc_id": "./1406.2199v2.hocr", "tokens": ["Two-Stream", "Convolutional", "Networks", "for", "Action", "Recognition", "in", "Videos", "Karen", "Simonyan", "Andrew", "Zisserman", "Visual", "Geometry", "Group,", "University", "of", "Oxford", "{karen,", "az}@robots.ox.ac.uk", "Abstract", "We", "investigate", "architectures", "of", "discriminatively", "trained", "deep", "Convolutional", "Net-", "works", "(ConvNets)", "for", "action", "recognition", "in", "video.", "The", "challenge", "is", "to", "capture", "the", "complementary", "information", "on", "appearance", "from", "still", "frames", "and", "motion", "be-", "tween", "frames.", "We", "also", "aim", "to", "generalise", "the", "best", "performing", "hand-crafted", "features", "within", "a", "data-driven", "learning", "framework.", "Our", "contribution", "is", "three-fold.", "First,", "we", "propose", "a", "two-stream", "ConvNet", "architec-", "ture", "which", "incorporates", "spatial", "and", "temporal", "networks.", "Second,", "we", "demonstrate", "that", "a", "ConvNet", "trained", "on", "multi-frame", "dense", "optical", "flow", "is", "able", "to", "achieve", "very", "good", "performance", "in", "spite", "of", "limited", "training", "data.", "Finally,", "we", "show", "that", "multi-", "task", "learning,", "applied", "to", "two", "different", "action", "classification", "datasets,", "can", "be", "used", "to", "increase", "the", "amount", "of", "training", "data", "and", "improve", "the", "performance", "on", "both.", "Our", "architecture", "is", "trained", "and", "evaluated", "on", "the", "standard", "video", "actions", "bench-", "marks", "of", "UCF-101", "and", "HMDB-51,", "where", "it", "is", "competitive", "with", "the", "state", "of", "the", "art.", "It", "also", "exceeds", "by", "a", "large", "margin", "previous", "attempts", "to", "use", "deep", "nets", "for", "video", "classification.", "1", "Introduction", "Recognition", "of", "human", "actions", "in", "videos", "is", "a", "challenging", "task", "which", "has", "received", "a", "significant", "amount", "of", "attention", "in", "the", "research", "community", "[11,", "14,", "17,", "26].", "Compared", "to", "still", "image", "classification,", "the", "temporal", "component", "of", "videos", "provides", "an", "additional", "(and", "important)", "clue", "for", "recognition,", "as", "a", "number", "of", "actions", "can", "be", "reliably", "recognised", "based", "on", "the", "motion", "information.", "Additionally,", "video", "provides", "natural", "data", "augmentation", "(jittering)", "for", "single", "image", "(video", "frame)", "classification.", "In", "this", "work,", "we", "aim", "at", "extending", "deep", "Convolutional", "Networks", "(ConvNets)", "[19],", "a", "state-of-the-", "art", "still", "image", "representation", "[15],", "to", "action", "recognition", "in", "video", "data.", "This", "task", "has", "recently", "been", "addressed", "in", "[14]", "by", "using", "stacked", "video", "frames", "as", "input", "to", "the", "network,", "but", "the", "results", "were", "signif-", "icantly", "worse", "than", "those", "of", "the", "best", "hand-crafted", "shallow", "representations", "[20,", "26].", "We", "investigate", "a", "different", "architecture", "based", "on", "two", "separate", "recognition", "streams", "(spatial", "and", "temporal),", "which", "are", "then", "combined", "by", "late", "fusion.", "The", "spatial", "stream", "performs", "action", "recognition", "from", "still", "video", "frames,", "whilst", "the", "temporal", "stream", "is", "trained", "to", "recognise", "action", "from", "motion", "in", "the", "form", "of", "dense", "optical", "flow.", "Both", "streams", "are", "implemented", "as", "ConvNets.", "Decoupling", "the", "spatial", "and", "temporal", "nets", "also", "allows", "us", "to", "exploit", "the", "availability", "of", "large", "amounts", "of", "annotated", "image", "data", "by", "pre-training", "the", "spatial", "net", "on", "the", "ImageNet", "challenge", "dataset", "[1].", "Our", "proposed", "architecture", "is", "related", "to", "the", "two-streams", "hypothesis", "[9],", "according", "to", "which", "the", "human", "visual", "cortex", "contains", "two", "pathways:", "the", "ventral", "stream", "(which", "performs", "object", "recognition)", "and", "the", "dorsal", "stream", "(which", "recognises", "motion);", "though", "we", "do", "not", "investigate", "this", "connection", "any", "further", "here.", "The", "rest", "of", "the", "paper", "is", "organised", "as", "follows.", "In", "Sect.", "1.1", "we", "review", "the", "related", "work", "on", "action", "recognition", "using", "both", "shallow", "and", "deep", "architectures.", "In", "Sect.", "2", "we", "introduce", "the", "two-stream", "architecture", "and", "specify", "the", "Spatial", "ConvNet.", "Sect.", "3", "introduces", "the", "Temporal", "ConvNet", "and", "in", "particular", "how", "it", "generalizes", "the", "previous", "architectures", "reviewed", "in", "Sect.", "1.1.", "A", "mult-task", "learning", "framework", "is", "developed", "in", "Sect.", "4", "in", "order", "to", "allow", "effortless", "combination", "of", "training", "data", "over", "multiple", "datasets.", "Implementation", "details", "are", "given", "in", "Sect.", "5,", "and", "the", "performance", "is", "evaluated", "in", "Sect.", "6", "and", "compared", "to", "the", "state", "of", "the", "art.", "Our", "experiments", "on", "two", "challenging", "datasets", "(UCF-", "101", "[24]", "and", "HMDB-51", "[16])", "show", "that", "the", "two", "recognition", "streams", "are", "complementary,", "and", "our", "deep", "architecture", "significantly", "outperforms", "that", "of", "[14]", "and", "is", "competitive", "with", "the", "state", "of", "the", "art", "shallow", "representations", "[20,", "21,", "26]", "in", "spite", "of", "being", "trained", "on", "relatively", "small", "datasets.", "1.1", "Related", "work", "Video", "recognition", "research", "has", "been", "largely", "driven", "by", "the", "advances", "in", "image", "recognition", "methods,", "which", "were", "often", "adapted", "and", "extended", "to", "deal", "with", "video", "data.", "A", "large", "family", "of", "video", "action", "recognition", "methods", "is", "based", "on", "shallow", "high-dimensional", "encodings", "of", "local", "spatio-temporal", "fea-", "tures.", "For", "instance,", "the", "algorithm", "of", "[17]", "consists", "in", "detecting", "sparse", "spatio-temporal", "interest", "points,", "which", "are", "then", "described", "using", "local", "spatio-temporal", "features:", "Histogram", "of", "Oriented", "Gradients", "(HOG)", "[7]", "and", "Histogram", "of", "Optical", "Flow", "(HOF).", "The", "features", "are", "then", "encoded", "into", "the", "Bag", "Of", "Features", "(BoF)", "representation,", "which", "is", "pooled", "over", "several", "spatio-temporal", "grids", "(similarly", "to", "spa-", "tial", "pyramid", "pooling)", "and", "combined", "with", "an", "SVM", "classifier.", "In", "a", "later", "work", "[28],", "it", "was", "shown", "that", "dense", "sampling", "of", "local", "features", "outperforms", "sparse", "interest", "points.", "Instead", "of", "computing", "local", "video", "features", "over", "spatio-temporal", "cuboids,", "state-of-the-art", "shallow", "video", "representations", "[20,", "21,", "26]", "make", "use", "of", "dense", "point", "trajectories.", "The", "approach,", "first", "in-", "troduced", "in", "[29],", "consists", "in", "adjusting", "local", "descriptor", "support", "regions,", "so", "that", "they", "follow", "dense", "trajectories,", "computed", "using", "optical", "flow.", "The", "best", "performance", "in", "the", "trajectory-based", "pipeline", "was", "achieved", "by", "the", "Motion", "Boundary", "Histogram", "(MBH)", "[8],", "which", "is", "a", "gradient-based", "feature,", "separately", "computed", "on", "the", "horizontal", "and", "vertical", "components", "of", "optical", "flow.", "A", "combination", "of", "several", "features", "was", "shown", "to", "further", "boost", "the", "accuracy.", "Recent", "improvements", "of", "trajectory-based", "hand-crafted", "representations", "include", "compensation", "of", "global", "(camera)", "motion", "[10,", "16,", "26],", "and", "the", "use", "of", "the", "Fisher", "vector", "encoding", "[22]", "(in", "[26])", "or", "its", "deeper", "variant", "[23]", "(in", "[21]).", "There", "has", "also", "been", "a", "number", "of", "attempts", "to", "develop", "a", "deep", "architecture", "for", "video", "recognition.", "In", "the", "majority", "of", "these", "works,", "the", "input", "to", "the", "network", "is", "a", "stack", "of", "consecutive", "video", "frames,", "so", "the", "model", "is", "expected", "to", "implicitly", "learn", "spatio-temporal", "motion-dependent", "features", "in", "the", "first", "layers,", "which", "can", "be", "a", "difficult", "task.", "In", "[11],", "an", "HMAX", "architecture", "for", "video", "recognition", "was", "proposed", "with", "pre-defined", "spatio-temporal", "filters", "in", "the", "first", "layer.", "Later,", "it", "was", "combined", "[16]", "with", "a", "spatial", "HMAX", "model,", "thus", "forming", "spatial", "(ventral-like)", "and", "temporal", "(dorsal-like)", "recognition", "streams.", "Unlike", "our", "work,", "however,", "the", "streams", "were", "implemented", "as", "hand-crafted", "and", "rather", "shallow", "(3-", "layer)", "HMAX", "models.", "In", "[4,", "18,", "25],", "a", "convolutional", "RBM", "and", "ISA", "were", "used", "for", "unsupervised", "learning", "of", "spatio-temporal", "features,", "which", "were", "then", "plugged", "into", "a", "discriminative", "model", "for", "action", "classification.", "Discriminative", "end-to-end", "learning", "of", "video", "ConvNets", "has", "been", "addressed", "in", "[12]", "and,", "more", "recently,", "in", "[14],", "who", "compared", "several", "ConvNet", "architectures", "for", "action", "recognition.", "Training", "was", "carried", "out", "on", "a", "very", "large", "Sports-1M", "dataset,", "comprising", "1.1M", "YouTube", "videos", "of", "sports", "activities.", "Interestingly,", "[14]", "found", "that", "a", "network,", "operating", "on", "individual", "video", "frames,", "performs", "similarly", "to", "the", "networks,", "whose", "input", "is", "a", "stack", "of", "frames.", "This", "might", "indicate", "that", "the", "learnt", "spatio-temporal", "features", "do", "not", "capture", "the", "motion", "well.", "The", "learnt", "representation,", "fine-", "tuned", "on", "the", "UCF-101", "dataset,", "turned", "out", "to", "be", "20%", "less", "accurate", "than", "hand-crafted", "state-of-the-art", "trajectory-based", "representation", "[20,", "27].", "Our", "temporal", "stream", "ConvNet", "operates", "on", "multiple-frame", "dense", "optical", "flow,", "which", "is", "typically", "computed", "in", "an", "energy", "minimisation", "framework", "by", "solving", "for", "a", "displacement", "field", "(typically", "at", "multiple", "image", "scales).", "We", "used", "a", "popular", "method", "of", "[2],", "which", "formulates", "the", "energy", "based", "on", "constancy", "assumptions", "for", "intensity", "and", "its", "gradient,", "as", "well", "as", "smoothness", "of", "the", "displacement", "field.", "Recently,", "[30]", "proposed", "an", "image", "patch", "matching", "scheme,", "which", "is", "reminiscent", "of", "deep", "ConvNets,", "but", "does", "not", "incorporate", "learning.", "2", "Two-stream", "architecture", "for", "video", "recognition", "Video", "can", "naturally", "be", "decomposed", "into", "spatial", "and", "temporal", "components.", "The", "spatial", "part,", "in", "the", "form", "of", "individual", "frame", "appearance,", "carries", "information", "about", "scenes", "and", "objects", "depicted", "in", "the", "video.", "The", "temporal", "part,", "in", "the", "form", "of", "motion", "across", "the", "frames,", "conveys", "the", "movement", "of", "the", "observer", "(the", "camera)", "and", "the", "objects.", "We", "devise", "our", "video", "recognition", "architecture", "accordingly,", "dividing", "it", "into", "two", "streams,", "as", "shown", "in", "Fig.", "1.", "Each", "stream", "is", "implemented", "using", "a", "deep", "ConvNet,", "softmax", "scores", "of", "which", "are", "combined", "by", "late", "fusion.", "We", "consider", "two", "fusion", "methods:", "averaging", "and", "training", "a", "multi-class", "linear", "SVM", "[6]", "on", "stacked", "L2-normalised", "softmax", "scores", "as", "features.", "rE", "Spatial", "stream", "ConvNet", "convl", "||", "conv2", "||", "conv3", "||", "convd4", "||", "conv5", "||", "full6\u00e9", "full7", "|", "|softmax|", "7x7x96", "|}", "5x5x256", "||", "3x3x512", "||", "3x3x512", "||", "3x3x512", "4096", "2048", "stride", "2", "||", "stride", "2", "||", "stride", "1", "||", "stride", "1", "|]", "stride", "1", "||", "dropout", "||", "dropout", "norm.", "norm.", "pool", "2x2", "single", "frame", "pool", "2x2", "||", "pool", "2x2", "Temporal", "stream", "ConvNet", "Pal", "convl", "||", "conv2", "||", "conv3", "||", "convd4", "||", "conv5", "||", "full\u00e9", "full7", "|", "|softmax|", "7x7x96", "||", "5x5x256", "||", "3x3x512", "||", "3x3x512", "||", "3x3x512", "4096", "2048", "stride", "2", "||", "stride", "2", "||", "stride", "1", "}|", "stride", "1", "|]", "stride", "1", "||", "dropout", "||", "dropout", "-", "norm.", "|}", "pool", "2x2", "pool", "2x2", "multi-frame", "pool", "2x2", "optical", "flow", "Figure", "1:", "Two-stream", "architecture", "for", "video", "classification.", "Spatial", "stream", "ConvNet", "operates", "on", "individual", "video", "frames,", "effectively", "performing", "action", "recog-", "nition", "from", "still", "images.", "The", "static", "appearance", "by", "itself", "is", "a", "useful", "clue,", "since", "some", "actions", "are", "strongly", "associated", "with", "particular", "objects.", "In", "fact,", "as", "will", "be", "shown", "in", "Sect.", "6,", "action", "classification", "from", "still", "frames", "(the", "spatial", "recognition", "stream)", "is", "fairly", "competitive", "on", "its", "own.", "Since", "a", "spatial", "ConvNet", "is", "essentially", "an", "image", "classification", "architecture,", "we", "can", "build", "upon", "the", "recent", "advances", "in", "large-scale", "image", "recognition", "methods", "[15],", "and", "pre-train", "the", "network", "on", "a", "large", "image", "classifica-", "tion", "dataset,", "such", "as", "the", "ImageNet", "challenge", "dataset.", "The", "details", "are", "presented", "in", "Sect.", "5.", "Next,", "we", "describe", "the", "temporal", "stream", "ConvNet,", "which", "exploits", "motion", "and", "significantly", "improves", "accuracy.", "3.", "Optical", "flow", "ConvNets", "In", "this", "section,", "we", "describe", "a", "ConvNet", "model,", "which", "forms", "the", "temporal", "recognition", "stream", "of", "our", "architecture", "(Sect.", "2).", "Unlike", "the", "ConvNet", "models,", "reviewed", "in", "Sect.", "1.1,", "the", "input", "to", "our", "model", "is", "formed", "by", "stacking", "optical", "flow", "displacement", "fields", "between", "several", "consecutive", "frames.", "Such", "input", "explicitly", "describes", "the", "motion", "between", "video", "frames,", "which", "makes", "the", "recognition", "easier,", "as", "the", "network", "does", "not", "need", "to", "estimate", "motion", "implicitly.", "We", "consider", "several", "variations", "of", "the", "optical", "flow-based", "input,", "which", "we", "describe", "below.", "(a)", "(b)", "(c)", "(d)", "(e)", "Figure", "2:", "Optical", "flow.", "(a),(b):", "a", "pair", "of", "consecutive", "video", "frames", "with", "the", "area", "around", "a", "mov-", "ing", "hand", "outlined", "with", "a", "cyan", "rectangle.", "(c):", "a", "close-up", "of", "dense", "optical", "flow", "in", "the", "outlined", "area;", "(d):", "horizontal", "component", "d*", "of", "the", "displacement", "vector", "field", "(higher", "intensity", "corresponds", "to", "pos-", "itive", "values,", "lower", "intensity", "to", "negative", "values).", "(e):", "vertical", "component", "d\u2019.", "Note", "how", "(d)", "and", "(e)", "highlight", "the", "moving", "hand", "and", "bow.", "The", "input", "to", "a", "ConvNet", "contains", "multiple", "flows", "(Sect.", "3.1).", "3.1", "ConvNet", "input", "configurations", "Optical", "flow", "stacking.", "A", "dense", "optical", "flow", "can", "be", "seen", "as", "a", "set", "of", "displacement", "vector", "fields", "dy", "between", "the", "pairs", "of", "consecutive", "frames", "t", "and", "t", "+", "1.", "By", "d:(u,", "v)", "we", "denote", "the", "displacement", "vector", "at", "the", "point", "(u,v)", "in", "frame", "\u00a2,", "which", "moves", "the", "point", "to", "the", "corresponding", "point", "in", "the", "following", "frame", "t", "+", "1.", "The", "horizontal", "and", "vertical", "components", "of", "the", "vector", "field,", "d?", "and", "d/,", "can", "be", "seen", "as", "image", "channels", "(shown", "in", "Fig.", "2),", "well", "suited", "to", "recognition", "using", "a", "convolutional", "network.", "To", "represent", "the", "motion", "across", "a", "sequence", "of", "frames,", "we", "stack", "the", "flow", "channels", "d;\"\u201d", "of", "L", "consecutive", "frames", "to", "form", "a", "total", "of", "22", "input", "channels.", "More", "formally,", "let", "w", "and", "fh", "be", "the", "width", "and", "height", "of", "a", "video;", "a", "ConvNet", "input", "volume", "J,", "\u20ac", "Rex?", "X28", "for", "an", "arbitrary", "frame", "7", "is", "then", "constructed", "as", "follows:", "I-(u,", "v,", "2k", "\u2014", "1)", "=", "dry,", "\u20141(u,", "v),", "(1)", "T-(u,v,", "2k)", "=", "di?", ",(u,v),", "u=[bul,o=[LAj,&", "=", "[LL].", "For", "an", "arbitrary", "point", "(u,v),", "the", "channels", "I,(u,", "v,c),c", "=", "[1;2\u00a3]", "encode", "the", "motion", "at", "that", "point", "over", "a", "sequence", "of", "LE", "frames", "(as", "illustrated", "in", "Fig.", "3-left).", "Trajectory", "stacking.", "An", "alternative", "motion", "representation,", "inspired", "by", "the", "trajectory-based", "de-", "scriptors", "[29],", "replaces", "the", "optical", "flow,", "sampled", "at", "the", "same", "locations", "across", "several", "frames,", "with", "the", "flow,", "sampled", "along", "the", "motion", "trajectories.", "In", "this", "case,", "the", "input", "volume", "I,", "corresponding", "to", "a", "frame", "7,", "takes", "the", "following", "form:", "I,(u,v,", "2k", "\u2014", "1)", "=", "de,", "\u20141", "(Px),", "(2)", "T-(u,v,", "2k)", "=", "2,", "\\(Py),", "w=", "[Lu],0", "=", "[LA],", "k=", "[LZ].", "where", "p,,", "is", "the", "k-th", "point", "along", "the", "trajectory,", "which", "starts", "at", "the", "location", "(u,v)", "in", "the", "frame", "7", "and", "is", "defined", "by", "the", "following", "recurrence", "relation:", "Py", "=", "(U0);", "Pe", "=", "Pea", "+", "de+e\u20142(Py_1),", ">", "1.", "Compared", "to", "the", "input", "volume", "representation", "(1),", "where", "the", "channels", "J(u,", "v,", "c)", "store", "the", "displace-", "ment", "vectors", "at", "the", "locations", "(u,v),", "the", "input", "volume", "(2)", "stores", "the", "vectors", "sampled", "at", "the", "locations", "p;,", "along", "the", "trajectory", "(as", "illustrated", "in", "Fig.", "3-right).", "7", "P,", "=", "d,+2(P;)", ">", "\u2014", "d,4:(p,)", "Pi,", "7", "r+3", "3", "\u2014", "4-(p,)", "Ph", "|", "Vr", "+2", "input", "volume", "channels", "r+]", "7", "Plu", "ceny.", "channels", "T(t,", "ve)", "at", "point", "[-(ucu,", "\u00a2)", "at", "point", "Pp;", "=", "(uv)", "/", "[.", "Pp;", "=", "(uv)", "Figure", "3:", "ConvNet", "input", "derivation", "from", "the", "multi-frame", "optical", "flow.", "Left:", "optical", "flow", "stack-", "ing", "(1)", "samples", "the", "displacement", "vectors", "d", "at", "the", "same", "location", "in", "multiple", "frames.", "Right:", "trajectory", "stacking", "(2)", "samples", "the", "vectors", "along", "the", "trajectory.", "The", "frames", "and", "the", "corresponding", "displace-", "ment", "vectors", "are", "shown", "with", "the", "same", "colour.", "Bi-directional", "optical", "flow.", "Optical", "flow", "representations", "(1)", "and", "(2)", "deal", "with", "the", "forward", "optical", "flow,", "i.e.", "the", "displacement", "field", "d;", "of", "the", "frame", "\u00a2", "specifies", "the", "location", "of", "its", "pixels", "in", "the", "following", "frame", "t+", "1.", "It", "is", "natural", "to", "consider", "an", "extension", "to", "a", "bi-directional", "optical", "flow,", "which", "can", "be", "obtained", "by", "computing", "an", "additional", "set", "of", "displacement", "fields", "in", "the", "opposite", "direction.", "We", "then", "construct", "an", "input", "volume", "I,", "by", "stacking", "L./2", "forward", "flows", "between", "frames", "7", "and", "7+", "L/2", "and", "L/2", "backward", "flows", "between", "frames", "7", "\u2014", "L./2", "and", "7.", "The", "input", "J,", "thus", "has", "the", "same", "number", "of", "channels", "(2L)", "as", "before.", "The", "flows", "can", "be", "represented", "using", "either", "of", "the", "two", "methods", "(1)", "and", "(2).", "Mean", "flow", "subtraction.", "It", "is", "generally", "beneficial", "to", "perform", "zero-centering", "of", "the", "network", "input,", "as", "it", "allows", "the", "model", "to", "better", "exploit", "the", "rectification", "non-linearities.", "In", "our", "case,", "the", "displacement", "vector", "field", "components", "can", "take", "on", "both", "positive", "and", "negative", "values,", "and", "are", "naturally", "centered", "in", "the", "sense", "that", "across", "a", "large", "variety", "of", "motions,", "the", "movement", "in", "one", "direction", "is", "as", "probable", "as", "the", "movement", "in", "the", "opposite", "one.", "However,", "given", "a", "pair", "of", "frames,", "the", "optical", "flow", "between", "them", "can", "be", "dominated", "by", "a", "particular", "displacement,", "e.g.", "caused", "by", "the", "camera", "movement.", "The", "importance", "of", "camera", "motion", "compensation", "has", "been", "previously", "highlighted", "in", "[10,", "26],", "where", "a", "global", "motion", "component", "was", "estimated", "and", "subtracted", "from", "the", "dense", "flow.", "In", "our", "case,", "we", "consider", "a", "simpler", "approach:", "from", "each", "displacement", "field", "d", "we", "subtract", "its", "mean", "vector.", "Architecture.", "Above", "we", "have", "described", "different", "ways", "of", "combining", "multiple", "optical", "flow", "displace-", "ment", "fields", "into", "a", "single", "volume", "J,", "\u20ac", "exh", "x2b", "|", "Considering", "that", "a", "ConvNet", "requires", "a", "fixed-size", "input,", "we", "sample", "a", "224", "x", "224", "x", "2L", "sub-volume", "from", "J,", "and", "pass", "it", "to", "the", "net", "as", "input.", "The", "hid-", "den", "layers", "configuration", "remains", "largely", "the", "same", "as", "that", "used", "in", "the", "spatial", "net,", "and", "is", "illustrated", "in", "Fig.", "1.", "Testing", "is", "similar", "to", "the", "spatial", "ConvNet,", "and", "is", "described", "in", "detail", "in", "Sect.", "5.", "3.2", "Relation", "of", "the", "temporal", "ConvNet", "architecture", "to", "previous", "representations", "In", "this", "section,", "we", "put", "our", "temporal", "ConvNet", "architecture", "in", "the", "context", "of", "prior", "art,", "drawing", "con-", "nections", "to", "the", "video", "representations,", "reviewed", "in", "Sect.", "1.1.", "Methods", "based", "on", "feature", "encod-", "ings", "[17,", "29]", "typically", "combine", "several", "spatio-temporal", "local", "features.", "Such", "features", "are", "computed", "from", "the", "optical", "flow", "and", "are", "thus", "generalised", "by", "our", "temporal", "ConvNet.", "Indeed,", "the", "HOF", "and", "MBH", "local", "descriptors", "are", "based", "on", "the", "histograms", "of", "orientations", "of", "optical", "flow", "or", "its", "gradient,", "which", "can", "be", "obtained", "from", "the", "displacement", "field", "input", "(1)", "using", "a", "single", "convolutional", "layer", "(containing", "orientation-sensitive", "filters),", "followed", "by", "the", "rectification", "and", "pooling", "layers.", "The", "kinematic", "features", "of", "[10]", "(divergence,", "curl", "and", "shear)", "are", "also", "computed", "from", "the", "optical", "flow", "gradient,", "and,", "again,", "can", "be", "captured", "by", "our", "convolutional", "model.", "Finally,", "the", "trajectory", "feature", "[29]", "is", "computed", "by", "stack-", "ing", "the", "displacement", "vectors", "along", "the", "trajectory,", "which", "corresponds", "to", "the", "trajectory", "stacking", "(2).", "In", "Sect.", "3.3", "we", "visualise", "the", "convolutional", "filters,", "learnt", "in", "the", "first", "layer", "of", "the", "temporal", "network.", "This", "provides", "further", "evidence", "that", "our", "representation", "generalises", "hand-crafted", "features.", "As", "far", "as", "the", "deep", "networks", "are", "concerned,", "a", "two-stream", "video", "classification", "architecture", "of", "[16]", "contains", "two", "HMAX", "models", "which", "are", "hand-crafted", "and", "less", "deep", "than", "our", "discriminatively", "trained", "ConvNets,", "which", "can", "be", "seen", "as", "a", "learnable", "generalisation", "of", "HMAX.", "The", "convolutional", "models", "of", "[12,", "14]", "do", "not", "decouple", "spatial", "and", "temporal", "recognition", "streams,", "and", "rely", "on", "the", "motion-", "sensitive", "convolutional", "filters,", "learnt", "from", "the", "data.", "In", "our", "case,", "motion", "is", "explicitly", "represented", "using", "the", "optical", "flow", "displacement", "field,", "computed", "based", "on", "the", "assumptions", "of", "constancy", "of", "the", "intensity", "and", "smoothness", "of", "the", "flow.", "Incorporating", "such", "assumptions", "into", "a", "ConvNet", "framework", "might", "be", "able", "to", "boost", "the", "performance", "of", "end-to-end", "ConvNet-based", "methods,", "and", "is", "an", "interesting", "direction", "for", "future", "research.", "3.3", "Visualisation", "of", "learnt", "convolutional", "filters", "conv.", "fliters", "on", "horizontal", "flow", "components", "d*", "conv.", "filters", "on", "vertical", "flow", "components", "d\u00a5", "flow", "10)", "temporal", "spatial", "derivative", "derivative", "Figure", "4:", "First-layer", "convolutional", "filters", "learnt", "on", "10", "stacked", "optical", "flows.", "The", "visualisation", "is", "split", "into", "96", "columns", "and", "20", "rows:", "each", "column", "corresponds", "to", "a", "filter,", "each", "row", "\u2014", "to", "an", "input", "channel.", "In", "Fig.", "4", "we", "visualise", "the", "convolutional", "filters", "from", "the", "first", "layer", "of", "the", "temporal", "ConvNet,", "trained", "on", "the", "UCF-101", "dataset.", "Each", "of", "the", "96", "filters", "has", "a", "spatial", "receptive", "field", "of", "7", "x", "7", "pixels,", "and", "spans", "20", "input", "channels,", "corresponding", "to", "the", "horizontal", "(d*)", "and", "vertical", "(d\u00a5)", "components", "of", "10", "stacked", "optical", "flow", "displacement", "fields", "d.", "As", "can", "be", "seen,", "some", "filters", "compute", "spatial", "derivatives", "of", "the", "optical", "flow,", "capturing", "how", "mo-", "tion", "changes", "with", "image", "location,", "which", "generalises", "derivative-based", "hand-crafted", "descriptors", "(e.g.", "MBH).", "Other", "filters", "compute", "temporal", "derivatives,", "capturing", "changes", "in", "motion", "over", "time.", "4", "Multi-task", "learning", "Unlike", "the", "spatial", "stream", "ConvNet,", "which", "can", "be", "pre-trained", "on", "a", "large", "still", "image", "classification", "dataset", "(such", "as", "ImageNet),", "the", "temporal", "ConvNet", "needs", "to", "be", "trained", "on", "video", "data", "\u2014", "and", "the", "available", "datasets", "for", "video", "action", "classification", "are", "still", "rather", "small.", "In", "our", "experiments", "(Sect.", "6),", "training", "is", "performed", "on", "the", "UCF-101", "and", "HMDB-51", "datasets,", "which", "have", "only:", "9.5K", "and", "3.7K", "videos", "respectively.", "To", "decrease", "over-fitting,", "one", "could", "consider", "combining", "the", "two", "datasets", "into", "one;", "this,", "however,", "is", "not", "straightforward", "due", "to", "the", "intersection", "between", "the", "sets", "of", "classes.", "One", "option", "(which", "we", "evaluate", "later)", "is", "to", "only", "add", "the", "images", "from", "the", "classes,", "which", "do", "not", "appear", "in", "the", "original", "dataset.", "This,", "however,", "requires", "manual", "search", "for", "such", "classes", "and", "limits", "the", "amount", "of", "additional", "training", "data.", "A", "more", "principled", "way", "of", "combining", "several", "datasets", "is", "based", "on", "multi-task", "learning", "[5].", "Its", "aim", "is", "to", "learn", "a", "(video)", "representation,", "which", "is", "applicable", "not", "only", "to", "the", "task", "in", "question", "(such", "as", "HMDB-51", "classification),", "but", "also", "to", "other", "tasks", "(e.g.", "UCF-101", "classification).", "Additional", "tasks", "act", "as", "a", "regulariser,", "and", "allow", "for", "the", "exploitation", "of", "additional", "training", "data.", "In", "our", "case,", "a", "ConvNet", "architecture", "is", "modified", "so", "that", "it", "has", "two", "softmax", "classification", "layers", "on", "top", "of", "the", "last", "fully-", "connected", "layer:", "one", "softmax", "layer", "computes", "HMDB-51", "classification", "scores,", "the", "other", "one", "\u2014", "the", "UCF-101", "scores.", "Each", "of", "the", "layers", "is", "equipped", "with", "its", "own", "loss", "function,", "which", "operates", "only", "on", "the", "videos,", "coming", "from", "the", "respective", "dataset.", "The", "overall", "training", "loss", "is", "computed", "as", "the", "sum", "of", "the", "individual", "tasks\u2019", "losses,", "and", "the", "network", "weight", "derivatives", "can", "be", "found", "by", "back-propagation.", "5", "Implementation", "details", "ConvNets", "configuration.", "The", "layer", "configuration", "of", "our", "spatial", "and", "temporal", "ConvNets", "is", "schemat-", "ically", "shown", "in", "Fig.", "1.", "It", "corresponds", "to", "CNN-M-2048", "architecture", "of", "[3]", "and", "is", "similar", "to", "the", "network", "of", "[31].", "All", "hidden", "weight", "layers", "use", "the", "rectification", "(ReLU)", "activation", "function;", "max-", "pooling", "is", "performed", "over", "3", "x", "3", "spatial", "windows", "with", "stride", "2;", "local", "response", "normalisation", "uses", "the", "same", "settings", "as", "[15].", "The", "only", "difference", "between", "spatial", "and", "temporal", "ConvNet", "configurations", "is", "that", "we", "removed", "the", "second", "normalisation", "layer", "from", "the", "latter", "to", "reduce", "memory", "consumption.", "Training.", "The", "training", "procedure", "can", "be", "seen", "as", "an", "adaptation", "of", "that", "of", "[15]", "to", "video", "frames,", "and", "is", "generally", "the", "same", "for", "both", "spatial", "and", "temporal", "nets.", "The", "network", "weights", "are", "learnt", "using", "the", "mini-batch", "stochastic", "gradient", "descent", "with", "momentum", "(set", "to", "0.9).", "At", "each", "iteration,", "a", "mini-batch", "of", "256", "samples", "is", "constructed", "by", "sampling", "256", "training", "videos", "(uniformly", "across", "the", "classes),", "from", "each", "of", "which", "a", "single", "frame", "is", "randomly", "selected.", "In", "spatial", "net", "training,", "a", "224", "x", "224", "sub-image", "is", "randomly", "cropped", "from", "the", "selected", "frame;", "it", "then", "undergoes", "random", "horizontal", "flipping", "and", "RGB", "jittering.", "The", "videos", "are", "rescaled", "beforehand,", "so", "that", "the", "smallest", "side", "of", "the", "frame", "equals", "256.", "We", "note", "that", "unlike", "[15],", "the", "sub-image", "is", "sampled", "from", "the", "whole", "frame,", "not", "just", "its", "256", "x", "256", "center.", "In", "the", "temporal", "net", "training,", "we", "compute", "an", "optical", "flow", "volume", "J", "for", "the", "selected", "training", "frame", "as", "described", "in", "Sect.", "3.", "From", "that", "volume,", "a", "fixed-size", "224", "x", "224", "x", "2", "input", "is", "randomly", "cropped", "and", "flipped.", "The", "learning", "rate", "is", "initially", "set", "to", "10~?,", "and", "then", "decreased", "according", "to", "a", "fixed", "schedule,", "which", "is", "kept", "the", "same", "for", "all", "training", "sets.", "Namely,", "when", "training", "a", "ConvNet", "from", "scratch,", "the", "rate", "is", "changed", "to", "10~\u00b0", "after", "50K", "iterations,", "then", "to", "10~4", "after", "70K", "iterations,", "and", "training", "is", "stopped", "after", "80K", "iterations.", "In", "the", "fine-tuning", "scenario,", "the", "rate", "is", "changed", "to", "10\u00b0", "after", "14K", "iterations,", "and", "training", "stopped", "after", "20K", "iterations.", "Testing.", "At", "test", "time,", "given", "a", "video,", "we", "sample", "a", "fixed", "number", "of", "frames", "(25", "in", "our", "experiments)", "with", "equal", "temporal", "spacing", "between", "them.", "From", "each", "of", "the", "frames", "we", "then", "obtain", "10", "ConvNet", "inputs", "[15]", "by", "cropping", "and", "flipping", "four", "corners", "and", "the", "center", "of", "the", "frame.", "The", "class", "scores", "for", "the", "whole", "video", "are", "then", "obtained", "by", "averaging", "the", "scores", "across", "the", "sampled", "frames", "and", "crops", "therein.", "Pre-training", "on", "ImageNet", "ILSVRC-2012.", "When", "pre-training", "the", "spatial", "ConvNet,", "we", "use", "the", "same", "training", "and", "test", "data", "augmentation", "as", "described", "above", "(cropping,", "flipping,", "RGB", "jittering).", "This", "yields", "13.5%", "top-5", "error", "on", "ILSVRC-2012", "validation", "set,", "which", "compares", "favourably", "to", "16.0%", "reported", "in", "[31]", "for", "a", "similar", "network.", "We", "believe", "that", "the", "main", "reason", "for", "the", "improvement", "is", "sampling", "of", "ConvNet", "inputs", "from", "the", "whole", "image,", "rather", "than", "just", "its", "center.", "Multi-GPU", "training.", "Our", "implementation", "is", "derived", "from", "the", "publicly", "available", "Caffe", "toolbox", "[13],", "but", "contains", "a", "number", "of", "significant", "modifications,", "including", "parallel", "training", "on", "multiple", "GPUs", "installed", "in", "a", "single", "system.", "We", "exploit", "the", "data", "parallelism,", "and", "split", "each", "SGD", "batch", "across", "several", "GPUs.", "Training", "a", "single", "temporal", "ConvNet", "takes", "|", "day", "on", "a", "system", "with", "4", "NVIDIA", "Titan", "cards,", "which", "constitutes", "a", "3.2", "times", "speed-up", "over", "single-GPU", "training.", "Optical", "flow", "is", "computed", "using", "the", "off-the-shelf", "GPU", "implementation", "of", "[2]", "from", "the", "OpenCV", "toolbox.", "In", "spite", "of", "the", "fast", "computation", "time", "(0.06s", "for", "a", "pair", "of", "frames),", "it", "would", "still", "introduce", "a", "bottleneck", "if", "done", "on-the-fly,", "so", "we", "pre-computed", "the", "flow", "before", "training.", "To", "avoid", "storing", "the", "displacement", "fields", "as", "floats,", "the", "horizontal", "and", "vertical", "components", "of", "the", "flow", "were", "linearly", "rescaled", "to", "a", "[0,", "255]", "range", "and", "compressed", "using", "JPEG", "(after", "decompression,", "the", "flow", "is", "rescaled", "back", "to", "its", "original", "range).", "This", "reduced", "the", "flow", "size", "for", "the", "UCF-101", "dataset", "from", "1.5TB", "to", "27GB.", "6", "Evaluation", "Datasets", "and", "evaluation", "protocol.", "The", "evaluation", "is", "performed", "on", "UCF-101", "[24]", "and", "HMDB-51", "[16]", "action", "recognition", "benchmarks,", "which", "are", "among", "the", "largest", "available", "annotated", "video", "datasets!.", "UCF-101", "contains", "13K", "videos", "(180", "frames/video", "on", "average),", "annotated", "into", "101", "action", "classes;", "HMDB-51", "includes", "6.8K", "videos", "of", "51", "actions.", "The", "evaluation", "protocol", "is", "the", "same", "'Very", "recently,", "[14]", "released", "the", "Sports-1M", "dataset", "of", "1.1M", "automatically", "annotated", "YouTube", "sports", "videos.", "Processing", "the", "dataset", "of", "such", "scale", "is", "very", "challenging,", "and", "we", "plan", "to", "address", "it", "in", "future", "work.", "for", "both", "datasets:", "the", "organisers", "provide", "three", "splits", "into", "training", "and", "test", "data,", "and", "the", "performance", "is", "measured", "by", "the", "mean", "classification", "accuracy", "across", "the", "splits.", "Each", "UCF-101", "split", "contains", "9.5K", "training", "videos;", "an", "HMDB-51", "split", "contains", "3.7K", "training", "videos.", "We", "begin", "by", "comparing", "different", "architectures", "on", "the", "first", "split", "of", "the", "UCF-101", "dataset.", "For", "comparison", "with", "the", "state", "of", "the", "art,", "we", "follow", "the", "standard", "evaluation", "protocol", "and", "report", "the", "average", "accuracy", "over", "three", "splits", "on", "both", "UCF-101", "and", "HMDB-51.", "Spatial", "ConvNets.", "First,", "we", "measure", "the", "performance", "of", "the", "spatial", "stream", "ConvNet.", "Three", "sce-", "narios", "are", "considered:", "(i)", "training", "from", "scratch", "on", "UCF-101,", "(i1)", "pre-training", "on", "ILSVRC-2012", "followed", "by", "fine-tuning", "on", "UCF-101,", "(iii)", "keeping", "the", "pre-trained", "network", "fixed", "and", "only", "training", "the", "last", "(classification)", "layer.", "For", "each", "of", "the", "settings,", "we", "experiment", "with", "setting", "the", "dropout", "regu-", "larisation", "ratio", "to", "0.5", "or", "to", "0.9.", "From", "the", "results,", "presented", "in", "Table", "1a,", "it", "is", "clear", "that", "training", "the", "ConvNet", "solely", "on", "the", "UCF-101", "dataset", "leads", "to", "over-fitting", "(even", "with", "high", "dropout),", "and", "is", "inferior", "to", "pre-training", "on", "a", "large", "ILSVRC-2012", "dataset.", "Interestingly,", "fine-tuning", "the", "whole", "network", "gives", "only", "marginal", "improvement", "over", "training", "the", "last", "layer", "only.", "In", "the", "latter", "setting,", "higher", "dropout", "over-regularises", "learning", "and", "leads", "to", "worse", "accuracy.", "In", "the", "following", "experiments", "we", "opted", "for", "training", "the", "last", "layer", "on", "top", "of", "a", "pre-trained", "ConvNet.", "Table", "1:", "Individual", "ConvNets", "accuracy", "on", "UCF-101", "(split", "1).", "(a)", "Spatial", "ConvNet.", "(b)", "Temporal", "ConvNet.", "ean", "traction", "Oo", "on", "Training", "setting", "ratio", "Input", "configuration", "ow", "stac", "-", "ow", "stac", "trajectory", "ow", "stac", "Temporal", "ConvNets.", "Having", "evaluated", "spatial", "ConvNet", "variants,", "we", "now", "turn", "to", "the", "temporal", "ConvNet", "architectures,", "and", "assess", "the", "effect", "of", "the", "input", "configurations,", "described", "in", "Sect.", "3.1.", "In", "particular,", "we", "measure", "the", "effect", "of:", "using", "multiple", "(1", "=", "{5,", "10})", "stacked", "optical", "flows;", "trajectory", "stacking;", "mean", "displacement", "subtraction;", "using", "the", "bi-directional", "optical", "flow.", "The", "architectures", "are", "trained", "on", "the", "UCF-101", "dataset", "from", "scratch,", "so", "we", "used", "an", "aggressive", "dropout", "ratio", "of", "0.9", "to", "help", "improve", "generalisation.", "The", "results", "are", "shown", "in", "Table", "1b.", "First,", "we", "can", "conclude", "that", "stacking", "multiple", "(Z", ">", "1)", "displacement", "fields", "in", "the", "input", "is", "highly", "beneficial,", "as", "it", "provides", "the", "network", "with", "long-term", "motion", "information,", "which", "is", "more", "discriminative", "than", "the", "flow", "between", "a", "pair", "of", "frames", "(Z", "=", "1", "setting).", "Increasing", "the", "number", "of", "input", "flows", "from", "5", "to", "10", "leads", "to", "a", "smaller", "improvement,", "so", "we", "kept", "LE", "fixed", "to", "10", "in", "the", "following", "experiments.", "Second,", "we", "find", "that", "mean", "subtraction", "is", "helpful,", "as", "it", "reduces", "the", "effect", "of", "global", "motion", "between", "the", "frames.", "We", "use", "it", "in", "the", "following", "experiments", "as", "default.", "The", "difference", "between", "different", "stacking", "techniques", "is", "marginal;", "it", "turns", "out", "that", "optical", "flow", "stacking", "performs", "better", "than", "trajectory", "stacking,", "and", "using", "the", "bi-directional", "optical", "flow", "is", "only", "slightly", "better", "than", "a", "uni-directional", "forward", "flow.", "Finally,", "we", "note", "that", "temporal", "ConvNets", "significantly", "outperform", "the", "spatial", "ConvNets", "(Table", "1a),", "which", "confirms", "the", "importance", "of", "motion", "information", "for", "action", "recognition.", "We", "also", "implemented", "the", "\u201cslow", "fusion\u201d", "architecture", "of", "[14],", "which", "amounts", "to", "applying", "a", "ConvNet", "to", "a", "stack", "of", "RGB", "frames", "(11", "frames", "in", "our", "case).", "When", "trained", "from", "scratch", "on", "UCF-101,", "it", "achieved", "56.4%", "accuracy,", "which", "is", "better", "than", "a", "single-frame", "architecture", "trained", "from", "scratch", "(52.3%),", "but", "is", "still", "far", "off", "the", "network", "trained", "from", "scratch", "on", "optical", "flow.", "This", "shows", "that", "while", "multi-frame", "information", "is", "important,", "it", "is", "also", "important", "to", "present", "it", "to", "a", "ConvNet", "in", "an", "appropriate", "manner.", "Multi-task", "learning", "of", "temporal", "ConvNets.", "Training", "temporal", "ConvNets", "on", "UCF-101", "is", "challeng-", "ing", "due", "to", "the", "small", "size", "of", "the", "training", "set.", "An", "even", "bigger", "challenge", "is", "to", "train", "the", "ConvNet", "on", "HMDB-51,", "where", "each", "training", "split", "is", "2.6", "times", "smaller", "than", "that", "of", "UCF-101.", "Here", "we", "evaluate", "different", "options", "for", "increasing", "the", "effective", "training", "set", "size", "of", "HMDB-51:", "(4)", "fine-tuning", "a", "temporal", "network", "pre-trained", "on", "UCF-101;", "(ii)", "adding", "78", "classes", "from", "UCF-101,", "which", "are", "manually", "selected", "so", "that", "there", "is", "no", "intersection", "between", "these", "classes", "and", "the", "native", "HMDB-51", "classes;", "(ii1)", "using", "the", "multi-task", "formulation", "(Sect.", "4)", "to", "learn", "a", "video", "representation,", "shared", "between", "the", "UCF-101", "and", "HMDB-51", "classification", "tasks.", "The", "results", "are", "reported", "in", "Table", "2.", "As", "expected,", "it", "is", "beneficial", "to", "Table", "2:", "Temporal", "ConvNet", "accuracy", "on", "HMDB-51", "(split", "1", "with", "additional", "training", "data).", "raining", "setting", "raining", "on", "a", "et,", "raining", "on", "ti-", "earning", "on", "utilise", "full", "(all", "splits", "combined)", "UCF-101", "data", "for", "training", "(either", "explicitly", "by", "borrowing", "images,", "or", "implicitly", "by", "pre-training).", "Multi-task", "learning", "performs", "the", "best,", "as", "it", "allows", "the", "training", "procedure", "to", "exploit", "all", "available", "training", "data.", "We", "have", "also", "experimented", "with", "multi-task", "learning", "on", "the", "UCF-101", "dataset,", "by", "training", "a", "network", "to", "classify", "both", "the", "full", "HMDB-51", "data", "(all", "splits", "combined)", "and", "the", "UCF-101", "data", "(a", "single", "split).", "On", "the", "first", "split", "of", "UCF-101,", "the", "accuracy", "was", "measured", "to", "be", "81.5%,", "which", "improves", "on", "81.0%", "achieved", "using", "the", "same", "settings,", "but", "without", "the", "additional", "HMDB", "classification", "task", "(Table", "1b).", "Two-stream", "ConvNets.", "Here", "we", "evaluate", "the", "complete", "two-stream", "model,", "which", "combines", "the", "two", "recognition", "streams.", "One", "way", "of", "combining", "the", "networks", "would", "be", "to", "train", "a", "joint", "stack", "of", "fully-connected", "layers", "on", "top", "of", "full6", "or", "full7", "layers", "of", "the", "two", "nets.", "This,", "however,", "was", "not", "feasible", "in", "our", "case", "due", "to", "over-fitting.", "We", "therefore", "fused", "the", "softmax", "scores", "using", "either", "averaging", "or", "a", "linear", "SVM.", "From", "Table", "3", "we", "conclude", "that:", "(i)", "temporal", "and", "spatial", "recognition", "streams", "are", "complementary,", "as", "their", "fusion", "significantly", "improves", "on", "both", "(6%", "over", "temporal", "and", "14%", "over", "spatial", "nets);", "(ii)", "SVM-based", "fusion", "of", "softmax", "scores", "outperforms", "fusion", "by", "averaging;", "(iii)", "using", "bi-directional", "flow", "is", "not", "beneficial", "in", "the", "case", "of", "ConvNet", "fusion;", "(iv)", "temporal", "ConvNet,", "trained", "using", "multi-task", "learning,", "performs", "the", "best", "both", "alone", "and", "when", "fused", "with", "a", "spatial", "net.", "Table", "3:", "Two-stream", "ConvNet", "accuracy", "on", "UCF-101", "(split", "1).", "pati", "et", "et", "yer", "averaging", "yer", "averaging", "yer", "averaging", "Comparison", "with", "the", "state", "of", "the", "art.", "We", "conclude", "the", "experimental", "evaluation", "with", "the", "com-", "parison", "against", "the", "state", "of", "the", "art", "on", "three", "splits", "of", "UCF-101", "and", "HMDB-51.", "For", "that", "we", "used", "a", "spatial", "net,", "pre-trained", "on", "ILSVRC,", "with", "the", "last", "layer", "trained", "on", "UCF", "or", "HMDB.", "The", "temporal", "net", "was", "trained", "on", "UCF", "and", "HMDB", "using", "multi-task", "learning,", "and", "the", "input", "was", "computed", "using", "uni-directional", "optical", "flow", "stacking", "with", "mean", "subtraction.", "The", "softmax", "scores", "of", "the", "two", "nets", "were", "combined", "using", "averaging", "or", "SVM.", "As", "can", "be", "seen", "from", "Table", "4,", "both", "our", "spatial", "and", "temporal", "nets", "alone", "outperform", "the", "deep", "architectures", "of", "[14,", "16]", "by", "a", "large", "margin.", "The", "combination", "of", "the", "two", "nets", "further", "improves", "the", "results", "(in", "line", "with", "the", "single-split", "experiments", "above),", "and", "is", "comparable", "to", "the", "very", "recent", "state-of-the-art", "hand-crafted", "models", "[20,", "21,", "26].", "Table", "4:", "Mean", "accuracy", "(over", "three", "splits)", "on", "UCF-101", "and", "HMDB-51.", "trajectories", "Confusion", "matrix", "and", "per-class", "recall", "for", "UCF-101", "classification.", "In", "Fig.", "5", "we", "show", "the", "confu-", "sion", "matrix", "for", "UCF-101", "classification", "using", "our", "two-stream", "model,", "which", "achieves", "87.0%", "accuracy", "on", "the", "first", "dataset", "split", "(the", "last", "row", "of", "Table", "3).", "We", "also", "visualise", "the", "corresponding", "per-class", "recall", "in", "Fig.", "6.", "The", "worst", "class", "recall", "corresponds", "to", "Hammering", "class,", "which", "is", "confused", "with", "HeadMassage", "and", "BrushingTeeth", "classes.", "We", "found", "that", "this", "is", "due", "to", "two", "reasons.", "First,", "the", "spatial", "ConvNet", "confuses", "Hammering", "with", "HeadMassage,", "which", "can", "be", "caused", "by", "the", "significant", "presence", "of", "human", "faces", "in", "both", "classes.", "Second,", "the", "temporal", "ConvNet", "confuses", "Hammering", "with", "BrushingTeeth,", "as", "both", "actions", "contain", "recurring", "motion", "patterns", "(hand", "moving", "up", "and", "down).", "\u2018wasieiene", "Lee", "th", "n", "i", "?:", "te", "i", "FERPA", "EN", "ORR", "RR", "ATT", "Figure", "5:", "Confusion", "matrix", "of", "a", "two-stream", "model", "on", "the", "first", "split", "of", "UCF-101.", "7", "Conclusions", "and", "directions", "for", "improvement", "We", "proposed", "a", "deep", "video", "classification", "model", "with", "competitive", "performance,", "which", "incorporates", "separate", "spatial", "and", "temporal", "recognition", "streams", "based", "on", "ConyNets.", "Currently", "it", "appears", "that", "training", "a", "temporal", "ConvNet", "on", "optical", "flow", "(as", "here)", "is", "significantly", "better", "than", "training", "on", "raw", "stacked", "frames", "[14].", "The", "latter", "is", "probably", "too", "challenging,", "and", "might", "require", "architectural", "changes", "(for", "example,", "a", "combination", "with", "the", "deep", "matching", "approach", "of", "[30]).", "Despite", "using", "optical", "flow", "as", "input,", "our", "temporal", "model", "does", "not", "require", "significant", "hand-crafting,", "since", "the", "flow", "is", "computed", "using", "a", "method", "based", "on", "the", "generic", "assumptions", "of", "constancy", "and", "smoothness.", "As", "we", "have", "shown,", "extra", "training", "data", "is", "beneficial", "for", "our", "temporal", "ConvNet,", "so", "we", "are", "planning", "to", "train", "it", "on", "large", "video", "datasets,", "such", "as", "the", "recently", "released", "collection", "of", "[14].", "This,", "however,", "poses", "a", "significant", "challenge", "on", "its", "own", "due", "to", "the", "gigantic", "amount", "of", "training", "data", "(multiple", "TBs).", "There", "still", "remain", "some", "essential", "ingredients", "of", "the", "state-of-the-art", "shallow", "representation", "[26],", "which", "are", "missed", "in", "our", "current", "architecture.", "The", "most", "prominent", "one", "is", "local", "feature", "pooling", "over", "spatio-temporal", "tubes,", "centered", "at", "the", "trajectories.", "Even", "though", "the", "input", "(2)", "captures", "the", "opti-", "cal", "flow", "along", "the", "trajectories,", "the", "spatial", "pooling", "in", "our", "network", "does", "not", "take", "the", "trajectories", "into", "account.", "Another", "potential", "area", "of", "improvement", "is", "explicit", "handling", "of", "camera", "motion,", "which", "in", "our", "case", "is", "compensated", "by", "mean", "displacement", "subtraction.", "PPP", "PLAN", "TE", "Figure", "6:", "Per-class", "recall", "of", "a", "two-stream", "model", "on", "the", "first", "split", "of", "ae", "Acknowledgements", "This", "work", "was", "supported", "by", "ERC", "grant", "VisRec", "no.", "228180.", "We", "gratefully", "acknowledge", "the", "support", "of", "NVIDIA", "Corporation", "with", "the", "donation", "of", "the", "GPUs", "used", "for", "this", "research.", "References", "[1]", "[2]", "[3]", "[4]", "[5]", "[6]", "[7]", "[8]", "[9]", "[10]", "[11]", "[12]", "[13]", "[14]", "[15]", "A.", "Berg,", "J.", "Deng,", "and", "L.", "Fei-Fei.", "Large", "scale", "visual", "recognition", "challenge", "(ILSVRC),", "2010.", "URL", "http:", "//www.image-net", ".org/challenges/LSVRC/2010/.", "T.", "Brox,", "A.", "Bruhn,", "N.", "Papenberg,", "and", "J.", "Weickert.", "High", "accuracy", "optical", "flow", "estimation", "based", "on", "a", "theory", "for", "warping.", "In", "Proc.", "ECCV,", "pages", "25\u201436,", "2004.", "K.", "Chatfield,", "K.", "Simonyan,", "A.", "Vedaldi,", "and", "A.", "Zisserman.", "Return", "of", "the", "devil", "in", "the", "details:", "Delving", "deep", "into", "convolutional", "nets.", "In", "Proc.", "BMVC.,", "2014.", "B.", "Chen,", "J.", "A.", "Ting,", "B.", "Marlin,", "and", "N.", "de", "Freitas.", "Deep", "learning", "of", "invariant", "spatio-temporal", "features", "from", "video.", "In", "NIPS", "Deep", "Learning", "and", "Unsupervised", "Feature", "Learning", "Workshop,", "2010.", "R.", "Collobert", "and", "J.", "Weston.", "A", "unified", "architecture", "for", "natural", "language", "processing:", "deep", "neural", "networks", "with", "multitask", "learning.", "In", "Proc.", "ICML,", "pages", "160-167,", "2008.", "K.", "Crammer", "and", "Y.", "Singer.", "On", "the", "algorithmic", "implementation", "of", "multiclass", "kernel-based", "vector", "ma-", "chines.", "JMLR,", "2:265\u2014292,", "2001.", "N.", "Dalal", "and", "B", "Triggs.", "Histogram", "of", "Oriented", "Gradients", "for", "Human", "Detection.", "In", "Proc.", "CVPR,", "volume", "2,", "pages", "886-893,", "2005.", "N.", "Dalal,", "B.", "Triggs,", "and", "C.", "Schmid.", "Human", "detection", "using", "oriented", "histograms", "of", "flow", "and", "appearance.", "In", "Proc.", "ECCV,", "pages", "428-441,", "2006.", "M.", "A.", "Goodale", "and", "A.", "D.", "Milner.", "Separate", "visual", "pathways", "for", "perception", "and", "action.", "Trends", "in", "Neuro-", "sciences,", "15(1):20-25,", "1992.", "M.", "Jain,", "H.", "Jegou,", "and", "P.", "Bouthemy.", "Better", "exploiting", "motion", "for", "better", "action", "recognition.", "In", "Proc.", "CVPR,", "pages", "2555-2562,", "2013.", "H.", "Jhuang,", "T.", "Serre,", "L.", "Wolf,", "and", "T.", "Poggio.", "A", "biologically", "inspired", "system", "for", "action", "recognition.", "In", "Proc.", "ICCV,", "pages", "1-8,", "2007.", "S.", "Ji,", "W.", "Xu,", "M.", "Yang,", "and", "K.", "Yu.", "3D", "convolutional", "neural", "networks", "for", "human", "action", "recognition.", "JEEE", "PAMTI,", "35(1):221-231,", "2013.", "Y.", "Jia.", "Caffe:", "An", "open", "source", "convolutional", "architecture", "for", "fast", "feature", "embedding.", "http:", "//caffe.", "berkeleyvision.org/,", "2013.", "A.", "Karpathy,", "G.", "Toderici,", "S.", "Shetty,", "T.", "Leung,", "R.", "Sukthankar,", "and", "L.", "Fei-Fei.", "Large-scale", "video", "classifi-", "cation", "with", "convolutional", "neural", "networks.", "In", "Proc.", "CVPR,", "2014.", "A.", "Krizhevsky,", "I.", "Sutskever,", "and", "G.", "E.", "Hinton.", "ImageNet", "classification", "with", "deep", "convolutional", "neural", "networks.", "In", "N/PS,", "pages", "1106-1114,", "2012.", "10", "[16]", "[17]", "[18]", "[19]", "[20]", "[21]", "[22]", "[23]", "[24]", "[25]", "[26]", "[27]", "[28]", "[29]", "[30]", "[31]", "H.", "Kuehne,", "H.", "Jhuang,", "E.", "Garrote,", "T.", "Poggio,", "and", "T.", "Serre.", "HMDB:", "A", "large", "video", "database", "for", "human", "motion", "recognition.", "In", "Proc.", "ICCV,", "pages", "2556-2563,", "2011.", "I", "Laptev,", "M.", "Marszatek,", "C.", "Schmid,", "and", "B.", "Rozenfeld.", "Learning", "realistic", "human", "actions", "from", "movies.", "In", "Proc.", "CVPR,", "2008.", "Q.", "V.", "Le,", "W.", "Y.", "Zou,", "S.", "Y.", "Yeung,", "and", "A.", "Y.", "Ng.", "Learning", "hierarchical", "invariant", "spatio-temporal", "features", "for", "action", "recognition", "with", "independent", "subspace", "analysis.", "In", "Proc.", "CVPR,", "pages", "3361-3368,", "2011.", "Y.", "LeCun,", "B.", "Boser,", "J.", "S.", "Denker,", "D.", "Henderson,", "R.", "E.", "Howard,", "W.", "Hubbard,", "and", "L.", "D.", "Jackel.", "Backprop-", "agation", "applied", "to", "handwritten", "zip", "code", "recognition.", "Neural", "Computation,", "1(4):541\u2014551,", "1989.", "X.", "Peng,", "L.", "Wang,", "X.", "Wang,", "and", "Y.", "Qiao.", "Bag", "of", "visual", "words", "and", "fusion", "methods", "for", "action", "recognition:", "Comprehensive", "study", "and", "good", "practice.", "CoRR,", "abs/1405.4506,", "2014.", "X.", "Peng,", "C.", "Zou,", "Y.", "Qiao,", "and", "Q.", "Peng.", "Action", "recognition", "with", "stacked", "fisher", "vectors.", "In", "Proc.", "ECCV,", "pages", "581-595,", "2014.", "F.", "Perronnin,", "J.", "Sanchez,", "and", "T.", "Mensink.", "Improving", "the", "Fisher", "kernel", "for", "large-scale", "image", "classification.", "In", "Proc.", "ECCV,", "2010.", "K.", "Simonyan,", "A.", "Vedaldi,", "and", "A.", "Zisserman.", "Deep", "Fisher", "networks", "for", "large-scale", "image", "classification.", "In", "NIPS,", "2013.", "K.", "Soomro,", "A.", "R.", "Zamir,", "and", "M.", "Shah.", "UCF101:", "A", "dataset", "of", "101", "human", "actions", "classes", "from", "videos", "in", "the", "wild.", "CoRR,", "abs/1212.0402,", "2012.", "G.", "W.", "Taylor,", "R.", "Fergus,", "Y.", "LeCun,", "and", "C.", "Bregler.", "Convolutional", "learning", "of", "spatio-temporal", "features.", "In", "Proc.", "ECCV,", "pages", "140-153,", "2010.", "H.", "Wang", "and", "C.", "Schmid.", "Action", "recognition", "with", "improved", "trajectories.", "In", "Proc.", "ICCV,", "pages", "3551-3558,", "2013.", "H.", "Wang", "and", "C.", "Schmid.", "LEAR-INRIA", "submission", "for", "the", "THUMOS", "workshop.", "In", "ICCV", "Workshop", "on", "Action", "Recognition", "with", "a", "Large", "Number", "of", "Classes,", "2013.", "H.", "Wang,", "M.", "M.", "Ullah,", "A.", "Klaser,", "I.", "Laptev,", "and", "C.", "Schmid.", "Evaluation", "of", "local", "spatio-temporal", "features", "for", "action", "recognition.", "In", "Proc.", "BMVC.,", "pages", "1-11,", "2009.", "H.", "Wang,", "A.", "Klaser,", "C.", "Schmid,", "and", "C.-L.", "Liu.", "Action", "recognition", "by", "dense", "trajectories.", "In", "Proc.", "CVPR,", "pages", "3169-3176,", "2011.", "P.", "Weinzaepfel,", "J.", "Revaud,", "Z.", "Harchaoui,", "and", "C.", "Schmid.", "DeepFlow:", "Large", "displacement", "optical", "flow", "with", "deep", "matching.", "In", "Proc.", "ICCV,", "pages", "1385-1392,", "2013.", "M.D.", "Zeiler", "and", "R.", "Fergus.", "Visualizing", "and", "understanding", "convolutional", "networks.", "CoRR,", "abs/1311.2901,", "2013.", "11"], "positions": [[709, 462, 1080, 513], [1104, 462, 1529, 513], [1549, 464, 1841, 513], [778, 545, 866, 596], [885, 545, 1087, 596], [1108, 546, 1471, 610], [1491, 546, 1549, 595], [1569, 546, 1770, 596], [786, 799, 896, 828], [909, 798, 1084, 835], [1435, 798, 1576, 828], [1589, 798, 1773, 828], [891, 844, 996, 872], [1008, 844, 1172, 881], [1184, 844, 1297, 881], [1311, 844, 1483, 881], [1495, 844, 1531, 872], [1540, 844, 1658, 873], [958, 887, 1114, 928], [1128, 887, 1591, 928], [1182, 1010, 1367, 1045], [600, 1113, 637, 1140], [636, 1112, 843, 1149], [858, 1112, 1066, 1140], [1082, 1112, 1118, 1140], [1129, 1112, 1396, 1149], [1410, 1112, 1524, 1140], [1538, 1112, 1615, 1149], [1629, 1112, 1863, 1141], [1877, 1113, 1948, 1140], [600, 1157, 698, 1185], [717, 1157, 905, 1192], [923, 1157, 971, 1185], [988, 1157, 1086, 1185], [1102, 1157, 1291, 1194], [1308, 1157, 1338, 1185], [1355, 1157, 1453, 1186], [1485, 1157, 1548, 1185], [1564, 1157, 1722, 1194], [1739, 1157, 1763, 1185], [1781, 1161, 1812, 1185], [1829, 1161, 1950, 1194], [600, 1203, 649, 1231], [664, 1203, 920, 1240], [935, 1203, 1129, 1231], [1144, 1212, 1184, 1231], [1200, 1212, 1384, 1240], [1399, 1203, 1478, 1231], [1494, 1203, 1553, 1231], [1568, 1203, 1678, 1231], [1695, 1203, 1752, 1231], [1767, 1203, 1883, 1231], [1897, 1203, 1948, 1231], [600, 1253, 697, 1277], [708, 1249, 827, 1277], [843, 1250, 896, 1277], [907, 1249, 971, 1277], [983, 1249, 1043, 1277], [1053, 1253, 1083, 1277], [1094, 1249, 1261, 1286], [1271, 1249, 1320, 1277], [1329, 1249, 1396, 1277], [1405, 1249, 1591, 1286], [1600, 1249, 1809, 1277], [1820, 1249, 1948, 1277], [600, 1294, 704, 1322], [717, 1303, 733, 1322], [745, 1294, 931, 1323], [943, 1294, 1077, 1331], [1089, 1294, 1276, 1322], [600, 1347, 664, 1376], [676, 1347, 876, 1375], [889, 1347, 914, 1375], [928, 1347, 1098, 1375], [1118, 1347, 1201, 1381], [1216, 1356, 1263, 1375], [1275, 1356, 1406, 1384], [1420, 1356, 1436, 1375], [1449, 1351, 1634, 1375], [1646, 1347, 1782, 1376], [1783, 1347, 1948, 1375], [600, 1397, 663, 1421], [677, 1393, 777, 1421], [791, 1393, 993, 1430], [1009, 1393, 1115, 1430], [1130, 1393, 1187, 1421], [1201, 1393, 1347, 1430], [1361, 1393, 1519, 1421], [1543, 1393, 1671, 1427], [1687, 1402, 1734, 1421], [1748, 1393, 1950, 1421], [600, 1439, 661, 1467], [675, 1448, 691, 1467], [705, 1439, 840, 1468], [842, 1439, 979, 1467], [993, 1448, 1033, 1467], [1047, 1439, 1244, 1467], [1258, 1439, 1351, 1467], [1364, 1439, 1476, 1476], [1490, 1439, 1560, 1467], [1575, 1439, 1599, 1467], [1616, 1439, 1682, 1467], [1696, 1443, 1727, 1467], [1742, 1439, 1864, 1468], [1878, 1448, 1949, 1476], [600, 1484, 681, 1521], [695, 1484, 904, 1521], [918, 1484, 949, 1512], [965, 1484, 1041, 1521], [1055, 1484, 1091, 1512], [1102, 1484, 1218, 1512], [1233, 1484, 1360, 1521], [1375, 1484, 1450, 1512], [1475, 1484, 1597, 1521], [1614, 1493, 1661, 1512], [1676, 1484, 1760, 1512], [1774, 1484, 1835, 1512], [1850, 1484, 1948, 1512], [600, 1530, 666, 1558], [676, 1530, 819, 1567], [833, 1530, 953, 1567], [964, 1534, 995, 1558], [1006, 1534, 1066, 1558], [1077, 1530, 1218, 1558], [1230, 1530, 1328, 1558], [1340, 1530, 1555, 1558], [1566, 1530, 1704, 1564], [1717, 1539, 1773, 1558], [1783, 1530, 1822, 1558], [1832, 1530, 1908, 1558], [1919, 1534, 1949, 1558], [600, 1576, 735, 1604], [746, 1576, 796, 1604], [808, 1585, 919, 1604], [920, 1576, 978, 1604], [987, 1576, 1115, 1613], [1127, 1576, 1195, 1604], [1207, 1576, 1265, 1604], [1277, 1576, 1412, 1613], [1424, 1576, 1473, 1604], [1484, 1576, 1694, 1613], [1705, 1585, 1745, 1604], [1756, 1576, 1837, 1604], [600, 1629, 664, 1658], [681, 1629, 875, 1657], [892, 1629, 917, 1657], [936, 1629, 1049, 1657], [1068, 1629, 1125, 1657], [1143, 1629, 1298, 1658], [1316, 1638, 1356, 1657], [1373, 1629, 1423, 1657], [1441, 1629, 1579, 1657], [1596, 1629, 1687, 1658], [1706, 1629, 1819, 1657], [1837, 1629, 1948, 1657], [600, 1674, 698, 1702], [715, 1674, 751, 1702], [763, 1674, 914, 1703], [934, 1674, 991, 1702], [1007, 1674, 1193, 1708], [1211, 1674, 1311, 1702], [1326, 1674, 1347, 1702], [1362, 1674, 1387, 1702], [1404, 1674, 1596, 1711], [1611, 1674, 1683, 1702], [1699, 1674, 1748, 1702], [1764, 1678, 1837, 1702], [1852, 1674, 1888, 1702], [1900, 1674, 1950, 1702], [601, 1724, 650, 1748], [667, 1721, 691, 1748], [704, 1720, 768, 1748], [780, 1720, 908, 1748], [920, 1720, 961, 1757], [974, 1729, 990, 1748], [1002, 1720, 1083, 1757], [1095, 1720, 1210, 1757], [1221, 1720, 1361, 1757], [1375, 1724, 1512, 1757], [1525, 1724, 1556, 1748], [1567, 1729, 1622, 1748], [1634, 1720, 1711, 1757], [1723, 1724, 1786, 1748], [1800, 1720, 1848, 1748], [1859, 1720, 1949, 1749], [600, 1766, 823, 1794], [453, 1877, 472, 1911], [525, 1877, 794, 1912], [451, 1958, 652, 1995], [662, 1958, 697, 1986], [703, 1958, 816, 1986], [827, 1958, 925, 1986], [928, 1958, 982, 1986], [992, 1958, 1097, 1987], [1108, 1958, 1133, 1986], [1145, 1967, 1161, 1986], [1171, 1958, 1363, 1995], [1373, 1958, 1439, 1986], [1448, 1958, 1548, 1986], [1557, 1958, 1595, 1986], [1598, 1958, 1758, 1987], [1769, 1967, 1785, 1986], [1796, 1958, 1966, 1995], [1977, 1962, 2099, 1986], [451, 2004, 486, 2032], [498, 2004, 640, 2032], [653, 2004, 684, 2032], [697, 2004, 746, 2032], [758, 2004, 896, 2032], [909, 2004, 1097, 2041], [1113, 2004, 1172, 2038], [1191, 2004, 1236, 2038], [1254, 2004, 1299, 2038], [1314, 2004, 1375, 2038], [1396, 2004, 1547, 2041], [1548, 2004, 1611, 2032], [1625, 2004, 1685, 2032], [1698, 2004, 1798, 2041], [1811, 2004, 2035, 2038], [2050, 2004, 2099, 2032], [451, 2050, 597, 2087], [614, 2054, 797, 2087], [814, 2050, 850, 2078], [865, 2050, 970, 2079], [988, 2050, 1128, 2087], [1148, 2059, 1185, 2078], [1204, 2050, 1367, 2078], [1386, 2050, 1457, 2085], [1474, 2050, 1647, 2087], [1665, 2050, 1733, 2078], [1750, 2050, 1798, 2078], [1814, 2050, 2011, 2087], [2033, 2059, 2063, 2078], [2083, 2059, 2099, 2078], [451, 2095, 562, 2123], [562, 2095, 624, 2123], [635, 2095, 748, 2123], [762, 2104, 818, 2123], [830, 2095, 869, 2123], [880, 2095, 1006, 2132], [1018, 2095, 1197, 2132], [1209, 2095, 1303, 2123], [1316, 2104, 1355, 2123], [1368, 2095, 1417, 2123], [1430, 2095, 1546, 2123], [1558, 2095, 1760, 2123], [1780, 2095, 1994, 2132], [2008, 2095, 2099, 2124], [450, 2141, 590, 2178], [603, 2141, 717, 2169], [729, 2141, 797, 2169], [809, 2141, 1033, 2178], [1046, 2141, 1201, 2178], [1214, 2141, 1262, 2169], [1274, 2141, 1371, 2178], [1383, 2141, 1483, 2178], [1495, 2141, 1599, 2176], [1611, 2141, 1719, 2176], [1732, 2141, 1955, 2169], [451, 2212, 483, 2239], [499, 2211, 556, 2239], [574, 2211, 666, 2245], [685, 2220, 732, 2239], [748, 2211, 808, 2239], [825, 2215, 852, 2239], [868, 2211, 1030, 2248], [1046, 2211, 1122, 2248], [1139, 2211, 1372, 2240], [1388, 2211, 1546, 2239], [1564, 2211, 1753, 2246], [1773, 2211, 1846, 2245], [1866, 2220, 1882, 2239], [1899, 2211, 2098, 2239], [452, 2261, 493, 2285], [508, 2257, 567, 2285], [581, 2257, 681, 2294], [694, 2257, 929, 2294], [946, 2257, 1019, 2291], [1035, 2261, 1066, 2285], [1081, 2257, 1180, 2285], [1193, 2257, 1381, 2294], [1395, 2257, 1426, 2285], [1440, 2257, 1530, 2286], [1544, 2257, 1620, 2285], [1643, 2257, 1714, 2285], [1729, 2257, 1795, 2285], [1807, 2257, 1861, 2285], [1875, 2257, 2008, 2294], [2021, 2257, 2099, 2285], [452, 2303, 612, 2331], [624, 2303, 655, 2331], [670, 2303, 731, 2337], [745, 2303, 786, 2340], [797, 2303, 886, 2340], [900, 2303, 1021, 2331], [1033, 2303, 1123, 2332], [1135, 2303, 1231, 2331], [1233, 2312, 1290, 2331], [1303, 2303, 1387, 2340], [1399, 2307, 1430, 2331], [1442, 2303, 1491, 2331], [1503, 2303, 1645, 2337], [1658, 2303, 1710, 2331], [1722, 2303, 1771, 2331], [1781, 2303, 1888, 2331], [1901, 2312, 1980, 2331], [1993, 2303, 2098, 2340], [451, 2348, 562, 2385], [576, 2357, 674, 2376], [688, 2348, 758, 2376], [772, 2348, 858, 2376], [873, 2348, 909, 2376], [920, 2348, 970, 2376], [983, 2348, 1049, 2376], [1063, 2348, 1272, 2376], [1287, 2348, 1412, 2376], [1426, 2348, 1675, 2385], [1694, 2348, 1754, 2382], [1770, 2348, 1831, 2382], [1856, 2349, 1909, 2376], [1923, 2348, 2099, 2385], [452, 2403, 468, 2422], [485, 2394, 625, 2422], [643, 2394, 837, 2422], [853, 2394, 946, 2422], [964, 2403, 1003, 2422], [1021, 2398, 1081, 2422], [1099, 2398, 1233, 2431], [1249, 2394, 1437, 2431], [1456, 2398, 1578, 2422], [1598, 2394, 1718, 2431], [1736, 2394, 1793, 2422], [1810, 2394, 1979, 2431], [1999, 2394, 2099, 2422], [452, 2449, 500, 2468], [514, 2440, 584, 2468], [599, 2440, 740, 2468], [742, 2440, 815, 2477], [830, 2440, 888, 2468], [903, 2440, 1012, 2468], [1038, 2440, 1101, 2468], [1116, 2440, 1222, 2477], [1237, 2444, 1346, 2468], [1359, 2440, 1507, 2477], [1524, 2440, 1623, 2468], [1636, 2440, 1825, 2477], [1839, 2440, 1919, 2468], [1934, 2440, 1994, 2468], [2008, 2440, 2099, 2469], [451, 2485, 570, 2519], [586, 2485, 686, 2513], [699, 2485, 749, 2513], [762, 2485, 908, 2522], [922, 2489, 1031, 2513], [1044, 2485, 1068, 2513], [1083, 2485, 1197, 2513], [1210, 2489, 1241, 2513], [1253, 2485, 1412, 2522], [1426, 2485, 1525, 2513], [1538, 2485, 1618, 2513], [1631, 2485, 1747, 2513], [1760, 2485, 1791, 2513], [1805, 2485, 1854, 2513], [1867, 2485, 1947, 2513], [1960, 2485, 1995, 2513], [2006, 2485, 2099, 2513], [451, 2531, 562, 2568], [574, 2531, 650, 2559], [668, 2531, 747, 2559], [761, 2535, 883, 2559], [898, 2540, 947, 2559], [959, 2531, 1174, 2568], [1187, 2540, 1218, 2559], [1231, 2531, 1402, 2560], [1420, 2531, 1612, 2568], [1624, 2531, 1674, 2559], [1687, 2531, 1793, 2568], [1806, 2531, 1863, 2559], [1875, 2531, 2021, 2568], [2034, 2535, 2097, 2559], [452, 2577, 516, 2605], [531, 2577, 635, 2605], [650, 2586, 684, 2605], [701, 2581, 731, 2605], [746, 2577, 859, 2614], [873, 2577, 923, 2605], [938, 2577, 1120, 2614], [1135, 2577, 1171, 2605], [1183, 2577, 1263, 2614], [1279, 2581, 1415, 2605], [1432, 2577, 1467, 2605], [1480, 2577, 1639, 2605], [1653, 2577, 1754, 2614], [1768, 2577, 1836, 2605], [1849, 2577, 1890, 2614], [1904, 2577, 2099, 2614], [451, 2622, 500, 2650], [516, 2622, 622, 2659], [637, 2626, 686, 2650], [701, 2631, 741, 2650], [757, 2622, 806, 2650], [821, 2623, 983, 2659], [999, 2622, 1156, 2659], [1171, 2622, 1285, 2650], [1303, 2622, 1355, 2656], [1382, 2622, 1446, 2651], [1459, 2622, 1611, 2659], [1627, 2622, 1821, 2650], [1836, 2622, 1860, 2650], [1876, 2622, 1988, 2650], [2004, 2626, 2034, 2650], [2050, 2622, 2099, 2650], [451, 2672, 650, 2696], [662, 2668, 837, 2705], [853, 2668, 905, 2702], [919, 2668, 1080, 2705], [1092, 2672, 1122, 2696], [1134, 2668, 1233, 2696], [1245, 2668, 1294, 2696], [1304, 2668, 1396, 2696], [1398, 2668, 1526, 2697], [1537, 2672, 1638, 2696], [1650, 2668, 1785, 2696], [1798, 2672, 1858, 2696], [1868, 2668, 2033, 2705], [2050, 2668, 2099, 2696], [451, 2714, 564, 2743], [574, 2718, 683, 2742], [693, 2714, 806, 2749], [815, 2714, 948, 2751], [951, 2714, 1074, 2751], [1083, 2714, 1284, 2751], [1296, 2714, 1353, 2742], [1363, 2714, 1412, 2742], [1422, 2714, 1522, 2742], [1533, 2718, 1641, 2742], [1652, 2714, 1764, 2749], [1773, 2714, 1946, 2751], [1958, 2714, 2097, 2749], [451, 2759, 564, 2796], [576, 2768, 623, 2787], [635, 2759, 675, 2787], [687, 2763, 738, 2787], [750, 2759, 926, 2796], [938, 2759, 995, 2787], [1008, 2759, 1189, 2787], [1202, 2768, 1258, 2796], [1271, 2759, 1383, 2787], [1393, 2759, 1471, 2787], [451, 2830, 514, 2858], [529, 2834, 588, 2858], [604, 2830, 640, 2858], [653, 2830, 702, 2858], [717, 2839, 810, 2867], [825, 2830, 850, 2858], [867, 2830, 1026, 2867], [1043, 2839, 1074, 2858], [1091, 2830, 1221, 2858], [1251, 2831, 1283, 2858], [1301, 2830, 1377, 2859], [1400, 2830, 1442, 2858], [1463, 2839, 1510, 2858], [1524, 2830, 1634, 2859], [1651, 2830, 1700, 2858], [1715, 2830, 1827, 2858], [1844, 2830, 1928, 2858], [1943, 2839, 1983, 2858], [2000, 2830, 2099, 2858], [450, 2876, 638, 2913], [655, 2876, 744, 2913], [761, 2876, 835, 2904], [854, 2876, 979, 2904], [998, 2876, 1056, 2904], [1074, 2876, 1150, 2913], [1170, 2876, 1387, 2904], [1422, 2877, 1455, 2904], [1474, 2876, 1551, 2905], [1572, 2876, 1591, 2904], [1609, 2885, 1656, 2904], [1674, 2876, 1829, 2904], [1847, 2876, 1896, 2904], [1914, 2880, 2099, 2904], [452, 2921, 645, 2949], [664, 2921, 721, 2949], [740, 2921, 857, 2958], [875, 2921, 924, 2949], [943, 2921, 1055, 2958], [1073, 2921, 1227, 2950], [1263, 2921, 1340, 2950], [1361, 2921, 1377, 2950], [1397, 2921, 1567, 2949], [1586, 2921, 1635, 2949], [1653, 2921, 1810, 2958], [1828, 2921, 1974, 2950], [1993, 2921, 2050, 2949], [2068, 2921, 2099, 2949], [450, 2967, 609, 3004], [620, 2967, 690, 2995], [703, 2967, 725, 2995], [738, 2967, 922, 3004], [936, 2967, 986, 2995], [998, 2967, 1138, 3004], [1153, 2967, 1361, 2995], [1375, 2967, 1524, 2996], [1538, 2967, 1568, 2995], [1583, 2967, 1659, 2996], [1679, 2967, 1733, 2995], [1754, 2967, 1782, 2995], [1796, 2967, 1952, 2995], [1964, 2967, 2099, 3004], [451, 3013, 630, 3041], [646, 3013, 671, 3041], [689, 3013, 856, 3050], [873, 3013, 904, 3041], [922, 3013, 998, 3042], [1018, 3013, 1037, 3041], [1054, 3013, 1084, 3041], [1101, 3013, 1188, 3041], [1204, 3017, 1235, 3041], [1253, 3013, 1341, 3041], [1358, 3013, 1508, 3041], [1527, 3013, 1733, 3041], [1749, 3013, 1785, 3041], [1799, 3013, 1927, 3050], [1944, 3013, 2011, 3041], [2028, 3022, 2100, 3042], [451, 354, 587, 391], [604, 354, 741, 382], [772, 354, 1033, 391], [1050, 354, 1155, 382], [1174, 363, 1223, 382], [1239, 354, 1328, 391], [1344, 354, 1375, 382], [1393, 354, 1469, 383], [1488, 354, 1516, 388], [1537, 354, 1594, 382], [1611, 354, 1660, 382], [1675, 354, 1865, 391], [1868, 354, 1925, 382], [1944, 354, 2099, 383], [451, 400, 481, 428], [495, 400, 571, 429], [586, 400, 604, 429], [619, 400, 676, 428], [689, 409, 831, 437], [832, 400, 894, 428], [907, 400, 956, 428], [969, 404, 1043, 428], [1055, 400, 1091, 428], [1101, 400, 1150, 428], [1164, 404, 1212, 428], [1231, 400, 1295, 429], [1307, 400, 1506, 437], [1520, 409, 1560, 428], [1572, 404, 1633, 428], [1645, 400, 1837, 437], [1850, 400, 1978, 428], [1993, 400, 2098, 435], [455, 445, 507, 474], [529, 445, 590, 479], [609, 445, 667, 473], [682, 445, 837, 474], [845, 445, 955, 480], [972, 445, 1056, 473], [1071, 445, 1132, 473], [1147, 445, 1196, 473], [1210, 449, 1271, 473], [1285, 445, 1473, 482], [1489, 449, 1612, 473], [1629, 454, 1677, 473], [1692, 445, 1955, 482], [1973, 445, 2030, 473], [2045, 454, 2100, 473], [451, 491, 527, 528], [543, 491, 736, 519], [751, 491, 954, 528], [968, 491, 1168, 528], [1184, 491, 1244, 519], [1259, 491, 1294, 519], [1309, 491, 1370, 525], [1389, 491, 1446, 519], [1460, 491, 1485, 519], [1501, 491, 1693, 528], [1707, 491, 1780, 519], [1794, 491, 1843, 519], [1858, 495, 1932, 519], [1946, 491, 1982, 519], [1993, 491, 2043, 519], [2058, 495, 2099, 519], [452, 537, 577, 565], [588, 537, 837, 574], [854, 537, 913, 571], [927, 537, 975, 571], [989, 537, 1040, 571], [1055, 537, 1085, 565], [1098, 537, 1174, 574], [1186, 537, 1222, 565], [1230, 537, 1322, 574], [1334, 537, 1447, 565], [1459, 546, 1478, 565], [1480, 537, 1665, 574], [1678, 537, 1765, 565], [1777, 537, 1915, 565], [453, 606, 499, 635], [544, 607, 678, 636], [690, 607, 781, 636], [451, 678, 548, 706], [560, 678, 749, 715], [761, 678, 899, 706], [911, 678, 964, 706], [978, 678, 1056, 706], [1070, 678, 1182, 715], [1196, 678, 1299, 707], [1311, 678, 1352, 715], [1366, 678, 1415, 706], [1429, 678, 1576, 707], [1591, 678, 1622, 706], [1635, 678, 1735, 715], [1748, 678, 1936, 715], [1949, 678, 2097, 712], [451, 724, 550, 752], [567, 733, 646, 752], [662, 724, 746, 752], [763, 724, 890, 761], [907, 724, 965, 752], [981, 724, 1129, 752], [1145, 728, 1176, 752], [1192, 724, 1260, 752], [1276, 724, 1348, 752], [1365, 724, 1455, 753], [1472, 724, 1547, 752], [1578, 724, 1606, 752], [1623, 724, 1703, 761], [1720, 724, 1826, 761], [1843, 724, 1878, 752], [1892, 724, 1982, 753], [2000, 724, 2099, 752], [450, 769, 638, 806], [651, 769, 774, 797], [777, 769, 828, 797], [842, 769, 936, 797], [949, 778, 989, 797], [1004, 769, 1129, 797], [1142, 769, 1432, 806], [1445, 769, 1610, 806], [1625, 769, 1661, 797], [1671, 769, 1750, 797], [1765, 769, 2023, 806], [2036, 769, 2098, 797], [451, 819, 537, 843], [554, 816, 610, 843], [621, 815, 764, 849], [777, 815, 826, 843], [838, 815, 997, 852], [1007, 815, 1043, 843], [1054, 815, 1116, 849], [1130, 815, 1258, 843], [1271, 815, 1301, 843], [1312, 815, 1463, 852], [1475, 824, 1576, 852], [1588, 815, 1846, 852], [1857, 815, 1978, 843], [1988, 815, 2097, 852], [451, 861, 550, 889], [568, 870, 617, 889], [633, 861, 703, 889], [720, 861, 878, 889], [894, 861, 983, 898], [1000, 861, 1079, 889], [1097, 861, 1355, 898], [1372, 861, 1510, 889], [1538, 861, 1712, 898], [1729, 861, 1764, 889], [1778, 861, 1922, 890], [1939, 861, 2097, 890], [452, 906, 565, 941], [584, 907, 624, 940], [643, 906, 700, 934], [715, 906, 889, 943], [903, 906, 938, 934], [950, 906, 1071, 943], [1085, 906, 1167, 934], [1183, 906, 1299, 941], [1316, 906, 1379, 934], [1393, 906, 1521, 934], [1538, 915, 1587, 934], [1601, 906, 1671, 934], [1685, 906, 1822, 934], [1836, 906, 1899, 934], [1914, 906, 1963, 934], [1977, 907, 2042, 943], [2057, 906, 2102, 935], [451, 953, 588, 980], [603, 952, 698, 987], [711, 952, 954, 989], [968, 952, 1068, 980], [1080, 952, 1104, 980], [1117, 952, 1229, 989], [1242, 961, 1314, 981], [1326, 952, 1439, 981], [1452, 952, 1711, 989], [1723, 952, 1803, 989], [1817, 952, 1976, 989], [1988, 956, 2019, 980], [2032, 961, 2098, 989], [451, 998, 502, 1026], [513, 998, 651, 1035], [662, 998, 801, 1035], [816, 998, 873, 1026], [886, 998, 1047, 1026], [1060, 998, 1132, 1026], [1146, 1007, 1182, 1026], [1196, 998, 1283, 1027], [1296, 998, 1447, 1026], [1466, 999, 1498, 1026], [1512, 1007, 1528, 1026], [1540, 998, 1613, 1026], [1625, 998, 1709, 1026], [1724, 998, 1797, 1032], [1811, 998, 1833, 1026], [1845, 1007, 1906, 1026], [1921, 998, 2005, 1026], [2007, 998, 2099, 1026], [451, 1043, 544, 1071], [556, 1043, 706, 1080], [718, 1043, 754, 1071], [763, 1043, 842, 1071], [854, 1043, 982, 1071], [996, 1043, 1196, 1080], [1210, 1052, 1311, 1080], [1323, 1043, 1444, 1071], [1455, 1043, 1563, 1080], [451, 1114, 569, 1142], [587, 1114, 623, 1142], [638, 1114, 814, 1151], [832, 1114, 911, 1142], [929, 1114, 1020, 1143], [1038, 1114, 1166, 1142], [1186, 1123, 1257, 1143], [1276, 1114, 1534, 1151], [1552, 1114, 1688, 1148], [1710, 1114, 1954, 1142], [1973, 1114, 2099, 1142], [451, 1159, 541, 1188], [558, 1159, 807, 1196], [829, 1159, 889, 1193], [908, 1159, 957, 1193], [976, 1159, 1027, 1193], [1048, 1159, 1136, 1187], [1152, 1168, 1207, 1187], [1225, 1159, 1261, 1187], [1276, 1159, 1369, 1187], [1385, 1159, 1470, 1196], [1488, 1159, 1678, 1196], [1713, 1159, 1776, 1187], [1795, 1159, 1944, 1196], [1947, 1159, 2037, 1193], [2054, 1159, 2098, 1187], [451, 1205, 594, 1233], [610, 1205, 641, 1233], [660, 1205, 733, 1239], [751, 1205, 880, 1233], [897, 1205, 928, 1233], [945, 1205, 1094, 1242], [1110, 1205, 1189, 1233], [1205, 1205, 1370, 1242], [1386, 1209, 1508, 1242], [1523, 1205, 1653, 1242], [1672, 1214, 1707, 1233], [1723, 1205, 1783, 1233], [1799, 1205, 1868, 1242], [1884, 1205, 1990, 1233], [2006, 1205, 2099, 1233], [451, 1251, 642, 1288], [662, 1251, 824, 1288], [840, 1251, 929, 1288], [946, 1251, 1058, 1288], [1075, 1251, 1151, 1279], [1183, 1251, 1246, 1279], [1262, 1251, 1328, 1279], [1344, 1251, 1553, 1288], [1570, 1251, 1601, 1279], [1618, 1251, 1667, 1279], [1684, 1251, 1950, 1288], [1966, 1251, 2099, 1288], [451, 1305, 511, 1324], [530, 1296, 673, 1325], [688, 1296, 729, 1333], [745, 1296, 794, 1324], [810, 1296, 931, 1324], [947, 1296, 1109, 1333], [1125, 1296, 1299, 1333], [1316, 1296, 1421, 1331], [1423, 1296, 1507, 1331], [1525, 1296, 1625, 1324], [1641, 1296, 1666, 1324], [1684, 1305, 1700, 1324], [1716, 1296, 1959, 1333], [1975, 1296, 2097, 1330], [452, 1342, 617, 1379], [632, 1342, 793, 1379], [808, 1351, 848, 1370], [862, 1342, 912, 1370], [925, 1342, 1093, 1370], [1108, 1342, 1165, 1370], [1179, 1342, 1302, 1371], [1316, 1346, 1514, 1379], [1529, 1342, 1565, 1370], [1577, 1342, 1688, 1379], [1703, 1342, 1779, 1370], [1803, 1342, 1831, 1370], [1846, 1342, 2051, 1370], [2066, 1342, 2102, 1370], [452, 1388, 565, 1417], [578, 1388, 706, 1416], [720, 1397, 781, 1416], [796, 1388, 880, 1416], [882, 1392, 944, 1416], [957, 1388, 1069, 1416], [1080, 1388, 1170, 1416], [1182, 1388, 1232, 1416], [1245, 1397, 1394, 1425], [1414, 1389, 1527, 1416], [1540, 1388, 1773, 1425], [1787, 1388, 1823, 1416], [1833, 1388, 2099, 1425], [450, 1433, 658, 1461], [671, 1433, 920, 1470], [935, 1433, 1055, 1461], [1068, 1433, 1297, 1470], [1310, 1433, 1346, 1461], [1357, 1433, 1459, 1470], [1473, 1433, 1617, 1468], [1631, 1433, 1747, 1461], [1763, 1433, 1822, 1467], [1841, 1433, 1886, 1467], [1901, 1433, 1963, 1467], [1979, 1433, 2036, 1461], [2050, 1433, 2099, 1461], [450, 1488, 504, 1507], [516, 1479, 552, 1507], [561, 1479, 610, 1507], [622, 1479, 725, 1507], [736, 1483, 839, 1508], [850, 1479, 1000, 1516], [1015, 1479, 1077, 1513], [1093, 1479, 1136, 1514], [1152, 1479, 1229, 1514], [1242, 1488, 1276, 1507], [1287, 1479, 1323, 1507], [1336, 1479, 1446, 1516], [1457, 1479, 1570, 1508], [1585, 1479, 1646, 1513], [1663, 1479, 1706, 1514], [1721, 1479, 1807, 1514], [451, 1550, 546, 1578], [559, 1550, 612, 1578], [628, 1550, 692, 1578], [705, 1550, 783, 1578], [798, 1559, 814, 1578], [828, 1550, 939, 1578], [940, 1550, 1003, 1578], [1015, 1554, 1151, 1587], [1167, 1554, 1197, 1578], [1211, 1550, 1339, 1587], [1354, 1559, 1370, 1578], [1384, 1550, 1460, 1587], [1476, 1550, 1669, 1578], [1683, 1550, 1730, 1578], [1743, 1550, 1834, 1579], [1847, 1550, 2043, 1587], [2066, 1551, 2099, 1578], [451, 1595, 500, 1623], [513, 1595, 652, 1632], [665, 1595, 701, 1623], [711, 1595, 795, 1623], [808, 1595, 916, 1629], [931, 1595, 981, 1623], [994, 1595, 1078, 1632], [1091, 1599, 1121, 1623], [1135, 1595, 1184, 1623], [1197, 1595, 1332, 1623], [1344, 1595, 1369, 1623], [1384, 1604, 1400, 1623], [1414, 1595, 1498, 1623], [1510, 1595, 1546, 1623], [1556, 1595, 1749, 1624], [1762, 1595, 1853, 1624], [1866, 1595, 1986, 1629], [2002, 1604, 2036, 1623], [2050, 1595, 2099, 1623], [451, 1641, 553, 1669], [566, 1641, 591, 1669], [606, 1641, 751, 1678], [765, 1645, 795, 1669], [809, 1641, 969, 1678], [983, 1641, 1064, 1669], [1078, 1641, 1337, 1678], [1350, 1641, 1651, 1678], [1664, 1641, 1792, 1669], [1807, 1641, 1838, 1669], [1852, 1641, 1901, 1669], [1914, 1641, 1977, 1669], [1991, 1641, 2097, 1678], [451, 1687, 550, 1715], [565, 1696, 621, 1715], [635, 1687, 673, 1715], [689, 1696, 705, 1715], [719, 1687, 848, 1715], [863, 1687, 936, 1715], [961, 1688, 993, 1715], [1011, 1687, 1084, 1721], [1102, 1696, 1139, 1715], [1154, 1687, 1278, 1715], [1295, 1687, 1488, 1715], [1502, 1687, 1550, 1715], [1564, 1687, 1654, 1716], [1668, 1687, 1856, 1724], [1871, 1696, 1932, 1715], [1947, 1687, 2099, 1724], [451, 1732, 523, 1760], [535, 1732, 723, 1769], [737, 1732, 984, 1769], [985, 1732, 1100, 1760], [1114, 1732, 1145, 1760], [1158, 1732, 1207, 1760], [1220, 1732, 1283, 1760], [1296, 1732, 1383, 1769], [1403, 1733, 1496, 1766], [1511, 1732, 1533, 1760], [1546, 1741, 1607, 1760], [1621, 1732, 1783, 1760], [1799, 1732, 1861, 1766], [1877, 1732, 1949, 1760], [1963, 1741, 1979, 1760], [1993, 1732, 2099, 1769], [451, 1778, 575, 1806], [591, 1778, 702, 1812], [720, 1778, 786, 1806], [804, 1778, 936, 1815], [952, 1778, 1058, 1815], [1075, 1778, 1289, 1813], [1307, 1778, 1364, 1806], [1380, 1778, 1526, 1815], [1542, 1778, 1743, 1813], [1759, 1778, 1948, 1815], [1964, 1782, 2096, 1806], [451, 1824, 562, 1853], [577, 1833, 632, 1852], [647, 1824, 739, 1858], [756, 1824, 902, 1858], [921, 1824, 970, 1852], [987, 1828, 1109, 1852], [1127, 1833, 1206, 1852], [1221, 1824, 1436, 1861], [1453, 1833, 1484, 1852], [1500, 1824, 1709, 1852], [1726, 1824, 1783, 1852], [1798, 1824, 1895, 1852], [1911, 1824, 2036, 1852], [2053, 1824, 2098, 1859], [451, 1869, 544, 1906], [561, 1869, 686, 1897], [701, 1869, 827, 1897], [853, 1870, 886, 1897], [905, 1869, 943, 1903], [964, 1869, 1008, 1903], [1025, 1869, 1088, 1903], [1106, 1878, 1122, 1897], [1137, 1869, 1361, 1898], [1376, 1870, 1467, 1897], [1483, 1869, 1540, 1897], [1556, 1869, 1620, 1898], [1636, 1878, 1715, 1897], [1729, 1869, 1804, 1897], [1820, 1869, 1867, 1897], [1880, 1869, 2099, 1906], [451, 1915, 585, 1952], [596, 1915, 631, 1943], [640, 1915, 898, 1952], [909, 1915, 1047, 1949], [1060, 1915, 1159, 1943], [1170, 1924, 1249, 1943], [1260, 1915, 1330, 1943], [1339, 1915, 1452, 1952], [1453, 1915, 1546, 1943], [1558, 1924, 1574, 1943], [1584, 1915, 1818, 1944], [1829, 1915, 1931, 1943], [1942, 1915, 1989, 1943], [2000, 1915, 2099, 1943], [451, 1961, 673, 1989], [703, 1961, 947, 1990], [963, 1961, 1141, 1989], [1157, 1961, 1292, 1998], [1308, 1961, 1344, 1989], [1357, 1961, 1448, 1990], [1464, 1961, 1625, 1990], [1642, 1961, 1695, 1989], [1712, 1961, 1790, 1989], [1807, 1961, 1968, 1989], [1984, 1961, 2015, 1989], [2034, 1961, 2096, 1995], [452, 2006, 517, 2040], [537, 2015, 621, 2034], [636, 2006, 775, 2043], [794, 2006, 825, 2034], [844, 2006, 917, 2040], [936, 2006, 1006, 2034], [1023, 2006, 1185, 2043], [1202, 2006, 1315, 2035], [1332, 2006, 1479, 2035], [1496, 2006, 1704, 2034], [1722, 2006, 1769, 2034], [1786, 2006, 1885, 2034], [1900, 2006, 2096, 2043], [451, 2052, 590, 2089], [605, 2061, 666, 2080], [683, 2052, 796, 2080], [812, 2056, 863, 2080], [878, 2061, 918, 2080], [934, 2061, 950, 2080], [965, 2061, 1036, 2089], [1051, 2052, 1132, 2089], [1148, 2052, 1323, 2089], [1338, 2052, 1460, 2086], [1478, 2052, 1663, 2089], [1682, 2052, 1765, 2080], [1780, 2052, 1929, 2080], [1944, 2052, 2049, 2081], [2066, 2052, 2102, 2080], [452, 2102, 547, 2135], [566, 2098, 720, 2127], [753, 2098, 967, 2135], [989, 2098, 1050, 2132], [1070, 2098, 1165, 2126], [1183, 2098, 1243, 2126], [1262, 2107, 1278, 2126], [1294, 2098, 1437, 2132], [1457, 2098, 1612, 2135], [1630, 2107, 1669, 2126], [1687, 2098, 1852, 2127], [1869, 2098, 1960, 2127], [1977, 2098, 2097, 2132], [450, 2143, 597, 2180], [618, 2143, 763, 2180], [781, 2147, 811, 2171], [829, 2143, 879, 2171], [897, 2143, 1055, 2177], [1077, 2143, 1181, 2171], [1199, 2143, 1283, 2180], [1301, 2143, 1325, 2171], [1346, 2152, 1362, 2171], [1381, 2143, 1464, 2171], [1482, 2143, 1517, 2171], [1533, 2143, 1652, 2171], [1687, 2143, 1758, 2171], [1777, 2143, 1872, 2180], [1890, 2143, 2020, 2171], [2038, 2143, 2099, 2171], [451, 2189, 500, 2217], [513, 2189, 606, 2217], [621, 2189, 879, 2226], [893, 2189, 1021, 2217], [1036, 2189, 1076, 2217], [1090, 2193, 1142, 2217], [1155, 2193, 1276, 2226], [1290, 2189, 1339, 2217], [1353, 2189, 1469, 2217], [1483, 2189, 1560, 2217], [1583, 2189, 1646, 2217], [1660, 2189, 1752, 2217], [1765, 2189, 2008, 2226], [2024, 2189, 2098, 2217], [451, 2235, 541, 2263], [553, 2244, 593, 2263], [605, 2235, 655, 2263], [667, 2235, 818, 2264], [834, 2235, 956, 2269], [970, 2235, 1075, 2263], [1087, 2239, 1138, 2263], [1151, 2239, 1181, 2263], [1192, 2235, 1231, 2263], [1244, 2232, 1316, 2265], [1330, 2235, 1389, 2263], [1404, 2239, 1539, 2263], [1551, 2235, 1621, 2263], [1633, 2235, 1842, 2263], [1855, 2235, 2099, 2263], [451, 2280, 716, 2317], [727, 2280, 962, 2317], [977, 2280, 1036, 2314], [1050, 2280, 1111, 2314], [451, 2351, 514, 2380], [531, 2351, 677, 2388], [695, 2355, 803, 2379], [820, 2351, 967, 2380], [984, 2355, 1119, 2388], [1138, 2360, 1177, 2379], [1195, 2351, 1442, 2388], [1459, 2351, 1552, 2379], [1569, 2351, 1681, 2388], [1698, 2351, 1775, 2385], [1795, 2351, 1895, 2379], [1912, 2351, 1937, 2379], [1955, 2351, 2099, 2388], [451, 2396, 612, 2433], [629, 2396, 659, 2424], [677, 2405, 713, 2424], [730, 2405, 840, 2433], [856, 2396, 1074, 2424], [1090, 2396, 1270, 2424], [1285, 2396, 1325, 2433], [1343, 2396, 1462, 2433], [1479, 2396, 1526, 2424], [1543, 2405, 1559, 2424], [1575, 2396, 1780, 2433], [1782, 2396, 1880, 2424], [1898, 2396, 2054, 2433], [2072, 2400, 2099, 2424], [451, 2442, 587, 2479], [603, 2442, 703, 2479], [719, 2442, 837, 2477], [864, 2443, 917, 2470], [931, 2442, 1006, 2470], [1023, 2451, 1039, 2470], [1053, 2442, 1180, 2479], [1194, 2442, 1317, 2470], [1333, 2442, 1368, 2470], [1384, 2442, 1436, 2476], [1454, 2442, 1554, 2470], [1569, 2442, 1744, 2470], [1760, 2442, 1810, 2470], [1825, 2451, 1935, 2479], [1950, 2442, 2044, 2470], [2059, 2451, 2099, 2470], [451, 2492, 614, 2525], [625, 2488, 812, 2525], [815, 2488, 886, 2516], [895, 2488, 1036, 2525], [1048, 2488, 1105, 2516], [1115, 2488, 1151, 2516], [1163, 2488, 1306, 2525], [1319, 2497, 1349, 2516], [1361, 2488, 1431, 2516], [1442, 2497, 1473, 2516], [1485, 2488, 1659, 2516], [1663, 2488, 1722, 2516], [1730, 2488, 1779, 2516], [1789, 2488, 1995, 2525], [1996, 2488, 2096, 2516], [451, 2533, 602, 2570], [620, 2533, 681, 2567], [696, 2533, 847, 2570], [861, 2542, 897, 2561], [910, 2533, 1010, 2570], [1022, 2533, 1111, 2570], [1124, 2533, 1276, 2570], [1290, 2533, 1421, 2567], [1435, 2533, 1535, 2561], [1547, 2533, 1572, 2561], [1585, 2533, 1778, 2561], [1791, 2533, 1827, 2561], [1836, 2533, 1913, 2570], [1926, 2533, 2097, 2567], [450, 2579, 501, 2607], [513, 2579, 586, 2607], [600, 2583, 651, 2607], [663, 2579, 851, 2616], [862, 2579, 1004, 2616], [451, 2656, 474, 2690], [526, 2656, 776, 2691], [790, 2656, 1046, 2691], [1061, 2656, 1122, 2691], [1135, 2656, 1247, 2691], [1261, 2656, 1499, 2700], [451, 2737, 548, 2765], [562, 2746, 617, 2765], [631, 2737, 777, 2774], [790, 2737, 829, 2765], [842, 2737, 1048, 2774], [1062, 2737, 1125, 2765], [1140, 2737, 1246, 2774], [1260, 2737, 1318, 2765], [1332, 2737, 1478, 2774], [1491, 2741, 1698, 2774], [1721, 2737, 1784, 2765], [1798, 2737, 1904, 2774], [1917, 2741, 1989, 2774], [2005, 2737, 2036, 2765], [2050, 2737, 2099, 2765], [451, 2783, 530, 2811], [544, 2783, 580, 2811], [591, 2783, 757, 2812], [771, 2783, 866, 2811], [882, 2792, 1074, 2820], [1091, 2783, 1198, 2811], [1214, 2783, 1408, 2811], [1424, 2783, 1513, 2811], [1529, 2792, 1633, 2811], [1650, 2783, 1707, 2811], [1721, 2783, 1836, 2820], [1852, 2783, 1990, 2820], [2005, 2783, 2035, 2811], [2050, 2783, 2099, 2811], [451, 2828, 549, 2857], [575, 2828, 638, 2856], [653, 2828, 799, 2865], [813, 2832, 885, 2865], [903, 2828, 933, 2856], [948, 2828, 998, 2856], [1012, 2828, 1092, 2856], [1106, 2828, 1142, 2856], [1154, 2828, 1270, 2856], [1286, 2837, 1386, 2856], [1402, 2828, 1452, 2856], [1467, 2828, 1586, 2862], [1604, 2837, 1734, 2865], [1750, 2828, 1800, 2856], [1815, 2837, 1975, 2857], [1977, 2828, 2038, 2856], [2050, 2828, 2099, 2856], [451, 2874, 592, 2903], [608, 2874, 670, 2909], [685, 2874, 816, 2909], [833, 2874, 891, 2902], [906, 2874, 956, 2902], [971, 2874, 1094, 2911], [1122, 2875, 1175, 2902], [1190, 2874, 1294, 2903], [1309, 2883, 1363, 2902], [1378, 2874, 1469, 2903], [1483, 2874, 1672, 2911], [1688, 2874, 1882, 2902], [1898, 2874, 2097, 2911], [451, 2920, 586, 2957], [598, 2920, 619, 2948], [631, 2920, 694, 2948], [705, 2924, 765, 2948], [778, 2924, 911, 2954], [925, 2929, 956, 2948], [970, 2920, 1074, 2948], [1086, 2920, 1116, 2948], [1128, 2920, 1190, 2957], [1208, 2920, 1231, 2948], [1248, 2920, 1329, 2948], [1342, 2924, 1450, 2948], [1461, 2920, 1486, 2948], [1499, 2920, 1714, 2957], [1724, 2920, 1814, 2957], [1826, 2929, 1842, 2948], [1854, 2920, 1930, 2957], [1942, 2920, 2097, 2954], [452, 2965, 582, 2993], [597, 2974, 696, 2993], [711, 2965, 747, 2993], [757, 2965, 857, 2993], [872, 2974, 920, 2993], [933, 2965, 1095, 2993], [1107, 2965, 1148, 3002], [1161, 2965, 1220, 2993], [1233, 2965, 1343, 2993], [1364, 2966, 1416, 2993], [1430, 2965, 1569, 2993], [1582, 2969, 1642, 2993], [1655, 2965, 1757, 2993], [1771, 2965, 1918, 2993], [1939, 2965, 2099, 3002], [452, 3011, 509, 3039], [521, 3011, 648, 3048], [661, 3020, 677, 3039], [689, 3011, 868, 3039], [882, 3011, 975, 3039], [988, 3011, 1075, 3040], [1090, 3011, 1131, 3045], [1146, 3020, 1185, 3039], [1199, 3011, 1320, 3039], [1333, 3011, 1575, 3045], [1589, 3011, 1720, 3039], [1733, 3020, 1832, 3039], [1847, 3020, 1877, 3039], [1891, 3011, 2028, 3039], [823, 358, 851, 375], [1163, 353, 1312, 399], [1330, 356, 1479, 390], [1498, 354, 1691, 390], [990, 423, 1064, 442], [0, 0, 2550, 3300], [1104, 423, 1178, 442], [0, 0, 2550, 3300], [1217, 423, 1291, 442], [0, 0, 2550, 3300], [1331, 423, 1405, 442], [0, 0, 2550, 3300], [1444, 423, 1519, 442], [0, 0, 2550, 3300], [1568, 422, 1621, 442], [1681, 422, 1735, 442], [0, 0, 2550, 3300], [1773, 422, 1871, 442], [991, 453, 1064, 471], [0, 0, 2550, 3300], [1098, 453, 1184, 471], [0, 0, 2550, 3300], [1212, 454, 1296, 471], [0, 0, 2550, 3300], [1325, 454, 1397, 471], [1400, 454, 1410, 471], [1439, 454, 1523, 471], [1569, 453, 1620, 471], [1683, 453, 1733, 471], [989, 481, 1044, 499], [1053, 482, 1063, 499], [0, 0, 2550, 3300], [1103, 481, 1158, 499], [1167, 482, 1177, 499], [0, 0, 2550, 3300], [1216, 481, 1271, 499], [1282, 482, 1291, 499], [0, 0, 2550, 3300], [1330, 481, 1385, 499], [1395, 482, 1404, 499], [0, 0, 2550, 3300], [1444, 481, 1499, 499], [1509, 482, 1518, 499], [0, 0, 2550, 3300], [1556, 481, 1635, 504], [0, 0, 2550, 3300], [1669, 481, 1749, 504], [999, 515, 1055, 528], [1112, 515, 1168, 528], [1439, 510, 1481, 533], [1489, 511, 1523, 528], [779, 545, 853, 571], [860, 545, 931, 565], [985, 538, 1026, 561], [1035, 539, 1069, 556], [0, 0, 2550, 3300], [1098, 538, 1140, 561], [1148, 539, 1183, 556], [1133, 605, 1339, 651], [1357, 608, 1507, 642], [1525, 606, 1718, 642], [921, 666, 962, 731], [990, 683, 1064, 702], [0, 0, 2550, 3300], [1104, 683, 1178, 702], [0, 0, 2550, 3300], [1217, 683, 1291, 702], [0, 0, 2550, 3300], [1331, 683, 1405, 702], [0, 0, 2550, 3300], [1444, 683, 1519, 702], [0, 0, 2550, 3300], [1568, 682, 1621, 702], [1681, 682, 1735, 702], [0, 0, 2550, 3300], [1773, 682, 1871, 702], [991, 713, 1064, 731], [0, 0, 2550, 3300], [1098, 713, 1184, 731], [0, 0, 2550, 3300], [1212, 714, 1296, 731], [0, 0, 2550, 3300], [1325, 714, 1397, 731], [1400, 714, 1410, 731], [1439, 714, 1523, 731], [1569, 713, 1620, 731], [1683, 713, 1733, 731], [989, 741, 1044, 759], [1053, 742, 1063, 759], [0, 0, 2550, 3300], [1103, 741, 1158, 759], [1167, 742, 1177, 759], [0, 0, 2550, 3300], [1216, 741, 1271, 759], [1282, 742, 1291, 759], [0, 0, 2550, 3300], [1330, 741, 1385, 759], [1395, 742, 1404, 759], [0, 0, 2550, 3300], [1444, 741, 1499, 759], [1509, 742, 1518, 759], [0, 0, 2550, 3300], [1556, 741, 1635, 764], [0, 0, 2550, 3300], [1669, 741, 1749, 764], [841, 789, 845, 793], [999, 775, 1055, 788], [0, 0, 2550, 3300], [1098, 770, 1140, 793], [1148, 771, 1183, 788], [1439, 770, 1481, 793], [1489, 771, 1523, 788], [785, 789, 926, 809], [985, 798, 1026, 821], [1035, 799, 1069, 816], [784, 820, 866, 845], [874, 820, 926, 840], [769, 870, 876, 907], [891, 870, 915, 898], [933, 870, 1141, 899], [1153, 869, 1367, 899], [1379, 869, 1429, 899], [1441, 869, 1534, 899], [1546, 869, 1780, 899], [451, 939, 574, 977], [586, 942, 706, 969], [719, 939, 871, 969], [884, 944, 1019, 977], [1032, 949, 1072, 968], [1085, 940, 1250, 969], [1263, 940, 1353, 969], [1366, 940, 1485, 974], [1500, 940, 1673, 977], [1684, 940, 1870, 977], [1883, 940, 1982, 968], [1994, 949, 2098, 977], [451, 986, 546, 1014], [562, 986, 642, 1014], [659, 986, 719, 1014], [735, 986, 859, 1023], [889, 986, 952, 1014], [970, 986, 1054, 1014], [1072, 995, 1256, 1023], [1272, 986, 1291, 1014], [1294, 986, 1413, 1023], [1427, 986, 1452, 1014], [1471, 995, 1487, 1014], [1502, 986, 1603, 1014], [1619, 986, 1695, 1020], [1716, 986, 1799, 1014], [1816, 995, 1901, 1014], [1918, 986, 2032, 1014], [2051, 995, 2099, 1014], [452, 1032, 585, 1069], [598, 1032, 766, 1060], [779, 1032, 851, 1060], [863, 1032, 1022, 1069], [1033, 1032, 1157, 1069], [1176, 1033, 1209, 1060], [1221, 1032, 1290, 1066], [1305, 1041, 1336, 1060], [1350, 1032, 1413, 1060], [1424, 1032, 1463, 1060], [1476, 1032, 1560, 1060], [1562, 1032, 1624, 1060], [1638, 1032, 1714, 1061], [1729, 1032, 1757, 1066], [1772, 1032, 1871, 1060], [1884, 1032, 2099, 1060], [451, 1077, 530, 1105], [546, 1077, 606, 1105], [621, 1077, 731, 1105], [749, 1077, 811, 1112], [827, 1077, 933, 1114], [947, 1077, 1135, 1114], [1152, 1077, 1273, 1112], [1289, 1077, 1314, 1105], [1331, 1077, 1418, 1114], [1434, 1077, 1627, 1114], [1642, 1086, 1682, 1105], [1697, 1077, 1733, 1105], [1750, 1086, 1827, 1105], [1855, 1077, 1945, 1106], [1961, 1086, 1977, 1105], [1993, 1077, 2099, 1114], [451, 1123, 586, 1152], [587, 1123, 635, 1151], [651, 1123, 824, 1160], [839, 1132, 876, 1151], [889, 1123, 989, 1160], [1003, 1123, 1218, 1151], [1233, 1123, 1435, 1157], [1451, 1132, 1498, 1151], [1511, 1132, 1567, 1151], [1580, 1123, 1664, 1151], [1677, 1132, 1759, 1160], [1773, 1123, 1822, 1151], [1835, 1127, 1936, 1151], [1950, 1123, 2097, 1152], [451, 1169, 481, 1197], [492, 1169, 670, 1206], [680, 1169, 780, 1206], [790, 1169, 978, 1206], [989, 1169, 1112, 1197], [1115, 1169, 1215, 1203], [1229, 1169, 1286, 1197], [1296, 1169, 1438, 1206], [1449, 1169, 1499, 1197], [1509, 1169, 1644, 1197], [1654, 1178, 1694, 1197], [0, 0, 2550, 3300], [1706, 1169, 1813, 1206], [1824, 1169, 1905, 1206], [1907, 1169, 2098, 1197], [451, 1214, 513, 1242], [526, 1214, 648, 1248], [664, 1214, 737, 1242], [751, 1223, 781, 1242], [795, 1214, 845, 1242], [857, 1215, 1019, 1251], [1032, 1214, 1189, 1251], [1202, 1214, 1323, 1242], [1342, 1214, 1405, 1242], [1418, 1214, 1523, 1242], [1538, 1223, 1586, 1242], [1598, 1214, 1756, 1251], [1769, 1214, 1799, 1242], [1813, 1214, 1889, 1243], [1905, 1214, 1932, 1243], [1951, 1215, 2038, 1248], [2052, 1223, 2099, 1242], [451, 1260, 587, 1288], [599, 1260, 648, 1288], [660, 1260, 806, 1297], [819, 1264, 928, 1288], [939, 1260, 1095, 1294], [1108, 1260, 1208, 1288], [1220, 1260, 1348, 1297], [1361, 1260, 1477, 1288], [1490, 1260, 1548, 1288], [1561, 1260, 1763, 1297], [1775, 1260, 1925, 1297], [1940, 1269, 2089, 1297], [451, 1337, 473, 1372], [526, 1337, 681, 1381], [695, 1337, 782, 1372], [797, 1337, 999, 1372], [451, 1419, 483, 1446], [497, 1418, 553, 1446], [569, 1418, 693, 1452], [708, 1427, 755, 1446], [768, 1418, 905, 1446], [919, 1427, 935, 1446], [948, 1418, 1094, 1447], [1107, 1418, 1218, 1452], [1233, 1418, 1333, 1446], [1346, 1418, 1440, 1446], [1455, 1418, 1504, 1446], [1517, 1418, 1663, 1455], [1675, 1418, 1864, 1455], [1878, 1422, 1986, 1446], [1999, 1418, 2035, 1446], [2045, 1427, 2100, 1446], [452, 1463, 645, 1491], [659, 1463, 749, 1498], [765, 1463, 806, 1498], [826, 1463, 938, 1492], [951, 1463, 1000, 1491], [1013, 1463, 1160, 1492], [1173, 1463, 1300, 1497], [1314, 1463, 1463, 1492], [1476, 1463, 1507, 1491], [1521, 1463, 1598, 1492], [1618, 1463, 1672, 1497], [1688, 1463, 1737, 1491], [1750, 1463, 1834, 1500], [1847, 1467, 1877, 1491], [1891, 1472, 1945, 1491], [1958, 1463, 2048, 1491], [2050, 1463, 2097, 1491], [451, 1509, 569, 1537], [579, 1509, 598, 1537], [600, 1509, 767, 1546], [778, 1509, 890, 1546], [901, 1509, 971, 1537], [983, 1509, 1188, 1546], [1190, 1509, 1298, 1537], [1309, 1509, 1447, 1537], [1459, 1509, 1572, 1538], [1583, 1509, 1776, 1538], [1787, 1509, 1906, 1537], [1924, 1509, 2004, 1538], [2015, 1509, 2099, 1546], [451, 1555, 605, 1592], [620, 1555, 772, 1583], [789, 1555, 838, 1583], [853, 1555, 969, 1583], [983, 1555, 1121, 1583], [1136, 1555, 1227, 1584], [1242, 1555, 1362, 1589], [1380, 1555, 1480, 1583], [1495, 1555, 1598, 1583], [1614, 1555, 1664, 1583], [1678, 1555, 1866, 1592], [1882, 1555, 1984, 1589], [2003, 1564, 2033, 1583], [2050, 1555, 2099, 1583], [451, 1600, 585, 1628], [598, 1600, 671, 1628], [687, 1604, 738, 1628], [752, 1600, 829, 1628], [843, 1604, 873, 1628], [887, 1600, 1024, 1628], [1038, 1600, 1154, 1628], [1168, 1600, 1332, 1637], [1355, 1601, 1408, 1628], [1422, 1600, 1562, 1628], [1576, 1600, 1689, 1629], [1703, 1600, 1862, 1629], [1878, 1600, 1913, 1628], [1925, 1600, 1974, 1628], [1988, 1600, 2099, 1637], [451, 1646, 630, 1674], [642, 1646, 734, 1683], [748, 1646, 848, 1674], [860, 1655, 907, 1674], [919, 1646, 1056, 1674], [1066, 1646, 1171, 1674], [608, 1977, 646, 2009], [931, 1976, 971, 2009], [1256, 1977, 1294, 2009], [1579, 1977, 1619, 2009], [1904, 1977, 1942, 2009], [451, 2035, 557, 2072], [573, 2035, 601, 2063], [626, 2034, 756, 2072], [771, 2034, 850, 2064], [877, 2035, 988, 2070], [1014, 2044, 1030, 2063], [1045, 2035, 1110, 2072], [1125, 2035, 1160, 2063], [1173, 2035, 1366, 2064], [1382, 2035, 1472, 2064], [1488, 2035, 1598, 2063], [1615, 2035, 1687, 2063], [1703, 2035, 1753, 2063], [1769, 2044, 1836, 2063], [1852, 2035, 1965, 2063], [1982, 2044, 1998, 2063], [2014, 2044, 2098, 2064], [451, 2081, 502, 2118], [515, 2081, 595, 2109], [608, 2081, 743, 2109], [757, 2081, 829, 2109], [844, 2090, 860, 2109], [873, 2090, 949, 2118], [962, 2081, 1121, 2118], [1145, 2081, 1197, 2116], [1219, 2090, 1235, 2109], [1248, 2081, 1387, 2118], [1401, 2081, 1437, 2109], [1448, 2081, 1541, 2109], [1554, 2081, 1666, 2118], [1679, 2081, 1750, 2109], [1764, 2081, 1795, 2109], [1809, 2081, 1858, 2109], [1872, 2081, 2006, 2109], [2021, 2090, 2097, 2115], [452, 2126, 506, 2161], [524, 2126, 691, 2154], [704, 2135, 875, 2163], [877, 2125, 937, 2154], [953, 2126, 989, 2154], [998, 2126, 1048, 2154], [1060, 2126, 1278, 2163], [1290, 2130, 1393, 2155], [1404, 2126, 1476, 2154], [1490, 2126, 1608, 2163], [1620, 2126, 1761, 2163], [1774, 2126, 1972, 2163], [1986, 2130, 2016, 2154], [2028, 2135, 2098, 2163], [451, 2172, 521, 2201], [535, 2172, 647, 2206], [663, 2172, 756, 2200], [769, 2172, 910, 2209], [924, 2176, 955, 2200], [969, 2172, 1106, 2209], [1119, 2172, 1244, 2207], [1268, 2172, 1321, 2207], [1342, 2172, 1464, 2201], [1478, 2176, 1661, 2209], [1676, 2171, 1722, 2200], [1746, 2173, 1825, 2200], [1838, 2172, 1907, 2200], [1922, 2172, 1967, 2207], [1983, 2172, 2040, 2200], [2055, 2172, 2098, 2207], [450, 2218, 599, 2255], [611, 2218, 660, 2246], [672, 2218, 796, 2255], [808, 2218, 887, 2246], [901, 2218, 958, 2246], [969, 2218, 1038, 2246], [1040, 2218, 1124, 2246], [1136, 2218, 1220, 2255], [1232, 2222, 1262, 2246], [1275, 2227, 1291, 2246], [1303, 2218, 1438, 2247], [1440, 2218, 1597, 2246], [1610, 2218, 1747, 2255], [1759, 2218, 1845, 2246], [1859, 2218, 1950, 2253], [1966, 2218, 2036, 2253], [451, 2336, 499, 2366], [545, 2336, 697, 2366], [709, 2336, 802, 2374], [814, 2336, 1066, 2374], [451, 2406, 580, 2444], [595, 2406, 666, 2436], [681, 2406, 836, 2444], [858, 2407, 886, 2435], [901, 2407, 994, 2435], [1008, 2407, 1119, 2444], [1134, 2407, 1204, 2435], [1219, 2416, 1275, 2435], [1289, 2407, 1327, 2435], [1342, 2416, 1413, 2435], [1429, 2416, 1459, 2435], [1476, 2416, 1492, 2435], [1507, 2411, 1551, 2435], [1565, 2407, 1601, 2435], [1613, 2407, 1830, 2444], [1844, 2411, 1932, 2436], [1933, 2407, 2047, 2435], [2063, 2407, 2096, 2442], [450, 2453, 587, 2481], [599, 2453, 648, 2481], [659, 2453, 737, 2490], [751, 2453, 786, 2481], [795, 2453, 988, 2482], [1000, 2453, 1109, 2481], [1123, 2455, 1136, 2481], [1149, 2453, 1206, 2481], [1218, 2455, 1231, 2481], [1242, 2457, 1270, 2484], [1285, 2453, 1308, 2481], [1326, 2454, 1372, 2490], [1384, 2450, 1469, 2491], [1480, 2450, 1513, 2491], [1528, 2462, 1575, 2481], [1587, 2453, 1696, 2481], [1707, 2453, 1757, 2481], [1768, 2453, 1986, 2490], [1997, 2457, 2100, 2482], [451, 2503, 479, 2527], [495, 2499, 544, 2527], [558, 2499, 643, 2536], [662, 2496, 750, 2537], [769, 2499, 799, 2527], [815, 2499, 910, 2527], [926, 2501, 948, 2533], [966, 2499, 1066, 2527], [1082, 2508, 1171, 2528], [1174, 2499, 1252, 2527], [1267, 2499, 1351, 2536], [1367, 2503, 1398, 2527], [1413, 2499, 1463, 2527], [1478, 2499, 1714, 2536], [1729, 2499, 1813, 2536], [1829, 2499, 1860, 2527], [1875, 2499, 1925, 2527], [1940, 2499, 2099, 2536], [450, 2544, 546, 2572], [561, 2546, 574, 2572], [589, 2548, 617, 2575], [635, 2544, 659, 2572], [687, 2544, 751, 2572], [765, 2544, 933, 2572], [949, 2544, 1007, 2572], [1022, 2544, 1145, 2573], [1160, 2548, 1358, 2581], [1375, 2553, 1394, 2572], [1396, 2544, 1473, 2572], [1488, 2548, 1591, 2573], [1605, 2544, 1686, 2578], [1705, 2543, 1742, 2583], [1762, 2544, 1819, 2572], [1836, 2539, 1884, 2583], [1902, 2553, 1958, 2572], [1973, 2544, 2011, 2572], [2028, 2553, 2099, 2572], [451, 2599, 482, 2618], [497, 2590, 597, 2627], [611, 2590, 753, 2618], [769, 2590, 867, 2625], [869, 2590, 932, 2618], [946, 2590, 1008, 2627], [1024, 2590, 1066, 2625], [1082, 2590, 1152, 2618], [1166, 2590, 1263, 2618], [1277, 2594, 1307, 2618], [1320, 2590, 1509, 2627], [1522, 2590, 1611, 2627], [1626, 2599, 1642, 2618], [1655, 2590, 1880, 2619], [1893, 2590, 2035, 2618], [2058, 2591, 2099, 2618], [449, 2640, 601, 2673], [613, 2636, 662, 2664], [674, 2636, 790, 2664], [803, 2645, 903, 2664], [918, 2645, 934, 2664], [946, 2645, 1077, 2673], [1079, 2636, 1144, 2664], [1153, 2636, 1273, 2670], [1287, 2645, 1315, 2664], [1317, 2636, 1430, 2664], [1442, 2636, 1491, 2664], [1503, 2636, 1574, 2664], [1586, 2636, 1728, 2664], [1743, 2631, 1807, 2674], [1822, 2636, 1858, 2664], [1868, 2636, 1892, 2664], [1906, 2636, 2099, 2665], [450, 2681, 560, 2709], [577, 2685, 607, 2709], [622, 2681, 702, 2709], [717, 2690, 733, 2709], [748, 2681, 820, 2709], [835, 2681, 871, 2709], [884, 2681, 929, 2709], [946, 2681, 1029, 2718], [1044, 2681, 1195, 2709], [1222, 2682, 1310, 2709], [1325, 2681, 1472, 2718], [1490, 2681, 1529, 2709], [1544, 2691, 1572, 2709], [1589, 2681, 1647, 2709], [1663, 2680, 1684, 2709], [1698, 2681, 1737, 2709], [1752, 2681, 1801, 2709], [1816, 2681, 1908, 2709], [1924, 2681, 1982, 2709], [1996, 2681, 2099, 2718], [450, 2733, 486, 2761], [497, 2742, 513, 2761], [526, 2733, 626, 2767], [643, 2742, 659, 2761], [671, 2733, 818, 2762], [831, 2733, 915, 2770], [928, 2733, 1050, 2762], [1063, 2733, 1097, 2767], [1117, 2739, 1138, 2763], [1156, 2723, 1254, 2761], [1260, 2723, 1319, 2743], [1335, 2733, 1382, 2761], [1395, 2742, 1432, 2761], [1446, 2733, 1586, 2770], [1599, 2733, 1695, 2761], [1707, 2743, 1727, 2761], [1741, 2733, 1766, 2761], [1780, 2733, 1850, 2761], [1863, 2733, 2053, 2761], [2067, 2742, 2097, 2761], [451, 2779, 581, 2807], [731, 2836, 816, 2877], [828, 2849, 856, 2875], [869, 2838, 909, 2867], [923, 2856, 949, 2857], [965, 2836, 994, 2877], [1012, 2852, 1040, 2861], [1056, 2836, 1135, 2880], [1141, 2836, 1230, 2877], [1242, 2836, 1286, 2877], [2053, 2839, 2098, 2874], [731, 2898, 856, 2939], [869, 2898, 923, 2939], [940, 2914, 968, 2923], [984, 2896, 1045, 2945], [1050, 2898, 1215, 2942], [1268, 2898, 1660, 2939], [1676, 2914, 1704, 2923], [1722, 2898, 1816, 2939], [451, 2968, 507, 2995], [522, 2976, 558, 2995], [574, 2967, 715, 3004], [729, 2967, 813, 3004], [831, 2964, 931, 3005], [949, 2967, 998, 2995], [1013, 2967, 1155, 2995], [1172, 2964, 1257, 3005], [1269, 2964, 1378, 3005], [1397, 2980, 1425, 2989], [1450, 2964, 1551, 3005], [1570, 2967, 1686, 2995], [1701, 2967, 1751, 2995], [1765, 2967, 1881, 2995], [1897, 2971, 1925, 2995], [1940, 2967, 2000, 2995], [2014, 2967, 2099, 3004], [451, 3022, 522, 3042], [534, 3022, 550, 3041], [563, 3022, 713, 3050], [725, 3013, 760, 3041], [771, 3013, 795, 3041], [808, 3013, 904, 3041], [906, 3013, 977, 3048], [990, 3013, 1155, 3041], [1167, 3013, 1197, 3041], [1210, 3013, 1271, 3050], [1287, 3013, 1395, 3048], [451, 353, 637, 390], [654, 353, 809, 391], [840, 354, 889, 382], [908, 354, 1079, 383], [1096, 354, 1212, 382], [1228, 354, 1471, 391], [1492, 354, 1624, 391], [1640, 354, 1681, 391], [1698, 354, 1747, 382], [1764, 354, 2030, 391], [2047, 354, 2098, 382], [452, 400, 590, 437], [609, 400, 682, 434], [697, 400, 831, 437], [847, 400, 896, 428], [910, 400, 1022, 437], [1036, 400, 1113, 434], [1130, 400, 1266, 437], [1281, 404, 1308, 428], [1322, 400, 1372, 428], [1387, 409, 1469, 428], [1483, 400, 1630, 428], [1647, 409, 1746, 428], [1763, 400, 1876, 429], [1890, 400, 2010, 434], [2027, 400, 2099, 428], [451, 445, 500, 473], [512, 445, 589, 479], [605, 445, 740, 482], [754, 445, 844, 482], [857, 445, 906, 473], [918, 445, 1034, 473], [1047, 445, 1237, 482], [1257, 446, 1289, 473], [1302, 445, 1359, 473], [1373, 454, 1452, 479], [1466, 445, 1516, 473], [1528, 445, 1612, 482], [1624, 445, 1747, 474], [1759, 445, 1805, 480], [1820, 445, 2055, 482], [2068, 449, 2099, 473], [452, 500, 468, 519], [479, 491, 575, 519], [586, 501, 616, 525], [630, 491, 712, 519], [725, 491, 775, 519], [786, 491, 945, 528], [957, 491, 1045, 519], [741, 563, 867, 604], [879, 565, 919, 594], [933, 583, 959, 584], [976, 563, 1004, 604], [1022, 579, 1050, 588], [1066, 564, 1146, 608], [1151, 586, 1188, 605], [1196, 563, 1276, 605], [2053, 566, 2098, 601], [741, 626, 867, 667], [879, 626, 933, 667], [950, 642, 978, 651], [994, 624, 1074, 673], [1079, 626, 1205, 670], [1258, 639, 1322, 657], [1341, 626, 1466, 667], [1483, 642, 1511, 651], [1529, 626, 1619, 667], [1631, 628, 1693, 657], [1712, 626, 1806, 667], [451, 710, 550, 738], [562, 718, 601, 748], [617, 710, 641, 738], [655, 710, 704, 738], [717, 709, 783, 738], [795, 710, 879, 747], [892, 710, 982, 747], [994, 710, 1044, 738], [1056, 710, 1219, 747], [1233, 710, 1333, 738], [1346, 714, 1429, 738], [1444, 714, 1471, 738], [1484, 710, 1533, 738], [1545, 710, 1677, 738], [1692, 707, 1780, 748], [1796, 710, 1826, 738], [1839, 710, 1888, 738], [1900, 710, 1995, 738], [2007, 720, 2027, 738], [2042, 710, 2099, 738], [451, 756, 475, 784], [489, 756, 609, 784], [620, 756, 661, 793], [673, 756, 722, 784], [734, 756, 893, 793], [904, 765, 1059, 784], [1062, 756, 1224, 784], [830, 839, 866, 869], [885, 844, 913, 853], [930, 828, 1030, 869], [1101, 839, 1139, 869], [1157, 844, 1185, 853], [1200, 839, 1280, 869], [1294, 835, 1322, 862], [1332, 828, 1587, 869], [1611, 830, 1673, 861], [1691, 831, 1716, 859], [451, 906, 601, 943], [603, 906, 665, 934], [677, 906, 727, 934], [739, 906, 823, 943], [835, 906, 939, 935], [940, 906, 1203, 943], [1217, 906, 1271, 941], [1285, 906, 1385, 934], [1398, 906, 1447, 934], [1459, 906, 1601, 934], [1615, 903, 1701, 944], [1713, 916, 1741, 942], [1754, 903, 1782, 944], [1799, 910, 1877, 934], [1889, 906, 1938, 934], [1951, 906, 2098, 943], [451, 961, 520, 980], [522, 956, 660, 981], [675, 956, 702, 980], [714, 952, 763, 980], [775, 952, 922, 980], [938, 949, 1039, 990], [1052, 952, 1102, 980], [1114, 952, 1197, 989], [1209, 952, 1332, 981], [1344, 952, 1389, 987], [1403, 956, 1496, 980], [1509, 952, 1559, 980], [1571, 956, 1687, 981], [1701, 952, 1816, 989], [1818, 952, 1878, 980], [1889, 952, 1939, 980], [1951, 952, 2097, 980], [451, 1005, 489, 1036], [505, 997, 595, 1034], [607, 997, 656, 1025], [668, 997, 825, 1034], [839, 997, 868, 1032], [871, 997, 1061, 1025], [1073, 997, 1103, 1025], [1115, 997, 1177, 1034], [1193, 997, 1324, 1034], [630, 1202, 636, 1211], [897, 1176, 924, 1206], [474, 1209, 524, 1227], [551, 1202, 684, 1239], [898, 1209, 948, 1227], [474, 1271, 537, 1297], [551, 1264, 684, 1301], [855, 1248, 918, 1296], [1054, 1288, 1089, 1359], [1107, 1267, 1182, 1290], [1695, 1267, 1710, 1289], [474, 1319, 567, 1369], [574, 1339, 671, 1374], [810, 1319, 905, 1369], [1017, 1360, 1049, 1365], [1068, 1345, 1079, 1362], [1094, 1339, 1143, 1364], [452, 1404, 514, 1428], [519, 1404, 592, 1423], [595, 1404, 722, 1423], [1032, 1409, 1104, 1436], [1564, 1428, 1565, 1434], [1807, 1404, 1868, 1457], [1874, 1404, 1962, 1423], [1970, 1404, 2076, 1423], [454, 1431, 524, 1463], [537, 1439, 593, 1457], [605, 1435, 628, 1453], [635, 1434, 696, 1458], [1808, 1432, 1913, 1463], [1926, 1438, 1949, 1457], [1960, 1435, 1983, 1453], [1990, 1434, 2051, 1458], [512, 1473, 539, 1499], [559, 1477, 579, 1478], [598, 1471, 671, 1490], [979, 1432, 1012, 1500], [1519, 1489, 1532, 1492], [1865, 1473, 1892, 1499], [1912, 1477, 1934, 1478], [1954, 1468, 2027, 1494], [451, 1529, 557, 1566], [571, 1529, 598, 1558], [618, 1528, 770, 1558], [784, 1528, 876, 1566], [889, 1528, 1069, 1558], [1082, 1528, 1167, 1558], [1180, 1529, 1234, 1558], [1247, 1528, 1460, 1558], [1472, 1498, 1591, 1566], [1604, 1528, 1682, 1558], [1699, 1529, 1775, 1566], [1793, 1529, 1905, 1566], [1917, 1529, 1988, 1557], [2002, 1529, 2098, 1557], [451, 1575, 502, 1612], [514, 1575, 558, 1610], [572, 1575, 701, 1612], [714, 1575, 763, 1603], [774, 1575, 979, 1612], [981, 1579, 1118, 1604], [1131, 1575, 1152, 1604], [1164, 1579, 1192, 1603], [1202, 1575, 1252, 1603], [1263, 1584, 1346, 1603], [1357, 1575, 1489, 1603], [1500, 1575, 1531, 1603], [1542, 1575, 1679, 1612], [1689, 1575, 1808, 1603], [1823, 1575, 1925, 1612], [1941, 1575, 2099, 1612], [451, 1621, 587, 1658], [603, 1621, 647, 1656], [664, 1621, 794, 1658], [810, 1621, 859, 1649], [873, 1625, 989, 1650], [1006, 1621, 1096, 1658], [1110, 1621, 1160, 1649], [1174, 1621, 1336, 1658], [1361, 1621, 1424, 1649], [1438, 1621, 1548, 1649], [1565, 1621, 1622, 1649], [1637, 1621, 1686, 1649], [1700, 1621, 1936, 1658], [1951, 1621, 2098, 1658], [450, 1670, 532, 1694], [544, 1670, 660, 1695], [675, 1675, 723, 1694], [736, 1666, 840, 1694], [852, 1666, 924, 1694], [937, 1666, 986, 1694], [999, 1675, 1081, 1694], [1093, 1666, 1203, 1694], [450, 1764, 693, 1794], [706, 1764, 825, 1802], [839, 1764, 917, 1794], [938, 1765, 1058, 1802], [1072, 1765, 1143, 1793], [1156, 1765, 1405, 1802], [1422, 1765, 1466, 1800], [1482, 1765, 1539, 1793], [1554, 1765, 1599, 1800], [1614, 1765, 1682, 1793], [1695, 1765, 1767, 1793], [1781, 1765, 1831, 1793], [1844, 1765, 1974, 1793], [1987, 1765, 2099, 1802], [450, 1811, 528, 1845], [542, 1811, 588, 1839], [604, 1811, 653, 1839], [665, 1811, 871, 1848], [873, 1811, 967, 1839], [980, 1811, 1013, 1845], [1029, 1811, 1065, 1839], [1074, 1811, 1124, 1839], [1136, 1811, 1231, 1839], [1244, 1813, 1257, 1839], [1271, 1811, 1410, 1848], [1424, 1811, 1473, 1839], [1485, 1811, 1617, 1839], [1630, 1820, 1649, 1839], [1651, 1811, 1712, 1839], [1725, 1811, 1821, 1848], [1835, 1811, 1866, 1839], [1878, 1811, 1928, 1839], [1940, 1811, 2099, 1848], [450, 1857, 546, 1885], [562, 1859, 618, 1888], [637, 1857, 661, 1885], [690, 1858, 714, 1885], [730, 1857, 755, 1885], [773, 1857, 886, 1885], [902, 1861, 933, 1885], [949, 1857, 1089, 1885], [1106, 1866, 1142, 1885], [1158, 1857, 1315, 1885], [1331, 1861, 1362, 1885], [1379, 1866, 1395, 1885], [1410, 1857, 1633, 1885], [1649, 1857, 1761, 1894], [1777, 1857, 1854, 1891], [1873, 1857, 1973, 1885], [1989, 1866, 2045, 1885], [2060, 1857, 2099, 1885], [450, 1902, 592, 1930], [605, 1902, 646, 1939], [660, 1902, 836, 1939], [852, 1911, 888, 1930], [904, 1902, 1067, 1930], [1083, 1906, 1126, 1930], [1140, 1902, 1176, 1930], [1188, 1902, 1393, 1939], [1395, 1902, 1506, 1930], [1522, 1902, 1553, 1930], [1567, 1902, 1616, 1930], [1631, 1902, 1770, 1939], [1784, 1902, 1938, 1930], [1962, 1903, 2015, 1930], [2029, 1902, 2099, 1930], [450, 1952, 601, 1976], [613, 1957, 649, 1976], [660, 1948, 744, 1985], [754, 1948, 877, 1977], [887, 1948, 921, 1982], [934, 1948, 975, 1985], [986, 1948, 1122, 1985], [1134, 1945, 1200, 1986], [1212, 1948, 1341, 1976], [1352, 1948, 1437, 1976], [1448, 1948, 1586, 1976], [1597, 1948, 1707, 1976], [1719, 1958, 1739, 1976], [1752, 1948, 1809, 1976], [1820, 1952, 1876, 1979], [1884, 1945, 1950, 1986], [1963, 1948, 2020, 1976], [2032, 1945, 2098, 1986], [449, 1994, 610, 2022], [621, 1994, 707, 2022], [719, 1994, 857, 2022], [868, 1994, 978, 2022], [991, 2004, 1011, 2022], [1023, 2011, 1049, 2012], [1062, 1991, 1128, 2032], [1141, 1994, 1198, 2022], [1210, 2004, 1239, 2022], [1256, 1994, 1319, 2022], [1330, 1994, 1414, 2031], [1425, 1994, 1460, 2028], [1474, 1994, 1540, 2022], [1552, 1994, 1605, 2022], [1618, 1994, 1668, 2022], [1680, 2003, 1763, 2022], [1774, 1994, 1886, 2022], [1886, 1994, 1947, 2022], [1955, 1994, 2097, 2022], [451, 2039, 524, 2074], [539, 2048, 569, 2067], [581, 2039, 695, 2067], [712, 2039, 775, 2067], [787, 2039, 872, 2067], [886, 2048, 942, 2067], [953, 2039, 992, 2067], [1003, 2039, 1193, 2076], [1204, 2039, 1293, 2076], [1306, 2039, 1399, 2067], [1410, 2039, 1446, 2067], [1455, 2039, 1505, 2067], [1517, 2043, 1577, 2067], [1589, 2039, 1712, 2067], [1714, 2039, 1785, 2074], [1800, 2048, 1836, 2067], [1838, 2039, 1923, 2074], [450, 2110, 550, 2139], [565, 2109, 636, 2139], [651, 2109, 861, 2139], [883, 2111, 907, 2138], [921, 2110, 946, 2138], [962, 2110, 1114, 2147], [1128, 2110, 1288, 2138], [1303, 2114, 1333, 2138], [1346, 2110, 1480, 2147], [1494, 2110, 1732, 2147], [1746, 2110, 1782, 2138], [1793, 2110, 1843, 2138], [1857, 2110, 1991, 2138], [2005, 2110, 2097, 2147], [451, 2165, 482, 2184], [495, 2156, 516, 2184], [529, 2156, 632, 2184], [645, 2156, 694, 2184], [705, 2156, 807, 2184], [818, 2160, 849, 2184], [859, 2156, 954, 2184], [965, 2156, 1078, 2193], [1089, 2156, 1138, 2184], [1148, 2156, 1346, 2184], [1357, 2156, 1603, 2184], [1620, 2157, 1653, 2184], [1664, 2165, 1719, 2184], [1729, 2165, 1808, 2190], [1821, 2156, 1870, 2184], [1881, 2156, 2099, 2193], [450, 2205, 553, 2230], [564, 2201, 636, 2229], [648, 2205, 846, 2238], [859, 2210, 915, 2229], [927, 2201, 995, 2229], [1007, 2210, 1046, 2229], [1057, 2201, 1131, 2229], [1142, 2201, 1271, 2238], [1284, 2201, 1341, 2229], [1353, 2201, 1490, 2238], [1502, 2201, 1614, 2235], [1629, 2201, 1686, 2229], [1699, 2210, 1747, 2229], [1759, 2201, 1905, 2238], [1917, 2201, 2056, 2229], [2068, 2201, 2099, 2229], [450, 2247, 500, 2275], [513, 2256, 600, 2275], [613, 2247, 673, 2275], [686, 2256, 786, 2275], [801, 2256, 817, 2275], [829, 2247, 910, 2284], [922, 2247, 1034, 2284], [1047, 2247, 1083, 2275], [1092, 2247, 1233, 2281], [1247, 2247, 1296, 2275], [1308, 2256, 1469, 2276], [1471, 2247, 1524, 2275], [1536, 2256, 1576, 2275], [1578, 2247, 1753, 2275], [1765, 2247, 1789, 2275], [1804, 2256, 1835, 2275], [1848, 2247, 1992, 2284], [2005, 2256, 2036, 2275], [2050, 2247, 2099, 2275], [450, 2302, 611, 2322], [613, 2293, 666, 2321], [678, 2293, 728, 2321], [740, 2293, 879, 2330], [892, 2302, 957, 2321], [976, 2294, 1131, 2327], [1145, 2293, 1234, 2330], [1248, 2302, 1264, 2321], [1275, 2293, 1340, 2330], [1351, 2293, 1387, 2321], [1397, 2293, 1517, 2327], [1531, 2293, 1580, 2321], [1592, 2293, 1704, 2330], [1716, 2293, 1787, 2321], [1799, 2293, 1936, 2321], [1949, 2293, 2031, 2321], [2043, 2302, 2099, 2321], [449, 2338, 488, 2366], [502, 2338, 675, 2366], [689, 2338, 729, 2375], [744, 2347, 760, 2366], [773, 2338, 932, 2375], [945, 2338, 1171, 2375], [1188, 2347, 1243, 2375], [1260, 2338, 1371, 2366], [1384, 2338, 1425, 2375], [1439, 2338, 1488, 2366], [1502, 2347, 1620, 2366], [1634, 2342, 1814, 2367], [1837, 2338, 1900, 2366], [1914, 2338, 2099, 2375], [450, 2384, 486, 2412], [495, 2393, 614, 2412], [626, 2384, 742, 2412], [754, 2384, 983, 2421], [994, 2384, 1047, 2412], [1059, 2384, 1137, 2412], [1148, 2384, 1322, 2421], [1333, 2384, 1521, 2421], [1533, 2384, 1564, 2412], [1579, 2384, 1638, 2418], [1652, 2384, 1714, 2418], [1728, 2384, 1828, 2412], [1841, 2393, 1857, 2412], [1869, 2384, 1971, 2421], [1983, 2384, 2099, 2412], [450, 2434, 633, 2467], [648, 2439, 694, 2458], [697, 2430, 882, 2458], [898, 2430, 955, 2458], [971, 2430, 1139, 2458], [1153, 2430, 1233, 2458], [1247, 2430, 1296, 2458], [1310, 2430, 1404, 2458], [1418, 2430, 1494, 2458], [1519, 2431, 1552, 2458], [1566, 2439, 1621, 2458], [1634, 2439, 1713, 2464], [1730, 2439, 1777, 2458], [1791, 2430, 1931, 2458], [1946, 2439, 1962, 2458], [1977, 2430, 2100, 2467], [451, 2475, 610, 2512], [627, 2475, 706, 2503], [718, 2475, 792, 2503], [805, 2475, 1010, 2512], [1012, 2475, 1106, 2503], [1118, 2475, 1139, 2504], [1152, 2484, 1199, 2503], [1211, 2475, 1340, 2503], [1352, 2475, 1388, 2503], [1402, 2484, 1490, 2503], [1502, 2479, 1609, 2504], [449, 2545, 683, 2575], [698, 2546, 806, 2575], [816, 2555, 863, 2574], [872, 2546, 948, 2575], [959, 2546, 1116, 2574], [1126, 2546, 1267, 2574], [1277, 2555, 1359, 2583], [1371, 2546, 1406, 2574], [1414, 2546, 1590, 2583], [1600, 2546, 1737, 2583], [1747, 2546, 1859, 2583], [1869, 2546, 1940, 2574], [1951, 2546, 2098, 2583], [450, 2606, 520, 2625], [522, 2597, 632, 2625], [647, 2597, 709, 2625], [724, 2606, 740, 2625], [754, 2597, 850, 2634], [863, 2597, 986, 2626], [998, 2597, 1033, 2632], [1053, 2603, 1074, 2627], [1092, 2587, 1190, 2625], [1197, 2587, 1255, 2607], [1262, 2621, 1266, 2625], [1287, 2597, 1488, 2634], [1501, 2597, 1562, 2625], [1576, 2606, 1592, 2625], [1605, 2597, 1751, 2626], [1764, 2597, 1895, 2634], [1911, 2606, 1927, 2625], [1940, 2597, 2099, 2625], [450, 2643, 543, 2680], [559, 2652, 606, 2671], [622, 2643, 737, 2680], [752, 2652, 768, 2671], [783, 2643, 842, 2671], [860, 2651, 880, 2671], [899, 2643, 959, 2671], [977, 2651, 997, 2671], [1016, 2643, 1061, 2671], [1077, 2643, 1270, 2672], [1284, 2643, 1364, 2671], [1378, 2643, 1412, 2677], [1430, 2643, 1488, 2671], [1501, 2652, 1570, 2680], [1586, 2643, 1608, 2671], [1622, 2647, 1652, 2671], [1667, 2643, 1716, 2671], [1730, 2647, 1779, 2671], [1795, 2652, 1825, 2671], [1841, 2643, 1932, 2680], [1956, 2643, 2020, 2671], [2033, 2643, 2098, 2671], [450, 2689, 509, 2717], [523, 2689, 619, 2726], [636, 2689, 855, 2726], [869, 2689, 998, 2717], [1014, 2689, 1127, 2726], [1142, 2689, 1191, 2717], [1207, 2698, 1289, 2717], [1305, 2698, 1335, 2717], [1351, 2689, 1412, 2717], [1426, 2689, 1501, 2717], [1516, 2689, 1546, 2717], [1561, 2689, 1610, 2717], [1626, 2689, 1732, 2726], [1746, 2693, 1804, 2723], [1822, 2689, 1879, 2717], [1894, 2689, 1918, 2717], [1934, 2689, 2099, 2717], [450, 2734, 481, 2762], [493, 2734, 555, 2771], [573, 2734, 596, 2762], [613, 2734, 733, 2771], [745, 2734, 770, 2762], [784, 2734, 898, 2762], [909, 2738, 940, 2762], [952, 2734, 1001, 2762], [1014, 2734, 1120, 2771], [1132, 2734, 1287, 2768], [1302, 2734, 1359, 2762], [1371, 2734, 1395, 2762], [1409, 2734, 1566, 2762], [1578, 2734, 1609, 2762], [1621, 2734, 1712, 2762], [1724, 2734, 1754, 2762], [1767, 2734, 1844, 2763], [1859, 2734, 1885, 2763], [450, 2804, 501, 2834], [544, 2804, 692, 2834], [704, 2804, 740, 2834], [749, 2805, 803, 2834], [815, 2805, 975, 2842], [988, 2804, 1140, 2834], [1152, 2804, 1366, 2834], [1378, 2807, 1411, 2834], [1423, 2804, 1571, 2842], [1584, 2804, 1855, 2842], [450, 2877, 483, 2904], [497, 2876, 554, 2904], [570, 2876, 694, 2910], [710, 2885, 757, 2904], [770, 2880, 822, 2913], [836, 2885, 890, 2904], [903, 2876, 1049, 2913], [1063, 2876, 1210, 2905], [1224, 2876, 1418, 2904], [1432, 2876, 1462, 2904], [1476, 2876, 1525, 2904], [1539, 2880, 1659, 2904], [1673, 2876, 1709, 2904], [1718, 2876, 1799, 2913], [1813, 2880, 1863, 2910], [1879, 2876, 2013, 2913], [2027, 2885, 2098, 2904], [450, 2921, 586, 2949], [606, 2925, 636, 2949], [655, 2921, 704, 2949], [723, 2921, 813, 2950], [831, 2921, 1090, 2958], [1112, 2921, 1261, 2950], [1280, 2921, 1310, 2949], [1330, 2921, 1406, 2950], [1432, 2921, 1486, 2949], [1523, 2921, 1665, 2949], [1684, 2921, 1778, 2949], [1797, 2930, 1837, 2949], [1855, 2921, 1969, 2949], [1988, 2921, 2098, 2949], [450, 2967, 517, 3004], [534, 2967, 594, 3001], [609, 2967, 659, 3001], [675, 2967, 819, 3004], [832, 2967, 974, 2995], [988, 2967, 1101, 2996], [1115, 2967, 1373, 3004], [1386, 2967, 1466, 2995], [1479, 2967, 1616, 2995], [1638, 2967, 1718, 2996], [1732, 2967, 1860, 2995], [1876, 2976, 1924, 2995], [1937, 2967, 2099, 3004], [450, 3013, 530, 3041], [540, 3013, 590, 3041], [600, 3013, 712, 3050], [722, 3013, 793, 3041], [805, 3013, 862, 3041], [874, 3022, 922, 3041], [933, 3013, 999, 3041], [1011, 3013, 1199, 3050], [1208, 3013, 1249, 3050], [1260, 3022, 1315, 3041], [1325, 3013, 1471, 3050], [1481, 3013, 1635, 3042], [1652, 3013, 1772, 3047], [1785, 3013, 1834, 3041], [1845, 3013, 1927, 3042], [1938, 3013, 1995, 3041], [2006, 3014, 2099, 3041], [451, 354, 530, 382], [544, 354, 723, 391], [740, 363, 789, 382], [802, 354, 896, 382], [910, 363, 950, 382], [965, 354, 1014, 382], [1027, 354, 1208, 391], [1224, 354, 1259, 382], [1271, 354, 1464, 382], [1480, 354, 1516, 382], [1528, 354, 1639, 391], [1654, 354, 1724, 382], [1739, 363, 1773, 382], [1787, 354, 1823, 382], [1839, 354, 1982, 391], [1999, 354, 2099, 382], [451, 409, 506, 428], [518, 400, 556, 428], [568, 400, 709, 428], [722, 400, 801, 428], [813, 400, 862, 428], [874, 400, 1080, 437], [1082, 400, 1176, 428], [1188, 400, 1272, 437], [1285, 400, 1329, 435], [1342, 400, 1431, 437], [1444, 409, 1460, 428], [1473, 400, 1570, 437], [1582, 400, 1806, 429], [1818, 400, 1900, 437], [1912, 400, 2099, 437], [451, 445, 768, 474], [769, 445, 912, 480], [925, 445, 1069, 473], [1079, 445, 1098, 473], [1101, 445, 1161, 482], [1163, 445, 1386, 473], [1398, 445, 1455, 473], [1465, 445, 1591, 482], [1601, 445, 1706, 482], [1723, 445, 1786, 473], [1796, 445, 1958, 473], [1969, 445, 2097, 473], [451, 491, 486, 519], [497, 491, 558, 525], [573, 491, 773, 528], [785, 491, 848, 519], [860, 491, 917, 519], [928, 491, 1026, 526], [1039, 500, 1087, 519], [1098, 491, 1162, 519], [1173, 491, 1335, 528], [1346, 491, 1425, 519], [1435, 491, 1485, 519], [1495, 491, 1606, 528], [1617, 491, 1688, 519], [1698, 491, 1842, 528], [1855, 491, 1921, 525], [1935, 491, 2030, 528], [2043, 500, 2099, 519], [450, 537, 488, 565], [502, 537, 643, 574], [656, 537, 697, 574], [711, 546, 766, 565], [779, 537, 1003, 566], [1017, 537, 1127, 565], [1150, 537, 1272, 574], [1288, 537, 1337, 565], [1351, 537, 1508, 574], [1522, 537, 1636, 565], [1653, 537, 1714, 571], [1731, 537, 1756, 565], [1771, 537, 1933, 574], [1947, 537, 1987, 574], [2002, 537, 2098, 565], [451, 582, 502, 619], [516, 582, 565, 610], [578, 582, 796, 619], [809, 586, 926, 611], [942, 582, 1031, 619], [1045, 582, 1094, 610], [1108, 582, 1271, 619], [1287, 582, 1387, 610], [1400, 582, 1583, 619], [1586, 586, 1644, 610], [1657, 582, 1707, 610], [1720, 582, 1878, 619], [1892, 582, 2028, 619], [2043, 582, 2096, 617], [451, 629, 483, 656], [499, 628, 575, 657], [593, 628, 640, 657], [657, 637, 704, 656], [718, 628, 862, 657], [876, 628, 925, 656], [939, 628, 1152, 657], [1153, 628, 1279, 662], [1296, 628, 1389, 656], [1403, 628, 1433, 656], [1448, 628, 1497, 656], [1511, 628, 1574, 656], [1588, 628, 1670, 665], [1684, 628, 1720, 656], [1731, 628, 1780, 656], [1794, 628, 1940, 665], [1955, 628, 2096, 656], [451, 674, 521, 702], [534, 674, 674, 711], [687, 674, 800, 702], [811, 674, 956, 703], [968, 674, 1028, 702], [1040, 683, 1095, 702], [1105, 674, 1339, 711], [1351, 674, 1533, 711], [1545, 674, 1754, 702], [1766, 674, 1904, 702], [451, 744, 493, 772], [511, 744, 556, 772], [571, 753, 602, 772], [619, 744, 668, 772], [684, 744, 760, 781], [776, 744, 925, 772], [943, 753, 991, 772], [1007, 744, 1184, 778], [1204, 753, 1220, 772], [1235, 748, 1420, 772], [1436, 744, 1526, 773], [1542, 744, 1757, 772], [1774, 744, 1967, 772], [1983, 744, 2018, 772], [2034, 744, 2096, 778], [451, 790, 586, 818], [599, 794, 659, 818], [671, 790, 796, 818], [808, 790, 924, 818], [938, 790, 1037, 818], [1050, 799, 1098, 818], [1109, 790, 1318, 818], [1331, 790, 1388, 818], [1399, 790, 1459, 818], [1472, 790, 1548, 827], [1560, 790, 1630, 818], [1642, 799, 1696, 818], [1707, 790, 1973, 827], [1985, 790, 2099, 818], [451, 836, 622, 870], [640, 836, 740, 864], [756, 845, 812, 864], [826, 836, 865, 864], [882, 845, 953, 864], [969, 845, 1000, 864], [1018, 845, 1034, 864], [1049, 836, 1200, 864], [1215, 836, 1447, 873], [1462, 836, 1498, 864], [1511, 836, 1644, 864], [1662, 836, 1725, 864], [1741, 836, 1965, 865], [1981, 836, 2097, 864], [451, 881, 486, 909], [505, 881, 565, 915], [589, 881, 636, 915], [658, 881, 697, 909], [716, 885, 768, 909], [787, 881, 935, 918], [955, 881, 1061, 918], [1080, 881, 1137, 909], [1156, 881, 1302, 918], [1320, 881, 1509, 918], [1528, 885, 1661, 915], [1685, 881, 1742, 909], [1760, 881, 1823, 918], [1842, 890, 1882, 909], [1901, 881, 1950, 909], [1969, 881, 2098, 909], [452, 927, 593, 956], [609, 927, 833, 956], [850, 927, 951, 961], [970, 927, 1063, 955], [1080, 927, 1159, 955], [1175, 927, 1224, 955], [1241, 927, 1316, 955], [1346, 928, 1379, 955], [1396, 936, 1450, 955], [1466, 936, 1544, 961], [1563, 927, 1679, 955], [1696, 927, 1720, 955], [1738, 927, 1893, 964], [1908, 927, 2099, 964], [450, 973, 539, 1010], [553, 973, 603, 1001], [617, 973, 728, 1010], [742, 973, 813, 1001], [828, 973, 1034, 1010], [1036, 973, 1141, 1007], [1157, 973, 1319, 1010], [1333, 973, 1427, 1001], [1441, 982, 1481, 1001], [1495, 973, 1545, 1001], [1560, 973, 1761, 1010], [1777, 973, 1813, 1001], [1824, 977, 1988, 1010], [2002, 973, 2038, 1001], [2050, 973, 2099, 1001], [451, 1018, 592, 1055], [608, 1018, 665, 1046], [681, 1018, 871, 1046], [887, 1018, 923, 1046], [935, 1018, 984, 1046], [999, 1018, 1075, 1046], [1101, 1018, 1325, 1055], [1342, 1018, 1415, 1046], [1431, 1018, 1632, 1055], [1649, 1018, 1711, 1046], [1728, 1027, 1744, 1046], [1758, 1018, 1905, 1047], [1920, 1018, 2100, 1046], [451, 1064, 546, 1101], [556, 1064, 595, 1092], [607, 1064, 674, 1092], [685, 1068, 716, 1092], [726, 1064, 816, 1092], [827, 1064, 877, 1092], [887, 1064, 1096, 1101], [1107, 1064, 1143, 1092], [1152, 1064, 1330, 1092], [1341, 1064, 1596, 1093], [1608, 1064, 1756, 1098], [1770, 1073, 1806, 1092], [1808, 1064, 1863, 1092], [1877, 1073, 1914, 1092], [1925, 1064, 2099, 1101], [451, 1110, 596, 1138], [608, 1110, 656, 1138], [667, 1110, 765, 1138], [776, 1110, 921, 1138], [451, 1180, 500, 1209], [544, 1179, 771, 1209], [783, 1179, 819, 1209], [828, 1180, 932, 1209], [944, 1179, 1169, 1209], [1170, 1179, 1292, 1209], [453, 1332, 506, 1346], [509, 1326, 580, 1346], [591, 1332, 616, 1346], [454, 1357, 556, 1377], [561, 1357, 616, 1377], [453, 1390, 591, 1413], [601, 1387, 631, 1410], [453, 1480, 506, 1494], [509, 1474, 580, 1494], [591, 1480, 616, 1494], [453, 1505, 533, 1525], [542, 1505, 585, 1525], [453, 1538, 591, 1561], [600, 1535, 632, 1557], [589, 1578, 625, 1591], [629, 1578, 648, 1591], [879, 1669, 977, 1694], [1060, 1669, 1132, 1694], [874, 1700, 981, 1720], [1042, 1700, 1149, 1720], [451, 1751, 557, 1788], [572, 1751, 599, 1779], [621, 1750, 808, 1787], [822, 1750, 1059, 1780], [1073, 1750, 1172, 1780], [1187, 1751, 1290, 1780], [1305, 1759, 1347, 1780], [1363, 1750, 1401, 1780], [1415, 1751, 1547, 1780], [1561, 1750, 1680, 1788], [1694, 1750, 1792, 1780], [1813, 1751, 1877, 1779], [1891, 1751, 2099, 1780], [451, 1797, 475, 1825], [492, 1797, 561, 1834], [576, 1797, 639, 1825], [654, 1797, 692, 1826], [708, 1797, 846, 1825], [863, 1797, 920, 1825], [935, 1797, 975, 1826], [989, 1806, 1076, 1825], [1099, 1797, 1174, 1825], [1189, 1797, 1311, 1825], [1326, 1797, 1509, 1834], [1512, 1801, 1570, 1825], [0, 0, 2550, 3300], [1586, 1797, 1701, 1831], [1718, 1797, 1792, 1825], [1806, 1806, 1868, 1825], [1883, 1815, 1904, 1817], [1917, 1801, 1948, 1825], [1964, 1806, 2000, 1825], [2015, 1797, 2099, 1834], [451, 1842, 586, 1870], [451, 1938, 483, 1965], [496, 1937, 558, 1974], [573, 1937, 592, 1965], [605, 1946, 652, 1965], [665, 1937, 808, 1966], [821, 1937, 870, 1965], [883, 1937, 1107, 1966], [1120, 1937, 1211, 1965], [1225, 1937, 1305, 1965], [1317, 1937, 1367, 1965], [1379, 1937, 1442, 1965], [1455, 1937, 1537, 1974], [1549, 1937, 1585, 1965], [1595, 1937, 1644, 1965], [1657, 1937, 1803, 1974], [1815, 1937, 1971, 1971], [1985, 1937, 2099, 1965], [451, 1992, 490, 2011], [502, 1983, 551, 2011], [562, 1983, 714, 2012], [729, 1983, 850, 2011], [867, 1983, 949, 2011], [960, 1983, 996, 2011], [1005, 1983, 1054, 2011], [1066, 1983, 1083, 2012], [1087, 1983, 1208, 2012], [1220, 1983, 1273, 2011], [1287, 1992, 1303, 2011], [1316, 1983, 1421, 2020], [1432, 1983, 1582, 2020], [1593, 1983, 1665, 2011], [1677, 1983, 1713, 2011], [1722, 1983, 1740, 2012], [1754, 1991, 1774, 2011], [1790, 1983, 1808, 2012], [1819, 1983, 1925, 2020], [1939, 1983, 1997, 2011], [2009, 1992, 2097, 2020], [451, 2029, 490, 2058], [503, 2029, 587, 2066], [599, 2029, 752, 2063], [766, 2029, 1002, 2066], [1015, 2033, 1045, 2057], [1058, 2029, 1107, 2057], [1119, 2029, 1287, 2057], [1300, 2028, 1367, 2064], [1381, 2029, 1439, 2057], [1451, 2029, 1574, 2058], [1587, 2028, 1653, 2064], [1667, 2033, 1864, 2066], [1878, 2029, 1914, 2057], [1927, 2029, 1963, 2058], [1977, 2029, 2099, 2057], [451, 2074, 562, 2111], [574, 2074, 645, 2102], [657, 2074, 863, 2111], [865, 2074, 973, 2102], [987, 2074, 1016, 2103], [451, 2145, 493, 2173], [512, 2154, 568, 2173], [585, 2145, 623, 2173], [642, 2154, 721, 2179], [743, 2154, 810, 2173], [811, 2145, 936, 2173], [955, 2149, 1097, 2182], [1115, 2145, 1221, 2182], [1238, 2145, 1413, 2174], [1432, 2145, 1468, 2173], [1482, 2145, 1532, 2173], [1549, 2145, 1660, 2182], [1678, 2145, 1755, 2179], [1775, 2145, 1930, 2182], [1946, 2145, 2016, 2173], [2034, 2154, 2098, 2173], [451, 2191, 513, 2219], [526, 2191, 657, 2228], [671, 2191, 743, 2219], [756, 2191, 856, 2228], [868, 2191, 1009, 2225], [1023, 2191, 1123, 2219], [1136, 2191, 1317, 2228], [1331, 2191, 1600, 2220], [1612, 2191, 1821, 2219], [1834, 2191, 1999, 2228], [2001, 2191, 2096, 2228], [451, 2236, 565, 2271], [580, 2236, 659, 2265], [659, 2236, 776, 2264], [789, 2240, 931, 2273], [943, 2236, 1089, 2273], [1101, 2236, 1286, 2270], [1300, 2236, 1455, 2273], [1467, 2236, 1598, 2273], [1611, 2236, 1642, 2264], [1654, 2236, 1770, 2264], [1782, 2245, 1839, 2265], [1840, 2236, 1945, 2264], [451, 2313, 474, 2347], [525, 2313, 748, 2348], [762, 2313, 936, 2357], [451, 2394, 562, 2423], [578, 2394, 627, 2422], [644, 2394, 750, 2431], [767, 2398, 875, 2422], [891, 2394, 1047, 2428], [1066, 2394, 1165, 2422], [1182, 2403, 1238, 2422], [1253, 2394, 1292, 2422], [1307, 2394, 1488, 2431], [1505, 2403, 1544, 2422], [1562, 2403, 1578, 2422], [1594, 2394, 1675, 2431], [1692, 2394, 1751, 2422], [1768, 2394, 1868, 2431], [1884, 2394, 2099, 2422], [451, 2440, 564, 2468], [583, 2440, 670, 2475], [689, 2449, 719, 2468], [739, 2440, 923, 2477], [944, 2440, 994, 2468], [1011, 2440, 1157, 2477], [1175, 2440, 1322, 2469], [1339, 2440, 1431, 2468], [1450, 2444, 1481, 2468], [1497, 2440, 1536, 2468], [1554, 2440, 1667, 2468], [1685, 2449, 1725, 2468], [1743, 2440, 1833, 2469], [1851, 2440, 1919, 2468], [1936, 2458, 1957, 2460], [1975, 2440, 2032, 2468], [2050, 2440, 2099, 2468], [452, 2485, 597, 2514], [610, 2485, 738, 2513], [753, 2485, 801, 2513], [813, 2485, 904, 2514], [918, 2485, 1017, 2513], [1030, 2485, 1245, 2513], [1260, 2494, 1308, 2513], [1322, 2485, 1382, 2513], [1394, 2485, 1491, 2513], [1505, 2485, 1600, 2513], [1621, 2486, 1654, 2513], [1667, 2494, 1722, 2513], [1734, 2485, 1933, 2522], [1949, 2485, 2039, 2520], [2056, 2485, 2097, 2520], [451, 2531, 578, 2568], [594, 2531, 618, 2559], [634, 2531, 806, 2568], [822, 2540, 862, 2559], [878, 2531, 927, 2559], [942, 2531, 1093, 2560], [1114, 2531, 1171, 2559], [1187, 2531, 1361, 2560], [1381, 2531, 1519, 2565], [1537, 2531, 1637, 2559], [1652, 2531, 1728, 2560], [1744, 2531, 1824, 2568], [1849, 2531, 1930, 2560], [1946, 2531, 2003, 2559], [2020, 2531, 2100, 2560], [451, 2577, 556, 2606], [572, 2577, 775, 2614], [802, 2578, 843, 2605], [859, 2577, 1000, 2605], [1015, 2577, 1207, 2614], [1225, 2586, 1284, 2605], [1299, 2577, 1389, 2605], [1405, 2577, 1545, 2605], [1559, 2577, 1735, 2614], [1751, 2577, 1800, 2605], [1815, 2581, 1875, 2605], [1891, 2577, 2019, 2605], [2036, 2577, 2099, 2605], [451, 2631, 518, 2656], [536, 2622, 603, 2656], [619, 2622, 766, 2656], [783, 2622, 808, 2650], [824, 2626, 875, 2650], [891, 2622, 1143, 2659], [1158, 2622, 1217, 2650], [1231, 2626, 1262, 2650], [1277, 2622, 1326, 2650], [1340, 2622, 1532, 2650], [1546, 2622, 1684, 2650], [1698, 2622, 1748, 2650], [1763, 2626, 1821, 2650], [1837, 2622, 1873, 2650], [1885, 2622, 2006, 2650], [2031, 2622, 2099, 2651], [451, 2668, 555, 2705], [569, 2668, 681, 2703], [694, 2677, 741, 2696], [753, 2668, 888, 2697], [901, 2668, 985, 2703], [999, 2668, 1024, 2696], [1038, 2672, 1068, 2696], [1081, 2668, 1153, 2705], [1167, 2668, 1224, 2696], [1237, 2668, 1286, 2696], [1299, 2668, 1413, 2705], [1427, 2668, 1507, 2696], [1519, 2668, 1568, 2696], [1581, 2668, 1703, 2702], [1718, 2668, 1817, 2696], [1830, 2668, 1870, 2696], [1882, 2672, 1934, 2696], [1948, 2677, 2056, 2705], [2068, 2668, 2099, 2696], [451, 2714, 500, 2742], [514, 2714, 641, 2751], [655, 2714, 776, 2742], [799, 2714, 880, 2748], [895, 2714, 1042, 2748], [1057, 2714, 1189, 2751], [1204, 2714, 1325, 2742], [1340, 2714, 1443, 2742], [1457, 2714, 1505, 2742], [1519, 2714, 1592, 2742], [1606, 2714, 1718, 2742], [1735, 2714, 1792, 2742], [1806, 2714, 1897, 2742], [1913, 2714, 1962, 2742], [1977, 2718, 2099, 2742], [451, 2759, 486, 2787], [496, 2759, 660, 2787], [672, 2759, 799, 2796], [811, 2759, 887, 2787], [451, 2830, 479, 2858], [494, 2839, 560, 2858], [561, 2830, 759, 2867], [774, 2839, 841, 2867], [856, 2830, 892, 2858], [904, 2830, 1080, 2867], [1096, 2830, 1209, 2859], [1224, 2830, 1352, 2858], [1369, 2830, 1393, 2858], [1409, 2830, 1502, 2858], [1517, 2839, 1557, 2858], [1572, 2830, 1740, 2858], [1754, 2830, 1888, 2867], [1906, 2830, 1957, 2864], [1983, 2831, 2022, 2858], [2039, 2830, 2099, 2858], [451, 2876, 475, 2904], [493, 2880, 523, 2904], [540, 2876, 621, 2904], [638, 2885, 654, 2904], [671, 2876, 787, 2911], [804, 2876, 1047, 2913], [1066, 2876, 1166, 2904], [1182, 2876, 1207, 2904], [1225, 2876, 1393, 2913], [1409, 2880, 1461, 2904], [1477, 2876, 1549, 2913], [1566, 2880, 1596, 2904], [1612, 2876, 1662, 2904], [1678, 2876, 1744, 2904], [1759, 2876, 1790, 2904], [1806, 2876, 1945, 2913], [1962, 2876, 2050, 2911], [2067, 2885, 2097, 2904], [451, 2921, 606, 2950], [614, 2921, 878, 2956], [891, 2921, 943, 2949], [956, 2921, 1020, 2949], [1032, 2925, 1063, 2949], [1075, 2921, 1160, 2949], [1171, 2921, 1251, 2949], [1266, 2921, 1334, 2958], [1349, 2921, 1500, 2950], [1516, 2921, 1753, 2956], [1770, 2921, 1947, 2949], [1959, 2921, 2038, 2949], [2053, 2925, 2099, 2949], [452, 2976, 482, 2995], [499, 2976, 515, 2995], [528, 2967, 712, 3004], [730, 2967, 787, 2995], [802, 2967, 891, 2995], [906, 2967, 953, 2995], [967, 2967, 1016, 2995], [1030, 2967, 1226, 3004], [1241, 2967, 1277, 2995], [1290, 2967, 1453, 2995], [1468, 2967, 1595, 3004], [1610, 2967, 1685, 2995], [1710, 2968, 1743, 2995], [1757, 2976, 1812, 2995], [1826, 2976, 1904, 3001], [1922, 2976, 1938, 2995], [1952, 2967, 2099, 2996], [452, 3013, 645, 3041], [663, 3013, 687, 3041], [707, 3013, 853, 3041], [872, 3022, 906, 3041], [924, 3013, 985, 3041], [1003, 3013, 1024, 3041], [1041, 3013, 1094, 3041], [1115, 3019, 1171, 3042], [1191, 3013, 1322, 3041], [1340, 3013, 1555, 3041], [1573, 3013, 1669, 3050], [1689, 3022, 1729, 3041], [1747, 3017, 1798, 3050], [1816, 3013, 1852, 3041], [1867, 3013, 1916, 3041], [1934, 3013, 1990, 3041], [2008, 3013, 2098, 3050], [451, 354, 617, 382], [632, 354, 722, 391], [744, 363, 803, 382], [818, 354, 949, 382], [964, 354, 1046, 391], [1059, 358, 1215, 391], [1231, 354, 1406, 383], [1424, 354, 1639, 382], [1655, 363, 1765, 388], [1781, 354, 1831, 382], [1845, 354, 1930, 382], [1943, 363, 2002, 382], [2015, 372, 2036, 374], [2050, 354, 2099, 382], [451, 400, 602, 429], [619, 409, 728, 428], [747, 400, 828, 428], [841, 400, 877, 428], [887, 400, 936, 428], [948, 400, 1044, 437], [1059, 400, 1083, 428], [1097, 400, 1248, 437], [1260, 400, 1333, 428], [1345, 400, 1381, 428], [1395, 409, 1464, 428], [1477, 400, 1538, 428], [1553, 400, 1698, 434], [1712, 400, 1812, 428], [1825, 404, 1960, 437], [1974, 400, 2046, 437], [2059, 409, 2099, 428], [451, 445, 500, 473], [512, 445, 628, 479], [642, 445, 765, 482], [778, 445, 857, 473], [869, 445, 919, 473], [930, 445, 1096, 482], [1109, 445, 1230, 473], [1249, 445, 1312, 473], [1324, 445, 1437, 474], [1449, 445, 1577, 482], [1590, 445, 1651, 473], [1665, 445, 1690, 473], [1704, 445, 1866, 482], [1879, 454, 1910, 473], [1924, 445, 1973, 473], [1987, 454, 2054, 473], [2066, 445, 2102, 473], [451, 491, 500, 519], [512, 491, 677, 520], [689, 491, 780, 519], [797, 491, 903, 525], [917, 491, 975, 519], [987, 491, 1036, 519], [1048, 491, 1183, 519], [1194, 491, 1305, 528], [1317, 491, 1493, 520], [1506, 500, 1562, 519], [1573, 491, 1612, 519], [1624, 491, 1719, 519], [1730, 491, 1771, 528], [1782, 491, 2079, 528], [451, 568, 473, 602], [525, 568, 864, 612], [878, 568, 1014, 603], [452, 648, 620, 678], [631, 648, 877, 686], [891, 649, 955, 677], [965, 649, 1047, 686], [1057, 649, 1277, 686], [1288, 649, 1324, 677], [1332, 658, 1386, 677], [1397, 649, 1503, 686], [1515, 649, 1572, 677], [1583, 649, 1729, 686], [1740, 649, 1901, 678], [1914, 649, 1938, 677], [1952, 649, 2098, 677], [451, 695, 541, 732], [559, 695, 664, 723], [681, 695, 712, 723], [729, 695, 791, 732], [815, 695, 837, 723], [870, 696, 894, 723], [911, 695, 1109, 732], [1128, 699, 1158, 723], [1175, 695, 1407, 724], [1427, 695, 1621, 723], [1638, 695, 1674, 723], [1691, 695, 1732, 729], [1753, 695, 1810, 723], [1828, 695, 1852, 723], [1872, 695, 1985, 723], [2002, 699, 2032, 723], [2050, 695, 2099, 723], [451, 741, 585, 769], [600, 741, 636, 769], [651, 741, 724, 775], [751, 741, 803, 769], [817, 741, 930, 769], [945, 741, 1057, 778], [1072, 741, 1168, 778], [1184, 750, 1239, 769], [1254, 741, 1304, 769], [1318, 741, 1515, 769], [1532, 741, 1657, 776], [1675, 741, 1834, 770], [1850, 741, 1996, 775], [2015, 750, 2098, 769], [450, 786, 576, 823], [587, 786, 611, 814], [623, 786, 795, 823], [806, 795, 878, 815], [889, 786, 906, 815], [920, 794, 940, 814], [954, 786, 971, 815], [984, 786, 1090, 823], [1101, 786, 1232, 814], [1235, 786, 1331, 814], [1343, 786, 1433, 814], [1444, 786, 1473, 820], [1486, 786, 1565, 814], [1575, 795, 1720, 823], [1731, 786, 1958, 814], [1968, 795, 2037, 814], [2050, 786, 2099, 814], [452, 841, 534, 860], [548, 832, 671, 869], [686, 841, 717, 860], [734, 832, 806, 866], [826, 832, 889, 860], [902, 832, 974, 869], [987, 832, 1153, 860], [1164, 832, 1302, 860], [1316, 832, 1422, 869], [1436, 832, 1493, 860], [1506, 832, 1652, 869], [1665, 832, 1811, 861], [1824, 832, 2044, 869], [2046, 832, 2097, 860], [451, 878, 511, 906], [523, 887, 570, 906], [581, 878, 724, 907], [736, 878, 786, 906], [798, 878, 911, 906], [923, 878, 1150, 906], [1162, 878, 1244, 915], [1255, 878, 1335, 906], [1346, 878, 1395, 906], [1407, 878, 1492, 906], [1503, 882, 1534, 906], [1545, 878, 1655, 906], [1667, 887, 1803, 915], [1815, 878, 2036, 915], [451, 947, 612, 985], [630, 948, 694, 976], [706, 948, 834, 985], [846, 948, 1012, 985], [1025, 957, 1080, 976], [1093, 948, 1132, 976], [1145, 957, 1217, 976], [1231, 957, 1261, 976], [1277, 957, 1313, 976], [1328, 948, 1498, 985], [1511, 948, 1547, 976], [1557, 948, 1618, 976], [1631, 948, 1667, 976], [1680, 948, 1741, 982], [1758, 952, 1788, 976], [1802, 948, 1892, 977], [1905, 948, 2025, 982], [2042, 948, 2099, 976], [451, 994, 475, 1022], [490, 994, 643, 1031], [657, 994, 706, 1022], [721, 1003, 804, 1022], [817, 994, 865, 1022], [877, 994, 950, 1022], [965, 994, 1071, 1031], [1086, 994, 1143, 1022], [1157, 994, 1303, 1031], [1317, 998, 1389, 1022], [1412, 994, 1475, 1022], [1489, 994, 1624, 1022], [1637, 994, 1763, 1031], [1779, 1003, 1827, 1022], [1841, 994, 1934, 1022], [1947, 994, 2036, 1031], [2050, 994, 2099, 1022], [451, 1039, 629, 1067], [643, 1039, 803, 1067], [817, 1039, 951, 1076], [964, 1039, 1087, 1067], [1099, 1039, 1171, 1067], [1184, 1043, 1372, 1067], [1386, 1039, 1443, 1074], [1456, 1043, 1486, 1067], [1499, 1039, 1571, 1074], [1591, 1039, 1631, 1067], [1644, 1039, 1718, 1067], [1731, 1039, 1876, 1073], [1892, 1048, 1908, 1067], [1921, 1039, 2099, 1067], [451, 1085, 486, 1113], [496, 1085, 555, 1114], [570, 1085, 700, 1122], [714, 1085, 738, 1113], [752, 1085, 942, 1113], [954, 1085, 994, 1122], [1008, 1085, 1157, 1122], [1170, 1085, 1229, 1114], [1243, 1085, 1370, 1122], [1383, 1085, 1488, 1114], [1503, 1085, 1680, 1122], [1694, 1094, 1794, 1113], [1808, 1085, 1857, 1113], [1869, 1085, 2005, 1120], [2020, 1085, 2099, 1113], [451, 1131, 525, 1159], [537, 1131, 573, 1159], [582, 1131, 681, 1159], [694, 1140, 710, 1159], [723, 1131, 820, 1168], [831, 1131, 927, 1159], [938, 1131, 963, 1159], [975, 1131, 1134, 1168], [1147, 1131, 1285, 1159], [1302, 1132, 1335, 1159], [1348, 1131, 1454, 1168], [1466, 1135, 1515, 1159], [1527, 1131, 1663, 1168], [1678, 1140, 1694, 1159], [1706, 1131, 1766, 1159], [1781, 1139, 1801, 1159], [1818, 1131, 1878, 1159], [1891, 1131, 2061, 1168], [2073, 1131, 2097, 1159], [450, 1176, 608, 1213], [621, 1176, 753, 1213], [766, 1176, 846, 1204], [858, 1176, 908, 1204], [922, 1176, 1053, 1204], [1066, 1176, 1171, 1210], [1186, 1176, 1208, 1204], [1221, 1176, 1290, 1204], [1303, 1176, 1470, 1213], [1484, 1176, 1611, 1204], [1622, 1176, 1790, 1204], [1803, 1176, 1931, 1213], [1945, 1176, 2002, 1204], [2015, 1176, 2097, 1205], [447, 1222, 588, 1259], [607, 1222, 670, 1250], [683, 1222, 788, 1251], [803, 1231, 851, 1250], [863, 1222, 998, 1250], [1010, 1222, 1204, 1256], [1220, 1231, 1254, 1250], [1267, 1222, 1327, 1250], [1340, 1222, 1389, 1250], [1403, 1222, 1536, 1250], [1550, 1222, 1614, 1250], [1627, 1222, 1662, 1250], [1672, 1222, 1722, 1250], [1734, 1222, 1829, 1250], [1842, 1222, 1945, 1259], [1959, 1222, 2027, 1251], [2046, 1223, 2099, 1250], [451, 1272, 521, 1296], [532, 1268, 593, 1296], [604, 1268, 707, 1296], [722, 1268, 795, 1302], [809, 1268, 858, 1296], [871, 1268, 1041, 1305], [1053, 1268, 1078, 1296], [1092, 1268, 1228, 1305], [1240, 1268, 1320, 1296], [1331, 1268, 1380, 1296], [1392, 1268, 1492, 1296], [1504, 1268, 1600, 1296], [1602, 1272, 1673, 1302], [1681, 1268, 1744, 1305], [1756, 1268, 1792, 1296], [1806, 1268, 1865, 1297], [1882, 1276, 1902, 1296], [1919, 1268, 1978, 1297], [1991, 1272, 2096, 1296], [451, 1314, 483, 1341], [495, 1313, 545, 1341], [556, 1313, 702, 1350], [714, 1317, 763, 1341], [775, 1313, 911, 1350], [924, 1322, 971, 1341], [983, 1317, 1124, 1350], [1137, 1322, 1173, 1341], [1185, 1313, 1297, 1350], [1308, 1313, 1379, 1341], [1391, 1313, 1495, 1342], [1496, 1322, 1513, 1341], [1525, 1313, 1604, 1341], [1615, 1313, 1664, 1341], [1677, 1313, 1808, 1341], [1820, 1313, 1947, 1350], [1959, 1313, 2054, 1341], [2067, 1322, 2097, 1341], [451, 1359, 608, 1387], [620, 1359, 650, 1387], [663, 1359, 739, 1388], [755, 1359, 781, 1388], [798, 1360, 887, 1387], [898, 1359, 959, 1387], [970, 1359, 1092, 1388], [1095, 1368, 1131, 1393], [1143, 1359, 1302, 1387], [1315, 1359, 1374, 1387], [1389, 1367, 1409, 1387], [1426, 1359, 1485, 1387], [1500, 1367, 1520, 1387], [1536, 1359, 1553, 1387], [1557, 1359, 1678, 1396], [1690, 1359, 1714, 1387], [1727, 1359, 1885, 1396], [1897, 1359, 2029, 1396], [2042, 1359, 2099, 1387], [451, 1405, 572, 1442], [591, 1405, 654, 1433], [667, 1405, 781, 1433], [782, 1409, 856, 1442], [858, 1405, 912, 1433], [926, 1405, 1054, 1442], [1068, 1409, 1111, 1433], [1124, 1409, 1154, 1433], [1170, 1399, 1260, 1439], [1276, 1405, 1333, 1433], [1346, 1405, 1416, 1433], [1429, 1405, 1591, 1433], [1605, 1405, 1745, 1433], [1746, 1409, 1809, 1442], [1823, 1414, 1839, 1433], [1851, 1405, 1932, 1433], [1946, 1405, 2097, 1439], [451, 1450, 529, 1478], [530, 1450, 587, 1478], [599, 1450, 670, 1487], [681, 1450, 731, 1478], [743, 1459, 808, 1478], [809, 1450, 870, 1478], [871, 1450, 936, 1478], [948, 1450, 1075, 1487], [1088, 1454, 1155, 1478], [1173, 1450, 1308, 1487], [1322, 1450, 1410, 1478], [1422, 1450, 1549, 1487], [1562, 1459, 1578, 1478], [1590, 1450, 1737, 1479], [1748, 1450, 1828, 1478], [1840, 1450, 1955, 1478], [1958, 1450, 2027, 1484], [2037, 1454, 2099, 1478], [451, 1496, 475, 1524], [491, 1496, 627, 1533], [642, 1500, 673, 1524], [690, 1490, 768, 1525], [787, 1496, 861, 1524], [875, 1496, 945, 1525], [959, 1496, 1120, 1530], [1137, 1496, 1207, 1524], [1221, 1500, 1252, 1524], [1269, 1489, 1348, 1525], [1366, 1496, 1440, 1524], [1454, 1496, 1494, 1525], [1495, 1496, 1700, 1530], [1717, 1496, 1775, 1524], [1789, 1496, 1916, 1533], [1931, 1496, 1955, 1524], [1972, 1496, 2099, 1533], [452, 1542, 526, 1570], [537, 1542, 576, 1571], [577, 1542, 777, 1570], [794, 1543, 827, 1570], [838, 1542, 887, 1570], [898, 1542, 1078, 1579], [1090, 1542, 1226, 1570], [1228, 1542, 1297, 1576], [1306, 1546, 1368, 1570], [1379, 1542, 1403, 1570], [1416, 1542, 1552, 1579], [1563, 1546, 1594, 1570], [1608, 1536, 1686, 1571], [1701, 1542, 1775, 1570], [1789, 1542, 1856, 1570], [1866, 1542, 2028, 1576], [2042, 1542, 2099, 1570], [451, 1587, 578, 1624], [591, 1587, 717, 1624], [731, 1587, 805, 1615], [816, 1587, 886, 1616], [898, 1587, 1058, 1615], [451, 1657, 586, 1695], [607, 1658, 647, 1686], [661, 1662, 717, 1686], [731, 1658, 811, 1692], [828, 1658, 916, 1695], [932, 1667, 948, 1686], [961, 1658, 1061, 1692], [1077, 1667, 1124, 1686], [1138, 1658, 1254, 1695], [1268, 1667, 1284, 1686], [1298, 1658, 1379, 1686], [1393, 1658, 1519, 1686], [1532, 1658, 1568, 1686], [1579, 1658, 1689, 1686], [1705, 1658, 1757, 1693], [1772, 1658, 1803, 1686], [1817, 1667, 1871, 1686], [1884, 1658, 2098, 1695], [451, 1704, 523, 1732], [537, 1704, 626, 1741], [640, 1704, 786, 1741], [802, 1704, 926, 1741], [940, 1704, 1077, 1732], [1092, 1704, 1181, 1732], [1206, 1705, 1295, 1732], [1309, 1704, 1383, 1732], [1398, 1704, 1434, 1732], [1445, 1704, 1495, 1732], [1509, 1704, 1619, 1732], [1635, 1713, 1682, 1732], [1697, 1704, 1766, 1732], [1781, 1704, 1883, 1732], [1902, 1704, 1938, 1733], [1952, 1704, 2099, 1733], [451, 1749, 549, 1786], [564, 1749, 625, 1783], [637, 1749, 678, 1786], [688, 1749, 834, 1786], [845, 1749, 902, 1777], [913, 1749, 1040, 1786], [1050, 1749, 1119, 1777], [1128, 1758, 1247, 1777], [1260, 1758, 1296, 1777], [1298, 1749, 1377, 1777], [1387, 1753, 1487, 1777], [1497, 1749, 1532, 1777], [1540, 1749, 1589, 1777], [1599, 1749, 1702, 1777], [1718, 1749, 1781, 1777], [1791, 1749, 1869, 1777], [1882, 1758, 1981, 1777], [1993, 1749, 2040, 1777], [2050, 1749, 2099, 1777], [451, 1795, 551, 1823], [562, 1795, 653, 1824], [665, 1804, 714, 1823], [725, 1795, 795, 1823], [807, 1795, 948, 1823], [959, 1795, 1000, 1832], [1013, 1795, 1172, 1832], [1184, 1795, 1233, 1823], [1246, 1804, 1345, 1823], [1360, 1804, 1459, 1823], [1472, 1795, 1522, 1823], [1534, 1795, 1670, 1832], [1682, 1795, 1792, 1823], [1806, 1795, 1863, 1823], [1875, 1804, 1947, 1832], [1950, 1795, 2096, 1823], [451, 1864, 667, 1902], [684, 1873, 726, 1894], [744, 1865, 915, 1902], [932, 1864, 1193, 1894], [1224, 1865, 1321, 1893], [1337, 1865, 1533, 1902], [1550, 1865, 1599, 1893], [1617, 1865, 1723, 1902], [1740, 1865, 1895, 1899], [1915, 1874, 1962, 1893], [1978, 1874, 2033, 1893], [2050, 1865, 2099, 1893], [452, 1920, 534, 1939], [551, 1911, 678, 1948], [695, 1911, 753, 1939], [769, 1915, 825, 1939], [841, 1911, 909, 1939], [926, 1911, 1150, 1948], [1167, 1920, 1197, 1939], [1215, 1911, 1373, 1939], [1390, 1911, 1486, 1940], [1503, 1911, 1670, 1948], [1689, 1911, 1826, 1948], [1845, 1911, 1926, 1940], [1941, 1911, 2096, 1948], [451, 1957, 521, 1985], [533, 1957, 629, 1994], [644, 1954, 746, 1987], [758, 1957, 842, 1994], [854, 1966, 934, 1985], [944, 1966, 984, 1985], [994, 1957, 1212, 1986], [1218, 1957, 1411, 1986], [1422, 1961, 1474, 1991], [1487, 1957, 1586, 1985], [1597, 1966, 1753, 1994], [1765, 1957, 1941, 1994], [1951, 1961, 1982, 1985], [1995, 1954, 2097, 1987], [450, 2002, 587, 2039], [604, 2002, 635, 2030], [655, 2002, 716, 2036], [736, 2002, 784, 2030], [801, 2011, 817, 2030], [835, 2002, 948, 2030], [965, 2002, 1106, 2030], [1138, 2003, 1191, 2030], [1207, 2002, 1325, 2031], [1342, 2002, 1402, 2030], [1419, 2002, 1469, 2030], [1485, 2002, 1567, 2030], [1583, 2011, 1690, 2030], [1707, 2002, 1755, 2030], [1771, 2002, 1821, 2030], [1837, 2002, 2044, 2039], [2046, 2002, 2097, 2030], [452, 2048, 601, 2085], [613, 2048, 649, 2076], [658, 2048, 805, 2077], [817, 2048, 915, 2085], [929, 2048, 1008, 2076], [1020, 2048, 1069, 2076], [1081, 2048, 1181, 2076], [1193, 2048, 1301, 2085], [1314, 2048, 1411, 2076], [1422, 2048, 1492, 2076], [1500, 2048, 1562, 2085], [1574, 2048, 1610, 2076], [1624, 2052, 1729, 2076], [451, 2118, 620, 2148], [621, 2118, 810, 2156], [825, 2119, 889, 2148], [898, 2119, 1157, 2156], [1167, 2119, 1192, 2147], [1204, 2119, 1325, 2148], [1335, 2119, 1415, 2147], [1425, 2119, 1474, 2147], [1483, 2119, 1618, 2156], [1630, 2119, 1775, 2148], [1786, 2119, 1875, 2148], [1885, 2119, 2011, 2147], [2024, 2119, 2097, 2153], [450, 2164, 501, 2192], [518, 2164, 653, 2192], [672, 2173, 688, 2192], [704, 2164, 816, 2192], [816, 2164, 882, 2192], [897, 2164, 1067, 2201], [1084, 2164, 1317, 2198], [1336, 2164, 1491, 2201], [1507, 2164, 1631, 2201], [1647, 2164, 1775, 2201], [1792, 2173, 1831, 2192], [1848, 2164, 1985, 2201], [2001, 2164, 2097, 2193], [451, 2210, 589, 2238], [600, 2210, 631, 2238], [643, 2219, 659, 2238], [670, 2210, 767, 2247], [779, 2214, 899, 2247], [916, 2211, 969, 2238], [979, 2210, 1092, 2247], [1103, 2210, 1152, 2238], [1163, 2210, 1231, 2238], [1240, 2210, 1433, 2247], [1447, 2210, 1504, 2238], [1516, 2210, 1585, 2247], [1595, 2210, 1670, 2238], [1682, 2210, 1761, 2239], [1772, 2210, 1861, 2238], [1873, 2219, 1972, 2238], [1986, 2210, 2099, 2239], [451, 2256, 556, 2285], [581, 2256, 721, 2293], [737, 2265, 753, 2284], [768, 2256, 865, 2293], [880, 2256, 1026, 2293], [1041, 2256, 1187, 2285], [1202, 2256, 1284, 2284], [1304, 2256, 1315, 2284], [1334, 2256, 1392, 2293], [1407, 2265, 1447, 2284], [1463, 2265, 1479, 2284], [1494, 2260, 1607, 2293], [1622, 2256, 1694, 2284], [1709, 2256, 1728, 2284], [1743, 2256, 1888, 2284], [1903, 2256, 1988, 2284], [2003, 2256, 2097, 2290], [451, 2301, 550, 2329], [562, 2301, 737, 2329], [751, 2310, 767, 2329], [780, 2301, 829, 2330], [843, 2301, 929, 2329], [944, 2301, 1091, 2338], [1103, 2310, 1175, 2330], [1187, 2301, 1351, 2338], [1352, 2301, 1528, 2338], [451, 2371, 580, 2409], [597, 2371, 669, 2401], [686, 2372, 711, 2400], [729, 2372, 891, 2409], [908, 2372, 997, 2409], [1014, 2372, 1063, 2400], [1080, 2372, 1288, 2400], [1302, 2372, 1383, 2401], [1401, 2372, 1659, 2409], [1677, 2372, 1712, 2400], [1730, 2372, 1770, 2406], [1791, 2372, 1870, 2400], [1887, 2372, 1936, 2400], [1953, 2372, 2098, 2409], [451, 2418, 583, 2446], [607, 2419, 640, 2446], [655, 2418, 731, 2455], [745, 2418, 781, 2446], [792, 2418, 842, 2446], [856, 2418, 914, 2446], [928, 2418, 1134, 2455], [1148, 2418, 1220, 2446], [1235, 2418, 1335, 2453], [1351, 2418, 1398, 2446], [1413, 2427, 1429, 2446], [1442, 2418, 1506, 2455], [1520, 2418, 1556, 2446], [1567, 2418, 1701, 2453], [1717, 2418, 1739, 2446], [1753, 2418, 1854, 2446], [1870, 2418, 1930, 2446], [1944, 2418, 2099, 2446], [452, 2472, 468, 2491], [484, 2463, 658, 2491], [675, 2463, 701, 2491], [717, 2463, 796, 2491], [814, 2463, 982, 2500], [1004, 2472, 1039, 2491], [1057, 2472, 1104, 2491], [1121, 2463, 1351, 2500], [1369, 2463, 1418, 2491], [1436, 2463, 1507, 2491], [1524, 2463, 1630, 2491], [1648, 2463, 1783, 2500], [1819, 2464, 1860, 2491], [1879, 2463, 1967, 2492], [1986, 2463, 2099, 2500], [451, 2509, 500, 2537], [514, 2509, 720, 2546], [722, 2509, 834, 2537], [851, 2518, 881, 2537], [898, 2509, 995, 2543], [1012, 2509, 1061, 2537], [1075, 2509, 1243, 2537], [1259, 2509, 1316, 2537], [1331, 2509, 1453, 2538], [1468, 2513, 1666, 2546], [1682, 2509, 1718, 2537], [1730, 2509, 1779, 2537], [1794, 2509, 1865, 2537], [1880, 2518, 1959, 2537], [1974, 2509, 2099, 2546], [450, 2555, 585, 2583], [599, 2559, 629, 2583], [644, 2564, 660, 2583], [677, 2552, 713, 2593], [725, 2552, 792, 2593], [809, 2564, 901, 2592], [915, 2555, 973, 2583], [986, 2555, 1181, 2592], [1193, 2555, 1283, 2592], [1296, 2555, 1389, 2584], [1404, 2555, 1492, 2590], [1505, 2555, 1761, 2592], [1777, 2555, 1826, 2583], [1840, 2555, 1911, 2583], [1925, 2555, 1949, 2583], [1964, 2555, 2099, 2583], [450, 2600, 506, 2628], [507, 2600, 569, 2628], [580, 2600, 616, 2628], [629, 2600, 756, 2637], [766, 2600, 879, 2637], [896, 2600, 967, 2628], [978, 2600, 1088, 2628], [1090, 2600, 1169, 2628], [1180, 2600, 1251, 2628], [1263, 2600, 1325, 2628], [1336, 2600, 1384, 2628], [1394, 2600, 1443, 2628], [1454, 2600, 1605, 2629], [1620, 2600, 1734, 2628], [1745, 2600, 1824, 2628], [1839, 2600, 1936, 2629], [1949, 2604, 1980, 2628], [1991, 2600, 2096, 2629], [451, 2677, 474, 2712], [525, 2677, 756, 2712], [451, 2758, 598, 2787], [627, 2758, 692, 2787], [721, 2757, 902, 2787], [931, 2758, 1086, 2795], [1150, 2758, 1213, 2786], [1241, 2758, 1410, 2787], [1439, 2758, 1463, 2786], [1492, 2758, 1664, 2795], [1693, 2767, 1733, 2786], [1761, 2758, 1912, 2787], [1948, 2758, 2009, 2792], [2042, 2758, 2099, 2786], [451, 2804, 625, 2833], [648, 2804, 710, 2838], [730, 2804, 829, 2832], [844, 2804, 1033, 2841], [1048, 2804, 1257, 2838], [1276, 2804, 1376, 2832], [1394, 2813, 1442, 2832], [1459, 2813, 1569, 2841], [1586, 2804, 1635, 2832], [1652, 2804, 1760, 2841], [1777, 2804, 1923, 2833], [1940, 2804, 2099, 2832], [451, 2850, 541, 2879], [555, 2843, 709, 2878], [731, 2850, 882, 2879], [900, 2850, 1035, 2878], [1054, 2850, 1120, 2879], [1133, 2850, 1239, 2879], [1255, 2850, 1328, 2885], [1342, 2850, 1557, 2879], [1571, 2859, 1610, 2878], [1625, 2850, 1773, 2887], [1789, 2850, 1948, 2878], [1962, 2850, 2024, 2878], [2042, 2850, 2095, 2879], [452, 2895, 550, 2923], [564, 2895, 687, 2929], [703, 2895, 877, 2924], [895, 2895, 1030, 2923], [1045, 2895, 1126, 2924], [1139, 2895, 1244, 2924], [1259, 2895, 1295, 2923], [1305, 2895, 1341, 2924], [1360, 2895, 1482, 2923], [1504, 2895, 1567, 2923], [1580, 2895, 1749, 2924], [1762, 2895, 1900, 2932], [1913, 2895, 1938, 2923], [1953, 2895, 2002, 2923], [2016, 2904, 2099, 2923], [506, 2967, 587, 3007], [595, 2974, 720, 3007], [733, 2974, 789, 3005], [800, 2974, 922, 2999], [931, 2974, 975, 2999], [985, 2974, 1142, 3007], [1152, 2974, 1254, 2999], [1263, 2973, 1295, 2999], [1305, 2974, 1380, 2999], [1390, 2974, 1591, 3007], [1601, 2974, 1744, 2999], [1754, 2973, 1870, 2999], [1872, 2977, 1983, 3007], [1994, 2974, 2097, 2999], [451, 3016, 611, 3049], [622, 3016, 666, 3041], [677, 3016, 779, 3041], [790, 3015, 821, 3041], [831, 3016, 897, 3041], [909, 3016, 981, 3041], [992, 3016, 1014, 3041], [1026, 3024, 1091, 3049], [1102, 3016, 1282, 3049], [1295, 3016, 1347, 3041], [1358, 3024, 1400, 3041], [1410, 3016, 1473, 3049], [1484, 3019, 1512, 3041], [1523, 3016, 1618, 3041], [1621, 3016, 1664, 3041], [1674, 3016, 1702, 3041], [1713, 3015, 1800, 3041], [1811, 3016, 1894, 3041], [451, 354, 498, 382], [508, 354, 581, 382], [593, 354, 732, 382], [749, 354, 798, 382], [810, 354, 976, 391], [989, 354, 1115, 391], [1126, 354, 1208, 382], [1221, 354, 1304, 391], [1317, 354, 1380, 382], [1392, 354, 1520, 391], [1533, 354, 1590, 382], [1602, 358, 1658, 382], [1670, 354, 1746, 388], [1761, 354, 1818, 382], [1830, 354, 1879, 382], [1890, 354, 2099, 391], [451, 400, 475, 428], [487, 400, 645, 428], [655, 400, 696, 437], [707, 400, 756, 428], [767, 409, 834, 428], [836, 400, 1081, 428], [1093, 409, 1237, 437], [1249, 409, 1349, 428], [1361, 400, 1410, 428], [1422, 400, 1515, 437], [1532, 400, 1613, 428], [1624, 400, 1775, 429], [1791, 400, 1860, 437], [1871, 400, 2006, 428], [2019, 400, 2100, 429], [451, 445, 578, 482], [590, 445, 706, 479], [721, 454, 757, 473], [769, 445, 925, 474], [933, 445, 1029, 482], [1041, 445, 1176, 473], [1191, 445, 1271, 474], [1282, 445, 1409, 482], [1421, 445, 1536, 474], [1553, 446, 1606, 473], [1616, 445, 1707, 482], [1718, 445, 1759, 482], [1771, 445, 1947, 482], [1959, 445, 2099, 473], [452, 491, 659, 519], [674, 500, 714, 519], [727, 491, 777, 519], [790, 491, 853, 519], [867, 491, 936, 528], [949, 491, 985, 519], [995, 491, 1044, 519], [1057, 491, 1209, 520], [1226, 491, 1347, 519], [1368, 492, 1424, 519], [1437, 491, 1629, 528], [1642, 491, 1714, 519], [1727, 491, 1777, 519], [1791, 495, 1864, 519], [1877, 491, 1913, 519], [1924, 491, 1973, 519], [1987, 495, 2037, 525], [2052, 500, 2099, 519], [451, 537, 556, 565], [572, 537, 621, 565], [638, 537, 776, 565], [792, 537, 961, 566], [976, 537, 1114, 574], [1131, 537, 1188, 565], [1203, 541, 1301, 574], [1317, 537, 1366, 565], [1383, 546, 1508, 574], [1525, 546, 1669, 574], [1685, 546, 1757, 566], [1772, 537, 1853, 565], [1870, 537, 1954, 574], [1971, 546, 2011, 565], [2026, 537, 2099, 565], [451, 582, 602, 611], [619, 582, 676, 610], [688, 582, 874, 611], [451, 652, 574, 690], [589, 652, 767, 682], [790, 653, 873, 687], [890, 662, 937, 681], [951, 662, 1088, 681], [1103, 653, 1152, 681], [1165, 653, 1375, 690], [1389, 653, 1425, 681], [1436, 653, 1486, 681], [1501, 653, 1607, 690], [1622, 657, 1731, 681], [1745, 653, 1899, 682], [1924, 653, 2019, 681], [2035, 662, 2098, 681], [451, 699, 549, 727], [569, 708, 617, 727], [634, 699, 821, 727], [850, 699, 886, 734], [904, 699, 1032, 736], [1049, 699, 1128, 727], [1147, 699, 1261, 727], [1279, 708, 1319, 727], [1336, 699, 1500, 733], [1522, 699, 1568, 734], [1586, 699, 1781, 736], [1799, 708, 1839, 727], [1856, 699, 2099, 728], [451, 744, 595, 772], [609, 744, 649, 781], [664, 744, 844, 781], [858, 753, 898, 772], [913, 744, 1076, 778], [1094, 744, 1152, 779], [1167, 744, 1297, 781], [1311, 744, 1361, 772], [1374, 744, 1555, 781], [1569, 744, 1704, 772], [1717, 744, 1798, 772], [1813, 744, 1871, 772], [1885, 744, 1957, 781], [1971, 744, 2099, 781], [451, 790, 500, 818], [512, 790, 568, 818], [581, 790, 822, 825], [836, 790, 922, 827], [941, 791, 997, 818], [1008, 790, 1083, 818], [1095, 790, 1131, 818], [1141, 790, 1190, 818], [1203, 790, 1336, 827], [1350, 799, 1397, 818], [1409, 790, 1594, 827], [1606, 790, 1678, 818], [1692, 790, 1800, 827], [1812, 790, 1861, 818], [1874, 790, 2001, 827], [2013, 799, 2098, 827], [451, 836, 603, 864], [616, 836, 692, 864], [705, 840, 736, 864], [751, 836, 800, 865], [815, 845, 849, 864], [862, 840, 893, 864], [907, 836, 965, 865], [988, 837, 1077, 864], [1090, 836, 1140, 864], [1152, 836, 1269, 870], [1284, 836, 1442, 873], [1456, 836, 1486, 864], [1500, 836, 1590, 864], [1608, 836, 1650, 870], [1666, 836, 1688, 864], [1701, 836, 1726, 864], [1741, 836, 1821, 864], [1834, 836, 1895, 864], [1908, 836, 2036, 873], [2050, 836, 2099, 864], [450, 881, 586, 910], [587, 881, 705, 918], [716, 890, 755, 909], [766, 881, 815, 909], [825, 881, 976, 910], [991, 881, 1105, 909], [1115, 881, 1197, 909], [1209, 885, 1240, 909], [1250, 881, 1433, 918], [1445, 881, 1533, 916], [1543, 881, 1615, 909], [1625, 881, 1698, 918], [1708, 881, 1858, 918], [1872, 881, 1929, 909], [1940, 881, 1964, 909], [1976, 881, 2100, 909], [450, 931, 481, 955], [493, 927, 688, 964], [701, 936, 741, 955], [754, 936, 770, 955], [783, 927, 864, 964], [876, 927, 1119, 956], [1131, 927, 1253, 955], [1272, 927, 1486, 964], [1501, 927, 1681, 964], [1694, 927, 1743, 955], [1755, 927, 1855, 955], [1868, 927, 2003, 955], [2015, 927, 2097, 964], [450, 973, 523, 1010], [538, 973, 684, 1010], [699, 973, 918, 1010], [933, 982, 1005, 1002], [1020, 973, 1147, 1010], [1163, 973, 1213, 1001], [1228, 973, 1284, 1001], [1300, 973, 1382, 1010], [1397, 973, 1474, 1010], [1502, 974, 1535, 1001], [1551, 973, 1600, 1001], [1616, 973, 1700, 1001], [1716, 973, 1833, 1010], [1850, 973, 1956, 1010], [1971, 973, 2099, 1010], [450, 1018, 712, 1055], [729, 1018, 863, 1055], [879, 1018, 936, 1046], [951, 1018, 1033, 1046], [1050, 1022, 1080, 1046], [1095, 1027, 1193, 1046], [1208, 1027, 1358, 1055], [1384, 1019, 1416, 1046], [1431, 1018, 1481, 1046], [1496, 1018, 1654, 1055], [1669, 1018, 1868, 1055], [1885, 1027, 1932, 1046], [1947, 1018, 2037, 1055], [2052, 1018, 2100, 1046], [450, 1064, 578, 1101], [590, 1064, 639, 1092], [651, 1064, 707, 1092], [719, 1064, 801, 1101], [813, 1073, 852, 1092], [864, 1068, 916, 1101], [928, 1064, 964, 1092], [974, 1073, 990, 1092], [1001, 1064, 1182, 1101], [1194, 1064, 1348, 1093], [744, 1152, 833, 1180], [849, 1152, 873, 1180], [890, 1151, 1073, 1181], [1086, 1151, 1254, 1181], [1267, 1160, 1424, 1188], [1436, 1160, 1478, 1181], [1490, 1151, 1648, 1181], [1663, 1151, 1750, 1189], [1764, 1151, 1805, 1187], [621, 1218, 659, 1250], [671, 1217, 781, 1251], [793, 1217, 939, 1244], [1459, 1213, 1499, 1246], [1511, 1214, 1664, 1247], [1676, 1213, 1821, 1240], [1863, 1270, 1913, 1287], [1976, 1265, 2088, 1287], [1856, 1311, 1873, 1328], [2007, 1311, 2042, 1328], [469, 1286, 594, 1319], [606, 1286, 703, 1319], [1025, 1268, 1093, 1290], [1173, 1282, 1251, 1315], [1262, 1282, 1459, 1315], [1314, 1397, 1356, 1414], [1369, 1392, 1423, 1414], [1871, 1404, 1881, 1407], [1314, 1441, 1356, 1458], [1369, 1436, 1423, 1458], [1194, 1479, 1326, 1509], [1314, 1527, 1356, 1544], [1369, 1522, 1423, 1544], [451, 1639, 620, 1676], [639, 1638, 817, 1668], [849, 1639, 968, 1676], [986, 1639, 1141, 1668], [1160, 1639, 1266, 1676], [1283, 1639, 1430, 1668], [1447, 1639, 1584, 1673], [1605, 1648, 1652, 1667], [1669, 1648, 1738, 1667], [1756, 1643, 1821, 1667], [1838, 1643, 1869, 1667], [1886, 1639, 1936, 1667], [1953, 1639, 2099, 1676], [451, 1684, 586, 1713], [587, 1684, 830, 1718], [848, 1684, 905, 1712], [921, 1693, 1018, 1712], [1034, 1684, 1083, 1712], [1097, 1684, 1189, 1712], [1203, 1684, 1239, 1712], [1250, 1684, 1300, 1712], [1314, 1684, 1398, 1721], [1412, 1684, 1656, 1721], [1673, 1684, 1830, 1712], [1845, 1684, 1875, 1712], [1891, 1684, 1967, 1713], [1985, 1684, 2042, 1713], [2066, 1685, 2099, 1712], [450, 1730, 615, 1767], [630, 1739, 677, 1758], [690, 1739, 809, 1758], [810, 1730, 889, 1758], [902, 1730, 994, 1758], [1007, 1730, 1049, 1758], [1067, 1730, 1156, 1767], [1170, 1730, 1307, 1767], [1321, 1730, 1358, 1765], [1376, 1743, 1404, 1752], [1423, 1727, 1470, 1768], [1484, 1727, 1554, 1768], [1570, 1730, 1691, 1758], [1704, 1730, 1816, 1767], [1829, 1730, 1926, 1764], [1941, 1730, 2099, 1767], [451, 1776, 597, 1813], [617, 1785, 705, 1804], [722, 1776, 939, 1813], [956, 1776, 1148, 1810], [1167, 1776, 1256, 1813], [1272, 1776, 1322, 1804], [1337, 1776, 1560, 1804], [1576, 1776, 1687, 1813], [1703, 1776, 1779, 1804], [1809, 1776, 1872, 1804], [1889, 1776, 2097, 1804], [451, 1830, 500, 1849], [514, 1821, 627, 1849], [641, 1830, 681, 1849], [695, 1821, 745, 1849], [758, 1821, 909, 1850], [928, 1821, 1041, 1849], [1055, 1821, 1135, 1849], [1150, 1821, 1273, 1855], [1290, 1830, 1324, 1849], [1339, 1830, 1386, 1849], [1399, 1821, 1474, 1849], [1489, 1830, 1525, 1849], [1541, 1821, 1712, 1858], [1726, 1821, 1841, 1858], [1843, 1821, 1942, 1849], [1956, 1821, 1991, 1849], [2004, 1821, 2053, 1850], [2068, 1825, 2099, 1849], [449, 1867, 520, 1904], [531, 1867, 667, 1904], [678, 1867, 917, 1904], [934, 1867, 997, 1895], [1007, 1867, 1113, 1895], [1127, 1876, 1175, 1895], [1187, 1867, 1292, 1895], [1303, 1867, 1333, 1895], [1345, 1867, 1434, 1895], [1449, 1867, 1493, 1895], [1510, 1867, 1593, 1901], [1606, 1876, 1653, 1895], [1664, 1876, 1720, 1895], [1731, 1867, 1879, 1895], [1890, 1867, 1951, 1895], [1963, 1867, 2099, 1904], [450, 1913, 587, 1950], [599, 1913, 637, 1948], [654, 1919, 680, 1943], [698, 1913, 727, 1948], [739, 1913, 945, 1950], [947, 1913, 1054, 1941], [1066, 1913, 1097, 1941], [1108, 1913, 1157, 1941], [1167, 1913, 1251, 1950], [1262, 1913, 1286, 1941], [1298, 1913, 1403, 1950], [1413, 1913, 1582, 1947], [1596, 1922, 1626, 1941], [1639, 1913, 1660, 1941], [1670, 1913, 1810, 1950], [1822, 1913, 1871, 1941], [1882, 1913, 2017, 1941], [2027, 1913, 2099, 1941], [450, 1958, 613, 1995], [625, 1958, 741, 1986], [753, 1958, 956, 1992], [970, 1958, 1070, 1986], [1082, 1958, 1107, 1986], [1120, 1967, 1204, 1986], [1216, 1958, 1451, 1987], [1463, 1958, 1532, 1986], [1545, 1958, 1594, 1986], [1606, 1958, 1677, 1986], [1688, 1958, 1805, 1986], [1807, 1967, 1855, 1986], [1866, 1958, 1931, 1995], [1942, 1958, 1978, 1986], [1988, 1958, 2097, 1986], [451, 2004, 489, 2039], [506, 2017, 534, 2026], [552, 2004, 565, 2032], [581, 2004, 711, 2041], [729, 2004, 900, 2041], [912, 2004, 961, 2032], [973, 2004, 1085, 2032], [1085, 2004, 1147, 2032], [1156, 2004, 1240, 2041], [1252, 2004, 1338, 2032], [1352, 2004, 1431, 2032], [1444, 2004, 1461, 2033], [1474, 2008, 1505, 2032], [1520, 2004, 1556, 2033], [1569, 2004, 1651, 2032], [1665, 2008, 1696, 2032], [1709, 2013, 1725, 2032], [1738, 2004, 1859, 2032], [1870, 2004, 2097, 2041], [451, 2059, 486, 2078], [501, 2059, 548, 2078], [562, 2050, 633, 2087], [649, 2050, 673, 2078], [690, 2050, 771, 2078], [786, 2054, 817, 2078], [835, 2050, 871, 2079], [887, 2050, 918, 2078], [933, 2050, 983, 2078], [998, 2050, 1156, 2087], [1172, 2050, 1380, 2087], [1408, 2050, 1537, 2084], [1555, 2059, 1602, 2078], [1617, 2050, 1680, 2078], [1695, 2050, 1756, 2078], [1771, 2059, 1859, 2078], [1876, 2050, 2057, 2078], [2073, 2050, 2097, 2078], [449, 2095, 575, 2132], [594, 2104, 625, 2123], [642, 2095, 664, 2123], [678, 2095, 803, 2123], [820, 2095, 869, 2123], [885, 2095, 977, 2123], [992, 2095, 1028, 2123], [1041, 2095, 1143, 2132], [1158, 2095, 1274, 2123], [1289, 2095, 1427, 2123], [1442, 2095, 1492, 2123], [1507, 2095, 1626, 2123], [1654, 2096, 1707, 2123], [1722, 2104, 1777, 2123], [1792, 2095, 1814, 2123], [1829, 2095, 1860, 2123], [1875, 2095, 1925, 2123], [1940, 2095, 2099, 2132], [450, 2141, 650, 2178], [667, 2150, 697, 2169], [714, 2141, 835, 2169], [860, 2141, 923, 2169], [938, 2141, 1104, 2169], [1117, 2141, 1255, 2169], [1270, 2141, 1410, 2169], [1426, 2141, 1562, 2178], [1577, 2141, 1751, 2178], [1767, 2141, 1792, 2169], [1808, 2141, 1963, 2178], [1981, 2141, 2003, 2169], [2017, 2145, 2097, 2169], [450, 2191, 502, 2215], [516, 2187, 577, 2215], [591, 2187, 702, 2224], [716, 2187, 787, 2215], [802, 2187, 938, 2224], [951, 2187, 1099, 2224], [1114, 2187, 1208, 2215], [1222, 2187, 1291, 2215], [1306, 2187, 1463, 2224], [1478, 2187, 1622, 2224], [1640, 2187, 1697, 2215], [1710, 2187, 1799, 2224], [1814, 2187, 1863, 2215], [1876, 2187, 2099, 2215], [450, 2232, 562, 2269], [573, 2232, 644, 2260], [655, 2232, 679, 2260], [692, 2232, 764, 2269], [776, 2232, 898, 2269], [908, 2232, 1003, 2260], [1013, 2232, 1082, 2260], [1094, 2241, 1110, 2260], [1120, 2232, 1364, 2260], [1375, 2232, 1504, 2260], [1515, 2232, 1591, 2260], [1608, 2232, 1730, 2269], [1743, 2241, 1790, 2260], [1801, 2236, 1871, 2260], [1881, 2232, 1942, 2260], [1953, 2232, 2099, 2269], [450, 2278, 612, 2307], [627, 2278, 829, 2315], [841, 2278, 1027, 2315], [1039, 2278, 1088, 2306], [1101, 2278, 1207, 2315], [1219, 2278, 1381, 2307], [1395, 2278, 1498, 2313], [1514, 2278, 1570, 2313], [1584, 2278, 1684, 2306], [1696, 2278, 1839, 2306], [1852, 2278, 1902, 2306], [1914, 2278, 2099, 2315], [450, 2324, 486, 2352], [495, 2324, 611, 2352], [623, 2324, 818, 2352], [830, 2324, 877, 2352], [890, 2324, 988, 2352], [999, 2324, 1196, 2361], [450, 2395, 487, 2422], [486, 2394, 580, 2422], [593, 2394, 808, 2431], [820, 2394, 869, 2422], [882, 2394, 975, 2422], [987, 2394, 1097, 2422], [1101, 2394, 1315, 2422], [1327, 2394, 1362, 2422], [1375, 2394, 1448, 2428], [1462, 2394, 1561, 2422], [1575, 2398, 1711, 2422], [1725, 2398, 1755, 2422], [1769, 2394, 1911, 2431], [1924, 2403, 1940, 2422], [1952, 2394, 2099, 2423], [450, 2444, 481, 2468], [500, 2449, 516, 2468], [534, 2440, 618, 2468], [634, 2440, 670, 2468], [685, 2440, 766, 2469], [786, 2440, 896, 2468], [916, 2440, 965, 2475], [986, 2440, 1096, 2468], [1115, 2440, 1145, 2468], [1163, 2449, 1218, 2468], [1234, 2440, 1326, 2475], [1359, 2440, 1457, 2468], [1474, 2440, 1588, 2468], [1605, 2440, 1685, 2468], [1703, 2440, 1818, 2468], [1836, 2449, 1875, 2468], [1893, 2440, 2057, 2474], [2077, 2440, 2099, 2468], [451, 2485, 595, 2514], [615, 2482, 718, 2515], [740, 2494, 890, 2522], [913, 2485, 1012, 2513], [1031, 2485, 1056, 2513], [1075, 2485, 1170, 2513], [1188, 2485, 1258, 2513], [1278, 2494, 1294, 2513], [1313, 2485, 1521, 2522], [1540, 2485, 1734, 2513], [1753, 2485, 1866, 2513], [1885, 2485, 1964, 2513], [1984, 2485, 2099, 2513], [451, 2528, 594, 2566], [608, 2531, 660, 2559], [673, 2531, 697, 2559], [713, 2531, 773, 2559], [786, 2531, 831, 2559], [843, 2531, 892, 2559], [902, 2531, 951, 2559], [964, 2531, 1099, 2559], [1112, 2531, 1225, 2559], [1239, 2531, 1318, 2559], [1332, 2531, 1447, 2559], [1460, 2540, 1500, 2559], [1513, 2531, 1625, 2568], [1638, 2531, 1714, 2559], [1735, 2531, 1805, 2559], [1821, 2531, 1920, 2559], [1934, 2531, 1995, 2559], [2008, 2531, 2099, 2559], [450, 2577, 647, 2605], [658, 2577, 852, 2605], [863, 2577, 887, 2605], [899, 2577, 1068, 2614], [1080, 2577, 1102, 2605], [1112, 2577, 1137, 2605], [1150, 2577, 1214, 2605], [1224, 2577, 1384, 2614], [1395, 2581, 1425, 2605], [1435, 2581, 1554, 2614], [1565, 2577, 1586, 2605], [1597, 2581, 1627, 2605], [1639, 2586, 1655, 2605], [1665, 2577, 1800, 2606], [1802, 2577, 1853, 2605], [1864, 2586, 1901, 2605], [1912, 2577, 2099, 2614], [450, 2631, 579, 2650], [450, 2692, 636, 2722], [647, 2692, 792, 2730], [803, 2692, 838, 2722], [847, 2693, 1006, 2730], [1018, 2692, 1196, 2722], [1211, 2693, 1351, 2730], [1362, 2693, 1508, 2730], [1519, 2693, 1680, 2722], [1692, 2702, 1732, 2721], [1743, 2693, 1877, 2722], [1883, 2693, 1934, 2721], [1946, 2693, 2098, 2730], [450, 2739, 502, 2776], [517, 2739, 575, 2767], [590, 2743, 620, 2767], [635, 2739, 685, 2767], [700, 2739, 788, 2767], [804, 2739, 866, 2767], [880, 2739, 916, 2767], [928, 2739, 977, 2767], [992, 2739, 1119, 2776], [1135, 2743, 1187, 2767], [1212, 2739, 1261, 2767], [1276, 2748, 1351, 2768], [1365, 2739, 1472, 2776], [1486, 2739, 1643, 2776], [1658, 2739, 1682, 2767], [1699, 2743, 1729, 2767], [1744, 2739, 1819, 2767], [1834, 2739, 1883, 2767], [1898, 2739, 2044, 2768], [2059, 2748, 2099, 2767], [450, 2784, 637, 2818], [653, 2784, 753, 2812], [767, 2784, 841, 2812], [855, 2784, 982, 2821], [997, 2784, 1066, 2821], [1080, 2784, 1104, 2812], [1121, 2784, 1170, 2813], [1185, 2784, 1272, 2812], [1288, 2784, 1408, 2812], [1421, 2784, 1491, 2812], [1505, 2784, 1565, 2812], [1579, 2784, 1615, 2812], [1626, 2784, 1789, 2813], [1811, 2785, 1890, 2812], [1904, 2793, 1951, 2812], [1964, 2784, 2099, 2813], [451, 2830, 591, 2858], [601, 2830, 720, 2867], [731, 2830, 779, 2858], [788, 2830, 957, 2867], [967, 2830, 1016, 2858], [1026, 2830, 1167, 2859], [1177, 2830, 1304, 2867], [1316, 2834, 1359, 2858], [1370, 2830, 1432, 2858], [1442, 2830, 1478, 2858], [1485, 2830, 1672, 2859], [1689, 2830, 1724, 2865], [1736, 2830, 1916, 2867], [1927, 2839, 1943, 2858], [1953, 2830, 2099, 2867], [451, 2876, 585, 2904], [594, 2876, 775, 2913], [786, 2885, 825, 2904], [836, 2876, 1001, 2910], [1014, 2876, 1061, 2911], [1074, 2876, 1184, 2913], [1195, 2876, 1233, 2905], [1245, 2876, 1357, 2904], [1369, 2876, 1448, 2904], [1458, 2876, 1622, 2910], [1634, 2876, 1734, 2904], [1745, 2885, 1794, 2904], [1804, 2876, 1956, 2913], [1968, 2876, 2099, 2904], [452, 2930, 486, 2949], [496, 2921, 557, 2949], [568, 2921, 649, 2949], [660, 2921, 684, 2949], [697, 2930, 736, 2949], [747, 2921, 939, 2949], [949, 2921, 1087, 2949], [1098, 2921, 1181, 2949], [1192, 2921, 1304, 2949], [1317, 2921, 1374, 2949], [1385, 2921, 1435, 2949], [1445, 2921, 1544, 2950], [1554, 2921, 1728, 2950], [1743, 2921, 1866, 2955], [1880, 2921, 1939, 2956], [1950, 2921, 2039, 2958], [2050, 2921, 2099, 2949], [451, 2967, 618, 2995], [632, 2967, 826, 2995], [842, 2967, 932, 3002], [950, 2967, 981, 3002], [997, 2971, 1028, 2995], [1042, 2967, 1124, 2995], [1139, 2976, 1155, 2995], [1170, 2967, 1260, 2996], [1274, 2967, 1517, 3004], [1535, 2967, 1641, 2995], [1655, 2967, 1792, 2995], [1807, 2967, 1856, 2995], [1871, 2967, 2022, 2996], [2042, 2967, 2099, 2995], [451, 3013, 606, 3042], [614, 3013, 858, 3041], [872, 3013, 961, 3041], [983, 3013, 1046, 3041], [1059, 3013, 1165, 3041], [1182, 3022, 1230, 3041], [1242, 3013, 1380, 3050], [1394, 3013, 1424, 3041], [1438, 3013, 1528, 3041], [1542, 3013, 1569, 3041], [1591, 3013, 1634, 3041], [1650, 3013, 1795, 3050], [1797, 3013, 1841, 3047], [1855, 3013, 1879, 3041], [1894, 3013, 2054, 3041], [2068, 3017, 2099, 3041], [486, 345, 576, 373], [588, 345, 615, 373], [633, 345, 803, 382], [815, 344, 968, 374], [980, 353, 1137, 381], [1149, 353, 1191, 374], [1204, 344, 1384, 373], [1400, 344, 1487, 382], [1501, 344, 1516, 373], [1530, 344, 1606, 374], [1619, 344, 1797, 374], [1809, 344, 1950, 382], [1962, 344, 2063, 380], [762, 417, 867, 442], [879, 412, 976, 442], [762, 460, 867, 485], [878, 460, 914, 477], [925, 503, 941, 520], [1057, 498, 1090, 525], [762, 546, 867, 571], [878, 546, 914, 563], [804, 584, 834, 606], [917, 589, 1027, 614], [1038, 589, 1074, 606], [450, 657, 551, 685], [561, 657, 617, 685], [629, 657, 681, 692], [693, 657, 776, 694], [789, 657, 963, 692], [975, 657, 1126, 686], [1141, 657, 1190, 685], [1193, 657, 1267, 685], [1277, 657, 1404, 694], [1416, 657, 1522, 692], [1532, 657, 1687, 694], [1696, 657, 1737, 694], [1747, 657, 1918, 694], [1929, 657, 2053, 694], [2066, 666, 2100, 685], [451, 703, 610, 740], [621, 703, 661, 740], [672, 703, 889, 740], [906, 703, 1078, 731], [1088, 703, 1223, 740], [1233, 703, 1367, 740], [1369, 703, 1443, 731], [1453, 703, 1528, 737], [1542, 712, 1573, 731], [1585, 703, 1607, 731], [1619, 703, 1722, 731], [1735, 703, 1785, 731], [1796, 703, 1923, 740], [1934, 703, 2099, 740], [451, 752, 481, 776], [493, 748, 606, 785], [619, 748, 658, 776], [671, 748, 817, 777], [828, 748, 956, 785], [968, 748, 1043, 776], [451, 820, 503, 847], [514, 819, 591, 848], [604, 819, 668, 847], [681, 819, 904, 856], [916, 819, 989, 847], [1001, 819, 1169, 847], [1180, 819, 1314, 856], [1327, 828, 1366, 847], [1379, 819, 1428, 847], [1440, 819, 1591, 848], [1608, 819, 1730, 853], [1743, 819, 1784, 856], [1796, 819, 1923, 856], [1937, 828, 1953, 847], [1965, 819, 2100, 847], [451, 868, 481, 892], [494, 864, 619, 901], [631, 864, 704, 892], [716, 864, 766, 892], [778, 864, 834, 892], [847, 864, 1021, 893], [1037, 864, 1105, 892], [1119, 864, 1171, 899], [1185, 864, 1268, 901], [1282, 864, 1457, 899], [1472, 864, 1529, 892], [1542, 864, 1591, 892], [1604, 864, 1755, 893], [1771, 864, 1839, 892], [1852, 864, 1882, 899], [1896, 864, 1992, 901], [2006, 864, 2096, 901], [451, 910, 479, 939], [480, 910, 544, 938], [546, 910, 639, 938], [654, 910, 723, 947], [737, 910, 773, 938], [784, 910, 947, 944], [964, 910, 1013, 938], [1027, 919, 1172, 947], [1186, 919, 1247, 938], [1262, 910, 1419, 938], [1433, 914, 1464, 938], [1477, 910, 1515, 938], [1530, 910, 1643, 944], [1659, 910, 1759, 938], [1773, 910, 1923, 947], [1938, 919, 1978, 938], [1993, 907, 2097, 940], [452, 956, 595, 985], [606, 956, 695, 993], [707, 956, 756, 984], [769, 965, 834, 984], [835, 956, 998, 993], [1010, 956, 1062, 984], [1074, 956, 1199, 984], [1211, 956, 1261, 984], [1273, 956, 1437, 984], [1449, 957, 1543, 984], [1546, 956, 1799, 984], [1811, 956, 1877, 984], [1889, 956, 1992, 991], [2008, 956, 2065, 991], [451, 1026, 659, 1055], [677, 1025, 855, 1055], [884, 1027, 963, 1054], [980, 1035, 1027, 1054], [1043, 1026, 1178, 1055], [1195, 1026, 1244, 1054], [1260, 1026, 1411, 1063], [1427, 1030, 1612, 1054], [1629, 1026, 1740, 1060], [1759, 1026, 1859, 1054], [1876, 1026, 2032, 1054], [2050, 1026, 2099, 1054], [451, 1076, 511, 1100], [526, 1072, 714, 1109], [732, 1076, 863, 1100], [893, 1072, 961, 1101], [977, 1081, 1044, 1109], [1060, 1072, 1096, 1100], [1109, 1072, 1285, 1109], [1302, 1072, 1351, 1100], [1367, 1072, 1515, 1100], [1533, 1072, 1635, 1100], [1650, 1072, 1669, 1100], [1672, 1076, 1735, 1100], [1752, 1072, 1826, 1100], [1843, 1081, 1859, 1100], [1871, 1072, 1950, 1109], [1967, 1072, 2051, 1100], [2066, 1072, 2102, 1100], [451, 1118, 709, 1155], [721, 1118, 817, 1155], [829, 1127, 869, 1146], [881, 1122, 932, 1155], [943, 1118, 979, 1146], [987, 1118, 1063, 1147], [1075, 1127, 1109, 1146], [1120, 1118, 1195, 1146], [1208, 1118, 1304, 1155], [1316, 1118, 1352, 1146], [1361, 1118, 1410, 1146], [1421, 1122, 1481, 1146], [1492, 1122, 1565, 1146], [1582, 1118, 1663, 1152], [1675, 1118, 1822, 1152], [1835, 1127, 1882, 1146], [1884, 1122, 1960, 1146], [1971, 1118, 2099, 1146], [451, 1163, 481, 1191], [498, 1172, 552, 1191], [569, 1172, 639, 1191], [655, 1163, 714, 1191], [730, 1167, 761, 1191], [778, 1163, 968, 1200], [1000, 1164, 1053, 1191], [1070, 1163, 1218, 1191], [1235, 1163, 1323, 1191], [1340, 1163, 1389, 1191], [1407, 1163, 1538, 1191], [1556, 1172, 1655, 1191], [1673, 1163, 1762, 1200], [1779, 1163, 1872, 1191], [1890, 1163, 2049, 1200], [2066, 1172, 2100, 1191], [452, 1218, 468, 1237], [484, 1209, 577, 1237], [594, 1209, 689, 1238], [708, 1210, 797, 1237], [813, 1209, 902, 1237], [920, 1209, 936, 1238], [954, 1218, 1001, 1237], [1017, 1209, 1147, 1237], [1149, 1209, 1251, 1237], [1278, 1209, 1314, 1244], [1332, 1209, 1479, 1246], [1495, 1209, 1558, 1238], [1572, 1209, 1684, 1246], [1701, 1210, 1887, 1246], [1904, 1215, 2030, 1238], [2047, 1219, 2098, 1237], [451, 1255, 709, 1292], [731, 1265, 766, 1284], [785, 1255, 862, 1283], [871, 1255, 976, 1292], [995, 1255, 1196, 1292], [1214, 1256, 1361, 1292], [1379, 1265, 1417, 1283], [1436, 1255, 1508, 1283], [1526, 1252, 1591, 1290], [1610, 1264, 1681, 1284], [1698, 1255, 1844, 1292], [1862, 1255, 1919, 1283], [1939, 1252, 2009, 1285], [2028, 1264, 2100, 1284], [452, 1300, 557, 1337], [570, 1300, 659, 1335], [676, 1300, 723, 1335], [738, 1300, 933, 1329], [947, 1300, 1049, 1328], [1062, 1300, 1098, 1328], [1109, 1300, 1240, 1328], [1254, 1309, 1354, 1328], [1368, 1300, 1568, 1337], [1583, 1300, 1685, 1328], [1697, 1300, 1738, 1337], [1752, 1300, 1921, 1337], [1938, 1300, 1996, 1335], [2010, 1300, 2099, 1337], [450, 1346, 673, 1374], [687, 1346, 758, 1374], [772, 1346, 797, 1374], [813, 1350, 864, 1374], [877, 1346, 1038, 1374], [1052, 1346, 1083, 1374], [1097, 1346, 1146, 1374], [1160, 1355, 1230, 1374], [1245, 1346, 1280, 1374], [1292, 1346, 1438, 1375], [1453, 1346, 1564, 1380], [1583, 1346, 1638, 1381], [1653, 1346, 1799, 1383], [1813, 1346, 1969, 1380], [1985, 1346, 2099, 1374], [450, 1392, 539, 1429], [551, 1392, 718, 1420], [730, 1392, 873, 1429], [885, 1392, 1033, 1429], [1047, 1392, 1096, 1420], [1107, 1392, 1173, 1420], [1184, 1392, 1257, 1420], [1270, 1392, 1358, 1420], [1370, 1392, 1428, 1420], [1440, 1392, 1507, 1420], [1509, 1392, 1628, 1420], [1640, 1392, 1712, 1420], [1726, 1401, 1742, 1420], [1754, 1392, 1860, 1429], [1872, 1396, 1929, 1420], [739, 1487, 829, 1515], [841, 1487, 868, 1516], [885, 1487, 1094, 1516], [1107, 1486, 1259, 1516], [1272, 1495, 1429, 1523], [1441, 1495, 1483, 1516], [1495, 1486, 1634, 1516], [1638, 1486, 1755, 1524], [1769, 1486, 1810, 1522], [663, 1554, 717, 1584], [862, 1554, 888, 1576], [1294, 1554, 1320, 1576], [937, 1602, 984, 1627], [1478, 1602, 1622, 1627], [937, 1645, 984, 1670], [1478, 1645, 1622, 1670], [937, 1688, 984, 1713], [1478, 1688, 1622, 1713], [452, 1850, 668, 1888], [684, 1850, 760, 1880], [776, 1851, 830, 1880], [846, 1853, 928, 1880], [943, 1850, 979, 1880], [992, 1851, 1046, 1880], [1062, 1853, 1123, 1880], [1149, 1852, 1202, 1879], [1218, 1851, 1366, 1879], [1382, 1851, 1431, 1879], [1447, 1851, 1661, 1888], [1677, 1851, 1846, 1880], [1862, 1851, 1934, 1879], [1950, 1851, 2000, 1879], [2015, 1860, 2098, 1879], [449, 1896, 571, 1933], [587, 1896, 701, 1933], [716, 1896, 765, 1924], [780, 1900, 854, 1924], [868, 1896, 904, 1924], [916, 1896, 965, 1924], [980, 1900, 1022, 1924], [1036, 1905, 1076, 1924], [1090, 1896, 1172, 1924], [1187, 1896, 1271, 1933], [1287, 1896, 1322, 1924], [1334, 1896, 1485, 1925], [1505, 1896, 1562, 1924], [1576, 1896, 1762, 1925], [1787, 1897, 1843, 1924], [1857, 1896, 1918, 1924], [1932, 1905, 1979, 1924], [1992, 1896, 2067, 1924], [2083, 1905, 2099, 1924], [451, 1942, 557, 1979], [573, 1946, 631, 1976], [648, 1942, 830, 1979], [846, 1951, 886, 1970], [902, 1942, 1046, 1971], [1050, 1942, 1146, 1976], [1162, 1942, 1211, 1970], [1227, 1942, 1283, 1970], [1299, 1942, 1381, 1979], [1396, 1942, 1509, 1970], [1525, 1951, 1565, 1970], [1581, 1942, 1661, 1971], [1676, 1951, 1710, 1970], [1725, 1943, 1855, 1970], [1874, 1942, 1937, 1970], [1953, 1942, 2099, 1979], [450, 1991, 500, 2015], [514, 1996, 575, 2015], [591, 1987, 705, 2015], [719, 1996, 759, 2015], [774, 1987, 854, 2016], [869, 1987, 926, 2015], [940, 1988, 1034, 2015], [1037, 1987, 1166, 2024], [1181, 1987, 1348, 2015], [1362, 1987, 1505, 2024], [1523, 1987, 1580, 2015], [1595, 1987, 1644, 2015], [1659, 1987, 1742, 2024], [1757, 1996, 1818, 2015], [1834, 1987, 1996, 2024], [2010, 1987, 2099, 2024], [449, 2033, 693, 2061], [704, 2033, 815, 2070], [825, 2033, 896, 2061], [908, 2033, 1044, 2070], [1054, 2033, 1126, 2061], [1137, 2042, 1225, 2061], [1236, 2033, 1426, 2061], [1442, 2033, 1506, 2061], [1517, 2033, 1648, 2061], [1659, 2042, 1759, 2061], [1771, 2033, 1807, 2061], [1814, 2033, 1863, 2061], [1874, 2037, 1934, 2061], [1944, 2037, 2008, 2061], [2020, 2042, 2099, 2061], [450, 2079, 612, 2107], [623, 2079, 712, 2116], [725, 2079, 884, 2116], [896, 2088, 930, 2107], [941, 2079, 1028, 2108], [1032, 2079, 1079, 2107], [1082, 2088, 1162, 2107], [1173, 2079, 1212, 2107], [1224, 2088, 1295, 2107], [1307, 2079, 1386, 2107], [1397, 2079, 1487, 2107], [1498, 2079, 1526, 2113], [1538, 2079, 1611, 2107], [1623, 2088, 1678, 2107], [1689, 2079, 1795, 2116], [1807, 2079, 1865, 2107], [1876, 2083, 2011, 2116], [2012, 2079, 2097, 2107], [451, 2124, 539, 2152], [552, 2124, 737, 2161], [750, 2124, 799, 2152], [812, 2124, 889, 2161], [903, 2124, 1111, 2152], [1126, 2124, 1161, 2152], [1175, 2124, 1234, 2158], [1253, 2124, 1299, 2158], [1315, 2124, 1355, 2161], [1370, 2133, 1386, 2152], [1398, 2124, 1479, 2161], [1492, 2124, 1615, 2161], [1635, 2124, 1699, 2152], [1711, 2124, 1917, 2152], [1930, 2124, 1966, 2152], [1976, 2124, 2026, 2152], [2039, 2128, 2099, 2152], [450, 2174, 514, 2198], [527, 2170, 639, 2198], [650, 2170, 785, 2207], [788, 2170, 862, 2198], [872, 2170, 978, 2198], [992, 2170, 1035, 2205], [1046, 2170, 1107, 2198], [1118, 2170, 1190, 2198], [1202, 2170, 1251, 2198], [1263, 2170, 1445, 2207], [1456, 2170, 1655, 2207], [1669, 2170, 1787, 2205], [1801, 2170, 1858, 2198], [1870, 2170, 1894, 2198], [1907, 2170, 2099, 2207], [450, 2220, 481, 2244], [493, 2216, 542, 2244], [554, 2225, 626, 2253], [637, 2220, 738, 2244], [751, 2216, 995, 2244], [1006, 2216, 1215, 2244], [1227, 2216, 1344, 2244], [1360, 2216, 1419, 2250], [1433, 2216, 1482, 2250], [1495, 2216, 1557, 2250], [652, 2311, 742, 2339], [754, 2311, 782, 2339], [799, 2311, 899, 2340], [911, 2319, 1048, 2340], [1049, 2310, 1170, 2347], [1182, 2311, 1272, 2340], [1284, 2310, 1387, 2348], [1400, 2319, 1442, 2340], [1455, 2310, 1612, 2340], [1626, 2311, 1691, 2340], [1704, 2310, 1896, 2339], [780, 2421, 943, 2451], [452, 2875, 631, 2905], [644, 2875, 762, 2905], [775, 2876, 840, 2905], [853, 2876, 1007, 2913], [1020, 2876, 1117, 2905], [1130, 2875, 1180, 2905], [1193, 2875, 1351, 2905], [1366, 2875, 1600, 2905], [1618, 2877, 1650, 2904], [1663, 2876, 1725, 2913], [1741, 2876, 1758, 2905], [1773, 2885, 1820, 2904], [1833, 2876, 1917, 2904], [1930, 2876, 1979, 2904], [1992, 2876, 2098, 2904], [452, 2921, 518, 2949], [529, 2921, 635, 2949], [646, 2921, 693, 2949], [703, 2921, 837, 2950], [843, 2921, 1084, 2949], [1093, 2921, 1183, 2958], [1193, 2930, 1248, 2949], [1257, 2925, 1442, 2949], [1453, 2921, 1563, 2955], [1576, 2921, 1676, 2949], [1687, 2921, 1824, 2950], [1837, 2918, 1941, 2951], [1955, 2930, 2099, 2958], [451, 2976, 470, 2995], [471, 2967, 550, 2995], [561, 2967, 624, 2995], [634, 2967, 748, 2995], [760, 2967, 829, 3004], [840, 2967, 902, 3002], [913, 2967, 969, 2995], [978, 2976, 1041, 2995], [1052, 2967, 1088, 2995], [1095, 2967, 1185, 2995], [1197, 2967, 1236, 3002], [1253, 2968, 1306, 2995], [1317, 2967, 1381, 2995], [1392, 2967, 1536, 2996], [1546, 2967, 1596, 2995], [1606, 2967, 1842, 3004], [1852, 2967, 1996, 3004], [2007, 2967, 2099, 2995], [451, 3013, 481, 3041], [493, 3013, 555, 3050], [569, 3013, 596, 3042], [451, 354, 514, 382], [527, 358, 617, 382], [630, 354, 707, 382], [721, 354, 813, 382], [826, 354, 1023, 391], [1038, 358, 1068, 382], [1080, 355, 1278, 391], [1291, 354, 1379, 388], [1394, 354, 1494, 382], [1507, 354, 1531, 382], [1546, 354, 1694, 382], [1707, 354, 1779, 382], [1791, 354, 2027, 391], [2042, 354, 2099, 382], [449, 400, 689, 437], [701, 400, 822, 428], [839, 401, 892, 428], [904, 400, 978, 428], [980, 400, 1071, 428], [1083, 400, 1139, 428], [1153, 400, 1177, 428], [1190, 400, 1249, 428], [1260, 404, 1291, 428], [1302, 404, 1362, 428], [1373, 409, 1505, 428], [1522, 400, 1605, 434], [1618, 400, 1667, 428], [1680, 400, 1786, 437], [1797, 400, 1944, 429], [1955, 400, 2097, 428], [449, 446, 647, 482], [662, 445, 734, 473], [749, 445, 993, 482], [1011, 445, 1111, 473], [1126, 454, 1182, 473], [1196, 445, 1235, 473], [1250, 445, 1361, 473], [1375, 445, 1416, 482], [1431, 445, 1481, 473], [1497, 445, 1667, 482], [1681, 454, 1826, 482], [1841, 445, 1877, 473], [1888, 445, 2000, 473], [2016, 445, 2097, 473], [450, 491, 481, 519], [495, 491, 568, 519], [582, 491, 703, 519], [729, 491, 857, 525], [874, 491, 923, 519], [938, 491, 1084, 528], [1098, 491, 1245, 520], [1259, 491, 1401, 519], [1416, 492, 1614, 528], [1628, 491, 1700, 519], [1714, 491, 1962, 528], [1980, 500, 2011, 519], [2026, 491, 2099, 519], [451, 537, 565, 565], [578, 537, 699, 565], [710, 537, 861, 574], [874, 537, 989, 565], [1001, 541, 1130, 574], [1144, 537, 1236, 572], [1248, 537, 1373, 574], [1384, 546, 1425, 574], [1438, 537, 1495, 565], [1507, 537, 1618, 572], [630, 675, 738, 712], [642, 710, 738, 781], [636, 914, 737, 973], [615, 1005, 622, 1017], [648, 1290, 679, 1301], [723, 1289, 737, 1302], [644, 1350, 738, 1549], [611, 1538, 643, 1549], [735, 1896, 937, 2019], [939, 1895, 1055, 2002], [1056, 1895, 1326, 2017], [1329, 1896, 1546, 1984], [1550, 1895, 1926, 2020], [577, 2038, 684, 2075], [696, 2038, 724, 2067], [742, 2037, 921, 2067], [934, 2037, 1052, 2067], [1064, 2037, 1100, 2067], [1109, 2046, 1128, 2067], [1140, 2040, 1338, 2067], [1350, 2038, 1445, 2067], [1447, 2038, 1510, 2067], [1523, 2038, 1558, 2066], [1560, 2037, 1658, 2067], [1670, 2037, 1745, 2075], [1757, 2037, 1793, 2067], [1802, 2037, 1971, 2067], [451, 2197, 474, 2231], [526, 2197, 780, 2232], [795, 2197, 874, 2232], [888, 2197, 1095, 2232], [1110, 2197, 1171, 2232], [1185, 2197, 1466, 2241], [451, 2279, 503, 2306], [516, 2278, 668, 2315], [683, 2287, 699, 2306], [713, 2278, 790, 2315], [804, 2278, 874, 2307], [876, 2278, 1124, 2306], [1138, 2278, 1241, 2306], [1255, 2278, 1327, 2306], [1341, 2278, 1534, 2315], [1547, 2278, 1765, 2315], [1781, 2278, 1881, 2306], [1895, 2278, 2097, 2315], [452, 2328, 585, 2361], [603, 2324, 709, 2361], [727, 2324, 784, 2352], [802, 2324, 948, 2361], [964, 2324, 1152, 2361], [1170, 2328, 1293, 2352], [1311, 2324, 1405, 2352], [1422, 2333, 1462, 2352], [1479, 2324, 1650, 2353], [1682, 2324, 1840, 2361], [1857, 2324, 1879, 2352], [1897, 2333, 2019, 2361], [2038, 2324, 2099, 2352], [451, 2369, 578, 2406], [595, 2378, 611, 2397], [627, 2369, 773, 2406], [789, 2369, 935, 2398], [951, 2378, 991, 2397], [1007, 2369, 1118, 2406], [1134, 2369, 1205, 2397], [1222, 2369, 1266, 2404], [1283, 2369, 1366, 2404], [1383, 2369, 1408, 2397], [1426, 2369, 1629, 2406], [1644, 2369, 1739, 2397], [1754, 2369, 1824, 2397], [1840, 2369, 1967, 2406], [1983, 2378, 2023, 2397], [2038, 2378, 2099, 2397], [452, 2415, 573, 2443], [585, 2415, 695, 2443], [711, 2415, 783, 2449], [800, 2415, 863, 2443], [875, 2415, 960, 2443], [971, 2415, 995, 2443], [1008, 2415, 1154, 2452], [1166, 2419, 1218, 2443], [1230, 2415, 1430, 2452], [1445, 2415, 1502, 2443], [1514, 2415, 1610, 2452], [1620, 2415, 1737, 2452], [1750, 2415, 1955, 2443], [1967, 2415, 2097, 2452], [452, 2460, 512, 2495], [525, 2460, 672, 2497], [688, 2469, 704, 2488], [717, 2460, 923, 2488], [937, 2460, 1009, 2488], [1022, 2460, 1072, 2488], [1085, 2460, 1162, 2497], [1175, 2460, 1328, 2497], [1343, 2460, 1492, 2497], [1505, 2460, 1541, 2488], [1555, 2460, 1641, 2495], [1662, 2460, 1788, 2497], [1800, 2460, 1889, 2497], [1903, 2460, 2014, 2497], [2028, 2460, 2099, 2488], [452, 2515, 482, 2534], [496, 2506, 589, 2543], [604, 2515, 658, 2534], [670, 2506, 816, 2543], [829, 2506, 932, 2534], [944, 2506, 1017, 2534], [1032, 2510, 1083, 2534], [1095, 2506, 1212, 2543], [1226, 2506, 1397, 2543], [1408, 2506, 1640, 2543], [1656, 2506, 1739, 2534], [1752, 2506, 1801, 2534], [1814, 2506, 1884, 2534], [1898, 2506, 1922, 2534], [1937, 2506, 2099, 2543], [450, 2552, 539, 2589], [552, 2561, 568, 2580], [580, 2552, 702, 2580], [714, 2552, 807, 2580], [819, 2561, 859, 2580], [871, 2552, 921, 2580], [932, 2552, 1052, 2589], [1066, 2552, 1267, 2589], [1281, 2552, 1316, 2580], [1326, 2556, 1489, 2589], [1502, 2552, 1560, 2580], [1573, 2552, 1771, 2580], [451, 2622, 493, 2650], [506, 2631, 553, 2650], [564, 2622, 640, 2651], [652, 2622, 757, 2650], [760, 2626, 842, 2656], [844, 2622, 999, 2659], [1010, 2622, 1078, 2650], [1089, 2622, 1114, 2650], [1126, 2622, 1287, 2650], [1298, 2622, 1346, 2650], [1356, 2631, 1411, 2650], [1422, 2622, 1568, 2659], [1579, 2622, 1734, 2656], [1749, 2631, 1783, 2650], [1794, 2631, 1822, 2650], [1824, 2631, 1902, 2650], [1912, 2622, 2057, 2659], [2068, 2626, 2099, 2650], [451, 2668, 525, 2696], [536, 2668, 558, 2696], [569, 2677, 609, 2696], [620, 2668, 701, 2705], [712, 2668, 803, 2697], [814, 2668, 953, 2702], [967, 2668, 1040, 2696], [1053, 2677, 1083, 2696], [1096, 2668, 1145, 2696], [1155, 2668, 1288, 2705], [1299, 2668, 1434, 2696], [1446, 2668, 1607, 2696], [1619, 2668, 1655, 2696], [1666, 2668, 1738, 2702], [1755, 2668, 1836, 2702], [1848, 2668, 1995, 2702], [2007, 2677, 2097, 2705], [452, 2723, 468, 2742], [480, 2714, 651, 2751], [663, 2714, 820, 2751], [832, 2723, 872, 2742], [884, 2714, 920, 2742], [934, 2723, 1002, 2742], [1014, 2714, 1054, 2742], [1056, 2718, 1115, 2742], [1127, 2714, 1177, 2742], [1189, 2714, 1320, 2751], [1333, 2723, 1444, 2742], [1445, 2714, 1503, 2742], [1512, 2714, 1640, 2751], [1652, 2714, 1720, 2742], [1732, 2714, 1882, 2751], [1894, 2714, 1983, 2749], [451, 2784, 546, 2812], [565, 2784, 625, 2812], [642, 2784, 757, 2812], [777, 2793, 862, 2812], [880, 2784, 1022, 2812], [1040, 2784, 1221, 2821], [1241, 2784, 1277, 2812], [1293, 2784, 1342, 2812], [1361, 2784, 1605, 2812], [1625, 2784, 1750, 2812], [1768, 2784, 2002, 2821], [2024, 2784, 2097, 2818], [451, 2830, 550, 2858], [569, 2839, 618, 2858], [636, 2830, 749, 2858], [767, 2830, 798, 2858], [816, 2839, 871, 2858], [888, 2834, 1004, 2858], [1023, 2830, 1224, 2858], [1259, 2830, 1322, 2858], [1340, 2834, 1419, 2858], [1436, 2830, 1606, 2867], [1624, 2839, 1683, 2858], [1701, 2830, 1725, 2858], [1745, 2830, 1824, 2858], [1842, 2830, 1956, 2858], [1973, 2830, 2099, 2867], [451, 2885, 522, 2905], [535, 2876, 793, 2913], [805, 2876, 899, 2910], [913, 2876, 1052, 2904], [1066, 2880, 1093, 2904], [1105, 2876, 1154, 2904], [1166, 2876, 1357, 2913], [1375, 2877, 1457, 2905], [1470, 2876, 1583, 2913], [1596, 2876, 1645, 2904], [1657, 2876, 1741, 2913], [1754, 2876, 1799, 2911], [1812, 2880, 1947, 2913], [1961, 2876, 2010, 2904], [2022, 2876, 2098, 2913], [451, 2921, 497, 2949], [510, 2921, 581, 2949], [596, 2921, 685, 2958], [698, 2921, 748, 2949], [761, 2921, 952, 2958], [967, 2921, 1016, 2949], [1030, 2921, 1136, 2958], [1148, 2921, 1274, 2958], [1288, 2921, 1318, 2949], [1331, 2930, 1386, 2949], [1398, 2921, 1533, 2949], [1545, 2921, 1618, 2949], [1633, 2925, 1684, 2949], [1698, 2921, 1765, 2949], [1778, 2921, 1827, 2949], [1840, 2921, 2021, 2958], [2036, 2921, 2099, 2949], [452, 2971, 586, 2995], [603, 2967, 723, 2995], [724, 2967, 892, 3004], [904, 2976, 971, 2995], [982, 2967, 1017, 2995], [1026, 2967, 1233, 3004], [1234, 2967, 1280, 2995], [1293, 2967, 1415, 3004], [1425, 2967, 1570, 3004], [1581, 2967, 1617, 2995], [1625, 2976, 1744, 2995], [1755, 2967, 1879, 3001], [1892, 2967, 1992, 2995], [2003, 2967, 2034, 2995], [2045, 2976, 2100, 2995], [451, 3022, 521, 3041], [532, 3013, 557, 3041], [570, 3013, 785, 3050], [796, 3013, 837, 3050], [849, 3022, 938, 3041], [950, 3013, 1155, 3050], [1157, 3013, 1370, 3041], [618, 1091, 1247, 1242], [1241, 1064, 1590, 1238], [1581, 1123, 1872, 1210], [601, 1259, 708, 1296], [720, 1259, 747, 1288], [765, 1259, 919, 1288], [932, 1259, 1029, 1288], [1041, 1258, 1076, 1288], [1086, 1267, 1105, 1288], [1117, 1261, 1314, 1288], [1326, 1259, 1433, 1288], [1445, 1267, 1487, 1288], [1499, 1259, 1534, 1287], [1536, 1258, 1635, 1288], [1647, 1258, 1721, 1296], [1733, 1258, 1769, 1288], [1778, 1181, 1948, 1288], [450, 1325, 860, 1369], [451, 1406, 521, 1434], [534, 1406, 618, 1434], [628, 1415, 689, 1434], [703, 1406, 864, 1443], [874, 1406, 915, 1443], [927, 1406, 1005, 1435], [1017, 1410, 1101, 1443], [1112, 1406, 1229, 1434], [1241, 1415, 1289, 1434], [1306, 1406, 1436, 1435], [1453, 1407, 1506, 1434], [1517, 1406, 1677, 1443], [1689, 1406, 1905, 1443], [1916, 1406, 1965, 1434], [1977, 1410, 2099, 1443], [451, 1451, 486, 1479], [495, 1451, 641, 1479], [653, 1451, 852, 1488], [864, 1451, 936, 1479], [949, 1451, 998, 1479], [1010, 1451, 1153, 1479], [1165, 1451, 1201, 1479], [1210, 1451, 1260, 1479], [1271, 1451, 1352, 1480], [1355, 1460, 1435, 1479], [1436, 1451, 1515, 1479], [1526, 1451, 1583, 1479], [1596, 1451, 1741, 1479], [451, 1528, 680, 1563], [471, 1609, 508, 1640], [471, 1707, 508, 1738], [471, 1804, 508, 1835], [471, 1902, 508, 1933], [471, 1999, 508, 2030], [471, 2096, 508, 2128], [471, 2194, 508, 2225], [471, 2292, 508, 2323], [471, 2389, 508, 2420], [453, 2487, 508, 2518], [452, 2584, 508, 2615], [453, 2682, 508, 2713], [452, 2779, 508, 2810], [453, 2877, 508, 2908], [452, 2974, 508, 3005], [534, 1609, 566, 1634], [585, 1609, 663, 1642], [681, 1609, 703, 1634], [721, 1609, 808, 1642], [827, 1609, 879, 1634], [895, 1609, 925, 1634], [942, 1609, 1057, 1634], [1090, 1609, 1176, 1642], [1193, 1609, 1265, 1634], [1282, 1609, 1370, 1634], [1385, 1609, 1554, 1642], [1571, 1609, 1713, 1642], [1730, 1609, 1893, 1641], [1911, 1609, 1992, 1635], [2026, 1609, 2099, 1634], [534, 1653, 636, 1683], [649, 1651, 978, 1683], [991, 1651, 1595, 1683], [534, 1707, 560, 1732], [576, 1707, 657, 1737], [674, 1707, 707, 1732], [723, 1707, 823, 1737], [839, 1707, 873, 1732], [889, 1706, 1052, 1740], [1069, 1707, 1121, 1732], [1135, 1707, 1156, 1732], [1172, 1707, 1312, 1732], [1341, 1707, 1414, 1740], [1428, 1715, 1559, 1740], [1574, 1707, 1674, 1740], [1688, 1707, 1752, 1732], [1767, 1707, 1921, 1732], [1934, 1706, 2019, 1732], [2034, 1715, 2069, 1732], [2084, 1715, 2100, 1732], [533, 1748, 627, 1781], [638, 1747, 681, 1773], [691, 1748, 819, 1781], [836, 1748, 865, 1773], [875, 1749, 951, 1773], [965, 1748, 1068, 1778], [1079, 1756, 1163, 1781], [1175, 1747, 1274, 1778], [1287, 1748, 1368, 1774], [534, 1804, 566, 1829], [578, 1804, 721, 1834], [733, 1804, 766, 1829], [778, 1804, 934, 1837], [946, 1804, 979, 1829], [991, 1804, 1111, 1834], [1123, 1804, 1175, 1829], [1185, 1804, 1218, 1829], [1229, 1804, 1391, 1829], [1406, 1804, 1506, 1829], [1516, 1803, 1547, 1829], [1555, 1804, 1599, 1829], [1609, 1804, 1681, 1829], [1691, 1804, 1718, 1829], [1728, 1804, 1773, 1829], [1782, 1804, 1886, 1829], [1901, 1804, 2020, 1837], [2030, 1804, 2099, 1837], [533, 1846, 590, 1871], [601, 1846, 803, 1871], [814, 1849, 880, 1871], [897, 1846, 926, 1871], [936, 1847, 1012, 1871], [1026, 1846, 1144, 1876], [1156, 1846, 1237, 1872], [534, 1902, 564, 1927], [580, 1902, 665, 1932], [680, 1902, 702, 1927], [717, 1902, 750, 1927], [766, 1902, 841, 1935], [857, 1902, 888, 1927], [903, 1902, 1012, 1932], [1028, 1902, 1080, 1927], [1093, 1902, 1127, 1927], [1143, 1902, 1176, 1927], [1189, 1902, 1298, 1927], [1324, 1902, 1401, 1935], [1415, 1902, 1536, 1935], [1550, 1901, 1581, 1927], [1593, 1902, 1722, 1927], [1737, 1902, 1969, 1935], [1982, 1901, 2098, 1927], [533, 1942, 605, 1968], [615, 1943, 704, 1968], [721, 1943, 751, 1968], [760, 1943, 840, 1969], [849, 1944, 927, 1976], [937, 1944, 1073, 1976], [1084, 1942, 1141, 1968], [1153, 1942, 1356, 1976], [1364, 1944, 1476, 1968], [1487, 1944, 1623, 1976], [1636, 1943, 1788, 1976], [1801, 1943, 1882, 1969], [534, 1999, 564, 2024], [577, 1998, 717, 2025], [727, 1999, 779, 2024], [789, 1999, 811, 2024], [822, 1999, 940, 2024], [956, 1999, 981, 2024], [992, 1999, 1095, 2024], [1105, 1999, 1280, 2024], [1291, 1998, 1334, 2024], [1343, 1999, 1446, 2024], [1456, 1999, 1590, 2032], [1599, 1999, 1766, 2032], [1782, 1999, 1851, 2032], [1861, 1999, 1953, 2024], [1964, 1999, 2098, 2024], [533, 2041, 598, 2066], [609, 2041, 748, 2066], [758, 2041, 886, 2074], [903, 2041, 932, 2066], [942, 2042, 1018, 2066], [1032, 2041, 1128, 2071], [1140, 2049, 1223, 2074], [1238, 2040, 1372, 2071], [1385, 2041, 1465, 2067], [534, 2097, 566, 2122], [583, 2097, 710, 2123], [710, 2097, 789, 2122], [803, 2097, 831, 2122], [848, 2097, 949, 2130], [976, 2097, 1020, 2122], [1035, 2097, 1079, 2122], [1093, 2097, 1263, 2130], [1278, 2097, 1511, 2130], [1526, 2096, 1557, 2122], [1569, 2097, 1718, 2122], [1733, 2096, 1922, 2122], [1937, 2100, 2029, 2122], [2042, 2105, 2098, 2122], [533, 2138, 635, 2163], [651, 2139, 749, 2168], [762, 2137, 928, 2168], [940, 2138, 1021, 2164], [533, 2194, 559, 2219], [562, 2194, 658, 2219], [667, 2194, 720, 2219], [730, 2194, 751, 2219], [763, 2194, 865, 2227], [880, 2194, 1036, 2227], [1046, 2193, 1077, 2219], [1085, 2194, 1214, 2219], [1224, 2194, 1367, 2220], [1378, 2193, 1421, 2219], [1430, 2194, 1538, 2219], [1548, 2194, 1699, 2219], [1714, 2194, 1743, 2219], [1752, 2195, 1828, 2219], [1843, 2194, 1941, 2224], [1953, 2194, 2047, 2219], [2048, 2194, 2097, 2224], [532, 2244, 616, 2269], [629, 2235, 765, 2266], [777, 2236, 858, 2262], [533, 2292, 559, 2317], [562, 2292, 666, 2322], [679, 2292, 710, 2317], [723, 2292, 825, 2325], [838, 2292, 890, 2317], [901, 2292, 932, 2318], [946, 2292, 1065, 2317], [1082, 2292, 1191, 2317], [1202, 2292, 1337, 2317], [1347, 2292, 1428, 2325], [1439, 2292, 1560, 2317], [1570, 2292, 1732, 2325], [1744, 2291, 1776, 2317], [1785, 2292, 1848, 2317], [1860, 2292, 1912, 2317], [1923, 2300, 2097, 2325], [533, 2333, 563, 2358], [573, 2334, 649, 2358], [663, 2333, 765, 2363], [777, 2341, 860, 2366], [871, 2333, 1009, 2363], [1022, 2332, 1102, 2359], [533, 2389, 565, 2414], [569, 2389, 619, 2414], [633, 2389, 758, 2415], [770, 2389, 822, 2414], [834, 2389, 867, 2414], [881, 2389, 914, 2414], [927, 2389, 1033, 2414], [1054, 2389, 1180, 2422], [1192, 2389, 1280, 2414], [1291, 2389, 1430, 2422], [1443, 2388, 1486, 2414], [1496, 2389, 1653, 2422], [1665, 2389, 1717, 2414], [1729, 2389, 1826, 2414], [1847, 2388, 1945, 2414], [1958, 2390, 1983, 2414], [1994, 2390, 2098, 2415], [533, 2432, 664, 2461], [680, 2431, 867, 2463], [883, 2431, 961, 2457], [533, 2487, 565, 2512], [569, 2487, 655, 2517], [672, 2487, 705, 2512], [721, 2487, 814, 2520], [832, 2487, 884, 2512], [899, 2487, 921, 2512], [938, 2487, 1097, 2520], [1125, 2487, 1216, 2512], [1230, 2487, 1379, 2520], [1394, 2487, 1498, 2512], [1512, 2486, 1556, 2512], [1568, 2486, 1654, 2512], [1667, 2487, 1757, 2512], [1770, 2487, 1948, 2520], [1976, 2487, 2006, 2512], [2019, 2488, 2095, 2512], [534, 2528, 625, 2554], [628, 2536, 728, 2561], [740, 2527, 914, 2558], [927, 2528, 1008, 2554], [534, 2584, 566, 2609], [581, 2584, 693, 2617], [709, 2584, 735, 2609], [751, 2584, 835, 2614], [850, 2584, 880, 2609], [894, 2583, 975, 2614], [990, 2584, 1043, 2609], [1056, 2584, 1082, 2609], [1097, 2584, 1209, 2617], [1234, 2584, 1259, 2609], [1271, 2583, 1449, 2617], [1463, 2584, 1581, 2617], [1596, 2587, 1697, 2617], [1710, 2583, 1753, 2609], [1766, 2584, 1855, 2609], [1868, 2584, 2045, 2617], [2069, 2584, 2099, 2609], [532, 2627, 608, 2651], [622, 2626, 714, 2656], [726, 2634, 809, 2659], [824, 2626, 883, 2656], [896, 2626, 977, 2652], [535, 2682, 560, 2707], [572, 2682, 604, 2712], [615, 2682, 654, 2707], [665, 2682, 718, 2712], [729, 2682, 769, 2707], [782, 2682, 865, 2715], [877, 2682, 930, 2707], [940, 2682, 973, 2707], [985, 2682, 1033, 2707], [1050, 2682, 1093, 2707], [1104, 2682, 1306, 2707], [1316, 2682, 1408, 2707], [1418, 2682, 1552, 2707], [1564, 2681, 1607, 2707], [1615, 2682, 1716, 2707], [1727, 2682, 1817, 2707], [1826, 2682, 2004, 2715], [2019, 2683, 2101, 2707], [532, 2723, 625, 2753], [639, 2723, 866, 2755], [879, 2723, 959, 2749], [534, 2779, 562, 2804], [574, 2779, 622, 2804], [640, 2778, 728, 2805], [745, 2779, 789, 2804], [800, 2787, 871, 2812], [884, 2787, 979, 2804], [990, 2779, 1192, 2804], [1203, 2779, 1378, 2804], [1389, 2778, 1432, 2804], [1442, 2778, 1494, 2804], [1506, 2778, 1608, 2804], [1619, 2778, 1791, 2812], [1810, 2781, 1912, 2811], [1924, 2779, 2091, 2807], [533, 2821, 965, 2853], [978, 2821, 1059, 2847], [534, 2877, 566, 2902], [580, 2877, 722, 2910], [736, 2877, 769, 2903], [783, 2877, 912, 2907], [927, 2877, 953, 2902], [967, 2877, 1066, 2910], [1079, 2877, 1105, 2902], [1118, 2877, 1220, 2910], [1234, 2877, 1265, 2902], [1280, 2877, 1453, 2907], [1467, 2877, 1519, 2902], [1530, 2877, 1560, 2902], [1573, 2877, 1688, 2902], [1706, 2877, 1879, 2910], [1891, 2877, 1972, 2902], [1984, 2877, 2098, 2902], [533, 2918, 623, 2943], [634, 2918, 699, 2943], [710, 2918, 912, 2943], [922, 2918, 1014, 2943], [1025, 2918, 1168, 2943], [1185, 2918, 1214, 2943], [1224, 2919, 1300, 2943], [1316, 2918, 1414, 2948], [1427, 2918, 1507, 2944], [534, 2974, 566, 2999], [582, 2974, 756, 3007], [772, 2974, 790, 2999], [807, 2974, 956, 3004], [972, 2974, 1024, 2999], [1038, 2974, 1071, 3000], [1085, 2974, 1115, 2999], [1130, 2974, 1240, 2999], [1265, 2974, 1400, 3007], [1402, 2974, 1617, 2999], [1631, 2974, 1696, 2999], [1709, 2974, 1778, 3007], [1792, 2974, 1994, 2999], [2007, 2974, 2099, 2999], [533, 3016, 676, 3041], [693, 3016, 722, 3041], [731, 3016, 818, 3046], [830, 3024, 913, 3049], [928, 3015, 1099, 3046], [1112, 3016, 1193, 3042], [1259, 3137, 1295, 3166], [453, 356, 508, 388], [452, 457, 508, 488], [452, 556, 508, 587], [453, 656, 508, 687], [453, 756, 508, 787], [452, 855, 508, 886], [452, 955, 508, 986], [452, 1054, 508, 1085], [452, 1154, 508, 1185], [452, 1254, 508, 1285], [452, 1352, 508, 1384], [453, 1453, 508, 1484], [453, 1553, 508, 1584], [452, 1652, 508, 1683], [453, 1752, 508, 1783], [453, 1851, 508, 1882], [534, 357, 566, 382], [581, 357, 703, 387], [718, 357, 751, 382], [764, 357, 877, 390], [891, 357, 921, 382], [936, 357, 1056, 387], [1071, 357, 1097, 382], [1112, 357, 1224, 390], [1239, 357, 1291, 382], [1304, 357, 1330, 382], [1346, 357, 1429, 382], [1452, 357, 1561, 382], [1567, 357, 1611, 382], [1624, 357, 1697, 390], [1710, 357, 1791, 382], [1804, 356, 1931, 382], [1944, 356, 1987, 382], [1998, 357, 2099, 382], [533, 399, 638, 424], [648, 399, 825, 432], [842, 399, 871, 424], [881, 400, 957, 424], [971, 399, 1063, 429], [1075, 407, 1158, 432], [1170, 398, 1344, 429], [1357, 399, 1437, 425], [534, 457, 552, 482], [563, 457, 670, 490], [682, 457, 722, 482], [733, 457, 895, 487], [908, 457, 939, 483], [952, 457, 1071, 487], [1083, 457, 1135, 482], [1146, 457, 1177, 482], [1189, 456, 1348, 482], [1363, 457, 1497, 490], [1506, 457, 1623, 482], [1633, 457, 1734, 482], [1745, 457, 1848, 482], [1859, 456, 1931, 482], [1941, 457, 2054, 482], [2069, 457, 2099, 482], [532, 499, 608, 523], [624, 498, 723, 528], [735, 498, 816, 524], [534, 556, 566, 588], [580, 556, 608, 581], [620, 556, 666, 586], [678, 556, 717, 581], [730, 556, 758, 581], [770, 556, 838, 586], [852, 556, 878, 581], [891, 556, 919, 581], [932, 556, 1034, 589], [1047, 556, 1099, 581], [1110, 556, 1143, 581], [1156, 556, 1185, 581], [1197, 556, 1249, 589], [1266, 556, 1400, 589], [1411, 556, 1587, 581], [1598, 556, 1727, 581], [1739, 556, 1971, 589], [1982, 555, 2098, 581], [533, 597, 577, 623], [586, 598, 676, 623], [686, 598, 856, 631], [867, 598, 931, 623], [942, 598, 1124, 631], [1135, 597, 1268, 631], [1278, 598, 1405, 631], [1422, 598, 1451, 623], [1461, 599, 1537, 623], [1553, 598, 1651, 628], [1663, 606, 1746, 631], [1759, 597, 1932, 628], [1945, 598, 2026, 624], [534, 656, 562, 681], [573, 656, 674, 682], [676, 656, 724, 686], [736, 656, 828, 686], [839, 656, 860, 681], [873, 656, 899, 681], [911, 656, 1025, 686], [1037, 656, 1070, 681], [1082, 656, 1250, 686], [1262, 656, 1293, 681], [1303, 656, 1333, 681], [1345, 656, 1470, 686], [1481, 656, 1520, 681], [1532, 655, 1669, 686], [1681, 656, 1733, 681], [1742, 656, 1772, 681], [1784, 656, 1817, 681], [1828, 656, 1928, 681], [1943, 656, 2098, 689], [533, 697, 642, 730], [653, 697, 761, 730], [772, 700, 799, 722], [809, 697, 987, 722], [998, 697, 1042, 730], [1053, 697, 1122, 722], [1132, 697, 1309, 730], [1324, 697, 1428, 723], [1440, 697, 1640, 730], [1655, 697, 1862, 729], [1877, 697, 1955, 723], [533, 756, 566, 781], [578, 756, 659, 789], [670, 756, 700, 781], [711, 756, 804, 789], [815, 756, 849, 781], [860, 756, 954, 789], [966, 756, 1018, 781], [1028, 756, 1056, 781], [1068, 756, 1147, 788], [1162, 756, 1221, 789], [1231, 755, 1263, 781], [1271, 756, 1358, 781], [1369, 756, 1457, 781], [1468, 756, 1520, 781], [1531, 755, 1622, 781], [1633, 756, 1743, 781], [1746, 755, 1811, 781], [1820, 756, 1910, 781], [1919, 756, 2096, 789], [533, 797, 765, 830], [777, 797, 855, 830], [866, 797, 918, 822], [929, 797, 1002, 830], [1012, 797, 1138, 830], [1156, 797, 1250, 827], [1262, 796, 1487, 827], [1500, 797, 1581, 823], [533, 855, 566, 880], [580, 855, 661, 888], [675, 855, 706, 881], [718, 855, 786, 885], [800, 855, 828, 880], [841, 855, 920, 887], [934, 855, 986, 880], [998, 855, 1031, 887], [1045, 855, 1126, 888], [1146, 855, 1246, 880], [1257, 855, 1426, 888], [1438, 855, 1503, 880], [1516, 855, 1625, 880], [1637, 855, 1719, 880], [1730, 858, 1844, 880], [1864, 855, 1893, 880], [1904, 856, 1980, 880], [1995, 855, 2097, 885], [532, 905, 616, 930], [628, 897, 765, 927], [777, 897, 858, 923], [533, 955, 557, 980], [568, 955, 722, 985], [732, 955, 754, 980], [766, 955, 895, 985], [907, 955, 959, 980], [969, 955, 995, 980], [1005, 955, 1143, 980], [1156, 955, 1312, 988], [1321, 955, 1365, 980], [1374, 955, 1468, 980], [1475, 955, 1567, 980], [1577, 954, 1620, 980], [1628, 955, 1788, 988], [1797, 955, 1870, 988], [1872, 955, 2097, 980], [533, 996, 563, 1021], [573, 997, 649, 1021], [663, 996, 765, 1026], [778, 996, 858, 1022], [534, 1054, 566, 1079], [581, 1054, 737, 1087], [752, 1054, 785, 1079], [799, 1054, 919, 1084], [933, 1054, 985, 1079], [998, 1054, 1031, 1079], [1044, 1054, 1206, 1079], [1227, 1054, 1305, 1087], [1316, 1054, 1410, 1079], [1421, 1054, 1555, 1079], [1568, 1053, 1611, 1079], [1622, 1054, 1782, 1087], [1794, 1054, 1867, 1087], [1869, 1054, 2097, 1079], [533, 1096, 563, 1121], [572, 1096, 659, 1126], [672, 1096, 752, 1122], [534, 1154, 566, 1179], [581, 1154, 704, 1184], [717, 1154, 750, 1179], [763, 1154, 794, 1179], [807, 1154, 903, 1184], [917, 1154, 969, 1179], [979, 1154, 1020, 1179], [1034, 1154, 1114, 1179], [1132, 1154, 1267, 1180], [1284, 1154, 1309, 1179], [1320, 1154, 1423, 1179], [1434, 1153, 1466, 1179], [1478, 1154, 1526, 1180], [1540, 1154, 1641, 1179], [1652, 1154, 1756, 1179], [1768, 1154, 1869, 1179], [1882, 1153, 1953, 1179], [1964, 1154, 2059, 1179], [2071, 1154, 2099, 1179], [533, 1196, 578, 1221], [588, 1196, 661, 1221], [679, 1196, 773, 1226], [786, 1195, 1011, 1226], [1023, 1196, 1104, 1222], [534, 1254, 566, 1280], [580, 1254, 615, 1279], [615, 1254, 734, 1287], [749, 1254, 780, 1279], [793, 1254, 901, 1287], [916, 1254, 944, 1279], [958, 1254, 1066, 1284], [1081, 1254, 1133, 1279], [1146, 1254, 1177, 1280], [1191, 1254, 1307, 1287], [1329, 1254, 1539, 1280], [1552, 1254, 1672, 1287], [1685, 1253, 1717, 1279], [1728, 1254, 1960, 1287], [1973, 1253, 2097, 1279], [533, 1295, 563, 1320], [573, 1296, 649, 1320], [663, 1295, 765, 1325], [777, 1303, 860, 1328], [875, 1295, 1009, 1325], [1022, 1295, 1102, 1321], [534, 1353, 566, 1378], [576, 1353, 662, 1386], [671, 1353, 723, 1378], [732, 1353, 763, 1379], [775, 1353, 894, 1378], [907, 1353, 1007, 1378], [1015, 1353, 1185, 1386], [1194, 1353, 1259, 1378], [1268, 1353, 1390, 1386], [1391, 1353, 1589, 1386], [1602, 1353, 1632, 1378], [1640, 1354, 1716, 1378], [1728, 1353, 1820, 1383], [1829, 1361, 1913, 1386], [1924, 1353, 2097, 1383], [533, 1395, 614, 1421], [534, 1453, 566, 1478], [579, 1453, 664, 1486], [675, 1453, 728, 1478], [739, 1453, 770, 1479], [784, 1453, 903, 1478], [920, 1453, 1133, 1478], [1146, 1452, 1311, 1478], [1323, 1452, 1366, 1478], [1376, 1453, 1420, 1478], [1431, 1453, 1585, 1478], [1599, 1453, 1752, 1486], [1770, 1453, 1799, 1478], [1810, 1453, 1897, 1479], [1907, 1453, 2052, 1486], [2063, 1462, 2098, 1478], [530, 1495, 628, 1520], [639, 1496, 818, 1528], [830, 1495, 893, 1521], [904, 1504, 921, 1520], [931, 1496, 1017, 1528], [1026, 1495, 1132, 1521], [1135, 1495, 1192, 1528], [1198, 1495, 1317, 1525], [1329, 1495, 1410, 1521], [534, 1553, 566, 1578], [578, 1553, 671, 1586], [683, 1553, 715, 1578], [719, 1553, 767, 1578], [771, 1553, 877, 1583], [890, 1553, 923, 1578], [936, 1553, 1038, 1583], [1051, 1553, 1069, 1578], [1081, 1553, 1188, 1586], [1201, 1553, 1253, 1578], [1264, 1553, 1295, 1579], [1309, 1553, 1428, 1578], [1444, 1553, 1605, 1578], [1616, 1552, 1647, 1578], [1656, 1553, 1727, 1578], [1739, 1553, 1971, 1586], [1982, 1552, 2098, 1578], [533, 1593, 577, 1619], [586, 1594, 676, 1619], [686, 1594, 863, 1627], [880, 1594, 909, 1619], [919, 1595, 995, 1619], [1009, 1594, 1127, 1624], [1139, 1602, 1222, 1627], [1237, 1594, 1315, 1624], [1328, 1594, 1408, 1620], [534, 1652, 566, 1677], [578, 1652, 664, 1685], [666, 1652, 709, 1682], [713, 1652, 832, 1682], [844, 1652, 875, 1678], [889, 1652, 1008, 1682], [1021, 1652, 1073, 1677], [1084, 1652, 1160, 1678], [1171, 1652, 1230, 1677], [1247, 1652, 1347, 1677], [1357, 1652, 1527, 1685], [1537, 1651, 1573, 1685], [1584, 1652, 1668, 1677], [1679, 1652, 1851, 1685], [1868, 1652, 1897, 1677], [1907, 1653, 1983, 1677], [1999, 1652, 2097, 1682], [532, 1702, 616, 1727], [629, 1693, 802, 1724], [815, 1694, 895, 1720], [534, 1752, 556, 1777], [571, 1751, 763, 1785], [779, 1752, 800, 1777], [816, 1752, 934, 1782], [949, 1752, 979, 1777], [994, 1752, 1156, 1782], [1172, 1752, 1225, 1777], [1238, 1752, 1269, 1778], [1286, 1752, 1405, 1777], [1431, 1752, 1592, 1785], [1612, 1752, 1698, 1785], [1712, 1752, 1908, 1785], [1921, 1752, 2021, 1785], [2035, 1752, 2099, 1777], [533, 1793, 598, 1818], [609, 1793, 678, 1826], [689, 1793, 834, 1826], [851, 1793, 880, 1818], [890, 1794, 966, 1818], [980, 1793, 1072, 1823], [1084, 1801, 1167, 1826], [1182, 1793, 1353, 1823], [1366, 1793, 1447, 1819], [533, 1851, 608, 1876], [612, 1851, 715, 1876], [723, 1851, 775, 1876], [784, 1851, 815, 1876], [824, 1851, 932, 1884], [944, 1851, 1113, 1884], [1122, 1851, 1174, 1876], [1182, 1851, 1393, 1884], [1401, 1851, 1603, 1876], [1612, 1851, 1754, 1876], [1767, 1851, 1862, 1881], [1872, 1850, 2097, 1881], [533, 1893, 614, 1919], [1259, 3137, 1291, 3165]], "scores": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "structures": {"pages": {"version": "1.0", "structure_value": [[0, 526], [526, 1282], [1282, 1894], [1894, 2552], [2552, 3158], [3158, 3945], [3945, 4647], [4647, 5126], [5126, 5455], [5455, 5844], [5844, 6218]], "positions": [[0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300]]}, "lines": {"version": "1.0", "structure_value": [[0, 3], [3, 8], [8, 12], [12, 18], [18, 20], [20, 21], [21, 30], [30, 42], [42, 53], [53, 65], [65, 70], [70, 81], [81, 91], [91, 105], [105, 118], [118, 131], [131, 143], [143, 155], [155, 169], [169, 185], [185, 186], [186, 188], [188, 204], [204, 220], [220, 234], [234, 248], [248, 259], [259, 273], [273, 289], [289, 307], [307, 321], [321, 334], [334, 349], [349, 366], [366, 380], [380, 396], [396, 412], [412, 426], [426, 439], [439, 449], [449, 468], [468, 482], [482, 496], [496, 510], [510, 526], [526, 540], [540, 558], [558, 573], [573, 589], [589, 603], [603, 606], [606, 620], [620, 637], [637, 649], [649, 663], [663, 675], [675, 692], [692, 705], [705, 723], [723, 732], [732, 743], [743, 758], [758, 773], [773, 785], [785, 799], [799, 813], [813, 826], [826, 839], [839, 855], [855, 872], [872, 891], [891, 904], [904, 920], [920, 936], [936, 947], [947, 961], [961, 977], [977, 991], [991, 1003], [1003, 1016], [1016, 1031], [1031, 1044], [1044, 1060], [1060, 1074], [1074, 1089], [1089, 1093], [1093, 1106], [1106, 1120], [1120, 1136], [1136, 1151], [1151, 1165], [1165, 1170], [1170, 1176], [1176, 1191], [1191, 1205], [1205, 1222], [1222, 1235], [1235, 1253], [1253, 1268], [1268, 1282], [1282, 1286], [1286, 1300], [1300, 1311], [1311, 1329], [1329, 1333], [1333, 1340], [1340, 1343], [1343, 1358], [1358, 1369], [1369, 1387], [1387, 1394], [1394, 1397], [1397, 1399], [1399, 1406], [1406, 1418], [1418, 1435], [1435, 1451], [1451, 1467], [1467, 1481], [1481, 1496], [1496, 1513], [1513, 1525], [1525, 1529], [1529, 1545], [1545, 1562], [1562, 1575], [1575, 1589], [1589, 1604], [1604, 1610], [1610, 1615], [1615, 1632], [1632, 1650], [1650, 1664], [1664, 1680], [1680, 1696], [1696, 1700], [1700, 1718], [1718, 1737], [1737, 1755], [1755, 1774], [1774, 1790], [1790, 1807], [1807, 1827], [1827, 1847], [1847, 1848], [1848, 1858], [1858, 1866], [1866, 1883], [1883, 1894], [1894, 1905], [1905, 1920], [1920, 1936], [1936, 1943], [1943, 1952], [1952, 1963], [1963, 1983], [1983, 1990], [1990, 2000], [2000, 2016], [2016, 2033], [2033, 2042], [2042, 2044], [2044, 2047], [2047, 2053], [2053, 2059], [2059, 2067], [2067, 2075], [2075, 2083], [2083, 2097], [2097, 2113], [2113, 2127], [2127, 2135], [2135, 2149], [2149, 2168], [2168, 2186], [2186, 2201], [2201, 2219], [2219, 2238], [2238, 2255], [2255, 2269], [2269, 2285], [2285, 2301], [2301, 2320], [2320, 2337], [2337, 2351], [2351, 2366], [2366, 2382], [2382, 2393], [2393, 2406], [2406, 2424], [2424, 2446], [2446, 2463], [2463, 2481], [2481, 2491], [2491, 2508], [2508, 2522], [2522, 2535], [2535, 2552], [2552, 2568], [2568, 2583], [2583, 2595], [2595, 2612], [2612, 2627], [2627, 2641], [2641, 2658], [2658, 2668], [2668, 2683], [2683, 2697], [2697, 2711], [2711, 2727], [2727, 2741], [2741, 2756], [2756, 2769], [2769, 2784], [2784, 2788], [2788, 2794], [2794, 2797], [2797, 2799], [2799, 2801], [2801, 2804], [2804, 2806], [2806, 2808], [2808, 2810], [2810, 2812], [2812, 2814], [2814, 2827], [2827, 2847], [2847, 2848], [2848, 2865], [2865, 2886], [2886, 2901], [2901, 2906], [2906, 2922], [2922, 2933], [2933, 2945], [2945, 2948], [2948, 2963], [2963, 2980], [2980, 2995], [2995, 3010], [3010, 3023], [3023, 3039], [3039, 3058], [3058, 3073], [3073, 3077], [3077, 3093], [3093, 3111], [3111, 3124], [3124, 3141], [3141, 3158], [3158, 3172], [3172, 3189], [3189, 3206], [3206, 3220], [3220, 3223], [3223, 3236], [3236, 3253], [3253, 3267], [3267, 3284], [3284, 3298], [3298, 3312], [3312, 3330], [3330, 3347], [3347, 3361], [3361, 3376], [3376, 3395], [3395, 3409], [3409, 3426], [3426, 3445], [3445, 3463], [3463, 3482], [3482, 3499], [3499, 3517], [3517, 3534], [3534, 3551], [3551, 3556], [3556, 3574], [3574, 3590], [3590, 3609], [3609, 3625], [3625, 3637], [3637, 3650], [3650, 3664], [3664, 3681], [3681, 3694], [3694, 3707], [3707, 3720], [3720, 3737], [3737, 3754], [3754, 3763], [3763, 3777], [3777, 3795], [3795, 3810], [3810, 3825], [3825, 3841], [3841, 3859], [3859, 3861], [3861, 3873], [3873, 3885], [3885, 3898], [3898, 3913], [3913, 3927], [3927, 3945], [3945, 3961], [3961, 3976], [3976, 3990], [3990, 4008], [4008, 4023], [4023, 4026], [4026, 4040], [4040, 4053], [4053, 4067], [4067, 4083], [4083, 4103], [4103, 4119], [4119, 4132], [4132, 4147], [4147, 4161], [4161, 4171], [4171, 4180], [4180, 4186], [4186, 4188], [4188, 4190], [4190, 4195], [4195, 4198], [4198, 4200], [4200, 4201], [4201, 4203], [4203, 4216], [4216, 4231], [4231, 4247], [4247, 4258], [4258, 4276], [4276, 4292], [4292, 4310], [4310, 4325], [4325, 4344], [4344, 4362], [4362, 4380], [4380, 4393], [4393, 4407], [4407, 4423], [4423, 4435], [4435, 4441], [4441, 4456], [4456, 4474], [4474, 4487], [4487, 4505], [4505, 4522], [4522, 4523], [4523, 4535], [4535, 4555], [4555, 4571], [4571, 4586], [4586, 4600], [4600, 4617], [4617, 4631], [4631, 4647], [4647, 4660], [4660, 4662], [4662, 4664], [4664, 4666], [4666, 4668], [4668, 4671], [4671, 4686], [4686, 4700], [4700, 4706], [4706, 4721], [4721, 4738], [4738, 4755], [4755, 4769], [4769, 4781], [4781, 4798], [4798, 4816], [4816, 4832], [4832, 4848], [4848, 4862], [4862, 4876], [4876, 4891], [4891, 4906], [4906, 4915], [4915, 4918], [4918, 4920], [4920, 4922], [4922, 4924], [4924, 4939], [4939, 4958], [4958, 4974], [4974, 4990], [4990, 5005], [5005, 5023], [5023, 5040], [5040, 5055], [5055, 5065], [5065, 5076], [5076, 5077], [5077, 5092], [5092, 5105], [5105, 5123], [5123, 5126], [5126, 5140], [5140, 5156], [5156, 5170], [5170, 5183], [5183, 5193], [5193, 5194], [5194, 5195], [5195, 5196], [5196, 5197], [5197, 5198], [5198, 5199], [5199, 5200], [5200, 5201], [5201, 5206], [5206, 5220], [5220, 5226], [5226, 5238], [5238, 5251], [5251, 5267], [5267, 5281], [5281, 5296], [5296, 5311], [5311, 5323], [5323, 5341], [5341, 5358], [5358, 5374], [5374, 5386], [5386, 5401], [5401, 5416], [5416, 5433], [5433, 5448], [5448, 5455], [5455, 5458], [5458, 5472], [5472, 5473], [5473, 5488], [5488, 5501], [5501, 5502], [5502, 5503], [5503, 5504], [5504, 5505], [5505, 5506], [5506, 5507], [5507, 5508], [5508, 5509], [5509, 5510], [5510, 5511], [5511, 5512], [5512, 5513], [5513, 5514], [5514, 5515], [5515, 5516], [5516, 5517], [5517, 5532], [5532, 5535], [5535, 5552], [5552, 5561], [5561, 5579], [5579, 5586], [5586, 5603], [5603, 5615], [5615, 5630], [5630, 5639], [5639, 5653], [5653, 5657], [5657, 5674], [5674, 5677], [5677, 5693], [5693, 5699], [5699, 5716], [5716, 5719], [5719, 5735], [5735, 5739], [5739, 5756], [5756, 5761], [5761, 5779], [5779, 5782], [5782, 5796], [5796, 5798], [5798, 5814], [5814, 5823], [5823, 5837], [5837, 5843], [5843, 5844], [5844, 5845], [5845, 5846], [5846, 5847], [5847, 5848], [5848, 5849], [5849, 5850], [5850, 5851], [5851, 5852], [5852, 5853], [5853, 5854], [5854, 5855], [5855, 5856], [5856, 5857], [5857, 5858], [5858, 5859], [5859, 5860], [5860, 5878], [5878, 5886], [5886, 5902], [5902, 5905], [5905, 5923], [5923, 5936], [5936, 5955], [5955, 5966], [5966, 5985], [5985, 5993], [5993, 6011], [6011, 6014], [6014, 6029], [6029, 6033], [6033, 6047], [6047, 6050], [6050, 6069], [6069, 6074], [6074, 6089], [6089, 6095], [6095, 6110], [6110, 6111], [6111, 6126], [6126, 6135], [6135, 6152], [6152, 6161], [6161, 6178], [6178, 6181], [6181, 6195], [6195, 6204], [6204, 6216], [6216, 6217], [6217, 6218]], "positions": [[709, 462, 1841, 513], [778, 545, 1770, 610], [786, 798, 1773, 835], [891, 844, 1658, 881], [958, 887, 1591, 928], [1182, 1010, 1367, 1045], [600, 1112, 1948, 1149], [600, 1157, 1950, 1194], [600, 1203, 1948, 1240], [600, 1249, 1948, 1286], [600, 1294, 1276, 1331], [600, 1347, 1948, 1384], [600, 1393, 1950, 1430], [600, 1439, 1949, 1476], [600, 1484, 1948, 1521], [600, 1530, 1949, 1567], [600, 1576, 1837, 1613], [600, 1629, 1948, 1658], [600, 1674, 1950, 1711], [601, 1720, 1949, 1757], [600, 1766, 823, 1794], [453, 1877, 794, 1912], [451, 1958, 2099, 1995], [451, 2004, 2099, 2041], [451, 2050, 2099, 2087], [451, 2095, 2099, 2132], [450, 2141, 1955, 2178], [451, 2211, 2098, 2248], [452, 2257, 2099, 2294], [452, 2303, 2098, 2340], [451, 2348, 2099, 2385], [452, 2394, 2099, 2431], [452, 2440, 2099, 2477], [451, 2485, 2099, 2522], [451, 2531, 2097, 2568], [452, 2577, 2099, 2614], [451, 2622, 2099, 2659], [451, 2668, 2099, 2705], [451, 2714, 2097, 2751], [451, 2759, 1471, 2796], [451, 2830, 2099, 2867], [450, 2876, 2099, 2913], [452, 2921, 2099, 2958], [450, 2967, 2099, 3004], [451, 3013, 2100, 3050], [451, 354, 2099, 391], [451, 400, 2098, 437], [455, 445, 2100, 482], [451, 491, 2099, 528], [452, 537, 1915, 574], [453, 606, 781, 636], [451, 678, 2097, 715], [451, 724, 2099, 761], [450, 769, 2098, 806], [451, 815, 2097, 852], [451, 861, 2097, 898], [452, 906, 2102, 943], [451, 952, 2098, 989], [451, 998, 2099, 1035], [451, 1043, 1563, 1080], [451, 1114, 2099, 1151], [451, 1159, 2098, 1196], [451, 1205, 2099, 1242], [451, 1251, 2099, 1288], [451, 1296, 2097, 1333], [452, 1342, 2102, 1379], [452, 1388, 2099, 1425], [450, 1433, 2099, 1470], [450, 1479, 1807, 1516], [451, 1550, 2099, 1587], [451, 1595, 2099, 1632], [451, 1641, 2097, 1678], [451, 1687, 2099, 1724], [451, 1732, 2099, 1769], [451, 1778, 2096, 1815], [451, 1824, 2098, 1861], [451, 1869, 2099, 1906], [451, 1915, 2099, 1952], [451, 1961, 2096, 1998], [452, 2006, 2096, 2043], [451, 2052, 2102, 2089], [452, 2098, 2097, 2135], [450, 2143, 2099, 2180], [451, 2189, 2098, 2226], [451, 2232, 2099, 2269], [451, 2280, 1111, 2317], [451, 2351, 2099, 2388], [451, 2396, 2099, 2433], [451, 2442, 2099, 2479], [451, 2488, 2096, 2525], [451, 2533, 2097, 2570], [450, 2579, 1004, 2616], [451, 2656, 1499, 2700], [451, 2737, 2099, 2774], [451, 2783, 2099, 2820], [451, 2828, 2099, 2865], [451, 2874, 2097, 2911], [451, 2920, 2097, 2957], [452, 2965, 2099, 3002], [452, 3011, 2028, 3048], [823, 353, 1691, 399], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [999, 510, 1523, 533], [0, 0, 2550, 3300], [1133, 605, 1718, 651], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [0, 0, 2550, 3300], [785, 789, 1069, 821], [784, 820, 926, 845], [769, 869, 1780, 907], [451, 939, 2098, 977], [451, 986, 2099, 1023], [452, 1032, 2099, 1069], [451, 1077, 2099, 1114], [451, 1123, 2097, 1160], [0, 0, 2550, 3300], [451, 1214, 2099, 1251], [451, 1260, 2089, 1297], [451, 1337, 999, 1381], [451, 1418, 2100, 1455], [452, 1463, 2097, 1500], [451, 1509, 2099, 1546], [451, 1555, 2099, 1592], [451, 1600, 2099, 1637], [451, 1646, 1171, 1683], [608, 1976, 1942, 2009], [451, 2034, 2098, 2072], [451, 2081, 2097, 2118], [452, 2125, 2098, 2163], [451, 2171, 2098, 2209], [450, 2218, 2036, 2255], [451, 2336, 1066, 2374], [451, 2406, 2096, 2444], [450, 2450, 2100, 2491], [451, 2496, 2099, 2537], [450, 2539, 2099, 2583], [451, 2590, 2099, 2627], [449, 2631, 2099, 2674], [450, 2680, 2099, 2718], [450, 2723, 2097, 2770], [451, 2779, 581, 2807], [731, 2836, 2098, 2880], [731, 2896, 1816, 2945], [451, 2964, 2099, 3005], [451, 3013, 1395, 3050], [451, 353, 2098, 391], [452, 400, 2099, 437], [451, 445, 2099, 482], [452, 491, 1045, 528], [741, 563, 2098, 608], [741, 624, 1806, 673], [451, 707, 2099, 748], [451, 756, 1224, 793], [830, 828, 1716, 869], [451, 903, 2098, 944], [451, 949, 2097, 990], [451, 997, 1324, 1036], [630, 1176, 924, 1211], [474, 1202, 948, 1239], [474, 1248, 1710, 1359], [474, 1319, 1143, 1374], [452, 1404, 2076, 1457], [454, 1431, 2051, 1463], [512, 1432, 2027, 1500], [451, 1498, 2098, 1566], [451, 1575, 2099, 1612], [451, 1621, 2098, 1658], [450, 1666, 1203, 1695], [450, 1764, 2099, 1802], [450, 1811, 2099, 1848], [450, 1857, 2099, 1894], [450, 1902, 2099, 1939], [450, 1945, 2098, 1986], [449, 1991, 2097, 2032], [451, 2039, 1923, 2076], [450, 2109, 2097, 2147], [451, 2156, 2099, 2193], [450, 2201, 2099, 2238], [450, 2247, 2099, 2284], [450, 2293, 2099, 2330], [449, 2338, 2099, 2375], [450, 2384, 2099, 2421], [450, 2430, 2100, 2467], [451, 2475, 1609, 2512], [449, 2545, 2098, 2583], [450, 2587, 2099, 2634], [450, 2643, 2098, 2680], [450, 2689, 2099, 2726], [450, 2734, 1885, 2771], [450, 2804, 1855, 2842], [450, 2876, 2098, 2913], [450, 2921, 2098, 2958], [450, 2967, 2099, 3004], [450, 3013, 2099, 3050], [451, 354, 2099, 391], [451, 400, 2099, 437], [451, 445, 2097, 482], [451, 491, 2099, 528], [450, 537, 2098, 574], [451, 582, 2096, 619], [451, 628, 2096, 665], [451, 674, 1904, 711], [451, 744, 2096, 781], [451, 790, 2099, 827], [451, 836, 2097, 873], [451, 881, 2098, 918], [452, 927, 2099, 964], [450, 973, 2099, 1010], [451, 1018, 2100, 1055], [451, 1064, 2099, 1101], [451, 1110, 921, 1138], [451, 1179, 1292, 1209], [453, 1326, 616, 1346], [454, 1357, 616, 1377], [453, 1387, 631, 1413], [453, 1474, 616, 1494], [453, 1505, 585, 1525], [453, 1535, 632, 1561], [589, 1578, 648, 1591], [879, 1669, 1132, 1694], [874, 1700, 1149, 1720], [451, 1750, 2099, 1788], [0, 0, 2550, 3300], [451, 1842, 586, 1870], [451, 1937, 2099, 1974], [451, 1983, 2097, 2020], [451, 2028, 2099, 2066], [451, 2074, 1016, 2111], [451, 2145, 2098, 2182], [451, 2191, 2096, 2228], [451, 2236, 1945, 2273], [451, 2313, 936, 2357], [451, 2394, 2099, 2431], [451, 2440, 2099, 2477], [452, 2485, 2097, 2522], [451, 2531, 2100, 2568], [451, 2577, 2099, 2614], [451, 2622, 2099, 2659], [451, 2668, 2099, 2705], [451, 2714, 2099, 2751], [451, 2759, 887, 2796], [451, 2830, 2099, 2867], [451, 2876, 2097, 2913], [451, 2921, 2099, 2958], [452, 2967, 2099, 3004], [452, 3013, 2098, 3050], [451, 354, 2099, 391], [451, 400, 2099, 437], [451, 445, 2102, 482], [451, 491, 2079, 528], [451, 568, 1014, 612], [452, 648, 2098, 686], [451, 695, 2099, 732], [451, 741, 2098, 778], [450, 786, 2099, 823], [452, 832, 2097, 869], [451, 878, 2036, 915], [451, 947, 2099, 985], [451, 994, 2099, 1031], [451, 1039, 2099, 1076], [451, 1085, 2099, 1122], [451, 1131, 2097, 1168], [450, 1176, 2097, 1213], [447, 1222, 2099, 1259], [451, 1268, 2096, 1305], [451, 1313, 2097, 1350], [451, 1359, 2099, 1396], [451, 1399, 2097, 1442], [451, 1450, 2099, 1487], [451, 1489, 2099, 1533], [452, 1536, 2099, 1579], [451, 1587, 1058, 1624], [451, 1657, 2098, 1695], [451, 1704, 2099, 1741], [451, 1749, 2099, 1786], [451, 1795, 2096, 1832], [451, 1864, 2099, 1902], [452, 1911, 2096, 1948], [451, 1954, 2097, 1994], [450, 2002, 2097, 2039], [452, 2048, 1729, 2085], [451, 2118, 2097, 2156], [450, 2164, 2097, 2201], [451, 2210, 2099, 2247], [451, 2256, 2097, 2293], [451, 2301, 1528, 2338], [451, 2371, 2098, 2409], [451, 2418, 2099, 2455], [452, 2463, 2099, 2500], [451, 2509, 2099, 2546], [450, 2552, 2099, 2593], [450, 2600, 2096, 2637], [451, 2677, 756, 2712], [451, 2757, 2099, 2795], [451, 2804, 2099, 2841], [451, 2843, 2095, 2887], [452, 2895, 2099, 2932], [506, 2967, 2097, 3007], [451, 3015, 1894, 3049], [451, 354, 2099, 391], [451, 400, 2100, 437], [451, 445, 2099, 482], [452, 491, 2099, 528], [451, 537, 2099, 574], [451, 582, 874, 611], [451, 652, 2098, 690], [451, 699, 2099, 736], [451, 744, 2099, 781], [451, 790, 2098, 827], [451, 836, 2099, 873], [450, 881, 2100, 918], [450, 927, 2097, 964], [450, 973, 2099, 1010], [450, 1018, 2100, 1055], [450, 1064, 1348, 1101], [744, 1151, 1805, 1189], [621, 1213, 1821, 1251], [1863, 1265, 2088, 1287], [1856, 1311, 2042, 1328], [469, 1268, 1459, 1319], [1314, 1392, 1881, 1414], [1314, 1436, 1423, 1458], [1194, 1479, 1326, 1509], [1314, 1522, 1423, 1544], [451, 1638, 2099, 1676], [451, 1684, 2099, 1721], [450, 1727, 2099, 1768], [451, 1776, 2097, 1813], [451, 1821, 2099, 1858], [449, 1867, 2099, 1904], [450, 1913, 2099, 1950], [450, 1958, 2097, 1995], [451, 2004, 2097, 2041], [451, 2050, 2097, 2087], [449, 2095, 2099, 2132], [450, 2141, 2097, 2178], [450, 2187, 2099, 2224], [450, 2232, 2099, 2269], [450, 2278, 2099, 2315], [450, 2324, 1196, 2361], [450, 2394, 2099, 2431], [450, 2440, 2099, 2475], [451, 2482, 2099, 2522], [451, 2528, 2099, 2568], [450, 2577, 2099, 2614], [450, 2631, 579, 2650], [450, 2692, 2098, 2730], [450, 2739, 2099, 2776], [450, 2784, 2099, 2821], [451, 2830, 2099, 2867], [451, 2876, 2099, 2913], [452, 2921, 2099, 2958], [451, 2967, 2099, 3004], [451, 3013, 2099, 3050], [486, 344, 2063, 382], [762, 412, 976, 442], [762, 460, 914, 485], [925, 498, 1090, 525], [762, 546, 914, 571], [804, 584, 1074, 614], [450, 657, 2100, 694], [451, 703, 2099, 740], [451, 748, 1043, 785], [451, 819, 2100, 856], [451, 864, 2096, 901], [451, 907, 2097, 947], [452, 956, 2065, 993], [451, 1025, 2099, 1063], [451, 1072, 2102, 1109], [451, 1118, 2099, 1155], [451, 1163, 2100, 1200], [452, 1209, 2098, 1246], [451, 1252, 2100, 1292], [452, 1300, 2099, 1337], [450, 1346, 2099, 1383], [450, 1392, 1929, 1429], [739, 1486, 1810, 1524], [663, 1554, 1320, 1584], [937, 1602, 1622, 1627], [937, 1645, 1622, 1670], [937, 1688, 1622, 1713], [452, 1850, 2098, 1888], [449, 1896, 2099, 1933], [451, 1942, 2099, 1979], [450, 1987, 2099, 2024], [449, 2033, 2099, 2070], [450, 2079, 2097, 2116], [451, 2124, 2099, 2161], [450, 2170, 2099, 2207], [450, 2216, 1557, 2253], [652, 2310, 1896, 2348], [780, 2421, 943, 2451], [452, 2875, 2098, 2913], [452, 2918, 2099, 2958], [451, 2967, 2099, 3004], [451, 3013, 596, 3050], [451, 354, 2099, 391], [449, 400, 2097, 437], [449, 445, 2097, 482], [450, 491, 2099, 528], [451, 537, 1618, 574], [630, 675, 738, 712], [642, 710, 738, 781], [636, 914, 737, 973], [615, 1005, 622, 1017], [648, 1290, 679, 1301], [723, 1289, 737, 1302], [644, 1350, 738, 1549], [611, 1538, 643, 1549], [735, 1895, 1926, 2020], [577, 2037, 1971, 2075], [451, 2197, 1466, 2241], [451, 2278, 2097, 2315], [452, 2324, 2099, 2361], [451, 2369, 2099, 2406], [452, 2415, 2097, 2452], [452, 2460, 2099, 2497], [452, 2506, 2099, 2543], [450, 2552, 1771, 2589], [451, 2622, 2099, 2659], [451, 2668, 2097, 2705], [452, 2714, 1983, 2751], [451, 2784, 2097, 2821], [451, 2830, 2099, 2867], [451, 2876, 2098, 2913], [451, 2921, 2099, 2958], [452, 2967, 2100, 3004], [451, 3013, 1370, 3050], [618, 1064, 1872, 1242], [601, 1181, 1948, 1296], [450, 1325, 860, 1369], [451, 1406, 2099, 1443], [451, 1451, 1741, 1488], [451, 1528, 680, 1563], [471, 1609, 508, 1640], [471, 1707, 508, 1738], [471, 1804, 508, 1835], [471, 1902, 508, 1933], [471, 1999, 508, 2030], [471, 2096, 508, 2128], [471, 2194, 508, 2225], [471, 2292, 508, 2323], [471, 2389, 508, 2420], [453, 2487, 508, 2518], [452, 2584, 508, 2615], [453, 2682, 508, 2713], [452, 2779, 508, 2810], [453, 2877, 508, 2908], [452, 2974, 508, 3005], [534, 1609, 2099, 1642], [534, 1651, 1595, 1683], [534, 1706, 2100, 1740], [533, 1747, 1368, 1781], [534, 1803, 2099, 1837], [533, 1846, 1237, 1876], [534, 1901, 2098, 1935], [533, 1942, 1882, 1976], [534, 1998, 2098, 2032], [533, 2040, 1465, 2074], [534, 2096, 2098, 2130], [533, 2137, 1021, 2168], [533, 2193, 2097, 2227], [532, 2235, 858, 2269], [533, 2291, 2097, 2325], [533, 2332, 1102, 2366], [533, 2388, 2098, 2422], [533, 2431, 961, 2463], [533, 2486, 2095, 2520], [534, 2527, 1008, 2561], [534, 2583, 2099, 2617], [532, 2626, 977, 2659], [535, 2681, 2101, 2715], [532, 2723, 959, 2755], [534, 2778, 2091, 2812], [533, 2821, 1059, 2853], [534, 2877, 2098, 2910], [533, 2918, 1507, 2948], [534, 2974, 2099, 3007], [533, 3015, 1193, 3049], [1259, 3137, 1295, 3166], [453, 356, 508, 388], [452, 457, 508, 488], [452, 556, 508, 587], [453, 656, 508, 687], [453, 756, 508, 787], [452, 855, 508, 886], [452, 955, 508, 986], [452, 1054, 508, 1085], [452, 1154, 508, 1185], [452, 1254, 508, 1285], [452, 1352, 508, 1384], [453, 1453, 508, 1484], [453, 1553, 508, 1584], [452, 1652, 508, 1683], [453, 1752, 508, 1783], [453, 1851, 508, 1882], [534, 356, 2099, 390], [533, 398, 1437, 432], [534, 456, 2099, 490], [532, 498, 816, 528], [534, 555, 2098, 589], [533, 597, 2026, 631], [534, 655, 2098, 689], [533, 697, 1955, 730], [533, 755, 2096, 789], [533, 796, 1581, 830], [533, 855, 2097, 888], [532, 897, 858, 930], [533, 954, 2097, 988], [533, 996, 858, 1026], [534, 1053, 2097, 1087], [533, 1096, 752, 1126], [534, 1153, 2099, 1184], [533, 1195, 1104, 1226], [534, 1253, 2097, 1287], [533, 1295, 1102, 1328], [534, 1353, 2097, 1386], [533, 1395, 614, 1421], [534, 1452, 2098, 1486], [530, 1495, 1410, 1528], [534, 1552, 2098, 1586], [533, 1593, 1408, 1627], [534, 1651, 2097, 1685], [532, 1693, 895, 1727], [534, 1751, 2099, 1785], [533, 1793, 1447, 1826], [533, 1850, 2097, 1884], [533, 1893, 614, 1919], [1259, 3137, 1291, 3165]]}}}}]}
